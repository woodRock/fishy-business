{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woodRock/fishy-business/blob/main/Part.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOF5V8spkFO9",
        "outputId": "5ec4b4a0-13aa-4a03-8910-cf79cd2b90c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: skfeature-chappers in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from skfeature-chappers) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from skfeature-chappers) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from skfeature-chappers) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->skfeature-chappers) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->skfeature-chappers) (2022.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->skfeature-chappers) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->skfeature-chappers) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->skfeature-chappers) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->skfeature-chappers) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install skfeature-chappers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0MTzt4gjyr-"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9HnqXEN83Ku"
      },
      "outputs": [],
      "source": [
        "run = 1\n",
        "seed = 1617 * run\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ao4c5MMgkVjn"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "def load_data(dataset=\"Fish\"):\n",
        "    folder = '' # folder = '../data/matlab/'\n",
        "    mat = scipy.io.loadmat(folder + dataset + '.mat')\n",
        "    X = mat['X']\n",
        "    X = X.astype(float)\n",
        "    y = mat['Y']\n",
        "    y = y[:, 0]\n",
        "    return X,y \n",
        "\n",
        "def get_labels(y):\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    le.fit(y)\n",
        "    y_ = le.transform(y)\n",
        "    labels = le.inverse_transform(np.unique(y_))\n",
        "    return y_, labels\n",
        "\n",
        "dataset = \"Part\"\n",
        "X,y = load_data(dataset=dataset)\n",
        "y_, labels = get_labels(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-p57D5p3Rxu"
      },
      "outputs": [],
      "source": [
        "inc = 50\n",
        "no_features = X.shape[1] + inc\n",
        "j = np.arange(inc,no_features,inc) # [50,4800]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixgnotRydOaz"
      },
      "outputs": [],
      "source": [
        "from skfeature.function.similarity_based import reliefF\n",
        "from skfeature.function.information_theoretical_based import MRMR\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.svm import LinearSVC as svm\n",
        "\n",
        "methods = { \"reliefF\" : reliefF.reliefF, \"mrmr\": MRMR.mrmr, \"chi2\": chi2}\n",
        "results = { \"reliefF\" : [], \"mrmr\": [], \"chi2\": [], \"pso\": []}\n",
        "penalty = 'l1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anadECrYde-L"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "def normalize(X_train, X_test):\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaler = scaler.fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    return X_train, X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QK01mdPZeX1"
      },
      "outputs": [],
      "source": [
        "from Problem import FeatureSelection\n",
        "from PSO import Swarm\n",
        "\n",
        "def pso(X,y):\n",
        "    prob = FeatureSelection(minimized=True, X=X, y=y)\n",
        "    pop_size = 30\n",
        "    n_iterations = 100\n",
        "    no_fea = X.shape[1]\n",
        "    swarm = Swarm(n_particle=pop_size, length=no_fea, n_iterations=n_iterations,\n",
        "                        max_pos=1.0, min_pos=0.0, max_vel=0.2, min_vel=-0.2,\n",
        "                        problem=prob)\n",
        "    best_sol, best_fit = swarm.iterate()\n",
        "    sel_fea = np.where(best_sol > prob.threshold)[0]\n",
        "    return sel_fea"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjJCiAYpcrH7",
        "outputId": "c036a3fe-b511-4dc4-efa8-38e568e9be6e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 0, fold 1 \n",
            "Run 0, fold 2 \n",
            "Run 0, fold 3 \n",
            "Run 0, fold 4 \n",
            "Run 0, fold 5 \n",
            "Run 0, fold 6 \n",
            "Run 0, fold 7 \n",
            "Run 0, fold 8 \n",
            "Run 0, fold 9 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/15 [1:01:29<14:20:58, 3689.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 0, fold 10 \n",
            "Run 1, fold 1 \n",
            "Run 1, fold 2 \n",
            "Run 1, fold 3 \n",
            "Run 1, fold 4 \n",
            "Run 1, fold 5 \n",
            "Run 1, fold 6 \n",
            "Run 1, fold 7 \n",
            "Run 1, fold 8 \n",
            "Run 1, fold 9 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 2/15 [2:00:38<13:01:31, 3607.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 1, fold 10 \n",
            "Run 2, fold 1 \n",
            "Run 2, fold 2 \n",
            "Run 2, fold 3 \n",
            "Run 2, fold 4 \n",
            "Run 2, fold 5 \n",
            "Run 2, fold 6 \n",
            "Run 2, fold 7 \n",
            "Run 2, fold 8 \n",
            "Run 2, fold 9 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 3/15 [3:00:39<12:00:51, 3604.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 2, fold 10 \n",
            "Run 3, fold 1 \n",
            "Run 3, fold 2 \n",
            "Run 3, fold 3 \n",
            "Run 3, fold 4 \n",
            "Run 3, fold 5 \n",
            "Run 3, fold 6 \n",
            "Run 3, fold 7 \n",
            "Run 3, fold 8 \n",
            "Run 3, fold 9 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 4/15 [4:01:14<11:03:00, 3616.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 3, fold 10 \n",
            "Run 4, fold 1 \n",
            "Run 4, fold 2 \n",
            "Run 4, fold 3 \n",
            "Run 4, fold 4 \n",
            "Run 4, fold 5 \n",
            "Run 4, fold 6 \n",
            "Run 4, fold 7 \n",
            "Run 4, fold 8 \n",
            "Run 4, fold 9 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 5/15 [5:01:18<10:01:58, 3611.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 4, fold 10 \n",
            "Run 5, fold 1 \n",
            "Run 5, fold 2 \n",
            "Run 5, fold 3 \n",
            "Run 5, fold 4 \n",
            "Run 5, fold 5 \n",
            "Run 5, fold 6 \n",
            "Run 5, fold 7 \n",
            "Run 5, fold 8 \n",
            "Run 5, fold 9 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 6/15 [6:00:15<8:57:58, 3586.48s/it] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 5, fold 10 \n",
            "Run 6, fold 1 \n",
            "Run 6, fold 2 \n",
            "Run 6, fold 3 \n",
            "Run 6, fold 4 \n",
            "Run 6, fold 5 \n",
            "Run 6, fold 6 \n",
            "Run 6, fold 7 \n",
            "Run 6, fold 8 \n",
            "Run 6, fold 9 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 7/15 [6:59:46<7:57:30, 3581.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 6, fold 10 \n",
            "Run 7, fold 1 \n",
            "Run 7, fold 2 \n",
            "Run 7, fold 3 \n",
            "Run 7, fold 4 \n",
            "Run 7, fold 5 \n",
            "Run 7, fold 6 \n",
            "Run 7, fold 7 \n",
            "Run 7, fold 8 \n",
            "Run 7, fold 9 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 8/15 [7:59:57<6:58:55, 3590.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 7, fold 10 \n",
            "Run 8, fold 1 \n",
            "Run 8, fold 2 \n",
            "Run 8, fold 3 \n",
            "Run 8, fold 4 \n",
            "Run 8, fold 5 \n",
            "Run 8, fold 6 \n",
            "Run 8, fold 7 \n",
            "Run 8, fold 8 \n",
            "Run 8, fold 9 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 9/15 [8:57:26<5:54:38, 3546.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 8, fold 10 \n",
            "Run 9, fold 1 \n",
            "Run 9, fold 2 \n",
            "Run 9, fold 3 \n",
            "Run 9, fold 4 \n",
            "Run 9, fold 5 \n",
            "Run 9, fold 6 \n",
            "Run 9, fold 7 \n",
            "Run 9, fold 8 \n",
            "Run 9, fold 9 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 10/15 [9:57:30<4:57:01, 3564.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 9, fold 10 \n",
            "Run 10, fold 1 \n",
            "Run 10, fold 2 \n",
            "Run 10, fold 3 \n",
            "Run 10, fold 4 \n",
            "Run 10, fold 5 \n",
            "Run 10, fold 6 \n",
            "Run 10, fold 7 \n",
            "Run 10, fold 8 \n",
            "Run 10, fold 9 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 11/15 [10:57:39<3:58:31, 3577.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 10, fold 10 \n",
            "Run 11, fold 1 \n",
            "Run 11, fold 2 \n",
            "Run 11, fold 3 \n",
            "Run 11, fold 4 \n",
            "Run 11, fold 5 \n",
            "Run 11, fold 6 \n",
            "Run 11, fold 7 \n",
            "Run 11, fold 8 \n",
            "Run 11, fold 9 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 12/15 [11:57:47<2:59:21, 3587.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 11, fold 10 \n",
            "Run 12, fold 1 \n",
            "Run 12, fold 2 \n",
            "Run 12, fold 3 \n",
            "Run 12, fold 4 \n",
            "Run 12, fold 5 \n",
            "Run 12, fold 6 \n",
            "Run 12, fold 7 \n",
            "Run 12, fold 8 \n",
            "Run 12, fold 9 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 13/15 [12:57:08<1:59:18, 3579.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 12, fold 10 \n",
            "Run 13, fold 1 \n",
            "Run 13, fold 2 \n",
            "Run 13, fold 3 \n",
            "Run 13, fold 4 \n",
            "Run 13, fold 5 \n",
            "Run 13, fold 6 \n",
            "Run 13, fold 7 \n",
            "Run 13, fold 8 \n",
            "Run 13, fold 9 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 14/15 [13:57:50<59:58, 3598.18s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 13, fold 10 \n",
            "Run 14, fold 1 \n",
            "Run 14, fold 2 \n",
            "Run 14, fold 3 \n",
            "Run 14, fold 4 \n",
            "Run 14, fold 5 \n",
            "Run 14, fold 6 \n",
            "Run 14, fold 7 \n",
            "Run 14, fold 8 \n",
            "Run 14, fold 9 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [14:56:33<00:00, 3586.26s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 14, fold 10 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "runs = 15\n",
        "name = \"pso\"\n",
        "folds = 10\n",
        "\n",
        "for k in tqdm(range(runs)):\n",
        "    train_accs = []\n",
        "    test_accs = []\n",
        "    skf = StratifiedKFold(n_splits=folds, random_state=1234, shuffle=True)\n",
        "\n",
        "    # DEBUG: Fold counter\n",
        "    f = 1\n",
        "\n",
        "    for train, test in skf.split(X, y):\n",
        "        X_train, X_test = (X[train], X[test])\n",
        "        y_train, y_test = y[train], y[test]\n",
        "        X_train, X_test = normalize(X_train, X_test)\n",
        "\n",
        "        sel_fea = pso(X_train, y_train)\n",
        "\n",
        "        # DEBUG: Measure progress.\n",
        "        print(f\"Run {k}, fold {f} \")\n",
        "\n",
        "        model = svm(penalty='l1', dual=False, tol=1e-3, max_iter=5_000)\n",
        "        model.fit(X_train[:, sel_fea], y_train)\n",
        "\n",
        "        y_predict = model.predict(X_train[:, sel_fea])\n",
        "        train_acc = balanced_accuracy_score(y_train, y_predict)\n",
        "        train_accs.append(train_acc)\n",
        "\n",
        "        y_predict = model.predict(X_test[:, sel_fea])\n",
        "        test_acc = balanced_accuracy_score(y_test, y_predict)\n",
        "        test_accs.append(test_acc)\n",
        "\n",
        "        # DEBUG: Increment fold counter\n",
        "        f += 1\n",
        "\n",
        "    no_fea = len(sel_fea)\n",
        "    results[name].append((no_fea, np.mean(train_accs), np.mean(test_accs)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RlFzQ0tAx6ar"
      },
      "outputs": [],
      "source": [
        "with open('results-pso-cloud.pkl', 'wb+') as f:\n",
        "    pickle.dump(results, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipKupS0pkkyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4446fa2-0c3c-4d17-e673-142eeb7bc53a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 8/96 [10:19<1:53:56, 77.69s/it]"
          ]
        }
      ],
      "source": [
        "for k in tqdm(j):\n",
        "    for name, fs_method in methods.items(): \n",
        "        if name == \"pso\":\n",
        "          continue\n",
        "\n",
        "        train_accs = []\n",
        "        test_accs = []\n",
        "        skf = StratifiedKFold(n_splits=folds, random_state=1234, shuffle=True)\n",
        "\n",
        "        for train, test in skf.split(X, y):\n",
        "            X_train, X_test = (X[train], X[test])\n",
        "            y_train, y_test = y[train], y[test]\n",
        "            X_train, X_test = normalize(X_train, X_test)\n",
        "\n",
        "            fs = SelectKBest(fs_method, k=k)\n",
        "            X_train = fs.fit_transform(X_train, y_train)\n",
        "            X_test = fs.transform(X_test)\n",
        "\n",
        "            model = svm(penalty='l1', dual=False, tol=1e-3, max_iter=5_000)\n",
        "            clf = model.fit(X_train, y_train)\n",
        "\n",
        "            y_predict = model.predict(X_train)\n",
        "            train_acc = balanced_accuracy_score(y_train, y_predict)\n",
        "            train_accs.append(train_acc)\n",
        "            y_predict = model.predict(X_test)\n",
        "            test_acc = balanced_accuracy_score(y_test, y_predict)\n",
        "            test_accs.append(test_acc)\n",
        "\n",
        "        no_fea = k \n",
        "        results[name].append((no_fea, np.mean(train_accs), np.mean(test_accs)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtXyU5eZx-6w"
      },
      "outputs": [],
      "source": [
        "with open('results-full-cloud.pkl', 'wb+') as f:\n",
        "    pickle.dump(results, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3fs1QSaMXPV"
      },
      "outputs": [],
      "source": [
        "for name, result in results.items():\n",
        "  k, train, test = zip(*result)\n",
        "  if name == \"pso\":\n",
        "    plt.scatter(k, train, label=name)\n",
        "  else:\n",
        "    plt.plot(k, train, label=name)\n",
        "\n",
        "plt.title(\"Train: Accuracy vs. No. Features\")\n",
        "plt.xlabel(\"No. Features\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.savefig(fname=f\"accuracy-features-{dataset}-train\", dpi=500)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-6dez8J6RO1"
      },
      "outputs": [],
      "source": [
        "for name, result in results.items():\n",
        "  k, train, test = zip(*result)\n",
        "  if name == \"pso\":\n",
        "    plt.scatter(k, test, label=name)\n",
        "  else:\n",
        "    plt.plot(k, test, label=name)\n",
        "\n",
        "plt.title(\"Test: Accuracy vs. No. Features\")\n",
        "plt.xlabel(\"No. Features\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.savefig(fname=f\"accuracy-features-{dataset}-test\", dpi=500)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "RzuEt1GBshGn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1263b63f-ba53-4880-b4af-c860bcfc48e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reliefF': [(50, 0.812469586315087, 0.5847222222222221), (100, 0.9155893685010833, 0.6527777777777778), (150, 0.9307986567918654, 0.6777777777777778), (200, 0.9489223465963705, 0.6888888888888889), (250, 0.9585619228912947, 0.7805555555555556), (300, 0.9720060455798996, 0.7583333333333333), (350, 0.9726293413559967, 0.773611111111111), (400, 0.9730705960077778, 0.773611111111111), (450, 0.9747890865972358, 0.7736111111111111), (500, 0.9782143163382552, 0.8027777777777778), (550, 0.9774904106143495, 0.7972222222222223), (600, 0.9795582594479029, 0.763888888888889), (650, 0.9795582594479029, 0.7847222222222222), (700, 0.9810218197824311, 0.7888888888888889), (750, 0.9810218197824311, 0.7888888888888889), (800, 0.9824366471734892, 0.7888888888888889), (850, 0.9857473432685657, 0.7916666666666667), (900, 0.9843325158775074, 0.7944444444444445), (950, 0.9839442243601836, 0.8125), (1000, 0.9839929573036533, 0.8263888888888887), (1050, 0.9840416902471232, 0.8055555555555556), (1100, 0.9839929573036533, 0.8097222222222221), (1150, 0.9836046657863295, 0.8097222222222221), (1200, 0.9839929573036535, 0.8180555555555555), (1250, 0.9848701502861095, 0.826388888888889), (1300, 0.9863337106206377, 0.8430555555555556), (1350, 0.9872109036030938, 0.8305555555555555), (1400, 0.989014022511476, 0.8388888888888888), (1450, 0.989014022511476, 0.8402777777777779), (1500, 0.989014022511476, 0.836111111111111), (1550, 0.98808809658555, 0.836111111111111), (1600, 0.9889652895680061, 0.836111111111111), (1650, 0.9871621706596241, 0.8444444444444444), (1700, 0.9889165566245364, 0.836111111111111), (1750, 0.9880393636420802, 0.8347222222222221), (1800, 0.988427655159404, 0.8291666666666666), (1850, 0.9878720996038484, 0.8305555555555555), (1900, 0.9869949066213921, 0.8305555555555555), (1950, 0.9875812739734642, 0.836111111111111), (2000, 0.9875812739734642, 0.8347222222222221), (2050, 0.9885071998993901, 0.825), (2100, 0.9911387788467586, 0.825), (2150, 0.9902615858643025, 0.8236111111111111), (2200, 0.9902615858643025, 0.8236111111111111), (2250, 0.9908171414198579, 0.8152777777777779), (2300, 0.99262026032824, 0.798611111111111), (2350, 0.99262026032824, 0.7888888888888889), (2400, 0.99262026032824, 0.7944444444444444), (2450, 0.9921134377161541, 0.8083333333333333), (2500, 0.9929906306986103, 0.7861111111111112), (2550, 0.9938678236810665, 0.7861111111111112), (2600, 0.9929418977551405, 0.8), (2650, 0.9924042633465383, 0.8097222222222221), (2700, 0.9915270703640822, 0.8041666666666666), (2750, 0.9933301892724643, 0.7958333333333334), (2800, 0.9933301892724643, 0.8013888888888889), (2850, 0.9930264729925172, 0.8263888888888887), (2900, 0.9944413003835754, 0.8263888888888887), (2950, 0.9944413003835754, 0.8263888888888887), (3000, 0.9944413003835754, 0.8097222222222221), (3050, 0.9944233792366222, 0.8069444444444445), (3100, 0.9944413003835754, 0.8125), (3150, 0.99388574482802, 0.8125), (3200, 0.9953005722190783, 0.8180555555555558), (3250, 0.9953005722190783, 0.8083333333333333), (3300, 0.9956888637364021, 0.8), (3350, 0.9956888637364021, 0.8083333333333333), (3400, 0.9962264981450041, 0.8041666666666666), (3450, 0.995349305162548, 0.8125), (3500, 0.9959048607181036, 0.8125), (3550, 0.9959048607181036, 0.798611111111111), (3600, 0.9959048607181036, 0.798611111111111), (3650, 0.9959048607181036, 0.8069444444444442), (3700, 0.9959048607181036, 0.8111111111111111), (3750, 0.9959048607181036, 0.8069444444444442), (3800, 0.9959048607181036, 0.8152777777777779), (3850, 0.9959048607181036, 0.8208333333333332), (3900, 0.995349305162548, 0.8180555555555558), (3950, 0.995349305162548, 0.8236111111111111), (4000, 0.995349305162548, 0.8097222222222221), (4050, 0.99588693957115, 0.8125), (4100, 0.9953493051625479, 0.8069444444444442), (4150, 0.9953493051625479, 0.8152777777777779), (4200, 0.9947937496069924, 0.8152777777777779), (4250, 0.9962264981450041, 0.8069444444444442), (4300, 0.9962264981450041, 0.7986111111111112), (4350, 0.9962264981450041, 0.7986111111111112), (4400, 0.9967820537005597, 0.7930555555555556), (4450, 0.9962264981450041, 0.7930555555555556), (4500, 0.9967820537005597, 0.7930555555555556), (4550, 0.9967820537005597, 0.8013888888888889), (4600, 0.9967820537005597, 0.7958333333333333), (4650, 0.9967820537005597, 0.8069444444444442), (4700, 0.9962264981450041, 0.8041666666666668), (4750, 0.9967820537005597, 0.8125), (4800, 0.9967820537005597, 0.7986111111111112)], 'mrmr': [(50, 0.7859168122326017, 0.576388888888889), (100, 0.898530147460538, 0.6249999999999999), (150, 0.9451949807722302, 0.6833333333333333), (200, 0.9467090992388106, 0.7638888888888888), (250, 0.9616326454781463, 0.8069444444444442), (300, 0.960441189320646, 0.7541666666666667), (350, 0.9716019520943121, 0.7583333333333332), (400, 0.9659805958362835, 0.7847222222222222), (450, 0.9716728363757227, 0.7777777777777778), (500, 0.9713330450597004, 0.773611111111111), (550, 0.9744895474267292, 0.7972222222222223), (600, 0.9786283891547051, 0.8319444444444445), (650, 0.9754062657458243, 0.7819444444444443), (700, 0.97987703863765, 0.8305555555555555), (750, 0.9817984028170785, 0.7916666666666666), (800, 0.9806385587624975, 0.8180555555555555), (850, 0.9834342576872288, 0.8069444444444445), (900, 0.9812818336162987, 0.8055555555555556), (950, 0.9854565176381815, 0.7763888888888889), (1000, 0.980316921335597, 0.7847222222222222), (1050, 0.9841083443375463, 0.8194444444444444), (1100, 0.981700936930139, 0.7777777777777778), (1150, 0.9856288121738037, 0.8208333333333334), (1200, 0.9835348676350375, 0.8111111111111111), (1250, 0.9864978305980003, 0.8013888888888889), (1300, 0.9837698718938107, 0.8208333333333332), (1350, 0.9849984279695654, 0.7902777777777779), (1400, 0.9856775451172736, 0.7930555555555555), (1450, 0.9903282399547255, 0.8125), (1500, 0.9914214299188833, 0.8694444444444445), (1550, 0.9909325284537509, 0.8152777777777779), (1600, 0.9870923725083319, 0.7736111111111111), (1650, 0.9861485254354525, 0.8125), (1700, 0.9882342954159593, 0.8027777777777778), (1750, 0.9867220021379612, 0.8097222222222221), (1800, 0.9909146073067975, 0.8416666666666666), (1850, 0.9904467710494875, 0.8111111111111111), (1900, 0.9934974533106962, 0.7986111111111112), (1950, 0.9926689932717098, 0.8180555555555553), (2000, 0.9882830283594292, 0.8277777777777778), (2050, 0.9885559328428599, 0.8333333333333333), (2100, 0.990112242973024, 0.8125), (2150, 0.9892837829340376, 0.836111111111111), (2200, 0.9906190655851097, 0.8388888888888889), (2250, 0.991809721436207, 0.836111111111111), (2300, 0.9934974533106962, 0.8027777777777777), (2350, 0.9900374143243414, 0.8111111111111111), (2400, 0.9926869144186631, 0.826388888888889), (2450, 0.9911875117902283, 0.825), (2500, 0.9935949191976358, 0.7819444444444444), (2550, 0.9948116707539458, 0.8319444444444445), (2600, 0.9933481104194177, 0.8444444444444447), (2650, 0.9939344777714897, 0.8458333333333334), (2700, 0.9947937496069924, 0.8208333333333332), (2750, 0.9953672263095014, 0.8138888888888889), (2800, 0.9930572847890335, 0.7888888888888889), (2850, 0.9959048607181036, 0.8333333333333333), (2900, 0.9924042633465385, 0.8208333333333334), (2950, 0.9944721121800917, 0.8208333333333332), (3000, 0.9930085518455638, 0.8013888888888889), (3050, 0.993952398918443, 0.8208333333333332), (3100, 0.9930393636420801, 0.8208333333333334), (3150, 0.9906677985285794, 0.8347222222222221), (3200, 0.9943746462931523, 0.8166666666666667), (3250, 0.9929906306986103, 0.8027777777777778), (3300, 0.994238194051437, 0.7958333333333333), (3350, 0.9945956737722442, 0.8125), (3400, 0.9945777526252909, 0.8208333333333332), (3450, 0.9947450166635227, 0.7958333333333333), (3500, 0.9944233792366219, 0.8055555555555556), (3550, 0.9933610010689808, 0.8069444444444445), (3600, 0.993378922215934, 0.8125), (3650, 0.9971216122744136, 0.7958333333333333), (3700, 0.9953672263095014, 0.8097222222222221), (3750, 0.9956709425894485, 0.8), (3800, 0.9939344777714897, 0.8180555555555558), (3850, 0.995349305162548, 0.8027777777777778), (3900, 0.9962264981450041, 0.8236111111111111), (3950, 0.9962264981450041, 0.8097222222222221), (4000, 0.9948116707539458, 0.8069444444444442), (4050, 0.9967820537005597, 0.8319444444444445), (4100, 0.9959048607181036, 0.826388888888889), (4150, 0.9962264981450041, 0.8208333333333332), (4200, 0.9962264981450041, 0.8041666666666666), (4250, 0.9967820537005597, 0.7986111111111112), (4300, 0.9944721121800919, 0.8152777777777777), (4350, 0.9962264981450041, 0.8013888888888889), (4400, 0.9967820537005597, 0.8097222222222221), (4450, 0.9962264981450041, 0.8069444444444442), (4500, 0.9967820537005597, 0.8013888888888889), (4550, 0.9967820537005597, 0.7986111111111112), (4600, 0.9967820537005597, 0.8013888888888889), (4650, 0.9962264981450041, 0.8125), (4700, 0.9967820537005597, 0.8041666666666668), (4750, 0.9967820537005597, 0.7930555555555555), (4800, 0.9967820537005597, 0.7986111111111112)], 'chi2': [(50, 0.7154292541389315, 0.4611111111111111), (100, 0.8141635818121384, 0.4569444444444445), (150, 0.8860081288264651, 0.49861111111111106), (200, 0.906022856914198, 0.5236111111111111), (250, 0.9280571214611962, 0.5513888888888889), (300, 0.9426398433359384, 0.5625), (350, 0.9530131781065568, 0.6208333333333333), (400, 0.9586066869683169, 0.6569444444444443), (450, 0.9620627285058525, 0.6263888888888889), (500, 0.96320465141348, 0.648611111111111), (550, 0.9669602321215225, 0.6666666666666665), (600, 0.9711220254938422, 0.7027777777777778), (650, 0.9722721229597291, 0.6986111111111112), (700, 0.9702003297589036, 0.7125000000000001), (750, 0.973312635613145, 0.7208333333333333), (800, 0.9760904133909227, 0.7541666666666667), (850, 0.9775758392396762, 0.7555555555555555), (900, 0.97822697424565, 0.7444444444444444), (950, 0.9814807628389971, 0.7486111111111111), (1000, 0.9814807628389971, 0.75), (1050, 0.9820363183945526, 0.75), (1100, 0.9809610495773484, 0.763888888888889), (1150, 0.9829801654674319, 0.7680555555555556), (1200, 0.9838573584498882, 0.7638888888888888), (1250, 0.9851886436521411, 0.7611111111111111), (1300, 0.9866701251336225, 0.8180555555555555), (1350, 0.9862818336162988, 0.8152777777777777), (1400, 0.9841391561340629, 0.8124999999999998), (1450, 0.9849984279695656, 0.8208333333333332), (1500, 0.9864132553606237, 0.8236111111111111), (1550, 0.9886046657863297, 0.8249999999999998), (1600, 0.9871898383952713, 0.8138888888888888), (1650, 0.9857262780607433, 0.8138888888888888), (1700, 0.9857262780607433, 0.8194444444444443), (1750, 0.9871411054518016, 0.8111111111111111), (1800, 0.9868015468779475, 0.8194444444444443), (1850, 0.9877274728038735, 0.8194444444444443), (1900, 0.9868502798214174, 0.8097222222222221), (1950, 0.9868502798214174, 0.8097222222222221), (2000, 0.9859730868389611, 0.8152777777777777), (2050, 0.9877762057473433, 0.8013888888888889), (2100, 0.9907473432685656, 0.8041666666666668), (2150, 0.9907473432685656, 0.7930555555555555), (2200, 0.9898214173426398, 0.7930555555555555), (2250, 0.9916245362510218, 0.7930555555555555), (2300, 0.9907473432685657, 0.7847222222222222), (2350, 0.9916245362510219, 0.7930555555555555), (2400, 0.9916245362510219, 0.7875), (2450, 0.9939344777714897, 0.7708333333333334), (2500, 0.9939344777714897, 0.7791666666666667), (2550, 0.9930572847890335, 0.7805555555555557), (2600, 0.9930572847890335, 0.7888888888888889), (2650, 0.9921800918065774, 0.788888888888889), (2700, 0.9944721121800917, 0.788888888888889), (2750, 0.9944721121800917, 0.7861111111111112), (2800, 0.9953493051625479, 0.7833333333333334), (2850, 0.9944721121800917, 0.7930555555555555), (2900, 0.9948116707539458, 0.7930555555555555), (2950, 0.9953493051625479, 0.7902777777777777), (3000, 0.9944721121800917, 0.7902777777777777), (3050, 0.9962264981450041, 0.7902777777777777), (3100, 0.9962264981450041, 0.7902777777777777), (3150, 0.9953493051625479, 0.7986111111111112), (3200, 0.9951153870338929, 0.7930555555555555), (3250, 0.9956709425894485, 0.7847222222222222), (3300, 0.9939165566245363, 0.7930555555555555), (3350, 0.9939165566245363, 0.7847222222222222), (3400, 0.9953493051625479, 0.7930555555555555), (3450, 0.9953493051625479, 0.8013888888888889), (3500, 0.9944721121800919, 0.8013888888888889), (3550, 0.9944721121800919, 0.8097222222222221), (3600, 0.9944721121800919, 0.8069444444444442), (3650, 0.9944721121800919, 0.8152777777777779), (3700, 0.9941504747531912, 0.8069444444444442), (3750, 0.9941504747531912, 0.8069444444444442), (3800, 0.9950276677356473, 0.7902777777777777), (3850, 0.9950276677356473, 0.7902777777777777), (3900, 0.9950276677356473, 0.798611111111111), (3950, 0.9950276677356473, 0.8069444444444442), (4000, 0.9959048607181036, 0.8069444444444442), (4050, 0.9941504747531912, 0.7986111111111112), (4100, 0.9959048607181036, 0.7986111111111112), (4150, 0.9950276677356473, 0.7986111111111112), (4200, 0.9950276677356473, 0.7986111111111112), (4250, 0.9950276677356473, 0.7986111111111112), (4300, 0.9950276677356473, 0.7930555555555555), (4350, 0.9950276677356473, 0.7986111111111112), (4400, 0.9950276677356473, 0.7986111111111112), (4450, 0.9950276677356473, 0.7986111111111112), (4500, 0.9959048607181036, 0.7986111111111112), (4550, 0.9959048607181036, 0.8041666666666668), (4600, 0.9959048607181036, 0.7986111111111112), (4650, 0.9967820537005597, 0.8041666666666668), (4700, 0.9967820537005597, 0.8041666666666668), (4750, 0.9962264981450041, 0.8041666666666668), (4800, 0.9967820537005597, 0.8041666666666668)], 'pso': [(1256, 0.9906190655851097, 0.8305555555555555), (1218, 0.9831157643211974, 0.7944444444444444), (1274, 0.985580079230334, 0.7986111111111112), (1236, 0.9888954914167138, 0.8125), (1261, 0.9853559076903728, 0.8013888888888889), (1220, 0.9856467333207573, 0.7972222222222223), (1170, 0.9862151795258758, 0.8180555555555555), (1223, 0.9858268880085518, 0.8208333333333334), (1186, 0.9849676161730491, 0.8069444444444442), (1302, 0.9846459787461486, 0.8013888888888889), (1184, 0.990112242973024, 0.7763888888888889), (1243, 0.9866732691944916, 0.8319444444444443), (1213, 0.9870923725083317, 0.8180555555555555), (1212, 0.9873492422813305, 0.8097222222222221), (1223, 0.9831465761177137, 0.8430555555555556)]}\n"
          ]
        }
      ],
      "source": [
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results['pso']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXBfU0aZ3RwT",
        "outputId": "ba69e818-e132-449e-ee1b-e6a818605113"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1256, 0.9906190655851097, 0.8305555555555555),\n",
              " (1218, 0.9831157643211974, 0.7944444444444444),\n",
              " (1274, 0.985580079230334, 0.7986111111111112),\n",
              " (1236, 0.9888954914167138, 0.8125),\n",
              " (1261, 0.9853559076903728, 0.8013888888888889),\n",
              " (1220, 0.9856467333207573, 0.7972222222222223),\n",
              " (1170, 0.9862151795258758, 0.8180555555555555),\n",
              " (1223, 0.9858268880085518, 0.8208333333333334),\n",
              " (1186, 0.9849676161730491, 0.8069444444444442),\n",
              " (1302, 0.9846459787461486, 0.8013888888888889),\n",
              " (1184, 0.990112242973024, 0.7763888888888889),\n",
              " (1243, 0.9866732691944916, 0.8319444444444443),\n",
              " (1213, 0.9870923725083317, 0.8180555555555555),\n",
              " (1212, 0.9873492422813305, 0.8097222222222221),\n",
              " (1223, 0.9831465761177137, 0.8430555555555556)]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uI3Kjkly5r78"
      },
      "outputs": [],
      "source": [
        "for method, result in results.items():\n",
        "    k, train, test = list(zip(*result))\n",
        "    best_k = np.argmax(test)\n",
        "    print(f\"{method} performed best at {k[best_k]} features, with {train[best_k]} training accuracy, and {test[best_k]} test accuracy.\")\n",
        "\n",
        "k, train, test = results['mrmr'][-1]\n",
        "print(f\"Full-dataset with {k} features, with {train} training accuracy, and {test} test accuracy.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OH2WH6qu8amG"
      },
      "outputs": [],
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "def show_results(results, label='Method'):\n",
        "    table = PrettyTable([label, 'Best K', 'Train', 'Test'])\n",
        "\n",
        "    for name, result in results.items():\n",
        "        k, train, test = list(zip(*result))\n",
        "        best_k = np.argmax(test)\n",
        "        vals = [k[best_k], train[best_k], test[best_k]]\n",
        "        row = ['%.4f' % elem if i != 0 else elem for i, elem in enumerate(vals) ]\n",
        "        table.add_row(np.concatenate([[name], row]))\n",
        "\n",
        "    k, train, test = results['mrmr'][-1]\n",
        "    vals = [k, train, test]\n",
        "    row = ['%.4f' % elem if i != 0 else elem for i, elem in enumerate(vals) ]\n",
        "    table.add_row(np.concatenate([['full'], row]))\n",
        "\n",
        "    print('\\n') # tqdm messses with table border.\n",
        "    print(table)\n",
        "\n",
        "show_results(results)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Fish-2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOTEqmzncg5T4kp1nRSJr/z",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}