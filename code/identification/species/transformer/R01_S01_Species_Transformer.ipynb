{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOaILdqufIc8cfzsyn9r548",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woodRock/fishy-business/blob/main/code/identification/species/transformer/R01_S01_Species_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "learning_rate = 1E-5 #@param {type:\"integer\"}\n",
        "batch_size = 64 # @param {type:\"integer\"}\n",
        "epochs = 100 # @param {type:\"integer\"}\n",
        "is_next_spectra = False # @param {type:\"boolean\"}\n",
        "is_masked_spectra = True # @param {type:\"boolean\"}"
      ],
      "metadata": {
        "id": "5ZOG3XjPWFOh"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXt9OBnbV8OE",
        "outputId": "8c733144-d7d1-4c97-be03-500854a40b16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[INFO] Reading the dataset.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.listdir('/content/drive/My Drive')\n",
        "\n",
        "path = ['drive', 'MyDrive', 'AI', 'fish', 'REIMS_data.xlsx']\n",
        "path = os.path.join(*path)\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "\n",
        "    def __init__(self, samples, labels):\n",
        "        self.samples = torch.tensor(samples.to_numpy(), dtype=torch.float32)\n",
        "        self.labels = torch.tensor([np.array(ys) for ys in labels], dtype=torch.float32)\n",
        "\n",
        "\n",
        "        # Normalize the features to be between in [0,1]\n",
        "        self.samples = F.normalize(self.samples, dim = 0)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "print(\"[INFO] Reading the dataset.\")\n",
        "raw = pd.read_excel(path)\n",
        "\n",
        "data = raw[~raw['m/z'].str.contains('HM')]\n",
        "data = data[~data['m/z'].str.contains('QC')]\n",
        "data = data[~data['m/z'].str.contains('HM')]\n",
        "X = data.drop('m/z', axis=1) # X contains only the features.\n",
        "# Onehot encoding for the class labels, e.g. [0,1] for Hoki, [1,0] for Mackeral.\n",
        "y = data['m/z'].apply(lambda x: [0,1] if 'H' in x else [1,0])\n",
        "y = np.array(y)\n",
        "\n",
        "# Evaluation parameters.\n",
        "train_split = 0.8\n",
        "val_split = 0.5 # 1/2 of 20%, validation and test, 10% and 10%, respectively.\n",
        "\n",
        "# Step 2: Split your dataset into training, validation, and testing sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, stratify=y, test_size=(1-train_split))\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=val_split)\n",
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "val_dataset = CustomDataset(X_val, y_val)\n",
        "test_dataset = CustomDataset(X_test, y_test)\n",
        "\n",
        "assert train_dataset.samples.shape[0] == train_dataset.labels.shape[0] , \"train_dataset samples and labels should have same length.\"\n",
        "assert val_dataset.samples.shape[0] == val_dataset.labels.shape[0] , \"train_dataset samples and labels should have same length.\"\n",
        "assert test_dataset.samples.shape[0] == test_dataset.labels.shape[0] , \"train_dataset samples and labels should have same length.\"\n",
        "\n",
        "# Step 4: Create PyTorch DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# calculate steps per epoch for training and validation set\n",
        "train_steps = len(train_loader.dataset) // batch_size\n",
        "val_steps = len(val_loader.dataset) // batch_size\n",
        "# when batch_size greater than dataset size, avoid division by zero.\n",
        "train_steps = max(1, train_steps)\n",
        "val_steps = max(1, val_steps)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, input_dim, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert input_dim % num_heads == 0\n",
        "        self.input_dim = input_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = input_dim // num_heads\n",
        "\n",
        "        self.query = nn.Linear(input_dim, input_dim)\n",
        "        self.key = nn.Linear(input_dim, input_dim)\n",
        "        self.value = nn.Linear(input_dim, input_dim)\n",
        "        self.fc_out = nn.Linear(input_dim, input_dim)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        \"\"\" Attention mechanism (Vaswani 2017)\"\"\"\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        # Split the heads\n",
        "        Q = self.query(query).view(batch_size, -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = self.key(key).view(batch_size, -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = self.value(value).view(batch_size, -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "        # Energy-based models\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))\n",
        "\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
        "\n",
        "        attention = F.softmax(energy, dim=-1)\n",
        "\n",
        "        x = torch.matmul(attention, V)\n",
        "        x = x.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, self.input_dim)\n",
        "\n",
        "        x = self.fc_out(x)\n",
        "        return x\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, dropout=0.1):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, input_dim)\n",
        "        # Dropout (Hinton 2012, Srivastava 2014)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # GELU (Hendrycks 2016)\n",
        "        x = F.gelu(self.fc1(x))\n",
        "        # Dropout (Hinton 2012, Srivastava 2014)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, input_dim, num_heads, hidden_dim, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(input_dim, num_heads)\n",
        "        self.feed_forward = FeedForward(input_dim, hidden_dim)\n",
        "        self.norm1 = nn.LayerNorm(input_dim)\n",
        "        self.norm2 = nn.LayerNorm(input_dim)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # Layer normalization (Ba 2016)\n",
        "        # Pre-norm formulation (Xiong 2020, Karpathy 2023)\n",
        "        x_norm = self.norm1(x)\n",
        "        atttention = self.self_attention(x_norm, x_norm, x_norm, mask)\n",
        "        # Residual connections (He 2016)\n",
        "        # Dropout (Srivastava 2014, Hinton 2012)\n",
        "        x = x + self.dropout1(atttention)\n",
        "        x_norm = self.norm2(x)\n",
        "        feed_forward_out = self.feed_forward(x_norm)\n",
        "        x = x + self.dropout2(feed_forward_out)\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, num_layers, num_heads, hidden_dim, dropout=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([EncoderLayer(input_dim, num_heads, hidden_dim, dropout) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, input_dim, num_heads, hidden_dim, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(input_dim, num_heads)\n",
        "        self.cross_attention = MultiHeadAttention(input_dim, num_heads)\n",
        "        self.feed_forward = FeedForward(input_dim, hidden_dim)\n",
        "        self.norm1 = nn.LayerNorm(input_dim)\n",
        "        self.norm2 = nn.LayerNorm(input_dim)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask=None, tgt_mask=None):\n",
        "        \"\"\" Attention mechanism (Vasawin 2017)\"\"\"\n",
        "        # Layer normalization (Ba 2016)\n",
        "        # Pre-norm formulation (Xiong 2020, Karpathy 2023)\n",
        "        x_norm = self.norm1(x)\n",
        "        # Self attention (Vaswani 2017)\n",
        "        attention = self.self_attention(x_norm, x_norm, x_norm, tgt_mask)\n",
        "        # Residual connections (He 2016)\n",
        "        # Dropout (Srivastava 2014, Hinton 2012)\n",
        "        x = x + self.dropout1(attention)\n",
        "        x_norm = self.norm2(x)\n",
        "        # Cross attention (Vaswani 2017)\n",
        "        cross_attention = self.cross_attention(x_norm, encoder_output, encoder_output, src_mask)\n",
        "        x = x + self.dropout2(cross_attention)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_dim, num_layers, num_heads, hidden_dim, dropout=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([DecoderLayer(input_dim, num_heads, hidden_dim, dropout) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask=None, tgt_mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output, src_mask, tgt_mask)\n",
        "        return x\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    References:\n",
        "    1. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez,\n",
        "        A. N., ... & Polosukhin, I. (2017).\n",
        "        Attention is all you need.\n",
        "        Advances in neural information processing systems, 30.\n",
        "    2. He, K., Zhang, X., Ren, S., & Sun, J. (2016).\n",
        "        Deep residual learning for image recognition.\n",
        "        In Proceedings of the IEEE conference on\n",
        "        computer vision and pattern recognition (pp. 770-778).\n",
        "    3. LeCun, Y. (1989). Generalization and network design strategies.\n",
        "        Connectionism in perspective, 19(143-155), 18.\n",
        "    4. LeCun, Y., Boser, B., Denker, J., Henderson, D., Howard,\n",
        "        R., Hubbard, W., & Jackel, L. (1989).\n",
        "        Handwritten digit recognition with a back-propagation network.\n",
        "        Advances in neural information processing systems, 2.\n",
        "    5. LeCun, Y., Boser, B., Denker, J. S., Henderson, D., Howard, R. E.,\n",
        "        Hubbard, W., & Jackel, L. D. (1989).\n",
        "        Backpropagation applied to handwritten zip code recognition.\n",
        "        Neural computation, 1(4), 541-551.\n",
        "    6. Hendrycks, D., & Gimpel, K. (2016).\n",
        "        Gaussian error linear units (gelus).\n",
        "        arXiv preprint arXiv:1606.08415.\n",
        "    7. Ba, J. L., Kiros, J. R., & Hinton, G. E. (2016).\n",
        "        Layer normalization. arXiv preprint arXiv:1607.06450.\n",
        "    8. Srivastava, N., Hinton, G., Krizhevsky, A.,\n",
        "        Sutskever, I., & Salakhutdinov, R. (2014).\n",
        "        Dropout: a simple way to prevent neural networks from overfitting.\n",
        "        The journal of machine learning research, 15(1), 1929-1958.\n",
        "    9. Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever,\n",
        "        I., & Salakhutdinov, R. R. (2012).\n",
        "        Improving neural networks by preventing co-adaptation of feature detectors.\n",
        "        arXiv preprint arXiv:1207.0580.\n",
        "    10. Glorot, X., & Bengio, Y. (2010, March).\n",
        "        Understanding the difficulty of training deep feedforward neural networks.\n",
        "        In Proceedings of the thirteenth international conference on artificial intelligence and statistics (pp. 249-256).\n",
        "        JMLR Workshop and Conference Proceedings.\n",
        "    11. Loshchilov, I., & Hutter, F. (2017).\n",
        "        Decoupled weight decay regularization.\n",
        "        arXiv preprint arXiv:1711.05101.\n",
        "    12. Goodfellow, Ian, Yoshua Bengio, and Aaron Courville.\n",
        "        Deep learning. MIT press, 2016.\n",
        "    13. Morgan, N., & Bourlard, H. (1989).\n",
        "        Generalization and parameter estimation in feedforward nets:\n",
        "        Some experiments. Advances in neural information processing systems, 2.\n",
        "    14. Xiong, R., Yang, Y., He, D., Zheng, K.,\n",
        "        Zheng, S., Xing, C., ... & Liu, T. (2020, November).\n",
        "        On layer normalization in the transformer architecture.\n",
        "        In International Conference on Machine Learning (pp. 10524-10533). PMLR.\n",
        "    14. Karpathy, Andrej (2023)\n",
        "        Let's build GPT: from scratch, in code, spelled out.\n",
        "        YouTube https://youtu.be/kCc8FmEb1nY?si=1vM4DhyqsGKUSAdV\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, num_layers, num_heads, hidden_dim, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = Encoder(input_dim, num_layers, num_heads, hidden_dim, dropout)\n",
        "        self.decoder = Decoder(input_dim, num_layers, num_heads, hidden_dim, dropout)\n",
        "        self.fc = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
        "        x = self.encoder(src, src_mask)\n",
        "        x = self.decoder(tgt, x, src_mask, tgt_mask)\n",
        "        x = self.fc(x[:, 0, :])\n",
        "        return x"
      ],
      "metadata": {
        "id": "bygy82tLE9N5"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "def pre_train_masked_spectra(model, filepath=\"next_spectra_model_weights.pth\", mask_prob=0.2):\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        for (x,y) in train_loader:\n",
        "            # Generate batch of data\n",
        "            tgt_x, x = x.to(device), x.to(device)\n",
        "\n",
        "            batch_size = x.shape[0]\n",
        "            mask = torch.rand(batch_size, 1023) < mask_prob\n",
        "            mask = mask.to(device)\n",
        "            x[mask] = 0\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x, x)\n",
        "            loss = criterion(outputs, tgt_x)  # Compare predicted spectra with true spectra\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        total_val_loss = 0.0\n",
        "        model.eval()\n",
        "        for (x,y) in val_loader:\n",
        "            tgt_x, x = x.to(device), x.to(device)\n",
        "\n",
        "            val_batch_size = x.shape[0]\n",
        "            mask = torch.rand(val_batch_size, 1023) < mask_prob\n",
        "            mask = mask.to(device)\n",
        "            x[mask] = 0\n",
        "\n",
        "            outputs = model(x, x)\n",
        "            val_loss = criterion(outputs, tgt_x)\n",
        "            total_val_loss += val_loss.item()\n",
        "\n",
        "        # Print average loss for the epoch\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/batch_size:.4f}, Val: {val_loss/val_batch_size:.4f}')\n",
        "\n",
        "    masked_spectra_prediction = model\n",
        "    torch.save(masked_spectra_prediction.state_dict(), filepath)\n",
        "    return model\n",
        "\n",
        "# Define hyperparameters\n",
        "input_dim = 1023\n",
        "output_dim = 1023  # Same as input_dim for masked spectra prediction\n",
        "num_layers = 3\n",
        "num_heads = 3\n",
        "hidden_dim = 128\n",
        "dropout = 0.2\n",
        "learning_rate = 1E-4\n",
        "batch_size = 64\n",
        "num_epochs = 100\n",
        "\n",
        "if is_masked_spectra:\n",
        "    # Load the transformer.\n",
        "    model = Transformer(input_dim, output_dim, num_layers, num_heads, hidden_dim, dropout)\n",
        "    # Specify the device (GPU or CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    # Initialize your model, loss function, and optimizer\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    model = pre_train_masked_spectra(model, filepath=\"next_spectra_model_weights.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd2kNbQLa63y",
        "outputId": "eff73062-a1a4-4e56-b2a6-e788b6aa14eb"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 0.0092, Val: 0.0072\n",
            "Epoch [2/100], Loss: 0.0077, Val: 0.0064\n",
            "Epoch [3/100], Loss: 0.0070, Val: 0.0056\n",
            "Epoch [4/100], Loss: 0.0063, Val: 0.0053\n",
            "Epoch [5/100], Loss: 0.0059, Val: 0.0046\n",
            "Epoch [6/100], Loss: 0.0054, Val: 0.0043\n",
            "Epoch [7/100], Loss: 0.0051, Val: 0.0041\n",
            "Epoch [8/100], Loss: 0.0047, Val: 0.0037\n",
            "Epoch [9/100], Loss: 0.0044, Val: 0.0036\n",
            "Epoch [10/100], Loss: 0.0042, Val: 0.0035\n",
            "Epoch [11/100], Loss: 0.0040, Val: 0.0033\n",
            "Epoch [12/100], Loss: 0.0038, Val: 0.0032\n",
            "Epoch [13/100], Loss: 0.0037, Val: 0.0032\n",
            "Epoch [14/100], Loss: 0.0035, Val: 0.0031\n",
            "Epoch [15/100], Loss: 0.0033, Val: 0.0029\n",
            "Epoch [16/100], Loss: 0.0032, Val: 0.0028\n",
            "Epoch [17/100], Loss: 0.0031, Val: 0.0028\n",
            "Epoch [18/100], Loss: 0.0030, Val: 0.0028\n",
            "Epoch [19/100], Loss: 0.0029, Val: 0.0028\n",
            "Epoch [20/100], Loss: 0.0028, Val: 0.0026\n",
            "Epoch [21/100], Loss: 0.0027, Val: 0.0026\n",
            "Epoch [22/100], Loss: 0.0026, Val: 0.0025\n",
            "Epoch [23/100], Loss: 0.0026, Val: 0.0025\n",
            "Epoch [24/100], Loss: 0.0025, Val: 0.0025\n",
            "Epoch [25/100], Loss: 0.0025, Val: 0.0024\n",
            "Epoch [26/100], Loss: 0.0024, Val: 0.0024\n",
            "Epoch [27/100], Loss: 0.0023, Val: 0.0023\n",
            "Epoch [28/100], Loss: 0.0023, Val: 0.0022\n",
            "Epoch [29/100], Loss: 0.0023, Val: 0.0022\n",
            "Epoch [30/100], Loss: 0.0022, Val: 0.0022\n",
            "Epoch [31/100], Loss: 0.0021, Val: 0.0022\n",
            "Epoch [32/100], Loss: 0.0021, Val: 0.0021\n",
            "Epoch [33/100], Loss: 0.0020, Val: 0.0021\n",
            "Epoch [34/100], Loss: 0.0020, Val: 0.0021\n",
            "Epoch [35/100], Loss: 0.0020, Val: 0.0021\n",
            "Epoch [36/100], Loss: 0.0019, Val: 0.0020\n",
            "Epoch [37/100], Loss: 0.0019, Val: 0.0020\n",
            "Epoch [38/100], Loss: 0.0019, Val: 0.0020\n",
            "Epoch [39/100], Loss: 0.0018, Val: 0.0020\n",
            "Epoch [40/100], Loss: 0.0018, Val: 0.0019\n",
            "Epoch [41/100], Loss: 0.0018, Val: 0.0019\n",
            "Epoch [42/100], Loss: 0.0017, Val: 0.0019\n",
            "Epoch [43/100], Loss: 0.0017, Val: 0.0019\n",
            "Epoch [44/100], Loss: 0.0017, Val: 0.0019\n",
            "Epoch [45/100], Loss: 0.0016, Val: 0.0018\n",
            "Epoch [46/100], Loss: 0.0016, Val: 0.0018\n",
            "Epoch [47/100], Loss: 0.0016, Val: 0.0018\n",
            "Epoch [48/100], Loss: 0.0016, Val: 0.0018\n",
            "Epoch [49/100], Loss: 0.0015, Val: 0.0017\n",
            "Epoch [50/100], Loss: 0.0016, Val: 0.0017\n",
            "Epoch [51/100], Loss: 0.0015, Val: 0.0017\n",
            "Epoch [52/100], Loss: 0.0015, Val: 0.0017\n",
            "Epoch [53/100], Loss: 0.0014, Val: 0.0017\n",
            "Epoch [54/100], Loss: 0.0014, Val: 0.0017\n",
            "Epoch [55/100], Loss: 0.0014, Val: 0.0016\n",
            "Epoch [56/100], Loss: 0.0014, Val: 0.0017\n",
            "Epoch [57/100], Loss: 0.0014, Val: 0.0016\n",
            "Epoch [58/100], Loss: 0.0014, Val: 0.0016\n",
            "Epoch [59/100], Loss: 0.0013, Val: 0.0016\n",
            "Epoch [60/100], Loss: 0.0013, Val: 0.0016\n",
            "Epoch [61/100], Loss: 0.0013, Val: 0.0016\n",
            "Epoch [62/100], Loss: 0.0013, Val: 0.0016\n",
            "Epoch [63/100], Loss: 0.0013, Val: 0.0016\n",
            "Epoch [64/100], Loss: 0.0013, Val: 0.0016\n",
            "Epoch [65/100], Loss: 0.0012, Val: 0.0016\n",
            "Epoch [66/100], Loss: 0.0013, Val: 0.0015\n",
            "Epoch [67/100], Loss: 0.0012, Val: 0.0016\n",
            "Epoch [68/100], Loss: 0.0012, Val: 0.0015\n",
            "Epoch [69/100], Loss: 0.0012, Val: 0.0015\n",
            "Epoch [70/100], Loss: 0.0012, Val: 0.0015\n",
            "Epoch [71/100], Loss: 0.0011, Val: 0.0015\n",
            "Epoch [72/100], Loss: 0.0011, Val: 0.0015\n",
            "Epoch [73/100], Loss: 0.0011, Val: 0.0014\n",
            "Epoch [74/100], Loss: 0.0011, Val: 0.0014\n",
            "Epoch [75/100], Loss: 0.0011, Val: 0.0014\n",
            "Epoch [76/100], Loss: 0.0011, Val: 0.0015\n",
            "Epoch [77/100], Loss: 0.0011, Val: 0.0015\n",
            "Epoch [78/100], Loss: 0.0010, Val: 0.0015\n",
            "Epoch [79/100], Loss: 0.0011, Val: 0.0014\n",
            "Epoch [80/100], Loss: 0.0010, Val: 0.0015\n",
            "Epoch [81/100], Loss: 0.0010, Val: 0.0014\n",
            "Epoch [82/100], Loss: 0.0010, Val: 0.0014\n",
            "Epoch [83/100], Loss: 0.0010, Val: 0.0014\n",
            "Epoch [84/100], Loss: 0.0010, Val: 0.0014\n",
            "Epoch [85/100], Loss: 0.0010, Val: 0.0014\n",
            "Epoch [86/100], Loss: 0.0010, Val: 0.0014\n",
            "Epoch [87/100], Loss: 0.0010, Val: 0.0014\n",
            "Epoch [88/100], Loss: 0.0010, Val: 0.0014\n",
            "Epoch [89/100], Loss: 0.0010, Val: 0.0014\n",
            "Epoch [90/100], Loss: 0.0009, Val: 0.0014\n",
            "Epoch [91/100], Loss: 0.0009, Val: 0.0014\n",
            "Epoch [92/100], Loss: 0.0009, Val: 0.0013\n",
            "Epoch [93/100], Loss: 0.0009, Val: 0.0013\n",
            "Epoch [94/100], Loss: 0.0009, Val: 0.0013\n",
            "Epoch [95/100], Loss: 0.0009, Val: 0.0013\n",
            "Epoch [96/100], Loss: 0.0009, Val: 0.0013\n",
            "Epoch [97/100], Loss: 0.0009, Val: 0.0013\n",
            "Epoch [98/100], Loss: 0.0008, Val: 0.0013\n",
            "Epoch [99/100], Loss: 0.0008, Val: 0.0013\n",
            "Epoch [100/100], Loss: 0.0008, Val: 0.0013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "def mask_left_side(input_spectra, mask_prob=0.5):\n",
        "    \"\"\"\n",
        "    Masks the left-hand side of the input spectra tensor.\n",
        "\n",
        "    Args:\n",
        "        input_spectra (torch.Tensor): Input spectra tensor of shape (batch_size, 1023).\n",
        "        mask_prob (float): Probability of masking each element of the left-hand side.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Masked input spectra tensor.\n",
        "    \"\"\"\n",
        "    # Calculate the index to split the tensor\n",
        "    split_index = input_spectra.shape[0] // 2\n",
        "    # Mask the left half of the input tensor\n",
        "    input_spectra[:split_index] = 0\n",
        "    return input_spectra\n",
        "\n",
        "def mask_right_side(input_spectra, mask_prob=0.5):\n",
        "    \"\"\"\n",
        "    Masks the right-hand side of the input spectra tensor.\n",
        "\n",
        "    Args:\n",
        "        input_spectra (torch.Tensor): Input spectra tensor of shape (batch_size, 1023).\n",
        "        mask_prob (float): Probability of masking each element of the right-hand side.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Masked input spectra tensor.\n",
        "    \"\"\"\n",
        "    # Calculate the index to split the tensor\n",
        "    split_index = input_spectra.shape[0] // 2\n",
        "    # Mask the left half of the input tensor\n",
        "    input_spectra[split_index:] = 0\n",
        "    return input_spectra\n",
        "\n",
        "def pre_train_model_next_spectra(model, filepath=\"next_spectra_model_weights.pth\"):\n",
        "    # Assume train_loader is your DataLoader containing spectra data\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        num_pairs = 0\n",
        "\n",
        "        # Iterate over batches in the train_loader\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Extract spectra from the batch\n",
        "            (x,y) = batch\n",
        "\n",
        "            # Randomly choose pairs of adjacent spectra from the same index or different indexes\n",
        "            pairs = []\n",
        "            labels = []\n",
        "            for i in range(len(x)):\n",
        "                if random.random() < 0.5:\n",
        "                    # Choose two adjacent spectra from the same index\n",
        "                    if i < len(x) - 1:\n",
        "                        # Mask the right side of the spectra\n",
        "                        left = mask_left_side(x[i])\n",
        "                        right = mask_right_side(x[i])\n",
        "                        pairs.append((left, right))\n",
        "                        labels.append([0,1])\n",
        "                else:\n",
        "                    # Choose two spectra from different indexes\n",
        "                    j = random.randint(0, len(x) - 1)\n",
        "                    if j != i:\n",
        "                        left = mask_left_side(x[i])\n",
        "                        right = mask_right_side(x[j])\n",
        "                        pairs.append((left, right))\n",
        "                        labels.append([1,0])\n",
        "\n",
        "            for (input_spectra, target_spectra), label in zip(pairs, labels):\n",
        "                # Forward pass\n",
        "                input_spectra = input_spectra.to(device)\n",
        "                target_spectra = target_spectra.to(device)\n",
        "                label = torch.tensor(label).to(device)\n",
        "                # print(f\"[DEBUG] input_spectra: {input_spectra.shape}\")\n",
        "                # print(f\"[DEBUG] target_spectra: {target_spectra.shape}\")\n",
        "                # print(f\"[DEBUG] target_spectra: {target_spectra} \")\n",
        "                output = model(input_spectra.unsqueeze(0), target_spectra.unsqueeze(0))\n",
        "                # Compute loss\n",
        "                # print(f\"[DEBUG] output: {output.shape}\")\n",
        "                # print(f\"[DEBUG] label: {label.shape}\")\n",
        "                label = label.float()\n",
        "\n",
        "                loss = criterion(output, label.unsqueeze(0))\n",
        "                total_loss += loss.item()\n",
        "                # Backpropagation\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                num_pairs += 1\n",
        "\n",
        "        # Calculate average loss for the epoch\n",
        "        avg_loss = total_loss / num_pairs\n",
        "        print(f\"Epoch {epoch + 1}, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    next_spectra_model = model\n",
        "    torch.save(next_spectra_model.state_dict(), filepath)\n",
        "    return model\n",
        "\n",
        "def transfer_learning(model, filepath='next_spectra_model_weights.pth', output_dim=2):\n",
        "    # Load the state dictionary from the checkpoint.\n",
        "    checkpoint = torch.load(filepath)\n",
        "    # Modify the 'fc.weight' and 'fc.bias' parameters\n",
        "    checkpoint['fc.weight'] = checkpoint['fc.weight'][:output_dim]  # Keep only the first 2 rows\n",
        "    checkpoint['fc.bias'] = checkpoint['fc.bias'][:output_dim] # Keep only the first 2 elements\n",
        "    # Load the modified state dictionary into the model.\n",
        "    model.load_state_dict(checkpoint, strict=False)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define hyperparameters\n",
        "input_dim = 1023  # Example: size of input sequence\n",
        "output_dim = 2  # Example: number of output classes\n",
        "num_layers = 3\n",
        "num_heads = 3\n",
        "hidden_dim = 128\n",
        "dropout = 0.2\n",
        "learning_rate = 1e-5\n",
        "num_epochs = 50\n",
        "\n",
        "if is_next_spectra:\n",
        "    # Initialize the model, criterion, and optimizer\n",
        "    model = Transformer(input_dim, output_dim, num_layers, num_heads, hidden_dim, dropout)\n",
        "\n",
        "    is_transfer_learning = True\n",
        "    # Transfer learning\n",
        "    if is_transfer_learning:\n",
        "        model = transfer_learning(model, filepath='next_spectra_model_weights.pth')\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # AdamW (Loshchilov 2017)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Specify the device (GPU or CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    print(\"[INFO] Training the network\")\n",
        "    startTime = time.time()\n",
        "\n",
        "\n",
        "    # Train the model\n",
        "    model = pre_train_model_next_spectra(model, filepath='next_spectra_model_weights.pth')\n",
        "\n",
        "    # finish measuring how long training took\n",
        "    endTime = time.time()\n",
        "    print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))"
      ],
      "metadata": {
        "id": "u59zTkBcbRJ6"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "def train(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, inputs, src_mask=None, tgt_mask=None)  # Assuming no masking is needed for now\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_predictions += (predicted == targets.argmax(1)).sum().item()\n",
        "        total_samples += targets.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_accuracy = correct_predictions / total_samples\n",
        "\n",
        "    return epoch_loss, epoch_accuracy\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs, inputs, src_mask=None, tgt_mask=None)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_predictions += (predicted == targets.argmax(1)).sum().item()\n",
        "            total_samples += targets.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_accuracy = correct_predictions / total_samples\n",
        "\n",
        "    return epoch_loss, epoch_accuracy\n",
        "\n",
        "def train_model(model, train_dataloader, val_dataloader, criterion, optimizer, num_epochs, device):\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_accuracy = train(model, train_dataloader, criterion, optimizer, device)\n",
        "        val_loss, val_accuracy = evaluate(model, val_dataloader, criterion, device)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f'[INFO] Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
        "\n",
        "        # Early stopping (Morgan 1989)\n",
        "        # if train_accuracy == 1 and val_accuracy == 1:\n",
        "        #     break\n",
        "\n",
        "    # plot the training loss and accuracy\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(train_losses, label=\"train_loss\")\n",
        "    plt.plot(val_losses, label=\"val_loss\")\n",
        "    plt.plot(train_accuracies, label=\"train_acc\")\n",
        "    plt.plot(val_accuracies, label=\"val_acc\")\n",
        "    plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.legend(bbox_to_anchor=(1.0, 1.0))\n",
        "    plt.savefig(\"model_accuracy.png\")\n",
        "    plt.show()\n",
        "\n",
        "    return train_losses, train_accuracies, val_losses, val_accuracies\n",
        "\n",
        "def transfer_learning(model, filepath='next_spectra_model_weights.pth', output_dim=2):\n",
        "    # Load the state dictionary from the checkpoint.\n",
        "    checkpoint = torch.load(filepath)\n",
        "    # Modify the 'fc.weight' and 'fc.bias' parameters\n",
        "    checkpoint['fc.weight'] = checkpoint['fc.weight'][:output_dim]  # Keep only the first 2 rows\n",
        "    checkpoint['fc.bias'] = checkpoint['fc.bias'][:output_dim] # Keep only the first 2 elements\n",
        "    # Load the modified state dictionary into the model.\n",
        "    model.load_state_dict(checkpoint, strict=False)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define hyperparameters\n",
        "input_dim = 1023  # Example: size of input sequence\n",
        "output_dim = 2  # Example: number of output classes\n",
        "num_layers = 3\n",
        "num_heads = 3\n",
        "hidden_dim = 128\n",
        "dropout = 0.2\n",
        "learning_rate = 1e-5\n",
        "num_epochs = 50\n",
        "\n",
        "# Initialize the model, criterion, and optimizer\n",
        "model = Transformer(input_dim, output_dim, num_layers, num_heads, hidden_dim, dropout)\n",
        "\n",
        "is_transfer_learning = True\n",
        "# Transfer learning\n",
        "if is_transfer_learning:\n",
        "    model = transfer_learning(model, filepath='next_spectra_model_weights.pth')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# AdamW (Loshchilov 2017)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Specify the device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"[INFO] Training the network\")\n",
        "startTime = time.time()\n",
        "\n",
        "# Train the model\n",
        "train_losses, train_accuracies, val_losses, val_accuracies = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n",
        "\n",
        "# finish measuring how long training took\n",
        "endTime = time.time()\n",
        "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xhhI4d1jW5d3",
        "outputId": "220695b3-b2d4-42da-e358-19bfddd178b3"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Training the network\n",
            "[INFO] Epoch 1/50, Train Loss: 0.6675, Train Acc: 0.5989, Val Loss: 0.5635, Val Acc: 0.9130\n",
            "[INFO] Epoch 2/50, Train Loss: 0.5810, Train Acc: 0.8610, Val Loss: 0.4502, Val Acc: 1.0000\n",
            "[INFO] Epoch 3/50, Train Loss: 0.4909, Train Acc: 0.9412, Val Loss: 0.3447, Val Acc: 1.0000\n",
            "[INFO] Epoch 4/50, Train Loss: 0.4093, Train Acc: 0.9626, Val Loss: 0.2535, Val Acc: 1.0000\n",
            "[INFO] Epoch 5/50, Train Loss: 0.3381, Train Acc: 0.9733, Val Loss: 0.1740, Val Acc: 1.0000\n",
            "[INFO] Epoch 6/50, Train Loss: 0.2634, Train Acc: 0.9786, Val Loss: 0.1099, Val Acc: 1.0000\n",
            "[INFO] Epoch 7/50, Train Loss: 0.1950, Train Acc: 0.9733, Val Loss: 0.0626, Val Acc: 1.0000\n",
            "[INFO] Epoch 8/50, Train Loss: 0.1366, Train Acc: 0.9786, Val Loss: 0.0327, Val Acc: 1.0000\n",
            "[INFO] Epoch 9/50, Train Loss: 0.0944, Train Acc: 0.9786, Val Loss: 0.0168, Val Acc: 1.0000\n",
            "[INFO] Epoch 10/50, Train Loss: 0.0689, Train Acc: 0.9840, Val Loss: 0.0086, Val Acc: 1.0000\n",
            "[INFO] Epoch 11/50, Train Loss: 0.0444, Train Acc: 0.9893, Val Loss: 0.0043, Val Acc: 1.0000\n",
            "[INFO] Epoch 12/50, Train Loss: 0.0268, Train Acc: 1.0000, Val Loss: 0.0021, Val Acc: 1.0000\n",
            "[INFO] Epoch 13/50, Train Loss: 0.0209, Train Acc: 1.0000, Val Loss: 0.0010, Val Acc: 1.0000\n",
            "[INFO] Epoch 14/50, Train Loss: 0.0128, Train Acc: 1.0000, Val Loss: 0.0005, Val Acc: 1.0000\n",
            "[INFO] Epoch 15/50, Train Loss: 0.0091, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
            "[INFO] Epoch 16/50, Train Loss: 0.0077, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
            "[INFO] Epoch 17/50, Train Loss: 0.0055, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
            "[INFO] Epoch 18/50, Train Loss: 0.0040, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
            "[INFO] Epoch 19/50, Train Loss: 0.0033, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
            "[INFO] Epoch 20/50, Train Loss: 0.0019, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
            "[INFO] Epoch 21/50, Train Loss: 0.0020, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
            "[INFO] Epoch 22/50, Train Loss: 0.0018, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
            "[INFO] Epoch 23/50, Train Loss: 0.0014, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
            "[INFO] Epoch 24/50, Train Loss: 0.0011, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 25/50, Train Loss: 0.0012, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 26/50, Train Loss: 0.0011, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 27/50, Train Loss: 0.0012, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 28/50, Train Loss: 0.0008, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 29/50, Train Loss: 0.0007, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 30/50, Train Loss: 0.0008, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 31/50, Train Loss: 0.0006, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 32/50, Train Loss: 0.0008, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 33/50, Train Loss: 0.0007, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 34/50, Train Loss: 0.0006, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 35/50, Train Loss: 0.0006, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 36/50, Train Loss: 0.0006, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 37/50, Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 38/50, Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 39/50, Train Loss: 0.0006, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 40/50, Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 41/50, Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 42/50, Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 43/50, Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 44/50, Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 45/50, Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 46/50, Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 47/50, Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 48/50, Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 49/50, Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n",
            "[INFO] Epoch 50/50, Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0000, Val Acc: 1.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArYAAAHMCAYAAAAgUuvWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACD00lEQVR4nO3dd3xUVfrH8c+d9F4IIUBIAoQivYMUaYoI6KIgi72igmX1Z0PQpSgqtnUtu2tH1kVBsFEEC0V6R6r0DoFAGull7u+PkJGQBJJMSfu+X6+8yNxy7jMnk/DMmeeeY5imaSIiIiIiUsVZKjoAERERERFHUGIrIiIiItWCElsRERERqRaU2IqIiIhItaDEVkRERESqBSW2IiIiIlItKLEVERERkWpBia2IiIiIVAtKbEVERESkWlBiK05jGAZ9+vSxu50+ffpgGIb9AUmlFBMTQ0xMTEWHISIi1YAS22rMMIwyfU2bNq2iQ64yli5d6rDEXcrvf//7n+31+9NPP1V0OOIiEydOLPS3y2KxEBgYSHR0NIMGDWLq1KkcP37cYderSm++qlKsIs7gXtEBiPNMmDChyLa3336b5ORk/va3vxEcHFxoX7t27Rx6/V27duHr62t3O9OnTyc9Pd0BEUl18+GHH2IYBqZp8uGHHzJgwICKDklcqHfv3rY3l2lpaZw8eZKVK1fy448/MmHCBCZOnMjYsWMrNkgRcSklttXYxIkTi2ybNm0aycnJPP74405/V9+8eXOHtBMVFeWQdqR62b17N7/99htXX301iYmJ/PDDD5w6dYo6depUdGjiIn369Cnyd840Tb755hseeOABnnvuOQAltyI1iEoRBPizjjU7O5vJkyfTrFkzvLy8uPvuuwFITk7m9ddfp1+/fkRGRuLp6Unt2rW54YYbWL16dbFtFvdRfcFHiEuXLmX27Nl06dIFX19fQkNDGTlyZLEfHxZXY1tQCjBx4kS2bNnC4MGDCQ4OxtfXl969e7Nq1apiYzp58iT33HMP4eHh+Pj40K5dOz7//PNC7TnDyZMnefjhh4mJibH13U033cTGjRuLHJudnc0777xDhw4dCAkJwdfXl5iYGP7yl7/wyy+/FDp2+fLlXH/99URGRuLl5UVERATdunVj0qRJpYorOzub9957j0GDBhEdHY2XlxehoaFcffXV/Pjjj8WeU/BRZ1paGk8//TRRUVF4eXkRGxvL1KlTMU2zyDmmafLee+/RsmVLvL29qV+/Po888gjJycmlirM4H330EQD33HMPd999Nzk5OZcsp0lISGD8+PG0atUKX19fgoKCaNu2LWPHjiUtLa1cx17qY98LX+sXKvi9iIuL4/7776d+/fq4ubnZYt+zZw9jx46lU6dO1K5dGy8vL6Kjo3nggQc4duxYic/vp59+4vrrryc8PBwvLy8aNGhQ6DWzaNEiDMPgnnvuKfb8rKwswsLCCAsLIysrq8TrXOjXX39l4MCBhIaG4uXlRdOmTRk7dmyxP9eC3+Pc3FxefvllmjRpYovz2WefJTs7u1TXvBzDMBg2bBizZ88GYPLkyZw8edK2vyyv+YK/C4cPH+bw4cOFyh8K/jYCfPfdd9x+++00bdoUPz8//Pz86NixI++88w5Wq7VIjKdOneKpp56iWbNm+Pn5ERwcTLNmzbj77rs5cOBAkeMXLVrEoEGDCAsLw8vLi8aNG/P000+TlJRU5lhFqjuN2Eohw4YNY/369Vx33XUMHTqU8PBwIL+sYPz48Vx11VUMHjyYkJAQjhw5wg8//MCPP/7I3LlzGThwYKmv869//YsffviBG264gd69e7N27VpmzpzJ77//zpYtW/Dy8ipVOxs2bOC1117jyiuv5P777+fIkSPMmTOH/v37s2XLFpo1a2Y79vTp01x55ZUcPnyYq666iu7duxMXF8eYMWOc+hH2wYMH6dmzJydOnKBfv37ccsstHD16lK+//pr58+czZ84chgwZYjv+7rvv5ssvv6RVq1bceeed+Pj4cOLECVasWMHChQu5+uqrAVi4cCGDBw8mMDCQG264gfr165OQkMCuXbv417/+VWwpysUSEhL429/+Rvfu3bnmmmuoXbs2J0+eZO7cuQwaNIiPPvqI+++/v8h5OTk5XHvttZw4cYLrrrsOd3d3vvvuO8aOHUtmZmaRaz/++OO888471K1blwceeAAPDw++//571q5dS3Z2Np6enmXq0+zsbD7//HOCgoK48cYbycjI4Mknn+Tjjz/mmWeeKfJG6ODBg/Tt25fDhw/TsWNHRo8ejdVqZc+ePfzjH//goYcews/Pr8zHlldCQgLdunXD39+fm266CYvFYhtp/uabb/jPf/5D37596d69O56enuzYsYOPP/6YuXPnsmHDBurXr1+ovQkTJjB58mT8/f0ZOnQoDRo04MSJE6xatYovvviCq6++mgEDBtC4cWNmzZrF22+/TVBQUKE25syZw9mzZ3nyySdL9fv3wQcfMHr0aPz8/Lj55psJDw9n6dKlTJ06lblz57Jy5coi5U4At956K8uXL+e6664jMDCQBQsW8Nprr3H69Gk+++yz8nfqRfr27UvPnj1ZsWIF33zzDQ8//DBQttd8TEwMEyZM4O233wbyX8cFLizdGjt2LBaLha5du1K/fn2Sk5NZvHgxf/vb31i/fj3//e9/bcemp6fTo0cP9u/fzzXXXMP111+PaZocPnyY77//nuHDh9OoUSPb8ZMmTWLixImEhoYyZMgQwsPD2bp1K2+88QYLFixg9erVBAYGljpWkWrPlBolOjraBMyDBw8W2t67d28TMFu3bm3Gx8cXOS8pKanY7UePHjXr1q1rNm/evMg+wOzdu3ehbRMmTDABMyAgwNy6dWuhfbfccosJmDNnziw2tgstWbLEBEzA/Oyzzwrt+89//mMC5ujRowttv/fee03AfOaZZwpt37Jli+np6WkC5oQJE4o8j+IUXP/i51ecAQMGmID50ksvFdq+cuVK083NzQwNDTXPnTtnmmZ+PxuGYXbs2NHMzc0t0taZM2ds3990000mYG7ZsqXIccX9rIqTmZlpHj16tMj2pKQks2XLlmZISIiZnp5eaF/Ba+i6664rtO/UqVNmUFCQGRQUZGZnZxd6noDZuHFj8+zZs7btGRkZZrdu3UzAjI6OLlW8Bb788ksTMB944AHbtmHDhpmA+csvvxQ5/sorrzQB8+WXXy6yLz4+3szIyCjXsdHR0SXGXvBaX7JkSaHtBa/bO+64w8zJySly3rFjx8zMzMwi2xctWmRaLBbzoYceKrIdMBs2bGgeO3asyHkX/nxff/11EzDffffdIscV/J7t3r272OdzoUOHDpmenp5mQECAuWvXrkL7Ro8ebQLmqFGjim2/Q4cOhV4HqampZuPGjU2LxWKePHnystc2zT/79nK/r88//7wJmHfeeadtW3lf85d6je7bt6/Itry8PPPOO+80AXPNmjW27T/88IMJmI8//niRc7KyssyUlBTb48WLF5uAeeWVV5qJiYmFjv3ss8+KbedysYpUd0psa5jLJbbfffddmdt89NFHTcA8fPhwoe2XSmzHjx9fpJ2CP+JPPvlksbFdqCCx7NGjR5F2srOzTXd3d7Njx462bVlZWaaPj48ZFBRU6D+OAvfff79TEtujR4+agBkVFVUo2Stw++23m4D5+eefm6ZpmsnJySZgdu/e3bRarZdsuyCxLU0iUh5vvvmmCZjLli0rtL3gNbR3794i5xT8R75t2zbbtoK+/fTTT4scX9CPZf2PuF+/fiZgrlq1yrZt7ty5JmCOGDGi0LEbNmwwAbNdu3ZmXl7eJdsty7GmWf7E1tPT0zx16tRl279Y69atzYYNGxbaNmTIEBMwv/nmm8uef+bMGdPb29ts1apVoe1//PGHCZh9+/YtVRwvvfSSCZjPPfdckX0JCQlmQECA6e3tXShBL/g9/vnnn4uc8/e//90EzLlz55bq+qVNbP/973/b3oSVxqVe8+VJFjdu3GgC5qRJk2zbChLb4vruYkOHDjUBc/v27cXub9eunVm7dm2HxCpSXajGVgrp0qVLiftWrlzJiBEjaNCgAV5eXrb6rXfffRegTNPrdOrUqci2Bg0aAJCYmGhXOx4eHtSpU6dQO7t37yYjI4M2bdoQEBBQ5JyePXuW+pplsXnzZgB69eqFh4dHkf39+vUrdFxgYCDXX389q1atol27dkyePJklS5YUOyvEbbfdBkDXrl156KGHmDlz5iVrMEuyY8cO7r77bho1aoSPj4/t5/rkk08Cxf9cg4KCiI2NLbK9uJ/hpk2bgPw72C/Ws2dP3NzcyhTvvn37WLJkCc2aNePKK6+0bR84cCARERF89913nDlzxrZ9zZo1AFx77bVYLJf+k1eWY+0RExNjK/O5mGmatvKB2rVr4+7ubvuZbNu2rcjPY82aNRiGUapSoFq1ajFixAi2b99eqA79ww8/BOChhx4qVfwFP9OC1++FQkJCaN++PZmZmfzxxx9F9jvqd780zPP13heXppTnNX8pZ8+eZezYsbRp0wZ/f39bex07dizSXu/evalfvz6vvvoqAwcO5J133mHjxo3k5eUVaXf16tV4eHjw9ddfM3HixCJf2dnZxMfHc/bs2TLFK1KdqcZWComIiCh2+7fffsvw4cPx9vbmmmuuoXHjxvj5+WGxWFi6dCnLli0r9Q0nQLG1d+7u+S/H4v7Al6WdgrYubKfgZpaS7ph31p30BdetW7dusfsLtl94E8jMmTOZOnUqM2bMsNWqent7M3z4cN544w1brDfddBPz5s3jzTff5NNPP+WDDz4AoGPHjrzyyitcc801l41vzZo19OvXj9zcXPr3788NN9xAYGAgFouFLVu28P333xf7c71UvwOl7nt3d3fCwsIuG+eFPvroI0zTLHJDjLu7O7fddhtvvvkm06ZN46mnngL+7NuL61KLU5Zj7VHS7xnA//3f//H2229Tt25drr32WurXr4+Pjw+QP6vJ4cOHCx2flJRESEiI7ZjLGTNmDNOnT+eDDz6ge/fuZGVl8fnnnxMeHs6NN95YqjbK87ou4Kjf/dI4ceIEALVr17ZtK+9rviRJSUl07tyZgwcP0qVLF+68805CQ0Nxd3cnKSmJf/7zn4XaCwwMZM2aNUyYMIEffviBRYsWARAWFsaYMWN4/vnnbW+Cz549S25u7mVvBk1NTaVWrVqljlmkOlNiK4WUtMLXCy+8gKenJxs2bOCKK64otO/BBx9k2bJlrgiv3AIDA4H8u5GLU9J2exXcoBMXF1fs/oK7tS+8kcfHx8c2InP06FF+++03pk2bxhdffMGhQ4dYvny57djBgwczePBg0tLSWLt2LfPmzePf//43Q4YMYfPmzbRo0eKS8b300ktkZGSwZMmSIjNYvPLKK3z//ffledqFFDy3U6dOFbopBiA3N5czZ84QGRlZqrYunPngueees03ndLGPPvrIltgWJFKlGYUry7EAFoulxLv5i0vqCpT0e3b69GneeecdWrVqxapVq4p8uvDll18WG/PZs2fJyMgoVXLbtWtX2rdvb7uJ7Mcff+Ts2bM8++yzxX6qUJwLX9ctW7Yssr+413VFWLJkCZD/nAs4+jX/8ccfc/DgQdu8uRdavXo1//znP4ucExkZySeffIJpmuzcuZPFixfz/vvvM3nyZKxWKy+++CKQ339Wq5WEhIQyxSRSk6kUQUpl3759tGjRokhSa7VaWbFiRQVFVXrNmzfHx8eHrVu3cu7cuSL7nfUc2rdvb2s/Nze3yP6C/3g7dOhQ7PkNGjTgtttuY9GiRcTGxrJixYpiP3b08/OjX79+vPXWW4wbN47s7OwSp+u60L59+wgNDS12BTVHvVkpeG7FtbdixYoyjdJ9//33nD59mmbNmnHfffcV+9WoUSP27Nlju163bt2A/CmTipt66UJlORbyP3Y/deoUOTk5RfZt2LCh1M+rwIEDB7BarQwYMKBIUnvs2LFip4Lq1q0bpmmycOHCUl9nzJgxZGZmMn36dNsiFw888ECpzy94XV88lRnkJ/RbtmzB29u7yN8LV1q8eDErV67Ex8en0Eh0eV7zbm5uJb5O9+3bB+TPKFPa9goYhkHLli159NFH+fnnn4H8qcMKdOvWjcTERHbs2HHJdkobq0hNoMRWSiUmJoa9e/faPtqD/Pq1iRMnsnPnzgqMrHQ8PT3561//SnJyMi+99FKhfb///jvTp093ynUjIyO55pprOHTokG0angJr165lxowZhISE2P7jjY+PZ9u2bUXaSUtLIzU1FXd3d9vUWL/99luxyXLB6HNpVn2LiYkhISGBrVu3Ftr+ySef2D4itVdBycCUKVMKjTxlZmaWOOJakoJa0MmTJ/Pxxx8X+zVu3LhCx3bs2JHu3buzZcsWpk6dWqTNs2fPkpmZWeZjIb8mPTc3t8g0VdOmTWPlypVlem6AbU7cixP+1NRURo0aVezP+9FHHwXgySefLHakubhtt956K0FBQbz22mssW7aMa665psho+qXcfvvteHh48O6779oSuwIvvPACKSkp3H777aWets+RzPMLNNx8881A/nRZF5Z+lOc1X6tWLeLj48nIyCiyr+BndnGSv3nzZl555ZUix+/YsaPYT4iK+7194oknABg1alShv70F0tLSbHXhpYlVpCZQKYKUyhNPPMFDDz1E+/btGTZsGB4eHqxcuZKdO3dy/fXXM3fu3IoO8bJeffVVFi9ezGuvvcbatWvp3r07J0+eZNasWQwaNIjvvvuuzDcM/fHHHyVOfh4VFcXkyZP5z3/+Q48ePXj66af56aef6NSpk20eW4vFwmeffWYbnTt+/Djt27endevWtGnThgYNGpCSksK8efOIi4vjsccesx372GOPcfz4cXr06GFb+GHjxo0sXryY6OhoRo4cedn4H3/8cRYtWkTPnj0ZMWIEQUFBbNiwgRUrVjB8+HDbJPf26NGjB48++ijvvvsurVq1Yvjw4bZ5bENCQkqs07zYwYMH+eWXXwgLC2Po0KElHvfXv/6Vxx9/nDlz5vDuu+8SGhrKF198QZ8+fRg3bhxz5syhT58+mKbJ3r17+emnn/jjjz9sCUpZjn300Uf57LPPGD16NL/++isNGjRgy5YtrF69miFDhjBv3rwy9VVERAQjR47kq6++ol27dgwYMIDk5GR+/vlnvL29adeuHVu2bCl0zoABA3j++ed56aWXuOKKK2zz2J46dYoVK1bQrVu3IgtX+Pr6ctddd/HOO+8A+eVEZRETE8Pbb7/Nww8/TIcOHRgxYgS1a9dm2bJlrF69mubNmxf7xsDRli5davv4PyMjgxMnTrBy5UoOHjyIl5cXU6dO5emnny50Tnle8/3792f9+vUMHDiQq666Ci8vL9q2bcv111/PnXfeyeuvv87jjz/OkiVLaNKkCXv37mXevHncdNNNzJw5s1BbP//8M08//TRXXnklTZs2JTw8nGPHjvH9999jsVgKxdu/f39effVVnnvuOZo0acKgQYNo2LAhqampHD58mGXLltGzZ89Co/WXilWkRqiw+RikQlxuuq9L+eyzz8y2bduavr6+Zq1atcyhQ4eaW7duveS0RiVN93XxsaZpmgcPHjQB86677rpsbAXTRJU03U9JU94cO3bMvPPOO82wsDDT29vbbNu2rTlt2jTz66+/NgHzH//4xyX74OLrX+qrbdu2ha770EMPmVFRUaaHh4dZq1Yt8y9/+Yu5bt26Qu0mJiaakyZNMvv27WvWq1fP9PT0NCMiIszevXubM2bMKDQF2MyZM82RI0easbGxpp+fnxkQEGC2bNnSHDdunHn69OlSPQ/TzJ8mq2vXrqa/v78ZFBRkXnPNNeayZcts82RePE9weaa4slqt5rvvvms2b97c9PT0NOvWrWuOGTPGTEpKKvX0ROPGjTMB84knnrjssaNGjTIB86233rJtO3PmjPnMM8+YTZs2Nb28vMygoCCzbdu25rhx48y0tLRC55fl2OXLl5u9evUyfXx8zICAAHPQoEHm77//XqbfiwulpaWZ48aNMxs3bmx6eXmZkZGR5pgxY8wzZ85c8vd0/vz55rXXXmuGhISYnp6eZmRkpDl06FDz119/Lfb4LVu2mIBZt27dYufTLY1FixaZ11xzjRkcHGx6enqajRs3Np9++ukic66a5qX/xpT0WitJQd8WfBmGYfr7+5tRUVHmddddZ7766qvFzulboKyv+dTUVPOhhx4y69evb7q5uRX5O7Vjxw7z+uuvN2vXrm36+vqaHTp0MD/66KNi/6bt3LnTfOKJJ8yOHTuaYWFhpqenpxkdHW0OGzbMXLlyZbHxLl++3Lz55pvNunXrmh4eHmZYWJjZtm1b84knnjDXr19fplhFqjvDNItZ/1Kkhhk/fjwvv/wyCxcu5Nprr63ocEScbtq0adxzzz08//zztpuVRESqOiW2UqOcOHGCevXqFdq2bds229Klx48fx9vbu4KiE3GN3NxcOnTowK5duzh48GCpZ6UQEansVGMrNUqnTp2IjY2lVatW+Pn5sXfvXubPn4/VauWDDz5QUivV2ooVK1i2bBlLly5l27ZtPPLII0pqRaRa0Yit1CiTJk3iu+++49ChQ5w7d47g4GC6devGU089Vez0PyLVycSJE5k0aRKhoaEMGzaMf/7zn6Ve2EFEpCpQYisiIiIi1YLmsRURERGRakGJrYiIiIhUC0psRURERKRaUGIrIiIiItWCpvs6LzExsdh12O1Vu3Zt4uPjHd6uFE/97Vrqb9dSf7uW+tu1ytrf7u7uhISEODEiqYqU2J6Xm5tLTk6OQ9s0DMPWtiafcD71t2upv11L/e1a6m/XUn+Lo6gUQURERESqBSW2IiIiIlItKLEVERERkWpBia2IiIiIVAu6eUxERESqpYyMDE6dOoVpmroprQrz9fUlIiKiVMcqsRUREZFqJyMjg+PHjxMQEIDFog+oq7K0tDSSkpIIDg6+7LH6SYuIiEi1c+rUKSW11YSvry+JiYmlOlY/bREREal2TNNUUltNGIZR6lIS/cRFRESk2lFNbc2kxFZEREREqoVKldju3LmTV199lQcffJARI0awbt26y56zY8cOnn32WW699VYeffRRli5d6vxARURERCq5jh078sEHHzikrZUrVxIeHk5ycrJD2nOWSpXYZmVlERMTw3333Veq40+fPs2rr75Ky5Ytee211xg8eDD/+c9/2LJli3MDFREREXGCoUOH8vzzzzukrUWLFnHHHXc4pK2qolJN99W+fXvat29f6uN/+uknwsPDufPOOwGIjIzkjz/+YP78+bRr185JUTpWXl4eaWlpFR1GtWAYBt7e3qSkpJRYW5WXZ5KdpborRzAMyMt148yZRFTK5nzqb9dSfzuWh4cbobUCKjqMasE0TfLy8nB3v3wKFxYW5oKIKpdKldiW1d69e2ndunWhbW3btmXatGklnpOTk0NOTo7tsWEY+Pj42L53pIL2SmrXarUyY8aMUk9hISIiUhX5+dTm/gduLXH/5f6/rCkeffRRVq1axapVq/jwww8BeOedd3jsscf48ssveeWVV9i1axezZs2iXr16TJgwgQ0bNpCenk7Tpk0ZP348vXv3trXXsWNHHnjgAR588EEAwsPDeeutt/j5559ZunQpERERTJo0iYEDB5Yr3rlz5/Laa69x8OBB6tSpw3333ceYMWNs+z/99FM++OADTpw4QUBAAN26dePTTz+1nfvGG29w8OBBfHx8aNWqFdOnT8fPz6+83QdU8cQ2KSmJoKCgQtuCgoLIyMggOzsbT0/PIud8++23zJ492/a4YcOGTJ06ldq1azstzpJWy9i/f78tqS3NOy8pO9MEq9UEjbiIiFQYNzd36tate9njSru6VHmYpgnZWU5r/5I8vUqVtE+ZMoX9+/dzxRVX8MwzzwCwe/duAF588UUmTpxIdHQ0wcHBHD9+nP79+/Pcc8/h5eXFrFmzuOOOO1i1ahWRkZElXuONN97g73//OxMmTOCTTz5h9OjRbNq0iZCQkDI9pd9//51Ro0bx9NNPM3ToUNavX8+zzz5LaGgoI0eOZMuWLYwfP57333+fzp07k5SUxJo1a4D8OYYffPBB/v73vzNo0CBSU1NZs2aNQ2ayqHHZ1I033siQIUNsjwteaPHx8eTm5jr0WoZhEBERQVxcXLE/rPXr1wNwxRVXMGDAAIdeuyYyDIM6deqwY+sxDu3P4uTRbKzW/H0WC9Rt4El0I09qhbvX+FEBR7jc61scS/3tWupvxzt58mSJ+8rT3+7u7mUblMrOIuvBG0t/vAN5ffAteHlf9rjAwEA8PT3x8fGhTp06AOzbtw+AZ599lj59+tiODQkJoVWrVrbHY8eOZcGCBSxatOiS9yqNHDmSm266CYBx48bx0UcfsXnzZvr161em5/Tvf/+bXr168eSTTwLQuHFjdu/ezfvvv8/IkSM5duwYvr6+DBgwAH9/fxo0aGD7lP3UqVPk5uYyePBgGjRoAECLFi3KdP2SVOnENjg4uMjdecnJyfj4+BQ7Wgvg4eGBh4dHsfuc9ceruDWqTdNk//79QP6LQX84yy8r00pSYh5JZ/NYcnw/KUnZtn2BQRaiGntRP9oDT88/75VUfzuO1mB3LfW3a6m/XUv9XbKL7x1KTU3l9ddf55dffrElipmZmRw7duyS7VyYQPr5+REQEEB8fHyZ49m7d2+REoYuXbrw4YcfkpeXR58+fYiMjKRz58707duXfv36MWjQIHx9fWnZsiW9evWid+/e9O3blz59+nD99deXasncy6nSiW2TJk3YvHlzoW1bt26ladOmFRRR6cXHx3Pu3Dnc3d2Jioqq6HCqBNM0ycwwSU7MIzkx9/y/eWRmFP4j6O4O9aM9iWrkSVCIm0ZnRUQEPL3yR04r6Nr28vX1LfR44sSJLFu2jIkTJ9KwYUO8vb257777Ct1HVJyLSx/LsqpXWfj7+/Prr7+ycuVKli5dytSpU3n99df56aefCAoKYvbs2axbt46lS5fy8ccf88orr/Djjz8SHR1t13UrVWKbmZlJXFyc7fHp06c5dOgQ/v7+hIWFMWPGDBISEnjkkUcAGDBgAIsWLeKLL76gb9++bN++ndWrVzN27NiKegqlVjBaGx0drfraYpimSXqa1Za8FnyVNKOBf4CFoFB3mjQLwzcwHTc3FwcsIiKVmmEYpSoHqGgeHh7k5eVd9rj169czcuRIBg8eDOSP4B49etTZ4dk0adKkyHoD69ato3Hjxrid/0/Y3d2d3r1707t3b5566imaNGnC8uXLGTJkCIZh0LVrV7p27cpTTz1Fhw4dWLBgAaNHj7YrrkqVUe3fv59JkybZHk+fPh2A3r178/DDD5OYmMiZM2ds+8PDwxk7diyff/45CxYsoFatWjz00ENVYqqvC8sQajrTapJ67oIkNil/RDa3mDedhgEBgRaCQtwJCnEjKMSNwGA33D0MDMOgbt1gTp7M0EdZIiJSJUVFRbFp0yaOHDmCn58f1oKbRS7SsGFD5s+fz4ABAzAMg6lTp5Z4rDOMGTOGAQMG8Oabb9puHvv000+ZOnUqkD8l6+HDh+nWrRvBwcH88ssvWK1WYmNj2bhxI8uXL6dPnz6EhYWxadMmzp4965BP3CtVYtuyZUtmzZpV4v6HH3642HNee+01Z4blcElJSSQkJGCxWIiJianQWIr7eD8lKQ93D+N84ng+gTyfPF5Kbq5JStKFI6y5ZKRdPsHMyzMp7nfRYoGAIDdbAhsc4kZAsBtubiotEBGR6mnMmDE88sgj9OrVi4yMDN55551ij5s8eTKPP/44Q4YMITQ0lEceeYRz5865LM42bdrw0Ucf8dprr/HWW29Rp04dnnnmGUaOHAnk3wg3f/58Xn/9dbKysmjYsCEffPABzZs3Z8+ePaxevZoPP/yQc+fOERkZyaRJk+jfv7/dcRmmhraA/JrXy9WllFX+CGJdTp48WWgEcePGjaxcuZIGDRpw442uvUMzPc1KUkJuqT7ev5hfgMWWZObXrlKondRz1nJPq+XmBoHBbhe0705AkAWLpfRJbEn9Lc6h/nYt9bdrqb9dqzz97eHhcclZEQ4cOEBAgBaFqC7OnTtHo0aNLntcpRqxrSlcXYaQm2Ny4mg2Rw5kk3i2aN2OYYB/oOXPEdpgN3JyCo/iZmaYpJ2zknbOyokjJb8B8PI2CiW//gH5CfClGBbw9bVglCGJFREREbmYElsXS0tLs90gV5p3HuVlmiZJCXkcOZDNiSPZFEzRaxgXj4y6ERjkhpt70aQyov6f06JlZRa9kcs0zUK1rkEhbnj7WIq0IyIiIpXbU089VWgBqwsNHz6cN954w8URlY8SWxc7cOAAAHXq1MHf39/h7WdnWTl2OIcjB7I4l/xn4aqfv4WoRp5ExniWK/n08rYQXtdCeN3i5wAWERGRquvZZ58ttBzuhapSSYcSWxdzVhlC6rk89mzP5OSxnD9X23KDepEeRDXyIrS25nMVERGR4tWuXbtsK7lVUkpsXSgrK8u2IogjyxBOHstmy9p0W7lBYLAb0Y08qR/tgYenSgNERESkZlBi60KHDh3CarUSEhJCaGio3e1ZrSZ/bMtk/x9ZANSq7UaLdj4Eh+rHKiIiIjWPMiAXKqivdUQZQlamlY2r0zl7On+YtnEzL5q38S7T9FgiIiIi1YkSWxfJzc3l0KFDgP1lCIlnctmwKo3MDBM3d2jXxZd6DTwdEKWIiIhI1aXE1kWOHj1KTk4Ofn5+1KlTp1xtmKbJ4X3ZbN+SgWkF/wALnXr6ERDo5uBoRURERKoe3VnkIgVlCI0aNSrX7AS5uSZb1qWzbVN+Uls30oNe1wQoqRURERGbjh078sEHH5Tq2PDwcBYsWODkiFxLI7YuYLVa7aqvTU/NY/3KNFKSrBgGXNHGm0bNvDR9l4iIiMgFlNi6wMmTJ8nIyMDLy4v69euX+fyNq9NJSbLi6WXQsbsvYeFaJEFERETkYipFcIGCRRliYmJwcytb6cC5lDySEvIwDOh1TYCSWhERkWpq+vTptG7dGqvVWmj7nXfeyd/+9jcOHjzInXfeSYsWLYiJiWHAgAEsW7bMYdffuXMnN910E1FRUTRr1ownn3yS1NRU2/6VK1dy7bXXEhMTQ2xsLIMHD+bo0aMAbN++nRtvvJGGDRvSqFEjrr76arZs2eKw2EpLia2TmaZp12pjJ47kAFA7wh1fP/24REREysM0TTJzrBXyZZpmqWK84YYbSExMZMWKFbZtiYmJLF68mGHDhpGWlkb//v2ZM2cOixcvpl+/ftxxxx22xZ/skZaWxl//+leCgoJYtGgRH3/8McuWLeO5554D8md3uuuuu7jyyitZsmQJCxYs4I477rCVRY4ZM4a6devy008/8csvv/DYY4/h7u76wgCVIjjZyZMnSUlJwc3Njejo6DKda5omJ45mA2g6LxERETtk5Zrc9L8dFXLtb25ribfH5e+LCQ4Opl+/fnzzzTdcddVVAMydO5fQ0FB69uyJxWKhVatWtuPHjh3LggULWLRoEffdd599MX7zDVlZWbz33nv4+fkB8Oqrr3L77bfzwgsv4OHhQUpKCgMGDKBhw4YANG3a1Hb+sWPHGDNmDE2aNAEcu8JqWWgI0Ml27twJQFRUFB4eZSsjOJdsJTXFisUCEfVVgiAiIlLdDR8+nHnz5pGVlb+q6Jw5cxg6dCgWi4XU1FQmTJhAjx49iI2NJSYmhj179jhkxHbPnj20bNnSltQCdOnSBavVyv79+wkJCWHkyJH89a9/5fbbb+fDDz/k1KlTtmMfeugh/u///o9hw4bxzjvvcPDgQbtjKg+N2DrZjh357w7LU4Zw/Ej+aG14XQ88PDUDgoiISHl5uRt8c1vLCrt2aQ0YMADTNPn5559p3749a9as4cUXXwRg4sSJLFu2jIkTJ9KwYUO8vb257777yMnJcVbohbzzzjuMGjWKxYsX89133/HKK6/w9ddf06lTJ5555hmGDRvGzz//zK+//sprr73GBx98wODBg10SWwEltk6UnJzMyZMnMQzDNmxfWvllCPkv1HpRGq0VERGxh2EYpSoHqGje3t4MHjyYOXPmcPDgQWJjY2nTpg0A69evZ+TIkbZkMTU11Xbzlr2aNm3KzJkzSUtLs43arlu3DovFUmhwrnXr1rRu3Zq//e1vXHfddXzzzTd06tQJyB/Ea9y4MQ899BAPPvggX331lcsTW5UiOFHBTWP169fHx8enTOcmJ+aRnmrFzQ3q1FNiKyIiUlMMGzaMX375hS+//JJhw4bZtjds2JD58+ezbds2tm/fzujRo4vMoGDPNb28vHj00UfZtWsXK1as4LnnnuPmm28mPDycw4cP89JLL7F+/XqOHj3KkiVLOHjwIE2aNCEjI4OxY8eycuVKjh49ytq1a9m8ebOt3taVNGLrRI6YDaFOPQ/cy/ARhoiIiFRtvXr1Ijg4mH379nHTTTfZtk+ePJnHH3+cIUOGEBoayiOPPMK5c+ccck1fX19mzpzJ888/z7XXXouPjw9Dhgxh0qRJAPj4+LB3715mzpxJYmIiderU4Z577uGuu+4iNzeXxMREHnnkEeLj4wkNDWXw4ME888wzDomtLAyztHNQVHPx8fEOrVFJT0/nk08+wTRN7rnnHgICAkp9rmma/DovhYx0k049fKkbqRkRSsMwDOrWrcvJkydLPbWKlJ/627XU366l/nat8vS3h4cHtWvXLnH/gQMHyvR/r1Ru586dK9VMCypFcJLjx49jmib169cnMDCwTOcmns0jI93E3R3CI1SGICIiIlIaKkVwkiZNmlCnTh18fX3LfO6J87Mh1KnvgZvKEERERKSMZs+ezVNPPVXsvgYNGrB8+XIXR+QaSmydKCgoyPbRSmmZ1j9nQ6gfpRIEERERKbuBAwfSoUOHYveVdV79qkSJbSVz9kwuWZkmHp4GtevoxyMiIiJl5+/vj7+/f0WH4XKqsa1kCmZDiKjvgcVNZQgiIiIipaXEthKxWk1OHisoQ6i+HxOIiIiIOIMS20rkzOlcsrNMPL0MaoWrDEFERESkLJTYViIFZQh1Iz2wWFSGICIiIlIWSmwribw8k7jzZQj1NBuCiIiISJkpsa0k4uNyyckx8fI2qBXmVtHhiIiISBXXsWNHPvjgg4oOw6VUyFlJnDiavyhDvQYeGCpDEBERqZGGDh1Kq1ateOmll+xua9GiReVaKKoqU2JbCeTlmsQdVxmCiIiIXJppmuTl5eHufvkULiwszAURVS4qRagETp3MIS8XfHwNQmqpDEFERKQmevTRR1m1ahUffvgh4eHhhIeH89VXXxEeHs6vv/7K1VdfTWRkJGvXruXgwYPceeedtGjRgpiYGAYMGMCyZcsKtXdxKUJ4eDhffPEFd911F9HR0XTt2pWFCxeWKra8vDwef/xxOnXqRFRUFFdeeSUffvhhkeNmzJhBr169iIyMpFWrVowdO9a2Lzk5mSeffJIWLVrQoEEDrrrqKn766ady9lbxNGJbCRQsoVsvyhPDUBmCiIiIo+WPdFbMtd3cKNX/71OmTGH//v1cccUVPPPMMwDs3r0bgBdffJGJEycSHR1NcHAwx48fp3///jz33HN4eXkxa9Ys7rjjDlatWkVkZGSJ13jjjTf4+9//zoQJE/jkk08YPXo0mzZtIiQk5JKxWa1W6taty8cff0xISAjr16/nqaeeok6dOvzlL38B4LPPPmPChAk8//zz9O/fn5SUFNatW2c7f+TIkaSlpfGvf/2LmJgY9uzZg5ubYwf0lNhWsNwck1Mnzie2DbQog4iIiDPk5cEPX52pkGvfMDKMUlQOEBgYiKenJz4+PtSpUweAffv2AfDss8/Sp08f27EhISG0atXK9njs2LEsWLCARYsWcd9995V4jZEjR3LTTTcBMG7cOD766CM2b95Mv379Lhmbh4cHzz77rO1xdHQ0GzZs4Pvvv7cltv/4xz8YPXo0DzzwgO249u3bA7Bs2TI2b97MypUrady4MQAxMTGX65IyU2JbwU6dyMGaB37+FoJCVIYgIiIiRbVr167Q49TUVF5//XV++eUXTp06RW5uLpmZmRw7duyS7bRo0cL2vZ+fHwEBAcTHx5cqhk8++YQvv/yS48ePk5GRQU5Oji25jo+PJy4ujl69ehV77vbt26lXr54tqXUWJbYV7HjBbAhRHipDEBERcRI3t/yR04q6tr0unt1g4sSJLFu2jIkTJ9KwYUO8vb257777yMnJuWQ7F990ZhgGpmle9vrffvstkyZNYuLEiXTu3Bk/Pz/ef/99Nm3aBICPj88lz7/cfkdRYluBrFaT+JO5ANRroNkQREREnMUwjFKVA1Q0Dw8P8kpRDLx+/XpGjhzJ4MGDgfwR3KNHjzotrnXr1tG5c2fuvfde27ZDhw7Zvvf39ycqKorly5fTs2fPIue3aNGCEydOsH//fqeO2mpWhAqUmWFitYJhgYAg/ShERERquqioKDZt2sSRI0c4e/YsVqu12OMaNmzI/Pnz2bZtG9u3b2f06NElHusIjRo1YsuWLSxevJj9+/fz6quvsmXLlkLHPPXUU/z73//mo48+4sCBA2zdupWPP/4YgO7du3PllVdy7733snTpUg4fPsyvv/7K4sWLHRqnsqkKlJmR/wL09jZUhiAiIiKMGTMGi8VCr169uOKKKzh+/Hixx02ePJng4GCGDBnCHXfcQZ8+fWjTpo3T4rrzzjsZPHgwDzzwAAMHDiQhIYF77rmn0DEjR47kxRdf5LPPPqNXr17cdtttHDhwwLb/008/pV27djz00EP06tWLyZMnl2p0uiwMszSFFTVAfHz8ZetSysowDOrWrcvJkyeLrV85cTSbjavSCanlRs+rAxx67Zrocv0tjqX+di31t2upv12rPP3t4eFB7dq1S9x/4MABAgL0f2t1ce7cORo1anTZ4zRiW4EyM/J/eb199GMQERERsVcVKKOuvmylCD4qQxAREZGK89RTTzF79uxi9w0fPpw33njDxRGVjxLbCvRnYqsRWxEREak4zz77LGPGjCl2X1Uq6VBiW4FUiiAiIiKVQe3atS9Zs1xVKKOqQLYRW1+VIoiIiIjYS4ltBTFNU6UIIiIiIg6kjKqC5OZAXv6iY0psRURERBxAGVUFyczMH6119wB3d5UiiIiIiNhLiW0FyUxXGYKIiIiIIymrqiCaEUFEREQcrWPHjnzwwQcVHUaFUVZVQbQ4g4iIiIhjKbGtIJoRQURERMSxlFVVkIJSBB8ltiIiIgJMnz6d1q1bY7VaC22/8847+dvf/sbBgwe58847adGiBTExMQwYMIBly5aV+3r//ve/6d27NzExMbRr145nnnmG1NTUQsesXbuWoUOHEh0dTZMmTRgxYgRJSUkAWK1W3n33Xbp06UJkZCTt27fnH//4R7njcYRKt/LYwoULmTt3LklJSURHR3PvvfcSGxtb4vHz58/np59+4syZMwQGBtK1a1duvfVWPD09XRh12RWM2HqpFEFERMTpTNMkNze3Qq7t7u6OYVz+//sbbriBcePGsWLFCq666ioAEhMTWbx4MTNmzCAtLY3+/fvz3HPP4eXlxaxZs7jjjjtYtWoVkZGRZY7LYrEwZcoUoqKiOHz4MM8++yyTJ0/mtddeA2Dbtm0MHz6cW265hZdeegl3d3dWrlxJXl4eAC+99BJffPEFkydPpmvXrpw6dYp9+/aVOQ5HqlSJ7apVq5g+fTqjRo2iSZMmzJ8/nylTpvD2228TFBRU5PgVK1YwY8YMRo8eTdOmTTl58iT/+te/MAyDu+66qwKeQekVJLYasRUREXG+3Nxc3nnnnQq59mOPPYaHh8dljwsODqZfv3588803tsR27ty5hIaG0rNnTywWC61atbIdP3bsWBYsWMCiRYu47777yhzXgw8+aPs+KiqK5557jqefftqW2L7//vu0bdvW9higefPmAKSmpvLRRx/xyiuvMHLkSAAaNmxIt27dyhyHI1WqrGrevHn079+fvn37EhkZyahRo/D09GTJkiXFHr97926aNWtGz549CQ8Pp23btvTo0aPC3y1cjmk1ycw8PyuCb6X6EYiIiEgFGj58OPPmzSMrKwuAOXPmMHToUCwWC6mpqUyYMIEePXoQGxtLTEwMe/bs4dixY+W61rJlyxg2bBht2rShYcOGPPzwwyQkJJCeng7A9u3b6dWrV7Hn7tmzh6ysrBL3V5RKM2Kbm5vLgQMHGDp0qG2bxWKhdevW7Nmzp9hzmjVrxvLly9m3bx+xsbGcOnWKzZs3X7KTc3JyyMnJsT02DAMfHx/b945U0N7F7WZlm2ACBnh7Wxx+3ZqqpP4W51B/u5b627XU367liv52d3fnsccec1r7l7t2aQ0YMADTNPn5559p3749a9as4cUXXwRg4sSJLFu2jIkTJ9KwYUO8vb257777CuU1pXXkyBFuv/127r77bp577jlCQkJYu3Ytjz/+uK09b2/vEs+/1L6KVGkS25SUFKxWK8HBwYW2BwcHc+LEiWLP6dmzJykpKbzwwgsA5OXlcc0113DTTTeVeJ1vv/2W2bNn2x43bNiQqVOnUrt2bfufRAkiIiIKPT4dlwEk4+vrTr369Zx23Zrq4v4W51J/u5b627XU367lzP42DKNU5QAVzdvbm8GDBzNnzhwOHjxIbGwsbdq0AWD9+vWMHDmSwYMHA/nlAEePHi3XdX7//XesViuTJk3CYsn/9Pj7778vdEyLFi1Yvnw5zz77bJHzGzVqhI+PD8uXLyc6OrpcMThDpUlsy2PHjh18++233H///TRp0oS4uDg+++wzZs+ezfDhw4s958Ybb2TIkCG2xwXvDuPj4x1eVG4YBhEREcTFxWGapm37yWPZAHh6mZw8edKh16zJSupvcQ71t2upv11L/e1a5elvd3d3pw5KVaRhw4Zx++23s3v37kL5TMOGDZk/fz4DBgzAMAymTp1aZAaF0mrYsCE5OTl8/PHHDBgwgHXr1vH5558XOuZvf/sbvXv35plnnuGuu+7C09OTFStWcMMNN1CrVi0eeeQRJk+ejIeHB126dOHs2bPs3r2b2267za7nb49Kk9gGBgZisVhsU0gUSEpKKjKKW2DmzJlcddVV9O/fH8gvfM7MzOTDDz/kpptusr0DuZCHh0eJ79ic9cfLNM1CbV+4nK7+YDrexf0tzqX+di31t2upv11L/Z2vV69eBAcHs2/fvkKfQk+ePJnHH3+cIUOGEBoayiOPPMK5c+fKdY1WrVoxefJk3n33XaZMmUK3bt0YP348jzzyiO2Yxo0bM2vWLKZMmcLAgQPx9vamQ4cOtpiefPJJ3N3dee2114iLi6NOnToVfvN+pUls3d3dadSoEdu3b6dLly5A/vxo27dvZ+DAgcWek5WVVaQep7hktrLJ0KpjIiIiUgKLxcK2bduKbI+KiuKbb74ptO3i2RA2btxY6us89NBDPPTQQ4W2jRgxotDj7t27M3/+/BLjfOKJJ3jiiSdKfU1nqzSJLcCQIUN4//33adSoEbGxsSxYsICsrCz69OkDwHvvvUdoaCi33norkL8e8vz582nYsKGtFGHmzJl07NixUie4WnVMRERExPEqVWLbvXt3UlJSmDVrFklJScTExDBu3DhbKcKZM2cKjdAOGzYMwzD46quvSEhIIDAwkI4dO3LLLbdU0DMonYJVx5TYioiIiDPMnj2bp556qth9DRo0YPny5S6OyDUqVWILMHDgwBJLDyZOnFjosZubGzfffDM333yzCyJznEyVIoiIiIgTDRw4kA4dOhS7ryrMDlFelS6xrQlsia0WZxAREREn8Pf3x9/fv6LDcDllVi6Wm2uSe34eZZUiiIiIiDiOMisXKxitdXOHMixEIiIiImWgVeNqJiW2LnbhjAj6pRMREXEOwzDKvXiBVC6maZY6Z1Ji62KZ6ZoRQURExNnq1KnDuXPnlNxWA+np6YSGhpbqWH0Y7mKaEUFERMT5fHx8qF+/PqdOndKKZlWcr68vQUFBpTpWia2LaXEGERER1/Dx8SEmJqaiwxAXUnblYlqcQURERMQ5lF25mEoRRERERJxDia2LFSS2PhqxFREREXEoZVcuZJqmrRTBS4mtiIiIiEMpu3Kh7CyTgpsyVYogIiIi4lhKbF2ooAzBy9vAYlFiKyIiIuJISmxdSDMiiIiIiDiPMiwXykjXjAgiIiIizqLE1oWyMrU4g4iIiIizKMNyocx0lSKIiIiIOIsyLBfK0OIMIiIiIk6jxNaF/lx1TN0uIiIi4mjKsFxIsyKIiIiIOI8yLBfJyzPJyS5IbFWKICIiIuJoSmxdpKAMweIGHp5KbEVEREQcTYmti1xYhmAYSmxFREREHE2JrYtkakYEEREREadSYusimhFBRERExLmUZbmIFmcQERERcS5lWS6iUgQRERER51Ji6yKZmSpFEBEREXEmZVkuolIEEREREedSluUCpmnaShF8VIogIiIi4hRKbF0gJ9vEmp/X4qURWxERERGnUJblAgWLM3h4Gri5acRWRERExBmU2LqAyhBEREREnE+JrQtkpJ+fEcFX3S0iIiLiLMq0XECrjomIiIg4nzItF9DiDCIiIiLO517RAVRXZnoa5rYNpAUEkJnRDNCIrYiIiIgzKdNylj+2Yv34TZL/98GfNbZKbEVEREScxq5M67vvviMhIcFRsVQvLTuApyd5p0+SmZYDqBRBRERExJnsKkX46quv+Oqrr7jiiiu46qqr6NatGz4+Po6KrUozvLwwWnYgb8t6snPy3z9oxFZERETEeezKtP71r39x6623kpqayn/+8x8eeOAB3n77bTZt2oS1YKmtGsxofyVZnsH531vA00sjtiIiIiLOYteIbWhoKDfccAM33HADR44cYcWKFaxcuZLVq1cTEBBA9+7d6dWrF02aNHFUvFWK0aYzmd/MB8Db04phKLEVERERcRaHzYoQFRXFrbfeyq233squXbuYP38+ixYtYtGiRURERHDVVVdx9dVXExQU5KhLVnqGfwB5TToC4J2TAoRWbEAiIiIi1ZhDiz6zs7NZuXIl33//PRs3bsRisdC+fXsaNGjAnDlzePTRR1m3bp0jL1np5cW2BcAr+WQFRyIiIiJSvdk9YmuaJlu3bmX58uWsX7+ezMxMYmJiuP322+nZs6dthDYxMZF//vOfTJ8+nS5dutgdeFWRHd4Y4jPwTjiCmdQMI1ijtiIiIiLOYFdiO23aNFavXk1SUhIhISFcc8019O7dmwYNGhQ5NiQkhH79+vH+++/bc8kqJyPPE8jAOysRc8tajD7XVXRIIiIiItWSXYntr7/+SpcuXejduzetW7e+7M1RzZs3Z/To0fZcsspJT82fw9YrMxFzy0lQYisiIiLiFHYlth999BHe3t6lPj48PJzw8HB7LlnlpKXlAuCdlQB/7MdMT8Pw9avgqERERESqH7tuHsvNzeXw4cMl7j9y5Aipqan2XKJKM02TtPMjtt5BPpCXi7ltQwVHJSIiIlI92ZXYTps2jQ8//LDE/R9++CH//e9/7blElZabA7k5JgA+LZoDYG5eXZEhiYiIiFRbdiW2O3bsoGPHjiXu79ixI9u2bbPnElVaZkb+6mseHgbuHTrnb9y+CTM7qwKjEhEREame7EpsU1JSCAwMLHF/QEAAycnJ9lyiSitIbL19DYiOhdAwyMqEXb9XcGQiIiIi1Y9diW1wcDAHDx4scf+BAwcumfhWdxkFia23BcMwMNp1A1SOICIiIuIMdiW2nTt3ZvHixWzYUPSGqPXr17NkyZIatRjDxTLTC0Zs87vZaH8+sf19HWZeXoXFJSIiIlId2TXd14gRI9i2bRuvv/46MTExtoUZjh49yqFDh4iMjGTEiBEOCbQqyszIv3HM2+f8+4cmLcE/AFLPwb6d0Kx1BUYnIiIiUr3YNWLr6+vLlClTGDZsGLm5uaxZs4Y1a9aQm5vLsGHDmDJlCn5+NXfOVluN7fnE1nBzw2iTP4Jtbl5TYXGJiIiIVEd2jdgCeHt7M2LECIeNzC5cuJC5c+eSlJREdHQ09957L7GxsSUen5aWxpdffsm6detITU2ldu3a3HXXXXTo0MEh8dijILH18f1zRTajfTfMVb9ibl6D+df7L7tam4iIiIiUjt2JrSOtWrWK6dOnM2rUKJo0acL8+fOZMmUKb7/9NkFBQUWOz83N5aWXXiIwMJD/+7//IzQ0lDNnzuDr61sB0Rd18YgtAC3agZc3JMTDkf35syWIiIiIiN3sTmyzs7NZu3YtBw8eJD09HavVWmi/YRiMHj26VG3NmzeP/v3707dvXwBGjRrFpk2bWLJkCUOHDi1y/OLFi0lNTeXFF1/E3T3/qVSWJXutVpPMzItqbAHD0wtadoBNqzA3rcFQYisiIiLiEHYltvHx8UyaNIn4+Hh8fX1JT0/H39/fluAGBATg7e1dqrZyc3M5cOBAoQTWYrHQunVr9uzZU+w5GzdupEmTJnzyySds2LCBwMBAevTowdChQ7FYii8fzsnJIScnx/bYMAx8fHxs3ztKTrYJJhhG/nRfXNC0pcOVWDetwtyyGuOmOxx2zZqu4Oen8g7XUH+7lvrbtdTfrqX+FkexK7H973//S3p6OlOmTCE8PJxRo0bxxBNP0KxZM3788UcWLlzI+PHjS9VWSkoKVquV4ODgQtuDg4M5ceJEseecOnWK+Ph4evbsyXPPPUdcXBwff/wxeXl53HzzzcWe8+233zJ79mzb44YNGzJ16lRq165duiddSqfjMoBkfP3cqVuvbqF91muGcPyzt+HEUcKs2XjUj3botWu6iIiIig6hRlF/u5b627XU366l/hZ72ZXY7tixgwEDBhAbG0tqaioApmni4eHBDTfcwLFjx5g2bRrPPfecQ4K9mGmaBAYG8uCDD2KxWGjUqBEJCQn88MMPJSa2N954I0OGDLE9Lnh3GB8fT25ursNiS07MJaK+B4GBvsTFxWGaZqH9RvM2mDs2c3rRD1iuG+6w69ZkhmEQERFRbH+L46m/XUv97Vrqb9cqT3+7u7s7fFBKqj67EtusrCxbTWvBx/np6em2/U2bNuW///1vqdoKDAzEYrGQlJRUaHtSUlKRUdwCwcHBuLu7Fyo7qF+/PklJSeTm5trqbi/k4eGBh4dHse058o9XYLAbXXr5U7duXU6ePFm07XbdYMdmrJtWYwwc5rDrSv7PUf8RuY7627XU366l/nYt9bfYy655bMPCwjh79iwAbm5uhIaGsnfvXtv+Y8eO4enpWaq23N3dadSoEdu3b7dts1qtbN++naZNmxZ7TrNmzYiLiyt0w9rJkycJCQkpNqmtTIx2XfMLcA/uwUw8W9HhiIiIiFR5diW2rVq1KrScbp8+fZg/fz7/+c9/+Pe//82iRYvo2LFjqdsbMmQIv/76K0uXLuXYsWN8/PHHZGVl0adPHwDee+89ZsyYYTt+wIABpKamMm3aNE6cOMGmTZv49ttvufbaa+15Wi5hBIdCo2YAmFvWVnA0IiIiIlWfXcOaQ4cOZd++feTk5ODh4cGNN95IYmIia9euxWKx0LNnT+68885St9e9e3dSUlKYNWsWSUlJxMTEMG7cOFspwpkzZwrdMRkWFsb48eP5/PPPefrppwkNDeW6664rdmqwysho3w1z/x+Ym1dD30EVHY6IiIhIlWaYKmYB8m8eu3AaMEcwDKPkGlvAPH0C6/iHwM0Ny5v/xfDzd+j1a5rL9bc4lvrbtdTfrqX+dq3y9LeHh4duHpMiyl2KkJWVxb333ssPP/zgyHhqFCO8HtSLgrw8zO0bKzocERERkSqt3Imtl5cXbm5ueHl5OTKeGsdo2yX/m9/XVWwgIiIiIlWcXTePde3alTVr1uhjGjsUJLbm9k2YuY4thRARERGpSey6eax79+588sknTJo0if79+1O7du1ip/dq1KiRPZep3ho2hYAgOJcMe3fCFW0rOiIRERGRKsmuxHbSpEm273ft2lXicTNnzrTnMlVSYkYu64+nEnjaypXhJQ+MGxYLRtsumCt+xvx9HYYSWxEREZFysSuxHT16tKPiqHYOJWXx/to46gUlceX1DS95rNG2c35iu2Ut5l/vLzSlmYiIiIiUjl2JbcHCCVJUszBvLAacSM4kPi2HMN9LdPUV7cDDE86ehuOHITLGVWGKiIiIVBt23TwmJfP1cKNxqDcAO0+nX/JYw8vbVltranYEERERkXKxa8T2X//612WPMQyjxpYstAz3Ze/ZTHacTueqmMBLHmu07YK5dX1+Yjt4hIsiFBEREak+7Epsd+zYUWSb1WolKSkJq9VKYGBgjZ7ntmW4L9/tSmDHZUZsAYw2nTEBDu7BTE7ECApxenwiIiIi1Yldie37779f7Pbc3Fx++eUX5s+fzwsvvGDPJaq0K8J9ADianE1SZi7B3iV3txEcmj/118E9mFvXY/Qa4KowRURERKoFp9TYuru7M3DgQNq2bcsnn3zijEtUCYFe7jQO8wNg1+mMyx5vW6xBdbYiIiIiZebUm8eio6MvOb9tTdA+MhigdOUIbTvnf7NzC2ZWlhOjEhEREal+nJrYbt26tUbX2AK0bxAMlC6xpX4M1AqHnGzYtcWZYYmIiIhUO3bV2M6ePbvY7WlpaezatYuDBw/yl7/8xZ5LVHkFI7aHkrJIy87Dz9OtxGMNw8ifHWHxvPxVyNp1dVGUIiIiIlWfXYnt119/Xex2Pz8/6tSpw6hRo+jfv789l6jyavt7UTfAg5PncvgjPoOO9f0vebwtsd26HtNqxbBoqmERERGR0rArsZ05c6aj4qjWWob7cvJcMjtOp182saVpS/DxhZQkOLQXGjVzSYwiIiIiVZ2GA12gZbgvADtKMzOCuwdGq46AZkcQERERKQu7EtutW7cyY8aMEvd/+eWXbN++3Z5LVAst6+QntvsSMsjKtV7+BE37JSIiIlJmdiW2c+bM4ezZsyXuT0hIYM6cOfZcolqo4+dBLV93cq2w+0wpRm1bdQSLBY4fxoyPc0GEIiIiIlWfXYntkSNHaNKkSYn7GzduzJEjR+y5RLVgGIatHGFnacoR/PyhSUtAo7YiIiIipWVXYpubm0tubu4l92dpoQEAWp5fXrdU89miVchEREREysquxLZBgwasW1d84mWaJmvXriUyMtKeS1QbLc6P2P5xJoOcPPOyxxcktuzdgZme6szQRERERKoFuxLbgQMHsnv3bt566y2OHDlCXl4eeXl5HD58mLfeeos9e/YwcOBAR8VapTUI9CTQy43sPJP9CZmXPd4Irwt1G0BeHub2TS6IUERERKRqs2se26uuuopTp04xZ84c1q5di+X8YgJWqxXDMBg2bBh9+vRxRJxVnmEYtAj3Yc3RVHacTqd5bZ/Ln9OuC+bJo/D7OuhylQuiFBEREam67EpsAW6++WZ69erFunXrOH36NAB16tShc+fORERE2B1gddIy3NeW2A5rWeuyxxttu2L+OAdz20bM3FwMd7t/XCIiIiLVlkMypYiICG644QZHNFWtFcyMsCs+gzyriZvFuPQJDZtAQBCcS4a9O+CKti6IUkRERKRqsqvG9sCBAyxatKjE/YsWLeLQoUP2XKJaiQn2wsfdQnqOlcNJl58twrC4YbTpBGh2BBEREZHLsSux/eqrr9i2bVuJ+7dv385XX31lzyWqFTdLfp0tlGXar65AfmJrmpefTUFERESkprJ7xLZ58+Yl7r/iiivYv3+/PZeodgqm/dpRioUa8k9oB+4ecOYUHD/svMBEREREqji7EtuMjAzc3NxK3G8YBunppRuZrCkKFmrYeTq9VCOwhpc3tGwPgLlplVNjExEREanK7Eps69aty++//17i/i1btlCnTh17LlHtxIb64OlmkJyVx/GU7FKdY3TsAYC5YaXKEURERERKYFdi269fPzZv3sznn39OWlqabXtaWhrTpk1jy5Yt9OvXz+4gqxMPN4NmYQV1tqUrRzDadgF3dzh5FE4ccWZ4IiIiIlWWXdN9XXfddRw6dIgFCxbw448/EhISAkBiYiKmadKrVy8GDx7skECrk5bhPmw7lc6O0+lc2yT4sscbvn7QsgP8vg5zwwqM+tHOD1JERESkirErsTUMgzFjxnDVVVexdu1a2wINnTt3pmvXrrRs2dIhQVY3+fPZnmX7+Tpbw7jMfLaA0aln/swIG1Zg3nBrqc4RERERqUkcskBDq1ataNWqVZHtVquVzZs307FjR0dcptpoFuaDmwFn03M5nZZDHX/Py55jtO2C6e4Bccfh+CGIbOj8QEVERESqEKes0bp7926WL1/OmjVrOHfuHDNnznTGZaosL3cLsbW82X0mkx2nM0qX2Pr4QquOsGUN5vqVGEpsRURERApxWGJ77NgxVqxYwYoVK4iPj8fb25u2bdtqtLYELcN9zye26fRrFFSqc4xOPTC3rMkvRxh6m8oRRERERC5gV2KbkJDAypUrWbFiBYcOHcLT05Ps7GxGjhzJ9ddfj7u7UwaEq4WW4b58szOBnaVcgQzAaNsZ08MTTp+AowchqpETIxQRERGpWsqceaanp7NmzRpWrFjBrl278PT0pGPHjvz1r38lPDycJ598knr16impvYzmtX0wgBPnckjIyCXU5/L9ZXj7QuuOsGl1/uwISmxFREREbMqcfT7wwAMAtG/fnscee4yOHTvi6ZlfIxoXF+fY6Koxf083YkK8OJiYxc7T6fSMDizVeUannpibVmNuXIl54x0qRxARERE5r8wLNOTk5ODn50d4eDh16tSxJbVSdvnTflG2coTWncDTE06fhKMHnBWaiIiISJVT5hHbt956i+XLl7NixQrmzZtHREQEPXr0oEePHri5uTkjxmqrZbgP83YnlnoFMgDD2wdadYJNq86XIzR2YoQiIiIiVUeZE9v69eszcuRIRo4cyR9//MHy5ctZtGgRc+bMITw8HIBz5845PNDqqMX5EdvDSVmkZOUR6FW6Nwb55QirMDesxLzxTpUjiIiIiGDnrAjNmzenefPm3HvvvWzevJnffvuNxMREPvroI3744Qc6depEx44dtQJZCYK93WkQ5MnR5Gx2nErnyqiAUp1ntOmE6ekJ8XFwZD9Exzo5UhEREZHKzyFTF7i5udGpUyc6depERkYGa9euZfny5SxYsID58+drgYZLaBPhx9HkbH6PSyt9YuvljdG6c/4NZOtXYCixFRERESl7YpucnExQUMkLCvj4+NCnTx/69OlDQkICq1atsivA6q5NHV/m705k26nS30AGYHTumZ/YbliBOewulSOIiIhIjVeu6b4aN25Mhw4d6NChA40alTyXamhoKEOGDLErwOquVbgvFgOOpWRzNj2HWr4epTyxE3h6wdnTcGgfNGzi3EBFREREKrkyJ7ZPP/00mzdvZvHixXz99dcEBQXRrl07OnbsSJs2bfDx8XFGnNWWv5cbjUK82ZeQybZT6fRpWMrldb28MNp2wVy/PH92BCW2IiIiUsOVObEtqKUFOHLkCJs2bWLz5s28/fbbGIZBs2bNbKO59evXd3jA1VGbCF/2JWTye1zpE1sAo1OP/MR240rM4XerHEFERERqNLtuHouKiiIqKoqhQ4eSnp7Oli1b2Lx5Mz/88ANffPEF4eHhtG/fng4dOtCyZUs8PEr5MXsN0ybCj292JrAtLg3TNEufoLbqCF7e58sR9kLDps4NVERERKQSc8isCAC+vr50796d7t27A7Bv3z7baO5PP/3E8OHDGT58uKMuV61cUdsHdwvEp+cSl5pD3YDSreZmeJ4vR1j32/lyBCW2IiIiUnM5LLG9WGxsLLGxsYwYMYLk5GTS08t2139N4u1uoVmYDztOZ7A1Lr3UiS2A0bGHLbE1h9+jcgQRERGpsSz2nHzmzBn++OOPQtsOHTrEe++9xz/+8Q/WrVsHQFBQEHXr1rXnUtVemzp+AGw9lVa2E1t1AC8fSDgDB3Y7ITIRERGRqsGuxPbTTz/l66+/tj1OSkpi0qRJrF27ll27dvHmm2+ydu1au4OsCVpH5C+vuy0uHatplvq8gnIEAHPDSqfEJiIiIlIV2JXY7t+/n9atW9se//bbb2RnZ/P666/zn//8h9atWzN37ly7g6wJmtbywcvNIDkrjyNJWWU61+jcAyB/dgSr1RnhiYiIiFR6diW2qamphVYh27hxIy1atCAiIgKLxUKXLl04fvx4mdtduHAhDz/8MLfddhvjxo1j3759pTpv5cqVjBgxgtdee63M16xoHm4GLcLzR223lnEVMlp2AG8fSFQ5goiIiNRcdiW2gYGBxMfHA5CWlsbevXtp27atbb/VasVaxhHEVatWMX36dIYPH87UqVOJjo5mypQpJCcnX/K806dP89///pcrrrii7E+kkmhzvhxha1wZl9f18MRo1xUAc+1SR4clIiIiUiXYldi2bt2aH3/8kXnz5vHee+9hmiZdunSx7T927Bi1atUqU5vz5s2jf//+9O3bl8jISEaNGoWnpydLliwp8Ryr1cq7777LiBEjCA8PL/fzqWgFN5DtOJ1OnrX0dbYAxpX9ADDX/oaZXbZSBhEREZHqwK7E9tZbbyUyMpL//ve/bN26lTvuuMOWWObk5LB69WpatWpV6vZyc3M5cOBAobpdi8VC69at2bNnT4nnzZ49m8DAQPr161f+J1MJNAzxws/TQnqOlX0JmWU7uXkbqBUOGWmYm1Y7J0ARERGRSsyueWyDg4N58cUXSU9Px9PTE3f3P5szTZMXXniBsLCwUreXkpKC1WolODi4yHVOnDhR7Dl//PEHixcvLnVdbU5ODjk5ObbHhmHg4+Nj+96RCtorbbvubgat6/ix5ug5tp1Kp3lt39Jfy80NelyN9YcZsPIXjCv7livmqqys/S32UX+7lvrbtdTfrqX+FkdxyAINvr5FEzBPT09iYmIc0XyJMjIyePfdd3nwwQcJDAws1Tnffvsts2fPtj1u2LAhU6dOpXbt2s4Kk4iIiFIf26tpHmuOnuOPhNwyz/2be+MtnJz7JeYfW6ltWHGPqF/WUKuFsvS32E/97Vrqb9dSf7uW+lvsZVdiu23bNg4ePMgNN9xg27Z48WK+/vprcnNz6dGjB3feeScWS+kqHgIDA7FYLCQlJRXanpSUVGQUF+DUqVPEx8czdepU2zbz/BywI0eO5O233y7yS3LjjTcyZMgQ2+OCd4fx8fHk5uaWKs7SMgyDiIgI4uLibHFdToxvfgy/H0/i8LHjeLqVrVrEuKIt5s4txH07A7eht5c55qqsPP0t5af+di31t2upv12rPP3t7u7u1EEpqZrsSmy//vrrQqUGR44c4aOPPiIqKoqIiAh+/PFHgoODGTp0aOmCcXenUaNGbN++3XYTmtVqZfv27QwcOLDI8fXq1eONN94otO2rr74iMzOTu+++u9gyCA8PDzw8PIq9vrP+eJmmWeq26wd4EOLtRmJmHrtOp9Mmwq9sF+txNezcgrnqV6zXj8SwuJUj4qqtLP0t9lN/u5b627XU366l/hZ72XXz2PHjx2ncuLHt8W+//YaPjw+TJ0/miSeeoH///vz2229lanPIkCH8+uuvLF26lGPHjvHxxx+TlZVFnz59AHjvvfeYMWMGkF/uEBUVVejLz88Pb29voqKiCtX8VhWGYdD6fDK7razz2QJG+27g65+/xO7O3x0dnoiIiEilZVdim5mZabvxCmDLli20a9cOLy8vAGJjY23z3JZW9+7dueOOO5g1axbPPPMMhw4dYty4cbZShDNnzpCYmGhP2JVe23LOZwvn57Tt2hsAc+UvDo1LREREpDKza0gzLCyM/fv3069fP+Li4jh69Gih+tXU1NQSP/a/lIEDBxZbegAwceLES5778MMPl/l6lU3rOvmJ7d6zGaTn5OHrUbZyAqPnNZhL5mNuWYOZmoLhX7ob60RERESqMrsS2549ezJ79mwSEhI4duwYfn5+dO7c2bb/wIEDZb6zX6COvycR/h7Epeaw83QGner7l+l8I6oRRDWCIwcw1y7D6H+9kyIVERERqTzsKkW46aabGDp0KGfPniUsLIynn34aP7/8+tDU1FR27NhBp06dHBJoTVMwars1Lq1c5xs9rwHAXPGzCvFFRESkRrBrxNbNzY1bbrmFW265pcg+f39/PvroI3uar9HaRPjx8/5ktpbjBjIAo0tvzFmfwrFDcGQ/RMc6NkARERGRSsauEdsLZWZmcuzYMY4dO0ZmZhmXg5Ui2pwfsT2YmEVKZtnn1zX8/DE6XAmAuUI3kYmIiEj1Z/d8WPv27eN///sff/zxB1arFQCLxULz5s25/fbbC00HJqUX7ONOVJAnR5Kz2XY6nR5RZb8BzOhxNea63zDXLsO8+R4MTy8nRCoiIiJSOdg1Yrt3714mTJjAgQMH6NevH3fddRd33XUX/fr14+DBg0yYMIF9+/Y5KtYap2Bxhm3lmPYLgOZtoFY4ZKRhbl7jwMhEREREKh+7EtuvvvqK0NBQ/vnPfzJq1CgGDRrEoEGDGDVqFG+//TYhISF8+eWXjoq1xikoR/i9nImtYbFgdO8P5N9EJiIiIlKd2T1ie80119gWT7hQcHAwV199NXv37rXnEjVayzq+WAw4cS6bM+k55WrD6NEfDAP+2IoZH+fgCEVEREQqD7sSW8MwyMvLK3G/1WrFMAx7LlGj+Xu60TjUGyjfKmQARq1wuKItAOaqXx0Wm4iIiEhlY1di26xZMxYtWlTssrlnzpzhp59+onnz5vZcosYrmM9226nyzWcL+TeRQX5ia1pLfiMiIiIiUpXZNSvCLbfcwoQJE3j88cfp0qWLbZWxEydOsGHDBiwWS7Fz3ErptY3w45udCWyNS8c0zXKNgBvtu2H6+kPCGdi1FVq2d0KkIiIiIhXLrsS2YcOGvPzyy3z55Zds2LCB7OxsADw9PWnXrh0333wzAQEBDgm0prqitg/uFoMz6bmcPJdDvUDPMrdheHhidO2NuWQ+5oqfMZTYioiISDVk9zy2kZGRPP3001itVlJSUgAIDAzEYrHwzTffMHPmTGbOnGl3oDWVl7uF5rV92H4qnY0nUqkXGFqudoye1+QntlvWYKamYPiXfV5cERERkcrMYSuPWSwWgoODCQ4OxmJxWLMCdK6fP5/t+uOp5W7DiGoEUY0gNxdz7TJHhSYiIiJSaSgDrQI6188v59hxOp30nPLf/GX0vAbQ7AgiIiJSPSmxrQLqB3pSL8CTXCtsPmHH7Aide4GbOxw5gHn8sAMjFBEREal4SmyriC6R/gCss6ccwT8QWncCwFy9xCFxiYiIiFQWZb557MCBA6U+NiEhoazNSwk61/fnu10JbDyRRp7VxM1SvoUvLFf2xbplDebapZg33YFhcXNwpCIiIiIVo8yJ7XPPPeeMOOQyrqjtg7+nhXNZeew+k0GLcN/yNdS6E/gFQFIC/LEVWmjqLxEREakeypzYjh492hlxyGW4WQw61PPnt0MprD+eWu7E1vDwwOjcC3PpAszVSzCU2IqIiEg1UebEtk+fPk4IQ0qjc/38xHbdsVTuah9e7naMK/vmJ7abVmPeloHh7ePAKEVEREQqhm4eq0I61PXDYsCxlGxOnssuf0MNm0Kd+pCdhblpteMCFBEREalASmyrEH8vN1sJwgZ7ZkcwDIxufQAw12h2BBEREakelNhWMV3q2z/tF2BLbPljK2ZCvJ1RiYiIiFQ8JbZVTOfzie2OU+mkZduxCllYHWjaCkxTS+yKiIhItaDEtoqpF+hJ/UBP8kzYfLL8q5BB/k1kkL9Yg2majghPREREpMIosa2CCkZt1x+zsxyhYw/w8ISTR+HwPkeEJiIiIlJhlNhWQQV1thtPpJJnLf9Iq+Hji9G+G6AldkVERKTqU2JbBTUvWIUs28ofZzLsasvodr4cYd1vmLm5jghPREREpEIosa2C3CwGHes5phyBFu0gMBhSU2DHJrtjExEREakoSmyrKFudrb3Tfrm5YXTtDYB19WK74xIRERGpKEpsq6j29fxwc8QqZIBxZb/8b35fh5lm5wiwiIiISAVRYltF+Xv+uQqZ3aO2DRpCZAzk5mJuWOGA6ERERERcT4ltFeaoab/gwjltVY4gIiIiVZMS2yqsS+T5VchO27cKGYDRpTcYFtj/B+bpk44IT0RERMSllNhWYXUDPIk8vwrZphN2rkIWHAot2gJgrtGctiIiIlL1KLGt4hw1OwL8eROZltgVERGRqkiJbRXXOdIxq5ABGO26gZcPnDkF+3Y5IjwRERERl1FiW8U1D/MhwNNCaraVP+LtXIXMywujU3dAN5GJiIhI1aPEtoortAqZI8sR1i/HzMq0uz0RERERV1FiWw10cmCdLU1aQu0IyMzAXL/c/vZEREREXESJbTXQwZGrkFksGFddC4D52yJHhCciIiLiEkpsqwE/Tzdanl+FbO2xc3a3Z3TvD27ucHAP5pEDdrcnIiIi4gpKbKuJbg0CAFhx2AGJbWAwRvtuAJjLNWorIiIiVYMS22qiR1QAFgP2ns20uxwB+LMcYc1S3UQmIiIiVYIS22oi2MedNnXyyxFWHE6xv8FmrSG8bv5NZOt+s789ERERESdTYluN9IoJBGC5I8oRLBaMXgMAMJf/ZHd7IiIiIs6mxLYa6RYZgLsFDidlcSQpy+72dBOZiIiIVCVKbKsRfy832tfNn9N2uQPKEXQTmYiIiFQlSmyrmV7R+bMjLD+cgmmadrdX6CayTPuW7BURERFxJiW21UyXyAA83QxOnsthf4L95QiFbiLTSmQiIiJSiSmxrWZ8PCx0ru/AcgStRCYiIiJVhBLbaqhgdoQVh1OwOqIc4cp++TeRHdqLeWS/3e2JiIiIOIMS22qoYz0/fNwtnEnPZXe8/XWxRmAwRocrAY3aioiISOWlxLYa8nSz0K1BfjnCb45YrAH+nNN27TLdRCYiIiKVkhLbauqq8+UIK4+cI89qfzkCzdvoJjIRERGp1NwrOoDiLFy4kLlz55KUlER0dDT33nsvsbGxxR77yy+/8Ntvv3H06FEAGjVqxC233FLi8TVFmwg/ArzcSM7MY9updNrV9bOrPcMwMK66FnP2tPxyhPMjuCIiIiKVRaUbsV21ahXTp09n+PDhTJ06lejoaKZMmUJycnKxx+/cuZMePXowYcIEXnrpJWrVqsVLL71EQkKCiyOvXNwtBt0b/DmnrSMY3fuDu24iExERkcqp0iW28+bNo3///vTt25fIyEhGjRqFp6cnS5YsKfb4xx57jGuvvZaYmBjq16/PQw89hGmabNu2zcWRVz69YvIT29VHz5GT54DZEQKCMNrrJjIRERGpnCpVYpubm8uBAwdo3bq1bZvFYqF169bs2bOnVG1kZWWRm5uLv7+/s8KsMlrU9iXEx520bCubT6Y6pE3bnLa6iUxEREQqmUpVY5uSkoLVaiU4OLjQ9uDgYE6cOFGqNv73v/8RGhpaKDm+UE5ODjk5ObbHhmHg4+Nj+96RCtpzdLul5e5m0DM6gLl/JLLi8Dm6Ngi0v9HmbaBOPTh1AtYvtyW6lUFF93dNo/52LfW3a6m/XUv9LY5SqRJbe3333XesXLmSiRMn4unpWewx3377LbNnz7Y9btiwIVOnTqV27dpOiysiIsJpbV/OTR19mfvHRtYdTyMkLBxvDze720wZfDPJn/4Tt9WLifjr3fYH6WAV2d81kfrbtdTfrqX+di31t9irUiW2gYGBWCwWkpKSCm1PSkoqMop7sR9++IHvvvuOF154gejo6BKPu/HGGxkyZIjtccG7w/j4eHJzc8sde3EMwyAiIoK4uDhMB6wAVh6hmIT7eXA6LYe5G/fRM9r+UVuzdWdwdydn705O/PYrRpMWDojUfpWhv2sS9bdrqb9dS/3tWuXpb3d3d6cOSknVVKkSW3d3dxo1asT27dvp0qULAFarle3btzNw4MASz/v+++/55ptvGD9+PI0bN77kNTw8PPDw8Ch2n7P+eJmmWaF/GHtFBzBnZwLLDyXTIyrA/gb9AzGu7Ie5/CfyFs7BLfYK+9t0oIru75pG/e1a6m/XUn+7lvpb7FWpbh4DGDJkCL/++itLly7l2LFjfPzxx2RlZdGnTx8A3nvvPWbMmGE7/rvvvmPmzJmMHj2a8PBwkpKSSEpKIjMzs4KeQeXT6/xiDRuOp5Gek+eQNo0BN4JhwO/rMI8fdkibIiIiIvaoVCO2AN27dyclJYVZs2aRlJRETEwM48aNs5UinDlzplBx+c8//0xubi5vvfVWoXaGDx/OiBEjXBl6pRUT7EVkoCfHUrJZczSVfo2C7G7TiKgPHa6EjaswF87BuO//HBCpiIiISPlVusQWYODAgSWWHkycOLHQ4/fff98FEVVthmHQKyaQL7eeYcXhFIcktgCW64Zj3bgKc91vmH+5DSOsjkPaFRERESmPSleKIM7RMzq/tnbLyTRSMh1zk5wRHQst2oHVivnTdw5pU0RERKS8lNjWEJGBXjQK8SLPhNVHHbNYA4Bl4DAAzBU/Y6YkOaxdERERkbJSYluD9Do/1dcv+5Mc12jzNhDTBHKyMRfPc1y7IiIiImWkxLYG6dcoCHeLwZ6zmew965jlcA3DwHLd+VHbJfMxM9Md0q6IiIhIWSmxrUGCfdxttbbzdic6ruF23SCiPqSnYf62yHHtioiIiJSBEtsaZkizEABWHE4hKcNBN5FZLBjX3gSA+fP3mDk5DmlXREREpCyU2NYwTWr50LSWN7lWWLQvyWHtGt36QHAtSErAXLPEYe2KiIiIlJYS2xqoYNT2x71J5Fods3Sh4e6BMWAoAObCbzCtjlnhTERERKS0lNjWQN2jAgnxdiMxI5dVR845rF2j1wDw9YfTJ2DzGoe1KyIiIlIaSmxrIA83g4FN8kdt5zvwJjLD2wej3xAArD/OwTQdMxosIiIiUhpKbGuoa5sE426BP85ksO9spsPaNfoNAU9POLwPdv3usHZFRERELkeJbQ0V4uNOj6j8BRvm70lwWLtGQCBGr2sBsC6c47B2RURERC5HiW0NNvj8TWS/HTpHUqZjpv4CMK75C7i5wa7fMQ/udVi7IiIiIpeixLYGaxbmQ5Na3uRaTX5y5NRftcIxulwFgHXhbIe1KyIiInIpSmxrONvUX3scN/UXgDEwf5ldNq/BPHbIYe2KiIiIlESJbQ3XIyqAYG83EjJyWXPUgVN/1YuCjt3BNLFOf0/z2oqIiIjTKbGt4TzcLFzbJBiAeQ6c+gvAMuJ+8PGFg3swF89zaNsiIiIiF1NiKwxsEoKbAbviMziQ4MCpv0LDMIbfDYD57ReY8XEOa1tERETkYkpshdALpv5y9Kit0XMANGsN2VlY//u+Fm0QERERp1FiK8CFU3+lkOzIqb8sFix3Ppy/aMOu3zFX/uKwtkVEREQupMRWAGgW5k1sqDc5VpOf9yU7tG0jvB7GX24DwJz1KWbSWYe2LyIiIgJKbOU8wzBso7YL9iaS58CpvwCM/jdATBPISMP6v/+oJEFEREQcTomt2PSKDiDI242z6bmsOea4qb8ADDc3LHc9mr8i2Za1sHGlQ9sXERERUWIrNh5uFq6NDQbg+12JDh9VNSJjMK67GQDrjA8wU1Mc2r6IiIjUbEpspZCBTYLxdDPYfSaDVUccO2oLYAy6Geo2gHPJmLM+cXj7IiIiUnMpsZVCavl6MKxFLQA+23SarFyrQ9s3PDzySxIMA3P1EsztGx3avoiIiNRcSmyliBtbhBLm6058ei7f7UpwePtG4+YY/a8HwPrff2Fmpjv8GiIiIlLzKLGVIrzcLdzTIRyA2TvOEp+W4/BrGENvh1rhkBCP+c1/Hd6+iIiI1DxKbKVYPaICaFHbh+w8k+lb4h3evuHljeXORwAwl8xXSYKIiIjYTYmtFMswDEZ1qoNB/mpku047vlzAaNEOo+c1AFjfn4K5abXDryEiIiI1hxJbKVGjUG+uiQ0C4KONp7E6YVEF49aHoMOVkJuL9T9Tsa781eHXEBERkZpBia1c0m1ta+PrYWF/QiaLDzh2qV04P0vCA89g9OgPphVz2j+x/vK9w68jIiIi1Z8SW7mkYG93RrYOA2D6lnjSc/Icfg3DzQ3jrscwrvkLAObMT7B+/z8tuysiIiJlosRWLmtQ0xDqBXiSnJnHrG1nnXINwzAwbr43f7YEwJw3E/PLDzGtjp1HV0RERKovJbZyWR5uBvd1zJ/+a+7uBE6kZDvlOoZhYBk8Ir/u1jDyZ0v49B+YublOuZ6IiIhUL0pspVQ61fenYz0/cq3w6abTTr2Wpe8gjPv+DywWzLXLsP77FczsLKdeU0RERKo+JbZSavd2CMfNgPXHU9l0ItWp17J07Y1lzHjw8ISt67H+cxJmhlYoExERkZIpsZVSiwzyYnCzEAA+2XiaXKtzb+4y2nbG8reJ4O0De7Zjff05zOREp15TREREqi4ltlImf20dRpCXG8dSsvlxj/OTTKNZKyxPvQwBQXD0INZXnsaMO+b064qIiEjVo8RWysTf043b29UG4MutZziS7PzaVyO6MZaxr0HtCDh7GuvUZzH3/+H064qIiEjVosRWyqx/oyCah/mQlmNl4uKjxKflOP2aRnjd/OQ2OhZSz2F963nM39c5/boiIiJSdSixlTJzsxiM7xNJZKAnZ9NzmbD4KCmZzp+SywgMxvLUFGjVEbKzsb7/MtbfFjn9uiIiIlI1KLGVcgn0cmNivwaE+bpzPCWbyUuPOWVVsosZ3j5YHh6P0ePq/CV4//s+1h9maJUyERERUWIr5Vfbz4NJ/RoQ4OXG3rOZvPrbcXLynL9SmOHujnHXoxiDRwBgzv0Kc/p7mHnOT6xFRESk8lJiK3aJDPLi730i8XY3+D0unX+sOkmek6cBg/OrlA29HeO20WBYMFf8jPX9l7BmZjj92iIiIlI5KbEVuzUN8+G5qyJxt8DKI+f4aMMpl5UGWPpch2XMWPDwxNy6gdNP3Yt5aJ9Lri0iIiKVixJbcYh2df34v+71MIAf9ybx5bYzLru20a4blv97EfwDyTm4l7yXn8Q6+zPMLC3DKyIiUpMosRWH6REdyIOd6wAwc9tZ5u923SphRuwVuE1+H5+rrgGrFXPRt1gnP4a5e5vLYhAREZGKpcRWHOq6piHc0iYMgI82nOK3Qykuu7YRGEzYs69geeR5CK4Fp09ifWM81v++j5me5rI4REREpGIosRWH+2urWgxuGowJvL3qBNM2nXbJVGAFLO26Ypn0HsZVAwEwf1uEdcLDmFvWuiwGERERcT0ltuJwhmFwf6c69GsURJ4J3+5KYPQPB/hlfxJWF91UZvj6YbljDJanXobwupCUgPX9KVg/eA0z2XUlEiIiIuI67hUdgFRPFsPgb1fWpUdUAJ9sPM2Jc9m8uyaOBXuSGNUpnCtq+7okDqNZKywT3smf6/anbzE3rMDcuArqNcBo2BQaNsFo2AzqRWG4ubkkJhEREXEOJbbiVJ3q+9M2wo/5exKYue0s+xMyGfvTEa6KCeSu9rUJ8/VwegyGpxfGsLswO/XE+sW/4NBeOH4Y8/hhWPEzJoCnF0Q3zk92Y5piNG6GEVrb6bGJiIiI4yixFafzcDMYekUt+sQE8cXv8fyyP5nfDqWw9ug5hreqxV+ah+Ll7vyqGCO6MW7j38RMSoBDezAP7sU8uCc/0c1Ih707MffuBMhPdutHY7TpjNGmMzRqimHRiK6IiEhlpsRWXCbYx51HutVlYJMQPt54il3xGfzv9zP8vC+Jvo2C6Fzfn8ah3lgMw6lxGMGh0K4bRrtuAJhWK5w6np/kFiS7Rw7YRnXNH2eDfwBGq04YbTtDi/YYvn5OjVFERETKTomtuFxsLW9euSaK5YfPMW3zaU6n5TJz21lmbjtLiI87ner50Tkyv4TB2xUjuRYL1G2AUbcBdO8PgJl2DnP7Jti6HnP7Rkg9h7lmCeaaJeDmBk1aYrTuiFEvGmpHQK3aGO7OL6sQERGRkimxlQphGAZXxQTSJdKfVUfOse5YKptPppGYkcvP+5P5eX8ynm4Grev40rm+P50j/V1Sj2uLzy8Ao2tv6NobMy8P9u3C3Loec+t6iDsGf2zF/GMrtjkeDAuEhkFYHYzwuhBWB2pHYIRFgH8AePvkf7l7YDh5RFpERKSmMkzTRfMvlcHChQuZO3cuSUlJREdHc++99xIbG1vi8atXr2bmzJnEx8cTERHBbbfdRocOHcp0zfj4eHJycuwNvRDDMKhbty4nT56kEnZzpZOTZ2X76QzWH09l/bFUTqcV/nmE+rgTGehJZJAnkYFeNAjyJDLIixBvNwzDcFl/m6dP5Ce5u7dDfFz+V3Ypl+91cwMvnz8TXW8f8PbF8PMH/8D8r4AgjIA/vycgEPwCK92sDXp9u5b627XU365Vnv728PCgdm3d5CuFVbrEdtWqVbz33nuMGjWKJk2aMH/+fNasWcPbb79NUFBQkeN3797NhAkTuPXWW+nQoQMrVqzg+++/Z+rUqURFRZX6ukpsKxfTNDmSnM36Y6msP57K7jMZlNSDfh4W6gd60iDIi4Z1QrDkZhDg6UaQtxuBXn9+ebg5p6zBNE1ISYL4OMyCRPdMHGb8KThzCjLSICvT/gv5+P2ZDPv4grcv+PhgePv+uc3LG9w9zn+5548Qn/8X278e4O2dn2D75J9bnjIKvb5dS/3tWupv11JiK45S6RLbcePG0bhxY+677z4ArFYro0eP5rrrrmPo0KFFjv/HP/5BVlYWY8eOtW0bP3480dHRPPDAA6W+rhLbyi0tO49jKdkcS87iWEo2R5OzOZaSxanUHKyl7FofdwtB3m74eVrwcrPg6W7B293Ay82Cl+1fC15uBh5uBu4WA4th4Gbhz++N899b8r+3GAYGYBR8b/DnY/58jGmF7GyM7CyMnCzIzsr/PjsrP+nNTIP0dIz0c5hpqRgZaZCWCumpkJGOYVqB820B5+dtwDj/3I0L0v6ihQ5FO8i4eJO7G4anF3h6g5dXfoJcXMnERa9jTw93cnJy8481LAUdcf5cw7bdsBhgKdjvln9swWM3t/PHAJzfbilor+A48v+1PR3zz3guei5/9oVRuENsz6fgX/Oi880izw83N1t8hb93Px+j2wXdVHC9C/rtgkvlX8ssePDntS685oX9WKg/8/siKDCQ5JQksFr/jL2gXdMErBS9uPHnt7afyQXbbdcCOP/v+ccGRfuXYrdR+BpFtl/YN8X9XC7aVrTREq5fzM/wwnMLnt+Fjwv1wUXXMf587RoWg+CQEJISEzGL/JG5RAdc6vVQWqVpw/a6ueD5l/X/mUL9UIZ4S7rOxede0LaHtzehDaMvEYoSW3GMSlVjm5uby4EDBwolsBaLhdatW7Nnz55iz9mzZw9DhgwptK1t27asX7++2ONzcnIKJbCGYeDj42P73pEK2lNNpf38vdxpXtud5hct7JCdZ+XkufxE93hKNpl4EpeYQkpWHsmZeaRk5ZKSlYfVhIxcKxmp1hKuUBE8z38FAOf/OFvOPwyosKAqnpXC+ZlcJLSiA6hBUoDKVQL0p4vfqFXEtUvLpFnWIV5vFFNyi/r/UhykUiW2KSkpWK1WgoODC20PDg7mxIkTxZ6TlJRUpEQhKCiIpKSkYo//9ttvmT17tu1xw4YNmTp1qlPf9UVERDitbYFooNsl9ltNk9SsXJIyckhMzyE1K5esnDwyc/PIzLEW/Tcnj6xcK3mmSW6elTyrSa5pkptnkmc1z2/P/9d6frTIappYzfyyBCv5/5rnt/85sGYWGlgxMYsdbCo4yjagd8E5F24pbpCm6OBa0ZEPs8gDM3+E5HxMfwZ10cjnpdopbgTLvMRxZrGHlri/hE1OVeL1zEvurQQMKm18l3qt2qHI4GvJL6MSVIb+qt4JnaeHO3Xr1r3scfr/UuxVqRJbV7jxxhsLjfAWvDuMj48nNzfXodcyDIOIiAji4uJUiuACl+tvDyDcAuE+gE/BVsv5Lykrvb5dS/3tWupvxzt58mSJ+8rT3+7u7ipFkCIqVWIbGBiIxWIpMtqalJRUZBS3QHBwMMnJyYW2JScnl3i8h4cHHh7F3yjjrD9e+aN3+sPoKupv11J/u5b627XU366l/hZ7VaqhKnd3dxo1asT27dtt26xWK9u3b6dp06bFntO0aVO2bdtWaNvWrVtp0qSJU2MVERERkcqlUiW2AEOGDOHXX39l6dKlHDt2jI8//pisrCz69OkDwHvvvceMGTNsxw8aNIjff/+duXPncvz4cWbNmsX+/fsZOHBgBT0DEREREakIlaoUAaB79+6kpKQwa9YskpKSiImJYdy4cbbSgjNnzhS6a7JZs2Y89thjfPXVV3z55ZfUrVuXp59+ukxz2IqIiIhI1Vfp5rGtKJrHtupTf7uW+tu11N+upf52Lc1jK45S6UoRRERERETKQ4mtiIiIiFQLSmxFREREpFpQYisiIiIi1YISWxERERGpFpTYioiIiEi1oMRWRERERKoFJbYiIiIiUi0osRURERGRaqHSLalbUdzdndcVzmxbilJ/u5b627XU366l/natsvS3fjZSHC2pKyIiIiLVgkoRnCgjI4Nnn32WjIyMig6lRlB/u5b627XU366l/nYt9bc4ihJbJzJNk4MHD6JBcddQf7uW+tu11N+upf52LfW3OIoSWxERERGpFpTYioiIiEi1oMTWiTw8PBg+fDgeHh4VHUqNoP52LfW3a6m/XUv97Vrqb3EUzYogIiIiItWCRmxFREREpFpQYisiIiIi1YISWxERERGpFpTYioiIiEi1oIWWnWThwoXMnTuXpKQkoqOjuffee4mNja3osKqFnTt38sMPP3Dw4EESExN56qmn6NKli22/aZrMmjWLX3/9lbS0NJo3b879999P3bp1KzDqqunbb79l3bp1HD9+HE9PT5o2bcrtt99OvXr1bMdkZ2czffp0Vq1aRU5ODm3btuX+++8nODi44gKvon766Sd++ukn4uPjAYiMjGT48OG0b98eUF8723fffceMGTMYNGgQd999N6A+d6RZs2Yxe/bsQtvq1avH22+/DaivxTE0YusEq1atYvr06QwfPpypU6cSHR3NlClTSE5OrujQqoWsrCxiYmK47777it3//fff8+OPPzJq1ChefvllvLy8mDJlCtnZ2S6OtOrbuXMn1157LVOmTOH5558nLy+Pl156iczMTNsxn3/+ORs3buT//u//mDRpEomJibz55psVGHXVFRoayq233sqrr77KK6+8QqtWrXjttdc4evQooL52pn379vHzzz8THR1daLv63LEaNGjAhx9+aPuaPHmybZ/6WhxBia0TzJs3j/79+9O3b18iIyMZNWoUnp6eLFmypKJDqxbat2/PyJEjC43SFjBNkwULFnDTTTfRuXNnoqOjeeSRR0hMTGT9+vUVEG3VNn78ePr06UODBg2IiYnh4Ycf5syZMxw4cACA9PR0Fi9ezF133UWrVq1o1KgRY8aMYffu3ezZs6eCo696OnXqRIcOHahbty716tXjlltuwdvbm71796qvnSgzM5N3332XBx98ED8/P9t29bnjWSwWgoODbV+BgYGA+locR4mtg+Xm5nLgwAFat25t22axWGjdurV+OV3g9OnTJCUl0aZNG9s2X19fYmNj1f8OkJ6eDoC/vz8ABw4cIC8vr9DrvX79+oSFham/7WS1Wlm5ciVZWVk0bdpUfe1EH3/8Me3bty/0dwP0+naGuLg4HnzwQR555BHeeecdzpw5A6ivxXFUY+tgKSkpWK3WIjVBwcHBnDhxomKCqkGSkpIACAoKKrQ9KCjItk/Kx2q1Mm3aNJo1a0ZUVBSQ39/u7u6FRrlA/W2PI0eOMH78eHJycvD29uapp54iMjKSQ4cOqa+dYOXKlRw8eJBXXnmlyD69vh2rSZMmjBkzhnr16pGYmMjs2bP5+9//zptvvqm+FodRYisipfLJJ59w9OjRQjVx4nj16tXj9ddfJz09nTVr1vD+++8zadKkig6rWjpz5gzTpk3j+eefx9PTs6LDqfYKboIEiI6OtiW6q1evVv+LwyixdbDAwEAsFkuRd5hJSUm6s9MFCvo4OTmZkJAQ2/bk5GRiYmIqJqhq4JNPPmHTpk1MmjSJWrVq2bYHBweTm5tLWlpaoZGW5ORkvd7Lyd3dnYiICAAaNWrE/v37WbBgAd27d1dfO9iBAwdITk7m2WeftW2zWq3s2rWLhQsXMn78ePW5E/n5+VGvXj3i4uJo06aN+locQjW2Dubu7k6jRo3Yvn27bZvVamX79u00bdq0AiOrGcLDwwkODmbbtm22benp6ezbt0/9Xw6mafLJJ5+wbt06/v73vxMeHl5of6NGjXBzcyvU3ydOnODMmTPqbwexWq3k5OSor52gdevWvPHGG7z22mu2r8aNG9OzZ0/b9+pz58nMzCQuLo7g4GC9vsVhNGLrBEOGDOH999+nUaNGxMbGsmDBArKysujTp09Fh1YtFPwxLHD69GkOHTqEv78/YWFhDBo0iG+++Ya6desSHh7OV199RUhICJ07d67AqKumTz75hBUrVvDMM8/g4+Nj+yTC19cXT09PfH196devH9OnT8ff3x9fX18+/fRTmjZtqv+MymHGjBm0a9eOsLAwMjMzWbFiBTt37mT8+PHqayfw8fGx1YsX8PLyIiAgwLZdfe4406dPp1OnToSFhZGYmMisWbOwWCz07NlTr29xGMM0TbOig6iOFi5cyA8//EBSUhIxMTHcc889NGnSpKLDqhZ27NhRbM1h7969efjhh20LNPzyyy+kp6fTvHlz7rvvvkKLCkjpjBgxotjtY8aMsb1RK5hUfeXKleTm5mpSdTv8+9//Zvv27SQmJuLr60t0dDR/+ctfbHfrq6+db+LEicTExBRZoEF9br+3336bXbt2ce7cOQIDA2nevDkjR460ld6or8URlNiKiIiISLWgGlsRERERqRaU2IqIiIhItaDEVkRERESqBSW2IiIiIlItKLEVERERkWpBia2IiIiIVAtKbEVERESkWlBiKyI10tKlSxkxYgT79++v6FBERMRBtKSuiDjF0qVL+de//lXi/pdeeqlaLZW5fv163nzzTaZNm4a3tzefffYZhw8fZuLEiRUdmohIjaHEVkScasSIEYSHhxfZXrCMZnWxd+9eoqKi8Pb2BmDPnj20atWqgqMSEalZlNiKiFO1b9+exo0bV3QYTrd//36aNGkC5K95f+jQIW688cYKjkpEpGZRYisiFer06dM88sgj3H777VgsFhYsWEBycjKxsbHcd999REVFFTp++/btzJo1i4MHD+Lm5kaLFi249dZbiYyMLHRcQkICM2fOZMuWLZw7d46QkBDatWvHPffcg7v7n3/6cnJy+Pzzz/ntt9/Izs6mTZs2PPjggwQGBl429pSUFNv3+/fvp1OnTqSkpLB//37y8vKoU6cOKSkpeHl54eXlZWdPiYjI5RimaZoVHYSIVD8FNbYvvPAC0dHRhfYZhkFAQADwZ2IbFRVFRkYGAwYMICcnhwULFmCxWHjjjTcIDg4GYOvWrbzyyiuEh4fTv39/srOz+fHHH7FarUydOtVW8pCQkMBzzz1Heno6/fv3p379+iQkJLBmzRpeeukl/Pz8bPE1bNgQPz8/unTpwunTp1mwYAFdu3bliSeeuOxzHDFiRKn6Yvjw4aU+VkREyk8jtiLiVC+++GKRbR4eHvzvf/8rtC0uLo533nmH0NBQANq1a8e4ceP4/vvvueuuuwD44osv8Pf3Z8qUKfj7+wPQuXNnnnnmGWbNmsUjjzwCwIwZM0hKSuLll18uVAbx17/+lYvfy/v7+/P8889jGAYApmny448/kp6ejq+v7yWf2/PPPw/AmjVrWL9+PY8++igA//vf/wgJCWHQoEEA1KlTpxQ9JSIi9lJiKyJOdd9991G3bt1C2yyWojMNdu7c2ZbUAsTGxtKkSRM2b97MXXfdRWJiIocOHeKGG26wJbUA0dHRtGnThs2bNwNgtVpZv349HTt2LLa2tyCBLXD11VcX2nbFFVcwf/584uPji4w0X6xNmzYA/PTTT7Rq1Yo2bdpgtVqJi4vjuuuus+0XERHXUGIrIk4VGxtbqpvHLk5+C7atXr0agPj4eADq1atX5Lj69evz+++/k5mZSWZmJhkZGUVqc0sSFhZW6LGfnx8AaWlplzwvNTUVq9UKwM6dO7nppptISUnhyJEjtuunpKTg6elpmylBREScS4mtiNRoxY0eA0VKFi727LPP2pJtgOnTpzN9+nTb47FjxwLQu3dvHn74YQdEKiIil6PEVkQqhZMnTxa7rXbt2gC2f0+cOFHkuBMnThAQEIC3tzeenp74+Phw5MgRp8b76KOPkp2dzfr161m9ejWPPfYYAF999RUBAQEMHjwYoFB5hYiIOJeW1BWRSmH9+vUkJCTYHu/bt4+9e/fSrl07AEJCQoiJiWHZsmWFygSOHDnC77//Tvv27YH8EdjOnTuzcePGYpfLddREMM2bN6dNmzZkZGTQtGlT2rRpQ5s2bThz5gwdO3a0Pb54GjIREXEejdiKiFNt3ryZ48ePF9nerFmzQrMFRERE8MILLxSa7isgIIC//OUvtmNuv/12XnnlFZ5//nn69u1LdnY2CxcuxNfXt9B0Wrfeeitbt25l4sSJ9O/fn8jISBITE1mzZg2TJ0+21dE6wu7du7n66qsBOHXqFElJSTRr1sxh7YuISOkpsRURp5o1a1ax28eMGVMosb3qqquwWCzMnz+flJQUYmNjuffeewkJCbEd06ZNG8aNG8esWbOYNWuWbYGG2267rdCyvaGhobz88st89dVXrFixgoyMDEJDQ2nXrp1DF0pISkri1KlTtkR2z549+Pj40KBBA4ddQ0RESk8LNIhIhbpw5bEbbrihosMREZEqTDW2IiIiIlItKLEVERERkWpBia2IiIiIVAuqsRURERGRakEjtiIiIiJSLSixFREREZFqQYmtiIiIiFQLSmxFREREpFpQYisiIiIi1YISWxERERGpFpTYioiIiEi1oMRWRERERKoFJbYiIiIiUi38P5QO4ifi92itAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] total time taken to train the model: 39.89s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "# switch off autograd\n",
        "with torch.no_grad():\n",
        "    # loop over the test set\n",
        "    datasets = [(\"train\", train_loader), (\"validation\", val_loader), (\"test\", test_loader)]\n",
        "    for name, dataset in datasets:\n",
        "        for (x,y) in dataset:\n",
        "            (x,y) = (x.to(device), y.to(device))\n",
        "            y_true = y\n",
        "            pred = model(x, x, src_mask=None)\n",
        "            # print(f\"pred: {pred}, y: {y}\")\n",
        "            test_correct = (pred.argmax(1) == y.argmax(1)).sum().item()\n",
        "            print(f\"[INFO] {name} accuracy {test_correct} / {len(x)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in6o5PQFXsLW",
        "outputId": "164a3a06-a14c-4887-c0d6-8485204a2f2a"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] train accuracy 64 / 64\n",
            "[INFO] train accuracy 64 / 64\n",
            "[INFO] train accuracy 59 / 59\n",
            "[INFO] validation accuracy 23 / 23\n",
            "[INFO] test accuracy 24 / 24\n"
          ]
        }
      ]
    }
  ]
}