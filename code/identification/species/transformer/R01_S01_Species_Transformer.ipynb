{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOaILdqufIc8cfzsyn9r548",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woodRock/fishy-business/blob/main/code/identification/species/transformer/R01_S01_Species_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "learning_rate = 1E-5 #@param {type:\"integer\"}\n",
        "batch_size = 64 # @param {type:\"integer\"}\n",
        "epochs = 100 # @param {type:\"integer\"}\n",
        "is_next_spectra = False # @param {type:\"boolean\"}\n",
        "is_masked_spectra = True # @param {type:\"boolean\"}"
      ],
      "metadata": {
        "id": "5ZOG3XjPWFOh"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXt9OBnbV8OE",
        "outputId": "66b097a9-c7ae-4fc2-8946-b61839a8f3dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[INFO] Reading the dataset.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "os.listdir('/content/drive/My Drive')\n",
        "\n",
        "path = ['drive', 'MyDrive', 'AI', 'fish', 'REIMS_data.xlsx']\n",
        "path = os.path.join(*path)\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "\n",
        "    def __init__(self, samples, labels):\n",
        "        self.samples = torch.tensor(samples.to_numpy(), dtype=torch.float32)\n",
        "        self.labels = torch.tensor([np.array(ys) for ys in labels], dtype=torch.float32)\n",
        "\n",
        "\n",
        "        # Normalize the features to be between in [0,1]\n",
        "        self.samples = F.normalize(self.samples, dim = 0)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "print(\"[INFO] Reading the dataset.\")\n",
        "raw = pd.read_excel(path)\n",
        "\n",
        "data = raw[~raw['m/z'].str.contains('HM')]\n",
        "data = data[~data['m/z'].str.contains('QC')]\n",
        "data = data[~data['m/z'].str.contains('HM')]\n",
        "X = data.drop('m/z', axis=1) # X contains only the features.\n",
        "# Onehot encoding for the class labels, e.g. [0,1] for Hoki, [1,0] for Mackeral.\n",
        "y = data['m/z'].apply(lambda x: [0,1] if 'H' in x else [1,0])\n",
        "y = np.array(y)\n",
        "\n",
        "# Evaluation parameters.\n",
        "train_split = 0.8\n",
        "val_split = 0.5 # 1/2 of 20%, validation and test, 10% and 10%, respectively.\n",
        "\n",
        "# Step 2: Split your dataset into training, validation, and testing sets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, stratify=y, test_size=(1-train_split))\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=val_split)\n",
        "train_dataset = CustomDataset(X_train, y_train)\n",
        "val_dataset = CustomDataset(X_val, y_val)\n",
        "test_dataset = CustomDataset(X_test, y_test)\n",
        "\n",
        "assert train_dataset.samples.shape[0] == train_dataset.labels.shape[0] , \"train_dataset samples and labels should have same length.\"\n",
        "assert val_dataset.samples.shape[0] == val_dataset.labels.shape[0] , \"train_dataset samples and labels should have same length.\"\n",
        "assert test_dataset.samples.shape[0] == test_dataset.labels.shape[0] , \"train_dataset samples and labels should have same length.\"\n",
        "\n",
        "# Step 4: Create PyTorch DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# calculate steps per epoch for training and validation set\n",
        "train_steps = len(train_loader.dataset) // batch_size\n",
        "val_steps = len(val_loader.dataset) // batch_size\n",
        "# when batch_size greater than dataset size, avoid division by zero.\n",
        "train_steps = max(1, train_steps)\n",
        "val_steps = max(1, val_steps)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, input_dim, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert input_dim % num_heads == 0\n",
        "        self.input_dim = input_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = input_dim // num_heads\n",
        "\n",
        "        self.query = nn.Linear(input_dim, input_dim)\n",
        "        self.key = nn.Linear(input_dim, input_dim)\n",
        "        self.value = nn.Linear(input_dim, input_dim)\n",
        "        self.fc_out = nn.Linear(input_dim, input_dim)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        \"\"\" Attention mechanism (Vaswani 2017)\"\"\"\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        # Split the heads\n",
        "        Q = self.query(query).view(batch_size, -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = self.key(key).view(batch_size, -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = self.value(value).view(batch_size, -1, self.num_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "        # Energy-based models\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))\n",
        "\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
        "\n",
        "        attention = F.softmax(energy, dim=-1)\n",
        "\n",
        "        x = torch.matmul(attention, V)\n",
        "        x = x.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, self.input_dim)\n",
        "\n",
        "        x = self.fc_out(x)\n",
        "        return x\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, dropout=0.1):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, input_dim)\n",
        "        # Dropout (Hinton 2012, Srivastava 2014)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # GELU (Hendrycks 2016)\n",
        "        x = F.gelu(self.fc1(x))\n",
        "        # Dropout (Hinton 2012, Srivastava 2014)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, input_dim, num_heads, hidden_dim, dropout=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(input_dim, num_heads)\n",
        "        self.feed_forward = FeedForward(input_dim, hidden_dim)\n",
        "        self.norm1 = nn.LayerNorm(input_dim)\n",
        "        self.norm2 = nn.LayerNorm(input_dim)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # Layer normalization (Ba 2016)\n",
        "        # Pre-norm formulation (Xiong 2020, Karpathy 2023)\n",
        "        x_norm = self.norm1(x)\n",
        "        atttention = self.self_attention(x_norm, x_norm, x_norm, mask)\n",
        "        # Residual connections (He 2016)\n",
        "        # Dropout (Srivastava 2014, Hinton 2012)\n",
        "        x = x + self.dropout1(atttention)\n",
        "        x_norm = self.norm2(x)\n",
        "        feed_forward_out = self.feed_forward(x_norm)\n",
        "        x = x + self.dropout2(feed_forward_out)\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, num_layers, num_heads, hidden_dim, dropout=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([EncoderLayer(input_dim, num_heads, hidden_dim, dropout) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        return x\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, input_dim, num_heads, hidden_dim, dropout=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(input_dim, num_heads)\n",
        "        self.cross_attention = MultiHeadAttention(input_dim, num_heads)\n",
        "        self.feed_forward = FeedForward(input_dim, hidden_dim)\n",
        "        self.norm1 = nn.LayerNorm(input_dim)\n",
        "        self.norm2 = nn.LayerNorm(input_dim)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask=None, tgt_mask=None):\n",
        "        \"\"\" Attention mechanism (Vasawin 2017)\"\"\"\n",
        "        # Layer normalization (Ba 2016)\n",
        "        # Pre-norm formulation (Xiong 2020, Karpathy 2023)\n",
        "        x_norm = self.norm1(x)\n",
        "        # Self attention (Vaswani 2017)\n",
        "        attention = self.self_attention(x_norm, x_norm, x_norm, tgt_mask)\n",
        "        # Residual connections (He 2016)\n",
        "        # Dropout (Srivastava 2014, Hinton 2012)\n",
        "        x = x + self.dropout1(attention)\n",
        "        x_norm = self.norm2(x)\n",
        "        # Cross attention (Vaswani 2017)\n",
        "        cross_attention = self.cross_attention(x_norm, encoder_output, encoder_output, src_mask)\n",
        "        x = x + self.dropout2(cross_attention)\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_dim, num_layers, num_heads, hidden_dim, dropout=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = nn.ModuleList([DecoderLayer(input_dim, num_heads, hidden_dim, dropout) for _ in range(num_layers)])\n",
        "\n",
        "    def forward(self, x, encoder_output, src_mask=None, tgt_mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, encoder_output, src_mask, tgt_mask)\n",
        "        return x\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    References:\n",
        "    1. Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez,\n",
        "        A. N., ... & Polosukhin, I. (2017).\n",
        "        Attention is all you need.\n",
        "        Advances in neural information processing systems, 30.\n",
        "    2. He, K., Zhang, X., Ren, S., & Sun, J. (2016).\n",
        "        Deep residual learning for image recognition.\n",
        "        In Proceedings of the IEEE conference on\n",
        "        computer vision and pattern recognition (pp. 770-778).\n",
        "    3. LeCun, Y. (1989). Generalization and network design strategies.\n",
        "        Connectionism in perspective, 19(143-155), 18.\n",
        "    4. LeCun, Y., Boser, B., Denker, J., Henderson, D., Howard,\n",
        "        R., Hubbard, W., & Jackel, L. (1989).\n",
        "        Handwritten digit recognition with a back-propagation network.\n",
        "        Advances in neural information processing systems, 2.\n",
        "    5. LeCun, Y., Boser, B., Denker, J. S., Henderson, D., Howard, R. E.,\n",
        "        Hubbard, W., & Jackel, L. D. (1989).\n",
        "        Backpropagation applied to handwritten zip code recognition.\n",
        "        Neural computation, 1(4), 541-551.\n",
        "    6. Hendrycks, D., & Gimpel, K. (2016).\n",
        "        Gaussian error linear units (gelus).\n",
        "        arXiv preprint arXiv:1606.08415.\n",
        "    7. Ba, J. L., Kiros, J. R., & Hinton, G. E. (2016).\n",
        "        Layer normalization. arXiv preprint arXiv:1607.06450.\n",
        "    8. Srivastava, N., Hinton, G., Krizhevsky, A.,\n",
        "        Sutskever, I., & Salakhutdinov, R. (2014).\n",
        "        Dropout: a simple way to prevent neural networks from overfitting.\n",
        "        The journal of machine learning research, 15(1), 1929-1958.\n",
        "    9. Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever,\n",
        "        I., & Salakhutdinov, R. R. (2012).\n",
        "        Improving neural networks by preventing co-adaptation of feature detectors.\n",
        "        arXiv preprint arXiv:1207.0580.\n",
        "    10. Glorot, X., & Bengio, Y. (2010, March).\n",
        "        Understanding the difficulty of training deep feedforward neural networks.\n",
        "        In Proceedings of the thirteenth international conference on artificial intelligence and statistics (pp. 249-256).\n",
        "        JMLR Workshop and Conference Proceedings.\n",
        "    11. Loshchilov, I., & Hutter, F. (2017).\n",
        "        Decoupled weight decay regularization.\n",
        "        arXiv preprint arXiv:1711.05101.\n",
        "    12. Goodfellow, Ian, Yoshua Bengio, and Aaron Courville.\n",
        "        Deep learning. MIT press, 2016.\n",
        "    13. Morgan, N., & Bourlard, H. (1989).\n",
        "        Generalization and parameter estimation in feedforward nets:\n",
        "        Some experiments. Advances in neural information processing systems, 2.\n",
        "    14. Xiong, R., Yang, Y., He, D., Zheng, K.,\n",
        "        Zheng, S., Xing, C., ... & Liu, T. (2020, November).\n",
        "        On layer normalization in the transformer architecture.\n",
        "        In International Conference on Machine Learning (pp. 10524-10533). PMLR.\n",
        "    14. Karpathy, Andrej (2023)\n",
        "        Let's build GPT: from scratch, in code, spelled out.\n",
        "        YouTube https://youtu.be/kCc8FmEb1nY?si=1vM4DhyqsGKUSAdV\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, num_layers, num_heads, hidden_dim, dropout=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = Encoder(input_dim, num_layers, num_heads, hidden_dim, dropout)\n",
        "        self.decoder = Decoder(input_dim, num_layers, num_heads, hidden_dim, dropout)\n",
        "        self.fc = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
        "        x = self.encoder(src, src_mask)\n",
        "        x = self.decoder(tgt, x, src_mask, tgt_mask)\n",
        "        x = self.fc(x[:, 0, :])\n",
        "        return x"
      ],
      "metadata": {
        "id": "bygy82tLE9N5"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "def pre_train_masked_spectra(model, filepath=\"next_spectra_model_weights.pth\", mask_prob=0.2):\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0.0\n",
        "        model.train()\n",
        "\n",
        "        for (x,y) in train_loader:\n",
        "            # Generate batch of data\n",
        "            tgt_x, x = x.to(device), x.to(device)\n",
        "\n",
        "            batch_size = x.shape[0]\n",
        "            mask = torch.rand(batch_size, 1023) < mask_prob\n",
        "            mask = mask.to(device)\n",
        "            x[mask] = 0\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x, x)\n",
        "            loss = criterion(outputs, tgt_x)  # Compare predicted spectra with true spectra\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        total_val_loss = 0.0\n",
        "        model.eval()\n",
        "        for (x,y) in val_loader:\n",
        "            tgt_x, x = x.to(device), x.to(device)\n",
        "\n",
        "            val_batch_size = x.shape[0]\n",
        "            mask = torch.rand(val_batch_size, 1023) < mask_prob\n",
        "            mask = mask.to(device)\n",
        "            x[mask] = 0\n",
        "\n",
        "            outputs = model(x, x)\n",
        "            val_loss = criterion(outputs, tgt_x)\n",
        "            total_val_loss += val_loss.item()\n",
        "\n",
        "        # Print average loss for the epoch\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/batch_size:.4f}, Val: {val_loss/val_batch_size:.4f}')\n",
        "\n",
        "    masked_spectra_prediction = model\n",
        "    torch.save(masked_spectra_prediction.state_dict(), filepath)\n",
        "    return model\n",
        "\n",
        "# Define hyperparameters\n",
        "input_dim = 1023\n",
        "output_dim = 1023  # Same as input_dim for masked spectra prediction\n",
        "num_layers = 3\n",
        "num_heads = 3\n",
        "hidden_dim = 128\n",
        "dropout = 0.2\n",
        "learning_rate = 1E-4\n",
        "batch_size = 64\n",
        "num_epochs = 100\n",
        "\n",
        "if is_masked_spectra:\n",
        "    # Load the transformer.\n",
        "    model = Transformer(input_dim, output_dim, num_layers, num_heads, hidden_dim, dropout)\n",
        "    # Specify the device (GPU or CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    # Initialize your model, loss function, and optimizer\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    model = pre_train_masked_spectra(model, filepath=\"next_spectra_model_weights.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd2kNbQLa63y",
        "outputId": "7873c759-38fd-4330-8836-59cac875efa8"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 0.0094, Val: 0.0070\n",
            "Epoch [2/100], Loss: 0.0078, Val: 0.0059\n",
            "Epoch [3/100], Loss: 0.0071, Val: 0.0054\n",
            "Epoch [4/100], Loss: 0.0064, Val: 0.0047\n",
            "Epoch [5/100], Loss: 0.0059, Val: 0.0043\n",
            "Epoch [6/100], Loss: 0.0054, Val: 0.0039\n",
            "Epoch [7/100], Loss: 0.0051, Val: 0.0036\n",
            "Epoch [8/100], Loss: 0.0047, Val: 0.0034\n",
            "Epoch [9/100], Loss: 0.0044, Val: 0.0032\n",
            "Epoch [10/100], Loss: 0.0042, Val: 0.0030\n",
            "Epoch [11/100], Loss: 0.0040, Val: 0.0028\n",
            "Epoch [12/100], Loss: 0.0039, Val: 0.0028\n",
            "Epoch [13/100], Loss: 0.0037, Val: 0.0027\n",
            "Epoch [14/100], Loss: 0.0035, Val: 0.0027\n",
            "Epoch [15/100], Loss: 0.0034, Val: 0.0025\n",
            "Epoch [16/100], Loss: 0.0032, Val: 0.0025\n",
            "Epoch [17/100], Loss: 0.0031, Val: 0.0024\n",
            "Epoch [18/100], Loss: 0.0031, Val: 0.0024\n",
            "Epoch [19/100], Loss: 0.0029, Val: 0.0022\n",
            "Epoch [20/100], Loss: 0.0028, Val: 0.0023\n",
            "Epoch [21/100], Loss: 0.0027, Val: 0.0022\n",
            "Epoch [22/100], Loss: 0.0027, Val: 0.0021\n",
            "Epoch [23/100], Loss: 0.0026, Val: 0.0021\n",
            "Epoch [24/100], Loss: 0.0025, Val: 0.0021\n",
            "Epoch [25/100], Loss: 0.0025, Val: 0.0021\n",
            "Epoch [26/100], Loss: 0.0024, Val: 0.0020\n",
            "Epoch [27/100], Loss: 0.0023, Val: 0.0019\n",
            "Epoch [28/100], Loss: 0.0023, Val: 0.0019\n",
            "Epoch [29/100], Loss: 0.0022, Val: 0.0019\n",
            "Epoch [30/100], Loss: 0.0022, Val: 0.0018\n",
            "Epoch [31/100], Loss: 0.0021, Val: 0.0018\n",
            "Epoch [32/100], Loss: 0.0021, Val: 0.0019\n",
            "Epoch [33/100], Loss: 0.0020, Val: 0.0018\n",
            "Epoch [34/100], Loss: 0.0020, Val: 0.0018\n",
            "Epoch [35/100], Loss: 0.0019, Val: 0.0017\n",
            "Epoch [36/100], Loss: 0.0019, Val: 0.0018\n",
            "Epoch [37/100], Loss: 0.0019, Val: 0.0017\n",
            "Epoch [38/100], Loss: 0.0018, Val: 0.0017\n",
            "Epoch [39/100], Loss: 0.0018, Val: 0.0016\n",
            "Epoch [40/100], Loss: 0.0018, Val: 0.0016\n",
            "Epoch [41/100], Loss: 0.0018, Val: 0.0016\n",
            "Epoch [42/100], Loss: 0.0017, Val: 0.0016\n",
            "Epoch [43/100], Loss: 0.0017, Val: 0.0016\n",
            "Epoch [44/100], Loss: 0.0017, Val: 0.0016\n",
            "Epoch [45/100], Loss: 0.0016, Val: 0.0016\n",
            "Epoch [46/100], Loss: 0.0016, Val: 0.0016\n",
            "Epoch [47/100], Loss: 0.0016, Val: 0.0016\n",
            "Epoch [48/100], Loss: 0.0016, Val: 0.0015\n",
            "Epoch [49/100], Loss: 0.0015, Val: 0.0015\n",
            "Epoch [50/100], Loss: 0.0015, Val: 0.0016\n",
            "Epoch [51/100], Loss: 0.0015, Val: 0.0016\n",
            "Epoch [52/100], Loss: 0.0015, Val: 0.0015\n",
            "Epoch [53/100], Loss: 0.0014, Val: 0.0015\n",
            "Epoch [54/100], Loss: 0.0014, Val: 0.0015\n",
            "Epoch [55/100], Loss: 0.0014, Val: 0.0014\n",
            "Epoch [56/100], Loss: 0.0014, Val: 0.0014\n",
            "Epoch [57/100], Loss: 0.0014, Val: 0.0014\n",
            "Epoch [58/100], Loss: 0.0013, Val: 0.0014\n",
            "Epoch [59/100], Loss: 0.0013, Val: 0.0014\n",
            "Epoch [60/100], Loss: 0.0014, Val: 0.0014\n",
            "Epoch [61/100], Loss: 0.0013, Val: 0.0014\n",
            "Epoch [62/100], Loss: 0.0013, Val: 0.0014\n",
            "Epoch [63/100], Loss: 0.0013, Val: 0.0014\n",
            "Epoch [64/100], Loss: 0.0012, Val: 0.0014\n",
            "Epoch [65/100], Loss: 0.0012, Val: 0.0013\n",
            "Epoch [66/100], Loss: 0.0012, Val: 0.0014\n",
            "Epoch [67/100], Loss: 0.0012, Val: 0.0013\n",
            "Epoch [68/100], Loss: 0.0012, Val: 0.0013\n",
            "Epoch [69/100], Loss: 0.0012, Val: 0.0013\n",
            "Epoch [70/100], Loss: 0.0012, Val: 0.0013\n",
            "Epoch [71/100], Loss: 0.0012, Val: 0.0013\n",
            "Epoch [72/100], Loss: 0.0011, Val: 0.0013\n",
            "Epoch [73/100], Loss: 0.0011, Val: 0.0013\n",
            "Epoch [74/100], Loss: 0.0011, Val: 0.0013\n",
            "Epoch [75/100], Loss: 0.0011, Val: 0.0012\n",
            "Epoch [76/100], Loss: 0.0011, Val: 0.0013\n",
            "Epoch [77/100], Loss: 0.0011, Val: 0.0013\n",
            "Epoch [78/100], Loss: 0.0011, Val: 0.0013\n",
            "Epoch [79/100], Loss: 0.0010, Val: 0.0012\n",
            "Epoch [80/100], Loss: 0.0010, Val: 0.0012\n",
            "Epoch [81/100], Loss: 0.0010, Val: 0.0013\n",
            "Epoch [82/100], Loss: 0.0010, Val: 0.0013\n",
            "Epoch [83/100], Loss: 0.0010, Val: 0.0012\n",
            "Epoch [84/100], Loss: 0.0010, Val: 0.0013\n",
            "Epoch [85/100], Loss: 0.0010, Val: 0.0013\n",
            "Epoch [86/100], Loss: 0.0010, Val: 0.0012\n",
            "Epoch [87/100], Loss: 0.0009, Val: 0.0011\n",
            "Epoch [88/100], Loss: 0.0009, Val: 0.0013\n",
            "Epoch [89/100], Loss: 0.0009, Val: 0.0012\n",
            "Epoch [90/100], Loss: 0.0009, Val: 0.0012\n",
            "Epoch [91/100], Loss: 0.0009, Val: 0.0013\n",
            "Epoch [92/100], Loss: 0.0009, Val: 0.0011\n",
            "Epoch [93/100], Loss: 0.0009, Val: 0.0012\n",
            "Epoch [94/100], Loss: 0.0009, Val: 0.0012\n",
            "Epoch [95/100], Loss: 0.0009, Val: 0.0011\n",
            "Epoch [96/100], Loss: 0.0009, Val: 0.0012\n",
            "Epoch [97/100], Loss: 0.0009, Val: 0.0012\n",
            "Epoch [98/100], Loss: 0.0008, Val: 0.0012\n",
            "Epoch [99/100], Loss: 0.0008, Val: 0.0012\n",
            "Epoch [100/100], Loss: 0.0008, Val: 0.0012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "def mask_left_side(input_spectra, mask_prob=0.5):\n",
        "    \"\"\"\n",
        "    Masks the left-hand side of the input spectra tensor.\n",
        "\n",
        "    Args:\n",
        "        input_spectra (torch.Tensor): Input spectra tensor of shape (batch_size, 1023).\n",
        "        mask_prob (float): Probability of masking each element of the left-hand side.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Masked input spectra tensor.\n",
        "    \"\"\"\n",
        "    # Calculate the index to split the tensor\n",
        "    split_index = input_spectra.shape[0] // 2\n",
        "    # Mask the left half of the input tensor\n",
        "    input_spectra[:split_index] = 0\n",
        "    return input_spectra\n",
        "\n",
        "def mask_right_side(input_spectra, mask_prob=0.5):\n",
        "    \"\"\"\n",
        "    Masks the right-hand side of the input spectra tensor.\n",
        "\n",
        "    Args:\n",
        "        input_spectra (torch.Tensor): Input spectra tensor of shape (batch_size, 1023).\n",
        "        mask_prob (float): Probability of masking each element of the right-hand side.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Masked input spectra tensor.\n",
        "    \"\"\"\n",
        "    # Calculate the index to split the tensor\n",
        "    split_index = input_spectra.shape[0] // 2\n",
        "    # Mask the left half of the input tensor\n",
        "    input_spectra[split_index:] = 0\n",
        "    return input_spectra\n",
        "\n",
        "def pre_train_model_next_spectra(model, filepath=\"next_spectra_model_weights.pth\"):\n",
        "    # Assume train_loader is your DataLoader containing spectra data\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        num_pairs = 0\n",
        "\n",
        "        # Iterate over batches in the train_loader\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}\"):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Extract spectra from the batch\n",
        "            (x,y) = batch\n",
        "\n",
        "            # Randomly choose pairs of adjacent spectra from the same index or different indexes\n",
        "            pairs = []\n",
        "            labels = []\n",
        "            for i in range(len(x)):\n",
        "                if random.random() < 0.5:\n",
        "                    # Choose two adjacent spectra from the same index\n",
        "                    if i < len(x) - 1:\n",
        "                        # Mask the right side of the spectra\n",
        "                        left = mask_left_side(x[i])\n",
        "                        right = mask_right_side(x[i])\n",
        "                        pairs.append((left, right))\n",
        "                        labels.append([0,1])\n",
        "                else:\n",
        "                    # Choose two spectra from different indexes\n",
        "                    j = random.randint(0, len(x) - 1)\n",
        "                    if j != i:\n",
        "                        left = mask_left_side(x[i])\n",
        "                        right = mask_right_side(x[j])\n",
        "                        pairs.append((left, right))\n",
        "                        labels.append([1,0])\n",
        "\n",
        "            for (input_spectra, target_spectra), label in zip(pairs, labels):\n",
        "                # Forward pass\n",
        "                input_spectra = input_spectra.to(device)\n",
        "                target_spectra = target_spectra.to(device)\n",
        "                label = torch.tensor(label).to(device)\n",
        "                # print(f\"[DEBUG] input_spectra: {input_spectra.shape}\")\n",
        "                # print(f\"[DEBUG] target_spectra: {target_spectra.shape}\")\n",
        "                # print(f\"[DEBUG] target_spectra: {target_spectra} \")\n",
        "                output = model(input_spectra.unsqueeze(0), target_spectra.unsqueeze(0))\n",
        "                # Compute loss\n",
        "                # print(f\"[DEBUG] output: {output.shape}\")\n",
        "                # print(f\"[DEBUG] label: {label.shape}\")\n",
        "                label = label.float()\n",
        "\n",
        "                loss = criterion(output, label.unsqueeze(0))\n",
        "                total_loss += loss.item()\n",
        "                # Backpropagation\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                num_pairs += 1\n",
        "\n",
        "        # Calculate average loss for the epoch\n",
        "        avg_loss = total_loss / num_pairs\n",
        "        print(f\"Epoch {epoch + 1}, Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    next_spectra_model = model\n",
        "    torch.save(next_spectra_model.state_dict(), filepath)\n",
        "    return model\n",
        "\n",
        "def transfer_learning(model, filepath='next_spectra_model_weights.pth', output_dim=2):\n",
        "    # Load the state dictionary from the checkpoint.\n",
        "    checkpoint = torch.load(filepath)\n",
        "    # Modify the 'fc.weight' and 'fc.bias' parameters\n",
        "    checkpoint['fc.weight'] = checkpoint['fc.weight'][:output_dim]  # Keep only the first 2 rows\n",
        "    checkpoint['fc.bias'] = checkpoint['fc.bias'][:output_dim] # Keep only the first 2 elements\n",
        "    # Load the modified state dictionary into the model.\n",
        "    model.load_state_dict(checkpoint, strict=False)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define hyperparameters\n",
        "input_dim = 1023  # Example: size of input sequence\n",
        "output_dim = 2  # Example: number of output classes\n",
        "num_layers = 3\n",
        "num_heads = 3\n",
        "hidden_dim = 128\n",
        "dropout = 0.2\n",
        "learning_rate = 1e-5\n",
        "num_epochs = 50\n",
        "\n",
        "if is_next_spectra:\n",
        "    # Initialize the model, criterion, and optimizer\n",
        "    model = Transformer(input_dim, output_dim, num_layers, num_heads, hidden_dim, dropout)\n",
        "\n",
        "    is_transfer_learning = True\n",
        "    # Transfer learning\n",
        "    if is_transfer_learning:\n",
        "        model = transfer_learning(model, filepath='next_spectra_model_weights.pth')\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # AdamW (Loshchilov 2017)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Specify the device (GPU or CPU)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    print(\"[INFO] Training the network\")\n",
        "    startTime = time.time()\n",
        "\n",
        "\n",
        "    # Train the model\n",
        "    model = pre_train_model_next_spectra(model, filepath='next_spectra_model_weights.pth')\n",
        "\n",
        "    # finish measuring how long training took\n",
        "    endTime = time.time()\n",
        "    print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))"
      ],
      "metadata": {
        "id": "u59zTkBcbRJ6"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "def train(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for inputs, targets in dataloader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs, inputs, src_mask=None, tgt_mask=None)  # Assuming no masking is needed for now\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_predictions += (predicted == targets.argmax(1)).sum().item()\n",
        "        total_samples += targets.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_accuracy = correct_predictions / total_samples\n",
        "\n",
        "    return epoch_loss, epoch_accuracy\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs, inputs, src_mask=None, tgt_mask=None)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_predictions += (predicted == targets.argmax(1)).sum().item()\n",
        "            total_samples += targets.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total_samples\n",
        "    epoch_accuracy = correct_predictions / total_samples\n",
        "\n",
        "    return epoch_loss, epoch_accuracy\n",
        "\n",
        "def train_model(model, train_dataloader, val_dataloader, criterion, optimizer, num_epochs, device):\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_accuracy = train(model, train_dataloader, criterion, optimizer, device)\n",
        "        val_loss, val_accuracy = evaluate(model, val_dataloader, criterion, device)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f'[INFO] Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}')\n",
        "\n",
        "        # Early stopping (Morgan 1989)\n",
        "        # if train_accuracy == 1 and val_accuracy == 1:\n",
        "        #     break\n",
        "\n",
        "    # plot the training loss and accuracy\n",
        "    plt.style.use(\"ggplot\")\n",
        "    plt.figure()\n",
        "    plt.plot(train_losses, label=\"train_loss\")\n",
        "    plt.plot(val_losses, label=\"val_loss\")\n",
        "    plt.plot(train_accuracies, label=\"train_acc\")\n",
        "    plt.plot(val_accuracies, label=\"val_acc\")\n",
        "    plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "    plt.xlabel(\"Epoch #\")\n",
        "    plt.ylabel(\"Loss/Accuracy\")\n",
        "    plt.legend(loc=\"lower left\")\n",
        "    plt.legend(bbox_to_anchor=(1.0, 1.0))\n",
        "    plt.savefig(\"model_accuracy.png\")\n",
        "    plt.show()\n",
        "\n",
        "    return train_losses, train_accuracies, val_losses, val_accuracies\n",
        "\n",
        "def transfer_learning(model, filepath='next_spectra_model_weights.pth', output_dim=2):\n",
        "    # Load the state dictionary from the checkpoint.\n",
        "    checkpoint = torch.load(filepath)\n",
        "    # Modify the 'fc.weight' and 'fc.bias' parameters\n",
        "    checkpoint['fc.weight'] = checkpoint['fc.weight'][:output_dim]  # Keep only the first 2 rows\n",
        "    checkpoint['fc.bias'] = checkpoint['fc.bias'][:output_dim] # Keep only the first 2 elements\n",
        "    # Load the modified state dictionary into the model.\n",
        "    model.load_state_dict(checkpoint, strict=False)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define hyperparameters\n",
        "input_dim = 1023  # Example: size of input sequence\n",
        "output_dim = 2  # Example: number of output classes\n",
        "num_layers = 3\n",
        "num_heads = 3\n",
        "hidden_dim = 128\n",
        "dropout = 0.2\n",
        "learning_rate = 1e-5\n",
        "num_epochs = 50\n",
        "\n",
        "# Initialize the model, criterion, and optimizer\n",
        "model = Transformer(input_dim, output_dim, num_layers, num_heads, hidden_dim, dropout)\n",
        "\n",
        "is_transfer_learning = True\n",
        "# Transfer learning\n",
        "if is_transfer_learning:\n",
        "    model = transfer_learning(model, filepath='next_spectra_model_weights.pth')\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# AdamW (Loshchilov 2017)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Specify the device (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"[INFO] Training the network\")\n",
        "startTime = time.time()\n",
        "\n",
        "# Train the model\n",
        "train_losses, train_accuracies, val_losses, val_accuracies = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n",
        "\n",
        "# finish measuring how long training took\n",
        "endTime = time.time()\n",
        "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(endTime - startTime))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xhhI4d1jW5d3",
        "outputId": "24d5be0a-e581-4961-fc67-2566a5eae47b"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Training the network\n",
            "[INFO] Epoch 1/50, Train Loss: 0.7077, Train Acc: 0.5080, Val Loss: 0.6299, Val Acc: 0.6087\n",
            "[INFO] Epoch 2/50, Train Loss: 0.5956, Train Acc: 0.8128, Val Loss: 0.5402, Val Acc: 0.9130\n",
            "[INFO] Epoch 3/50, Train Loss: 0.5154, Train Acc: 0.9037, Val Loss: 0.4765, Val Acc: 1.0000\n",
            "[INFO] Epoch 4/50, Train Loss: 0.4378, Train Acc: 0.9358, Val Loss: 0.4264, Val Acc: 0.9130\n",
            "[INFO] Epoch 5/50, Train Loss: 0.3649, Train Acc: 0.9519, Val Loss: 0.3647, Val Acc: 1.0000\n",
            "[INFO] Epoch 6/50, Train Loss: 0.3044, Train Acc: 0.9572, Val Loss: 0.2917, Val Acc: 1.0000\n",
            "[INFO] Epoch 7/50, Train Loss: 0.2383, Train Acc: 0.9840, Val Loss: 0.2237, Val Acc: 1.0000\n",
            "[INFO] Epoch 8/50, Train Loss: 0.1847, Train Acc: 0.9786, Val Loss: 0.1670, Val Acc: 1.0000\n",
            "[INFO] Epoch 9/50, Train Loss: 0.1389, Train Acc: 0.9840, Val Loss: 0.1263, Val Acc: 1.0000\n",
            "[INFO] Epoch 10/50, Train Loss: 0.0970, Train Acc: 0.9893, Val Loss: 0.0955, Val Acc: 1.0000\n",
            "[INFO] Epoch 11/50, Train Loss: 0.0666, Train Acc: 0.9947, Val Loss: 0.0689, Val Acc: 1.0000\n",
            "[INFO] Epoch 12/50, Train Loss: 0.0468, Train Acc: 0.9947, Val Loss: 0.0468, Val Acc: 1.0000\n",
            "[INFO] Epoch 13/50, Train Loss: 0.0339, Train Acc: 0.9947, Val Loss: 0.0307, Val Acc: 1.0000\n",
            "[INFO] Epoch 14/50, Train Loss: 0.0216, Train Acc: 1.0000, Val Loss: 0.0217, Val Acc: 1.0000\n",
            "[INFO] Epoch 15/50, Train Loss: 0.0139, Train Acc: 1.0000, Val Loss: 0.0163, Val Acc: 1.0000\n",
            "[INFO] Epoch 16/50, Train Loss: 0.0127, Train Acc: 1.0000, Val Loss: 0.0133, Val Acc: 1.0000\n",
            "[INFO] Epoch 17/50, Train Loss: 0.0080, Train Acc: 1.0000, Val Loss: 0.0118, Val Acc: 1.0000\n",
            "[INFO] Epoch 18/50, Train Loss: 0.0058, Train Acc: 1.0000, Val Loss: 0.0107, Val Acc: 1.0000\n",
            "[INFO] Epoch 19/50, Train Loss: 0.0045, Train Acc: 1.0000, Val Loss: 0.0099, Val Acc: 1.0000\n",
            "[INFO] Epoch 20/50, Train Loss: 0.0038, Train Acc: 1.0000, Val Loss: 0.0091, Val Acc: 1.0000\n",
            "[INFO] Epoch 21/50, Train Loss: 0.0032, Train Acc: 1.0000, Val Loss: 0.0084, Val Acc: 1.0000\n",
            "[INFO] Epoch 22/50, Train Loss: 0.0024, Train Acc: 1.0000, Val Loss: 0.0076, Val Acc: 1.0000\n",
            "[INFO] Epoch 23/50, Train Loss: 0.0021, Train Acc: 1.0000, Val Loss: 0.0066, Val Acc: 1.0000\n",
            "[INFO] Epoch 24/50, Train Loss: 0.0020, Train Acc: 1.0000, Val Loss: 0.0058, Val Acc: 1.0000\n",
            "[INFO] Epoch 25/50, Train Loss: 0.0015, Train Acc: 1.0000, Val Loss: 0.0052, Val Acc: 1.0000\n",
            "[INFO] Epoch 26/50, Train Loss: 0.0012, Train Acc: 1.0000, Val Loss: 0.0047, Val Acc: 1.0000\n",
            "[INFO] Epoch 27/50, Train Loss: 0.0013, Train Acc: 1.0000, Val Loss: 0.0044, Val Acc: 1.0000\n",
            "[INFO] Epoch 28/50, Train Loss: 0.0013, Train Acc: 1.0000, Val Loss: 0.0042, Val Acc: 1.0000\n",
            "[INFO] Epoch 29/50, Train Loss: 0.0010, Train Acc: 1.0000, Val Loss: 0.0040, Val Acc: 1.0000\n",
            "[INFO] Epoch 30/50, Train Loss: 0.0009, Train Acc: 1.0000, Val Loss: 0.0038, Val Acc: 1.0000\n",
            "[INFO] Epoch 31/50, Train Loss: 0.0011, Train Acc: 1.0000, Val Loss: 0.0037, Val Acc: 1.0000\n",
            "[INFO] Epoch 32/50, Train Loss: 0.0009, Train Acc: 1.0000, Val Loss: 0.0035, Val Acc: 1.0000\n",
            "[INFO] Epoch 33/50, Train Loss: 0.0008, Train Acc: 1.0000, Val Loss: 0.0034, Val Acc: 1.0000\n",
            "[INFO] Epoch 34/50, Train Loss: 0.0008, Train Acc: 1.0000, Val Loss: 0.0033, Val Acc: 1.0000\n",
            "[INFO] Epoch 35/50, Train Loss: 0.0007, Train Acc: 1.0000, Val Loss: 0.0032, Val Acc: 1.0000\n",
            "[INFO] Epoch 36/50, Train Loss: 0.0007, Train Acc: 1.0000, Val Loss: 0.0031, Val Acc: 1.0000\n",
            "[INFO] Epoch 37/50, Train Loss: 0.0007, Train Acc: 1.0000, Val Loss: 0.0030, Val Acc: 1.0000\n",
            "[INFO] Epoch 38/50, Train Loss: 0.0007, Train Acc: 1.0000, Val Loss: 0.0029, Val Acc: 1.0000\n",
            "[INFO] Epoch 39/50, Train Loss: 0.0007, Train Acc: 1.0000, Val Loss: 0.0028, Val Acc: 1.0000\n",
            "[INFO] Epoch 40/50, Train Loss: 0.0007, Train Acc: 1.0000, Val Loss: 0.0027, Val Acc: 1.0000\n",
            "[INFO] Epoch 41/50, Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0026, Val Acc: 1.0000\n",
            "[INFO] Epoch 42/50, Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0026, Val Acc: 1.0000\n",
            "[INFO] Epoch 43/50, Train Loss: 0.0006, Train Acc: 1.0000, Val Loss: 0.0025, Val Acc: 1.0000\n",
            "[INFO] Epoch 44/50, Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0024, Val Acc: 1.0000\n",
            "[INFO] Epoch 45/50, Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0023, Val Acc: 1.0000\n",
            "[INFO] Epoch 46/50, Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0023, Val Acc: 1.0000\n",
            "[INFO] Epoch 47/50, Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0022, Val Acc: 1.0000\n",
            "[INFO] Epoch 48/50, Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0021, Val Acc: 1.0000\n",
            "[INFO] Epoch 49/50, Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0021, Val Acc: 1.0000\n",
            "[INFO] Epoch 50/50, Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0020, Val Acc: 1.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] total time taken to train the model: 40.29s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "# switch off autograd\n",
        "with torch.no_grad():\n",
        "    # loop over the test set\n",
        "    datasets = [(\"train\", train_loader), (\"validation\", val_loader), (\"test\", test_loader)]\n",
        "    for name, dataset in datasets:\n",
        "        for (x,y) in dataset:\n",
        "            (x,y) = (x.to(device), y.to(device))\n",
        "            y_true = y\n",
        "            pred = model(x, x, src_mask=None)\n",
        "            # print(f\"pred: {pred}, y: {y}\")\n",
        "            test_correct = (pred.argmax(1) == y.argmax(1)).sum().item()\n",
        "            print(f\"[INFO] {name} accuracy {test_correct} / {len(x)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in6o5PQFXsLW",
        "outputId": "e33856f8-fe2d-443b-e221-db6f8c5ffb8c"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] train accuracy 64 / 64\n",
            "[INFO] train accuracy 64 / 64\n",
            "[INFO] train accuracy 59 / 59\n",
            "[INFO] validation accuracy 23 / 23\n",
            "[INFO] test accuracy 24 / 24\n"
          ]
        }
      ]
    }
  ]
}