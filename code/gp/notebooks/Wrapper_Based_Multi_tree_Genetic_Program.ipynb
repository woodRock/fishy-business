{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woodRock/fishy-business/blob/main/code/gp/notebooks/Wrapper_Based_Multi_tree_Genetic_Program.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAlW5BfrgjQk"
      },
      "source": [
        "# Multi-tree Genetic Program "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLL18yL7WWRt",
        "outputId": "e33fb5e4-8dc6-4f09-8777-ca17948e66fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: deap in /usr/local/lib/python3.7/dist-packages (1.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.21.6)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libgraphviz-dev is already the newest version (2.40.1-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pygraphviz in /usr/local/lib/python3.7/dist-packages (1.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: skfeature-chappers in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from skfeature-chappers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from skfeature-chappers) (1.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from skfeature-chappers) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->skfeature-chappers) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->skfeature-chappers) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->skfeature-chappers) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->skfeature-chappers) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->skfeature-chappers) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->skfeature-chappers) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install deap\n",
        "!apt install libgraphviz-dev\n",
        "!pip install pygraphviz\n",
        "!pip install skfeature-chappers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCcCiUIvL40G",
        "outputId": "f81a0b08-d025-4acb-8e09-aa98929ada70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path_gdrive = '/content/drive/MyDrive/AI/Data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD4BzYVvq9_j"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-0dl8EoqK0T",
        "outputId": "c912eb2e-613a-4f9e-f227-895e4f4cfdba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Counts: [68 26 31 29], Class Ratios: [0.44155844 0.16883117 0.2012987  0.18831169]\n",
            "Number of features: 4800\n",
            "Number of instances: 154\n",
            "Number of classes 4.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Data - data.py\n",
        "==============\n",
        "\n",
        "This is the data module. It contains the functions for loading, preparing, normalizing and encoding the data.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import preprocessing\n",
        "import scipy.io\n",
        "\n",
        "\n",
        "def encode_labels(y, y_test=None):\n",
        "    \"\"\"\n",
        "    Convert text labels to numbers.\n",
        "\n",
        "    Args:\n",
        "        y: The labels.\n",
        "        y_test: The test labels. Defaults to None.\n",
        "    \"\"\"\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    y = le.fit_transform(y)\n",
        "    if y_test is not None:\n",
        "        y_test = le.transform(y_test)\n",
        "    return y, y_test, le\n",
        "\n",
        "\n",
        "def load(filename, folder=''):\n",
        "    \"\"\"\n",
        "    Load the data from the mat file.\n",
        "\n",
        "    Args:\n",
        "        filename: The name of the mat file.\n",
        "        folder: The folder where the mat file is located.\n",
        "    \"\"\"\n",
        "    path = folder + \"/\" + filename\n",
        "    mat = scipy.io.loadmat(path)\n",
        "    return mat\n",
        "\n",
        "\n",
        "def prepare(mat):\n",
        "    \"\"\"\n",
        "    Load the data from matlab format into memory. \n",
        "\n",
        "    Args:\n",
        "        mat: The data in matlab format.\n",
        "    \"\"\"\n",
        "    X = mat['X']   \n",
        "    X = X.astype(float)\n",
        "    y = mat['Y']    \n",
        "    y = y[:, 0]\n",
        "    return X,y\n",
        "\n",
        "\n",
        "def normalize(X_train, X_test):\n",
        "    \"\"\"\n",
        "    Normalize the input features within range [0,1].\n",
        "\n",
        "    Args:\n",
        "        X_train: The training data.\n",
        "        X_test: The test data.\n",
        "    \"\"\"\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaler = scaler.fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    return X_train, X_test\n",
        "\n",
        "\n",
        "def one_hot_encoding(ys):\n",
        "    \"\"\" Convert a label to onehot encoding. A vector where its argmax, or 1 value, corresponds to the index of the class label. \n",
        "\n",
        "    Args: \n",
        "        ys: The class\n",
        "\n",
        "    Returngs: \n",
        "        one_hot: The class labels as onehot encoded vectors. \n",
        "    \"\"\"\n",
        "    n_instances, n_classes = len(ys), len(np.unique(ys))\n",
        "    one_hot = np.zeros((n_instances, n_classes))\n",
        "    for i,y in enumerate(ys):\n",
        "        one_hot[i][y] = 1 \n",
        "    return one_hot\n",
        "\n",
        "\n",
        "file = load('Fish.mat', folder=data_path_gdrive)\n",
        "X,y = prepare(file)\n",
        "X,_ = normalize(X,X)\n",
        "y, _, le = encode_labels(y)\n",
        "labels = le.inverse_transform(np.unique(y))\n",
        "classes, class_counts = np.unique(y, return_counts=True)\n",
        "# y = one_hot_encoding(y)\n",
        "n_features = X.shape[1]\n",
        "n_instances = X.shape[0]\n",
        "n_classes = len(classes)\n",
        "class_ratios = np.array(class_counts) / n_instances\n",
        "\n",
        "print(f\"Class Counts: {class_counts}, Class Ratios: {class_ratios}\")\n",
        "print(f\"Number of features: {n_features}\\nNumber of instances: {n_instances}\\nNumber of classes {n_classes}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eanPjO3KB121"
      },
      "source": [
        "## Activation Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP6upHxeyFX_"
      },
      "source": [
        "## Operators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8AQBTITsyEzE"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import copy\n",
        "import random\n",
        "import operator\n",
        "from re import I\n",
        "from operator import attrgetter\n",
        "from functools import wraps, partial\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from deap import algorithms\n",
        "from deap.algorithms import varAnd\n",
        "from deap import base\n",
        "from deap import creator\n",
        "from deap import tools\n",
        "from deap import gp\n",
        "\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "\n",
        "def protectedDiv(left, right):\n",
        "    \"\"\"\n",
        "    Protected division operator that avoids zero division.\n",
        "\n",
        "    Arg:\n",
        "        left: The left hand side expression. \n",
        "        right: The right hand side expression. \n",
        "\n",
        "    Returns: \n",
        "        left/right, when right is non-zero value. Otherwise, returns 1. \n",
        "    \"\"\"\n",
        "    if right == 0: \n",
        "        return 0.0 \n",
        "    if math.isnan(left) or math.isnan(right):\n",
        "        return 0.0\n",
        "    return left / right\n",
        "\n",
        "pset = gp.PrimitiveSet(\"MAIN\", n_features)\n",
        "pset.addPrimitive(operator.add, 2)\n",
        "pset.addPrimitive(operator.sub, 2)\n",
        "pset.addPrimitive(operator.mul, 2)\n",
        "pset.addPrimitive(protectedDiv, 2)\n",
        "pset.addPrimitive(operator.neg, 1)\n",
        "pset.addEphemeralConstant(\"rand101\", lambda: random.randint(-1,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kejku7hWyMbO"
      },
      "source": [
        "## Fitness Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rQE3P3qLyMDr"
      },
      "outputs": [],
      "source": [
        "toolbox = base.Toolbox()\n",
        "\n",
        "minimized = False\n",
        "if minimized: \n",
        "    weight = -1.0 \n",
        "else: \n",
        "    weight = 1.0\n",
        "\n",
        "weights = (weight,)\n",
        "\n",
        "if minimized: \n",
        "    creator.create(\"FitnessMin\", base.Fitness, weights=weights)\n",
        "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
        "else:\n",
        "    creator.create(\"FitnessMax\", base.Fitness, weights=weights)\n",
        "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "\n",
        "def compileMultiTree(expr, pset):\n",
        "    \"\"\"Compile the expression represented by a list of trees. \n",
        "\n",
        "    A variation of the gp.compileADF method, that handles Multi-tree GP. \n",
        "\n",
        "    Args: \n",
        "        expr: Expression to compile. It can either be a PrimitiveTree,\n",
        "                 a string of Python code or any object that when\n",
        "                 converted into string produced a valid Python code\n",
        "                 expression.\n",
        "        pset: Primitive Set\n",
        "\n",
        "    Returns: \n",
        "        A set of functions that correspond for each tree in the Multi-tree. \n",
        "    \"\"\"\n",
        "    funcs = []\n",
        "    gp_tree = None\n",
        "    func = None\n",
        "\n",
        "    for subexpr in expr:\n",
        "        gp_tree = gp.PrimitiveTree(subexpr)\n",
        "        func = gp.compile(gp_tree, pset)\n",
        "        funcs.append(func)\n",
        "    return funcs\n",
        "\n",
        "# MCIFC constructs 8 feautres for a (c=4) multi-class classification problem (Tran 2019).\n",
        "# c - number of classes, r - construction ratio, m - total number of constructed features.\n",
        "# m = r * c = 2 ratio * 4 classes = 8 features\n",
        "\n",
        "r = 2 \n",
        "c = n_classes \n",
        "m = r * c \n",
        "\n",
        "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=2)\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.expr, n=m)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "toolbox.register(\"compile\", compileMultiTree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSBBJ2cRMqWb",
        "outputId": "7e9d77ea-4d02-4fac-aecc-6c8f3a75766b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For v1: [0, 0, 0, 1], v2: [0, 1, 0, 1], the hamming distance is 1\n"
          ]
        }
      ],
      "source": [
        "def hamming_distance(v1, v2):\n",
        "    v1, v2 = np.array(v1), np.array(v2)\n",
        "    d = np.sum(np.abs(v1 - v2))\n",
        "    return d\n",
        "\n",
        "v1 = [0,0,0,1]\n",
        "v2 = [0,1,0,1]\n",
        "print(f\"For v1: {v1}, v2: {v2}, the hamming distance is {hamming_distance(v1,v2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC as svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def wrapper_classification_accuracy(X, verbose=False):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "    X_train, X_test = normalize(X_train, X_test)\n",
        "    model = svm(penalty='l2', max_iter=10_000)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_predict = model.predict(X_train)\n",
        "    train_acc = balanced_accuracy_score(y_train, y_predict)\n",
        "    y_predict = model.predict(X_test)\n",
        "    test_acc = balanced_accuracy_score(y_test, y_predict)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Train accuracy: {train_acc}, Test accuracy: {test_acc}\")\n",
        "\n",
        "    return test_acc\n",
        "\n",
        "wrapper_classification_accuracy(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryKFCvmusAlS",
        "outputId": "cfa37415-12bb-4094-d25e-ccb312a55b41"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9365384615384615"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vOz-1Oislgd",
        "outputId": "4a4165b2-026b-4184-94b8-9656cc11320a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \t      \t                                 fitness                                 \t                      size                     \n",
            "   \t      \t-------------------------------------------------------------------------\t-----------------------------------------------\n",
            "gen\tnevals\tavg     \tgen\tmax     \tmin     \tnevals\tstd      \tavg \tgen\tmax\tmin\tnevals\tstd    \n",
            "0  \t100   \t0.421174\t0  \t0.584885\t0.280702\t100   \t0.0662439\t6.21\t0  \t7  \t3  \t100   \t1.45117\n",
            "1  \t90    \t0.463341\t1  \t0.584885\t0.322312\t90    \t0.0623829\t6.12\t1  \t12 \t3  \t90    \t1.63878\n",
            "2  \t83    \t0.49922 \t2  \t0.615812\t0.314766\t83    \t0.0664149\t6.37\t2  \t12 \t3  \t83    \t1.55984\n",
            "3  \t73    \t0.54144 \t3  \t0.620569\t0.433783\t73    \t0.0425492\t6.5 \t3  \t9  \t3  \t73    \t1.33791\n",
            "4  \t83    \t0.552682\t4  \t0.642578\t0.414766\t83    \t0.0500697\t6.69\t4  \t12 \t3  \t83    \t1.39065\n",
            "5  \t86    \t0.580516\t5  \t0.665103\t0.471637\t86    \t0.0387838\t6.49\t5  \t9  \t3  \t86    \t1.63398\n",
            "6  \t80    \t0.596143\t6  \t0.68321 \t0.467488\t80    \t0.0409027\t6.35\t6  \t13 \t3  \t80    \t1.81865\n",
            "7  \t73    \t0.616933\t7  \t0.721671\t0.469411\t73    \t0.0436227\t6.09\t7  \t13 \t3  \t73    \t2.15914\n",
            "8  \t78    \t0.635029\t8  \t0.721671\t0.473099\t78    \t0.045216 \t5.08\t8  \t9  \t3  \t78    \t1.54713\n",
            "9  \t82    \t0.652282\t9  \t0.760133\t0.480432\t82    \t0.04963  \t4.44\t9  \t9  \t3  \t82    \t1.38072\n",
            "10 \t82    \t0.670563\t10 \t0.760133\t0.452654\t82    \t0.0480546\t3.96\t10 \t8  \t3  \t82    \t0.978979\n",
            "11 \t88    \t0.681646\t11 \t0.760133\t0.485189\t88    \t0.0560327\t4.21\t11 \t8  \t3  \t88    \t1.55753 \n",
            "12 \t86    \t0.709226\t12 \t0.779363\t0.545052\t86    \t0.0466881\t4.32\t12 \t8  \t3  \t86    \t1.69044 \n",
            "13 \t80    \t0.717143\t13 \t0.779363\t0.542578\t80    \t0.0452771\t4.53\t13 \t9  \t3  \t80    \t1.68199 \n",
            "14 \t74    \t0.724329\t14 \t0.779363\t0.513979\t74    \t0.0514215\t4.19\t14 \t9  \t3  \t74    \t1.52771 \n",
            "15 \t82    \t0.742392\t15 \t0.779363\t0.545445\t82    \t0.0385154\t3.88\t15 \t9  \t3  \t82    \t0.97242 \n",
            "16 \t77    \t0.743137\t16 \t0.779363\t0.564586\t77    \t0.0491933\t4   \t16 \t9  \t3  \t77    \t1.2     \n",
            "17 \t78    \t0.744425\t17 \t0.779363\t0.571975\t78    \t0.0505545\t3.95\t17 \t9  \t3  \t78    \t1.19478 \n",
            "18 \t79    \t0.760117\t18 \t0.779363\t0.539586\t79    \t0.0411834\t3.89\t18 \t8  \t3  \t79    \t0.988888\n",
            "19 \t87    \t0.758216\t19 \t0.779363\t0.52744 \t87    \t0.0439137\t3.89\t19 \t8  \t3  \t87    \t0.81111 \n",
            "20 \t88    \t0.756578\t20 \t0.779363\t0.469748\t88    \t0.0469598\t3.92\t20 \t9  \t3  \t88    \t1.03615 \n",
            "21 \t84    \t0.763207\t21 \t0.779363\t0.624753\t84    \t0.0284361\t3.97\t21 \t9  \t3  \t84    \t1.01445 \n",
            "22 \t86    \t0.757213\t22 \t0.779363\t0.577744\t86    \t0.0419599\t3.9 \t22 \t9  \t3  \t86    \t0.994987\n",
            "23 \t83    \t0.764742\t23 \t0.779363\t0.629116\t83    \t0.0314782\t3.92\t23 \t7  \t3  \t83    \t0.868101\n",
            "24 \t85    \t0.761623\t24 \t0.779363\t0.629363\t85    \t0.0352792\t3.93\t24 \t9  \t3  \t85    \t1.11584 \n",
            "25 \t73    \t0.770031\t25 \t0.779363\t0.654363\t73    \t0.025528 \t3.86\t25 \t6  \t3  \t73    \t0.80025 \n",
            "26 \t88    \t0.763553\t26 \t0.779363\t0.557355\t88    \t0.0387796\t3.89\t26 \t9  \t3  \t88    \t1.13044 \n",
            "27 \t84    \t0.762119\t27 \t0.779363\t0.629363\t84    \t0.0358087\t3.97\t27 \t9  \t3  \t84    \t1.11763 \n",
            "28 \t81    \t0.758509\t28 \t0.779363\t0.624966\t81    \t0.0381725\t3.95\t28 \t9  \t3  \t81    \t1.08051 \n",
            "29 \t87    \t0.767421\t29 \t0.779363\t0.56859 \t87    \t0.0317792\t3.99\t29 \t10 \t3  \t87    \t1.17894 \n",
            "30 \t82    \t0.7674  \t30 \t0.779363\t0.571975\t82    \t0.0331806\t3.92\t30 \t6  \t3  \t82    \t0.923905\n",
            "31 \t80    \t0.77261 \t31 \t0.792521\t0.651586\t80    \t0.0218117\t3.94\t31 \t10 \t3  \t80    \t1.15603 \n",
            "32 \t81    \t0.762541\t32 \t0.792521\t0.577744\t81    \t0.0402479\t4.12\t32 \t10 \t3  \t81    \t1.32121 \n",
            "33 \t84    \t0.759505\t33 \t0.792521\t0.577744\t84    \t0.042818 \t4.13\t33 \t10 \t3  \t84    \t1.43983 \n",
            "34 \t82    \t0.766188\t34 \t0.792521\t0.629363\t82    \t0.0321226\t4.05\t34 \t10 \t3  \t82    \t1.35185 \n",
            "35 \t87    \t0.7619  \t35 \t0.792521\t0.612697\t87    \t0.0443781\t4   \t35 \t8  \t3  \t87    \t1.42127 \n",
            "36 \t81    \t0.765468\t36 \t0.792521\t0.629363\t81    \t0.0405348\t4.11\t36 \t8  \t3  \t81    \t1.6118  \n",
            "37 \t85    \t0.766804\t37 \t0.792521\t0.637112\t85    \t0.037536 \t4.07\t37 \t8  \t3  \t85    \t1.42306 \n",
            "38 \t80    \t0.779133\t38 \t0.792521\t0.555432\t80    \t0.0297551\t3.66\t38 \t8  \t3  \t80    \t1.0509  \n",
            "39 \t84    \t0.759886\t39 \t0.792521\t0.589283\t84    \t0.0490035\t3.64\t39 \t9  \t3  \t84    \t1.20433 \n",
            "40 \t81    \t0.76758 \t40 \t0.792521\t0.635189\t81    \t0.0423084\t3.57\t40 \t9  \t3  \t81    \t1.22683 \n",
            "41 \t73    \t0.774356\t41 \t0.792521\t0.638428\t73    \t0.0370717\t3.44\t41 \t9  \t3  \t73    \t1.03267 \n",
            "42 \t77    \t0.776321\t42 \t0.792521\t0.638428\t77    \t0.0343179\t3.3 \t42 \t8  \t3  \t77    \t0.685565\n",
            "43 \t83    \t0.774643\t43 \t0.792521\t0.638428\t83    \t0.0357146\t3.48\t43 \t9  \t3  \t83    \t1.10887 \n",
            "44 \t81    \t0.773317\t44 \t0.792521\t0.615598\t81    \t0.0379968\t3.41\t44 \t9  \t3  \t81    \t0.917551\n",
            "45 \t82    \t0.773042\t45 \t0.792521\t0.638428\t82    \t0.0383002\t3.48\t45 \t7  \t3  \t82    \t0.865794\n",
            "46 \t75    \t0.771435\t46 \t0.792521\t0.632265\t75    \t0.0412259\t3.66\t46 \t8  \t3  \t75    \t1.06977 \n",
            "47 \t81    \t0.772865\t47 \t0.792521\t0.638428\t81    \t0.0387807\t3.43\t47 \t6  \t3  \t81    \t0.636475\n",
            "48 \t82    \t0.771243\t48 \t0.792521\t0.638428\t82    \t0.0407727\t3.45\t48 \t8  \t3  \t82    \t0.829156\n",
            "49 \t86    \t0.773148\t49 \t0.792521\t0.638428\t86    \t0.0366649\t3.52\t49 \t8  \t3  \t86    \t1.09982 \n",
            "50 \t78    \t0.778365\t50 \t0.792521\t0.638428\t78    \t0.0350062\t3.64\t50 \t8  \t3  \t78    \t1.19599 \n",
            "51 \t81    \t0.777042\t51 \t0.792521\t0.632355\t81    \t0.0356584\t3.79\t51 \t9  \t3  \t81    \t1.32887 \n",
            "52 \t83    \t0.766411\t52 \t0.792521\t0.55821 \t83    \t0.0491585\t3.86\t52 \t10 \t3  \t83    \t1.47662 \n",
            "53 \t84    \t0.771195\t53 \t0.792521\t0.638428\t84    \t0.0399086\t3.58\t53 \t8  \t3  \t84    \t1.0787  \n",
            "54 \t86    \t0.768724\t54 \t0.792521\t0.638428\t86    \t0.0388131\t3.74\t54 \t8  \t3  \t86    \t1.11911 \n",
            "55 \t82    \t0.771072\t55 \t0.792521\t0.612697\t82    \t0.038286 \t3.96\t55 \t8  \t3  \t82    \t1.29553 \n",
            "56 \t86    \t0.765749\t56 \t0.792521\t0.638428\t86    \t0.043134 \t4.07\t56 \t8  \t3  \t86    \t1.25901 \n",
            "57 \t77    \t0.770046\t57 \t0.792521\t0.599539\t77    \t0.0462737\t4   \t57 \t8  \t3  \t77    \t1.40712 \n",
            "58 \t83    \t0.774441\t58 \t0.792521\t0.638428\t83    \t0.0369331\t4.04\t58 \t9  \t3  \t83    \t1.40656 \n",
            "59 \t87    \t0.777511\t59 \t0.792521\t0.663428\t87    \t0.0342108\t3.85\t59 \t8  \t3  \t87    \t1.12583 \n",
            "60 \t81    \t0.776409\t60 \t0.793983\t0.62527 \t81    \t0.0343157\t3.76\t60 \t9  \t3  \t81    \t1.40798 \n",
            "61 \t81    \t0.779627\t61 \t0.793983\t0.638428\t81    \t0.0297768\t4.12\t61 \t8  \t3  \t81    \t1.63267 \n",
            "62 \t89    \t0.774914\t62 \t0.793983\t0.653048\t89    \t0.0348264\t4.14\t62 \t8  \t3  \t89    \t1.63107 \n",
            "63 \t84    \t0.773797\t63 \t0.793983\t0.638428\t84    \t0.0333707\t4.87\t63 \t13 \t3  \t84    \t2.14315 \n",
            "64 \t90    \t0.771877\t64 \t0.793983\t0.606287\t90    \t0.0415473\t5.3 \t64 \t13 \t3  \t90    \t2.29129 \n",
            "65 \t86    \t0.776944\t65 \t0.807141\t0.66859 \t86    \t0.0294589\t6.05\t65 \t10 \t3  \t86    \t2.18804 \n",
            "66 \t82    \t0.775366\t66 \t0.807141\t0.664744\t82    \t0.0341998\t6.98\t66 \t14 \t3  \t82    \t2.09752 \n",
            "67 \t86    \t0.779683\t67 \t0.807141\t0.585133\t86    \t0.035071 \t7.64\t67 \t10 \t3  \t86    \t1.41082 \n",
            "68 \t86    \t0.781933\t68 \t0.807141\t0.659031\t86    \t0.030258 \t7.94\t68 \t13 \t3  \t86    \t1.3625  \n",
            "69 \t84    \t0.780553\t69 \t0.807141\t0.68321 \t84    \t0.0327023\t8.03\t69 \t14 \t3  \t84    \t1.30733 \n",
            "70 \t82    \t0.782975\t70 \t0.807141\t0.668983\t82    \t0.0311339\t8.18\t70 \t15 \t3  \t82    \t1.79655 \n",
            "71 \t83    \t0.780975\t71 \t0.807141\t0.666206\t83    \t0.0374094\t7.88\t71 \t13 \t3  \t83    \t1.46479 \n",
            "72 \t80    \t0.783651\t72 \t0.807141\t0.66904 \t80    \t0.0333293\t7.79\t72 \t13 \t3  \t80    \t1.85092 \n",
            "73 \t86    \t0.787227\t73 \t0.807141\t0.638428\t86    \t0.0374918\t7.5 \t73 \t13 \t3  \t86    \t1.39642 \n",
            "74 \t80    \t0.791513\t74 \t0.807141\t0.670052\t80    \t0.0305181\t7.52\t74 \t10 \t4  \t80    \t0.974474\n",
            "75 \t77    \t0.784072\t75 \t0.807141\t0.651586\t77    \t0.0391762\t7.43\t75 \t13 \t4  \t77    \t1.35834 \n",
            "76 \t83    \t0.793691\t76 \t0.807141\t0.670052\t83    \t0.0313285\t7.53\t76 \t11 \t5  \t83    \t1.00454 \n",
            "77 \t81    \t0.790736\t77 \t0.807141\t0.670052\t81    \t0.0307286\t7.5 \t77 \t11 \t3  \t81    \t1.22882 \n",
            "78 \t77    \t0.791758\t78 \t0.807141\t0.545052\t77    \t0.0366026\t7.5 \t78 \t11 \t4  \t77    \t1.09087 \n",
            "79 \t86    \t0.788987\t79 \t0.807141\t0.670052\t86    \t0.0358819\t7.56\t79 \t13 \t4  \t86    \t1.0707  \n",
            "80 \t88    \t0.792154\t80 \t0.807141\t0.670052\t88    \t0.0325142\t7.63\t80 \t13 \t4  \t88    \t1.23008 \n",
            "81 \t79    \t0.791234\t81 \t0.807141\t0.657141\t79    \t0.0332525\t7.52\t81 \t13 \t3  \t79    \t1.38188 \n",
            "82 \t83    \t0.78512 \t82 \t0.807141\t0.670052\t83    \t0.0417565\t7.5 \t82 \t8  \t6  \t83    \t0.866025\n",
            "83 \t80    \t0.783359\t83 \t0.820299\t0.63791 \t80    \t0.0415108\t7.5 \t83 \t13 \t3  \t80    \t1.29228 \n",
            "84 \t80    \t0.790543\t84 \t0.820299\t0.612359\t80    \t0.032282 \t7.56\t84 \t13 \t4  \t80    \t1.22735 \n",
            "85 \t80    \t0.792184\t85 \t0.820299\t0.692521\t80    \t0.0295231\t7.48\t85 \t13 \t3  \t80    \t1.49318 \n",
            "86 \t74    \t0.796542\t86 \t0.820299\t0.692521\t74    \t0.0283262\t7.72\t86 \t14 \t4  \t74    \t1.2254  \n",
            "87 \t78    \t0.787157\t87 \t0.820299\t0.630522\t78    \t0.0413666\t7.67\t87 \t12 \t5  \t78    \t0.980357\n",
            "88 \t82    \t0.793522\t88 \t0.820299\t0.667521\t82    \t0.035724 \t7.73\t88 \t14 \t4  \t82    \t1.40609 \n",
            "89 \t84    \t0.800383\t89 \t0.820299\t0.62527 \t84    \t0.0310125\t8.3 \t89 \t13 \t4  \t84    \t1.64621 \n",
            "90 \t88    \t0.791282\t90 \t0.820299\t0.640812\t88    \t0.0408568\t8.69\t90 \t14 \t6  \t88    \t1.61676 \n",
            "91 \t85    \t0.799153\t91 \t0.820299\t0.667521\t85    \t0.0395435\t8.7 \t91 \t14 \t6  \t85    \t1.57162 \n",
            "92 \t81    \t0.793482\t92 \t0.820299\t0.621368\t81    \t0.0472764\t8.73\t92 \t17 \t6  \t81    \t1.75417 \n",
            "93 \t83    \t0.800204\t93 \t0.820299\t0.682872\t83    \t0.03551  \t8.67\t93 \t13 \t6  \t83    \t1.6435  \n",
            "94 \t86    \t0.803531\t94 \t0.820299\t0.668252\t86    \t0.0318722\t8.66\t94 \t14 \t6  \t86    \t1.5762  \n",
            "95 \t76    \t0.800957\t95 \t0.820299\t0.657141\t76    \t0.0391786\t8.44\t95 \t12 \t6  \t76    \t1.26744 \n",
            "96 \t84    \t0.804286\t96 \t0.820299\t0.667521\t84    \t0.0325159\t8.5 \t96 \t14 \t6  \t84    \t1.28452 \n",
            "97 \t83    \t0.7962  \t97 \t0.820299\t0.658356\t83    \t0.0429305\t8.54\t97 \t14 \t6  \t83    \t1.2839  \n",
            "98 \t81    \t0.801665\t98 \t0.820299\t0.667521\t81    \t0.0362293\t8.84\t98 \t14 \t6  \t81    \t1.32454 \n",
            "99 \t82    \t0.792115\t99 \t0.820299\t0.667521\t82    \t0.0480702\t8.81\t99 \t19 \t5  \t82    \t1.68342 \n",
            "100\t75    \t0.797825\t100\t0.820299\t0.605218\t75    \t0.0466684\t8.77\t100\t13 \t6  \t75    \t1.14765 \n",
            "101\t82    \t0.80673 \t101\t0.820299\t0.696368\t82    \t0.0288655\t8.88\t101\t19 \t6  \t82    \t1.53154 \n",
            "102\t86    \t0.809268\t102\t0.820299\t0.724145\t86    \t0.0229973\t8.96\t102\t15 \t6  \t86    \t1.22409 \n",
            "103\t85    \t0.788786\t103\t0.820299\t0.598291\t85    \t0.0473574\t9.1 \t103\t14 \t6  \t85    \t1.45258 \n",
            "104\t78    \t0.805018\t104\t0.820299\t0.670052\t78    \t0.0309937\t8.91\t104\t13 \t6  \t78    \t1.20079 \n",
            "105\t85    \t0.784396\t105\t0.820299\t0.555094\t85    \t0.0572517\t8.76\t105\t13 \t6  \t85    \t1.19264 \n",
            "106\t84    \t0.796468\t106\t0.820299\t0.666206\t84    \t0.0402189\t8.54\t106\t14 \t6  \t84    \t1.15256 \n",
            "107\t83    \t0.799091\t107\t0.820299\t0.687607\t83    \t0.0387467\t8.49\t107\t12 \t6  \t83    \t0.932684\n",
            "108\t76    \t0.799371\t108\t0.820299\t0.667521\t76    \t0.040089 \t8.52\t108\t15 \t6  \t76    \t1.49318 \n",
            "109\t77    \t0.800535\t109\t0.820299\t0.682141\t77    \t0.0356402\t8.51\t109\t13 \t6  \t77    \t1.24495 \n",
            "110\t80    \t0.803225\t110\t0.820299\t0.55821 \t80    \t0.0383705\t8.56\t110\t12 \t6  \t80    \t1.15169 \n",
            "111\t86    \t0.801546\t111\t0.820299\t0.585987\t86    \t0.0442289\t8.81\t111\t13 \t6  \t86    \t1.33188 \n",
            "112\t81    \t0.793215\t112\t0.820299\t0.596671\t81    \t0.0468224\t8.89\t112\t13 \t6  \t81    \t1.39208 \n",
            "113\t75    \t0.789905\t113\t0.820299\t0.667521\t75    \t0.0475483\t9.07\t113\t15 \t6  \t75    \t1.53789 \n",
            "114\t81    \t0.798026\t114\t0.828846\t0.585987\t81    \t0.0458189\t8.93\t114\t13 \t6  \t81    \t1.33608 \n",
            "115\t83    \t0.804485\t115\t0.828846\t0.649449\t83    \t0.0357648\t9.07\t115\t15 \t6  \t83    \t1.53137 \n",
            "116\t86    \t0.797652\t116\t0.828846\t0.648291\t86    \t0.0442969\t9.03\t116\t15 \t6  \t86    \t1.35244 \n",
            "117\t82    \t0.804228\t117\t0.828846\t0.638428\t82    \t0.0392298\t9.32\t117\t15 \t6  \t82    \t1.44139 \n",
            "118\t80    \t0.803659\t118\t0.828846\t0.560987\t80    \t0.0437092\t9.18\t118\t16 \t6  \t80    \t1.43792 \n",
            "119\t77    \t0.798871\t119\t0.828846\t0.698504\t77    \t0.0405024\t9.21\t119\t19 \t6  \t77    \t1.63887 \n",
            "120\t80    \t0.803196\t120\t0.828846\t0.691419\t80    \t0.0377222\t9.09\t120\t13 \t7  \t80    \t0.775822\n",
            "121\t86    \t0.804054\t121\t0.828846\t0.667521\t86    \t0.0413322\t9.03\t121\t13 \t6  \t86    \t0.684909\n",
            "122\t74    \t0.814133\t122\t0.828846\t0.624145\t74    \t0.0370612\t9.06\t122\t15 \t6  \t74    \t0.998198\n",
            "123\t84    \t0.803159\t123\t0.828846\t0.707501\t84    \t0.0373455\t9.15\t123\t13 \t7  \t84    \t0.68374 \n",
            "124\t79    \t0.802295\t124\t0.828846\t0.625607\t79    \t0.0441527\t9.11\t124\t11 \t6  \t79    \t0.563826\n",
            "125\t81    \t0.804886\t125\t0.828846\t0.593376\t81    \t0.0446911\t9.23\t125\t14 \t8  \t81    \t0.746391\n",
            "126\t81    \t0.818157\t126\t0.828846\t0.670726\t81    \t0.0320573\t9.23\t126\t11 \t9  \t81    \t0.443959\n",
            "127\t80    \t0.81077 \t127\t0.828846\t0.68791 \t80    \t0.0366011\t9.34\t127\t16 \t7  \t80    \t0.885664\n",
            "128\t87    \t0.807285\t128\t0.828846\t0.68791 \t87    \t0.0392483\t9.41\t128\t14 \t6  \t87    \t1.01089 \n",
            "129\t85    \t0.804162\t129\t0.828846\t0.633356\t85    \t0.0456926\t9.35\t129\t14 \t6  \t85    \t0.90967 \n",
            "130\t84    \t0.800764\t130\t0.828846\t0.584672\t84    \t0.0459401\t9.36\t130\t13 \t6  \t84    \t0.842852\n",
            "131\t82    \t0.809507\t131\t0.828846\t0.585987\t82    \t0.0443128\t9.32\t131\t14 \t4  \t82    \t1.03808 \n",
            "132\t84    \t0.810724\t132\t0.828846\t0.689957\t84    \t0.0339857\t9.37\t132\t14 \t8  \t84    \t0.890562\n",
            "133\t80    \t0.810709\t133\t0.828846\t0.584672\t80    \t0.0416543\t9.35\t133\t14 \t6  \t80    \t0.864581\n",
            "134\t90    \t0.808134\t134\t0.828846\t0.68791 \t90    \t0.0382945\t9.49\t134\t16 \t6  \t90    \t1.21239 \n",
            "135\t77    \t0.81165 \t135\t0.828846\t0.68791 \t77    \t0.0367892\t9.48\t135\t14 \t7  \t77    \t1.03421 \n",
            "136\t82    \t0.805748\t136\t0.828846\t0.68791 \t82    \t0.0384714\t9.57\t136\t16 \t6  \t82    \t1.46462 \n",
            "137\t79    \t0.808583\t137\t0.828846\t0.648437\t79    \t0.0385797\t9.42\t137\t15 \t8  \t79    \t1.03131 \n",
            "138\t84    \t0.805891\t138\t0.828846\t0.623437\t84    \t0.043864 \t9.6 \t138\t15 \t8  \t84    \t1.27279 \n",
            "139\t86    \t0.802669\t139\t0.828846\t0.651923\t86    \t0.0431618\t9.43\t139\t14 \t6  \t86    \t1.27479 \n",
            "140\t78    \t0.816555\t140\t0.828846\t0.610987\t78    \t0.0332392\t9.37\t140\t14 \t6  \t78    \t1.04551 \n",
            "141\t79    \t0.815737\t141\t0.828846\t0.674753\t79    \t0.0347386\t9.46\t141\t14 \t6  \t79    \t1.25236 \n",
            "142\t81    \t0.80554 \t142\t0.828846\t0.68791 \t81    \t0.0417101\t9.37\t142\t14 \t7  \t81    \t1.04551 \n",
            "143\t86    \t0.813765\t143\t0.828846\t0.704577\t86    \t0.0305595\t9.48\t143\t14 \t8  \t86    \t1.12677 \n",
            "144\t80    \t0.808659\t144\t0.828846\t0.59783 \t80    \t0.0419747\t9.59\t144\t15 \t8  \t80    \t1.30457 \n",
            "145\t80    \t0.811033\t145\t0.828846\t0.689957\t80    \t0.0386986\t9.49\t145\t16 \t6  \t80    \t1.27668 \n",
            "146\t81    \t0.809184\t146\t0.828846\t0.68791 \t81    \t0.0366259\t9.45\t146\t14 \t6  \t81    \t1.12583 \n",
            "147\t83    \t0.805097\t147\t0.828846\t0.68791 \t83    \t0.0388866\t9.51\t147\t18 \t8  \t83    \t1.29225 \n",
            "148\t78    \t0.812464\t148\t0.828846\t0.70253 \t78    \t0.0303077\t9.79\t148\t18 \t7  \t78    \t1.80164 \n",
            "149\t83    \t0.805089\t149\t0.848077\t0.660133\t83    \t0.0420908\t9.99\t149\t18 \t6  \t83    \t2.14241 \n",
            "150\t78    \t0.80563 \t150\t0.848077\t0.661595\t78    \t0.0430296\t9.79\t150\t18 \t6  \t78    \t1.7793  \n",
            "151\t82    \t0.804495\t151\t0.848077\t0.650484\t82    \t0.0460385\t9.97\t151\t18 \t6  \t82    \t1.97714 \n",
            "152\t86    \t0.8023  \t152\t0.848077\t0.661595\t86    \t0.0449103\t10.07\t152\t18 \t6  \t86    \t2.00127 \n",
            "153\t84    \t0.816235\t153\t0.848077\t0.68791 \t84    \t0.0384766\t9.97 \t153\t18 \t8  \t84    \t1.81359 \n",
            "154\t78    \t0.825221\t154\t0.848077\t0.695299\t78    \t0.0340191\t9.47 \t154\t18 \t6  \t78    \t1.25264 \n",
            "155\t76    \t0.82227 \t155\t0.848077\t0.695299\t76    \t0.0423811\t9.44 \t155\t15 \t8  \t76    \t0.972831\n",
            "156\t79    \t0.828381\t156\t0.848077\t0.640475\t79    \t0.0419456\t9.58 \t156\t14 \t8  \t79    \t1.0787  \n",
            "157\t81    \t0.820501\t157\t0.848077\t0.655522\t81    \t0.0465584\t9.64 \t157\t14 \t7  \t81    \t1.31545 \n",
            "158\t78    \t0.822737\t158\t0.848077\t0.605218\t78    \t0.0428057\t9.59 \t158\t14 \t6  \t78    \t1.31981 \n",
            "159\t82    \t0.81885 \t159\t0.848077\t0.602013\t82    \t0.0484432\t9.5  \t159\t14 \t6  \t82    \t1.20416 \n",
            "160\t80    \t0.826869\t160\t0.848077\t0.588574\t80    \t0.0443976\t9.7  \t160\t14 \t6  \t80    \t1.37477 \n",
            "161\t87    \t0.816748\t161\t0.848077\t0.643983\t87    \t0.0493802\t9.77 \t161\t14 \t7  \t87    \t1.48226 \n",
            "162\t82    \t0.83006 \t162\t0.848077\t0.629791\t82    \t0.0385299\t9.54 \t162\t14 \t8  \t82    \t1.12623 \n",
            "163\t83    \t0.820938\t163\t0.848077\t0.692521\t83    \t0.0403466\t9.84 \t163\t16 \t6  \t83    \t1.67762 \n",
            "164\t86    \t0.82924 \t164\t0.848077\t0.695299\t86    \t0.0336016\t9.95 \t164\t20 \t9  \t86    \t1.87816 \n",
            "165\t86    \t0.826812\t165\t0.848077\t0.663428\t86    \t0.0444367\t10.04\t165\t20 \t8  \t86    \t2.04411 \n",
            "166\t86    \t0.825453\t166\t0.848077\t0.695299\t86    \t0.0383588\t9.7  \t166\t16 \t6  \t86    \t1.53948 \n",
            "167\t82    \t0.828107\t167\t0.848077\t0.695299\t82    \t0.0361726\t10.33\t167\t18 \t6  \t82    \t2.23631 \n",
            "168\t82    \t0.824375\t168\t0.848077\t0.689283\t82    \t0.0436407\t10.13\t168\t18 \t6  \t82    \t2.08641 \n",
            "169\t88    \t0.833589\t169\t0.848077\t0.695299\t88    \t0.0359508\t10.29\t169\t18 \t6  \t88    \t2.0263  \n",
            "170\t78    \t0.827824\t170\t0.848077\t0.695299\t78    \t0.0401297\t10.02\t170\t18 \t6  \t78    \t1.64912 \n",
            "171\t79    \t0.824837\t171\t0.848077\t0.612607\t79    \t0.0503459\t10   \t171\t14 \t9  \t79    \t1.23288 \n",
            "172\t84    \t0.824465\t172\t0.848077\t0.629363\t84    \t0.0402886\t10.34\t172\t16 \t9  \t84    \t1.66865 \n",
            "173\t83    \t0.811534\t173\t0.848077\t0.657996\t83    \t0.0519524\t10.09\t173\t14 \t6  \t83    \t1.60059 \n",
            "174\t79    \t0.833814\t174\t0.848077\t0.720299\t79    \t0.0299219\t10.14\t174\t16 \t9  \t79    \t1.4968  \n",
            "175\t80    \t0.832517\t175\t0.848077\t0.713574\t80    \t0.0320116\t10.3 \t175\t16 \t9  \t80    \t1.74069 \n",
            "176\t81    \t0.830344\t176\t0.848077\t0.655825\t81    \t0.0351382\t10.22\t176\t16 \t6  \t81    \t1.86858 \n",
            "177\t80    \t0.828167\t177\t0.848077\t0.682355\t80    \t0.0441023\t10.5 \t177\t16 \t8  \t80    \t1.93649 \n",
            "178\t82    \t0.834117\t178\t0.848077\t0.589957\t82    \t0.036015 \t10.68\t178\t16 \t8  \t82    \t2.01435 \n",
            "179\t77    \t0.825834\t179\t0.848077\t0.62951 \t77    \t0.0449256\t10.32\t179\t16 \t6  \t77    \t1.90725 \n",
            "180\t86    \t0.821332\t180\t0.848077\t0.666565\t86    \t0.0454288\t10.21\t180\t18 \t6  \t86    \t2.01641 \n",
            "181\t83    \t0.820963\t181\t0.848077\t0.712112\t83    \t0.0402682\t10.17\t181\t18 \t8  \t83    \t1.89766 \n",
            "182\t82    \t0.820571\t182\t0.848077\t0.689283\t82    \t0.0446199\t9.87 \t182\t14 \t6  \t82    \t1.67126 \n",
            "183\t84    \t0.829413\t183\t0.848077\t0.670726\t84    \t0.0348485\t9.63 \t183\t14 \t7  \t84    \t1.60409 \n",
            "184\t86    \t0.825975\t184\t0.848077\t0.670726\t86    \t0.0411442\t10.07\t184\t18 \t6  \t86    \t1.95067 \n",
            "185\t85    \t0.818596\t185\t0.848077\t0.670726\t85    \t0.0481897\t9.98 \t185\t18 \t7  \t85    \t1.9999  \n",
            "186\t86    \t0.825748\t186\t0.848077\t0.707501\t86    \t0.0366559\t10.42\t186\t26 \t6  \t86    \t2.76471 \n",
            "187\t83    \t0.823779\t187\t0.848077\t0.695299\t83    \t0.0422962\t10.68\t187\t26 \t7  \t83    \t3.25847 \n",
            "188\t79    \t0.82213 \t188\t0.848077\t0.657141\t79    \t0.0437361\t10.65\t188\t26 \t8  \t79    \t3.45072 \n",
            "189\t82    \t0.82657 \t189\t0.848077\t0.636651\t82    \t0.0414847\t10.41\t189\t26 \t6  \t82    \t3.5358  \n",
            "190\t84    \t0.823775\t190\t0.848077\t0.695299\t84    \t0.0432274\t10.75\t190\t26 \t6  \t84    \t4.10944 \n",
            "191\t76    \t0.829795\t191\t0.848077\t0.726732\t76    \t0.0353714\t10.3 \t191\t26 \t6  \t76    \t3.43657 \n",
            "192\t79    \t0.824927\t192\t0.848077\t0.695299\t79    \t0.0395052\t10.38\t192\t26 \t6  \t79    \t3.3069  \n",
            "193\t76    \t0.819882\t193\t0.848077\t0.682141\t76    \t0.0433855\t10.74\t193\t26 \t6  \t76    \t3.54576 \n",
            "194\t82    \t0.827236\t194\t0.848077\t0.698504\t82    \t0.0378257\t11.35\t194\t26 \t9  \t82    \t3.61213 \n",
            "195\t82    \t0.820154\t195\t0.848077\t0.613338\t82    \t0.0468817\t12.35\t195\t30 \t8  \t82    \t4.70186 \n",
            "196\t82    \t0.830624\t196\t0.848077\t0.695299\t82    \t0.0355501\t11.42\t196\t26 \t9  \t82    \t3.60605 \n",
            "197\t80    \t0.825488\t197\t0.848077\t0.695299\t80    \t0.0393724\t10.94\t197\t26 \t8  \t80    \t2.52119 \n",
            "198\t88    \t0.80946 \t198\t0.848077\t0.629791\t88    \t0.0577514\t10.63\t198\t18 \t8  \t88    \t2.01323 \n",
            "199\t84    \t0.819663\t199\t0.848077\t0.682141\t84    \t0.0441724\t10.58\t199\t14 \t6  \t84    \t2.05514 \n",
            "200\t84    \t0.813472\t200\t0.848077\t0.60451 \t84    \t0.0595697\t10.55\t200\t22 \t7  \t84    \t2.26881 \n",
            "201\t79    \t0.824696\t201\t0.848077\t0.657141\t79    \t0.0441999\t10.52\t201\t16 \t8  \t79    \t2.07113 \n",
            "202\t79    \t0.825845\t202\t0.848077\t0.670299\t79    \t0.0419577\t11   \t202\t18 \t8  \t79    \t2.51396 \n",
            "203\t78    \t0.820214\t203\t0.848077\t0.635133\t78    \t0.0511731\t11.51\t203\t18 \t9  \t78    \t2.60958 \n",
            "204\t67    \t0.830823\t204\t0.848077\t0.588428\t67    \t0.0431571\t11.24\t204\t18 \t7  \t67    \t2.63484 \n",
            "205\t79    \t0.825088\t205\t0.848077\t0.695299\t79    \t0.0435658\t11.78\t205\t18 \t6  \t79    \t2.66676 \n",
            "206\t81    \t0.824693\t206\t0.848077\t0.654363\t81    \t0.0426509\t10.92\t206\t24 \t7  \t81    \t2.67088 \n",
            "207\t83    \t0.823724\t207\t0.848077\t0.593466\t83    \t0.046389 \t10.82\t207\t16 \t8  \t83    \t2.29948 \n",
            "208\t86    \t0.820778\t208\t0.848077\t0.638338\t86    \t0.0503131\t10.46\t208\t20 \t6  \t86    \t2.30833 \n",
            "209\t90    \t0.825529\t209\t0.848077\t0.689283\t90    \t0.039547 \t10.46\t209\t20 \t6  \t90    \t2.40175 \n",
            "210\t80    \t0.829155\t210\t0.848077\t0.637967\t80    \t0.0426498\t10.84\t210\t20 \t6  \t80    \t2.73393 \n",
            "211\t85    \t0.81941 \t211\t0.848077\t0.695299\t85    \t0.0417203\t10.3 \t211\t18 \t8  \t85    \t1.93649 \n",
            "212\t76    \t0.830195\t212\t0.848077\t0.657569\t76    \t0.0361169\t10.32\t212\t16 \t8  \t76    \t1.81593 \n",
            "213\t79    \t0.826911\t213\t0.848077\t0.695299\t79    \t0.0409617\t10.07\t213\t16 \t7  \t79    \t1.6808  \n",
            "214\t85    \t0.820697\t214\t0.848077\t0.689957\t85    \t0.0479989\t10.23\t214\t18 \t6  \t85    \t1.84312 \n",
            "215\t84    \t0.82565 \t215\t0.848077\t0.666116\t84    \t0.0427727\t10.56\t215\t18 \t6  \t84    \t2.17403 \n",
            "216\t80    \t0.832637\t216\t0.848077\t0.723077\t80    \t0.0304792\t10.41\t216\t18 \t8  \t80    \t2.12177 \n",
            "217\t80    \t0.819311\t217\t0.848077\t0.663641\t80    \t0.0472822\t10.49\t217\t18 \t5  \t80    \t2.38954 \n",
            "218\t79    \t0.82372 \t218\t0.848077\t0.698954\t79    \t0.0415675\t10.46\t218\t18 \t7  \t79    \t2.11386 \n",
            "219\t80    \t0.824083\t219\t0.848077\t0.678902\t80    \t0.0436917\t10.42\t219\t16 \t6  \t80    \t2.0009  \n",
            "220\t84    \t0.827776\t220\t0.848077\t0.685796\t84    \t0.0380127\t10.76\t220\t16 \t9  \t84    \t1.9956  \n",
            "221\t83    \t0.812859\t221\t0.848077\t0.588574\t83    \t0.0567586\t10.84\t221\t14 \t8  \t83    \t1.99359 \n",
            "222\t85    \t0.826707\t222\t0.848077\t0.653048\t85    \t0.0413197\t10.42\t222\t14 \t6  \t85    \t1.90882 \n",
            "223\t81    \t0.833659\t223\t0.848077\t0.698954\t81    \t0.030611 \t10.24\t223\t14 \t7  \t81    \t1.73274 \n",
            "224\t85    \t0.822527\t224\t0.848077\t0.629791\t85    \t0.0456499\t10.1 \t224\t18 \t6  \t85    \t2.0025  \n",
            "225\t87    \t0.828177\t225\t0.848077\t0.670299\t87    \t0.0398609\t10.36\t225\t14 \t6  \t87    \t1.90536 \n",
            "226\t82    \t0.818911\t226\t0.848077\t0.665688\t82    \t0.0475687\t10.65\t226\t18 \t8  \t82    \t2.11365 \n",
            "227\t80    \t0.827353\t227\t0.848077\t0.685987\t80    \t0.0390693\t10.98\t227\t20 \t8  \t80    \t2.45756 \n",
            "228\t81    \t0.832475\t228\t0.848077\t0.698954\t81    \t0.030948 \t11.19\t228\t18 \t9  \t81    \t2.52466 \n",
            "229\t81    \t0.833361\t229\t0.848077\t0.712112\t81    \t0.0298722\t10.9 \t229\t18 \t9  \t81    \t2.27816 \n",
            "230\t85    \t0.816308\t230\t0.848077\t0.63791 \t85    \t0.0485201\t10.87\t230\t18 \t7  \t85    \t2.17097 \n",
            "231\t81    \t0.824783\t231\t0.848077\t0.635133\t81    \t0.0430695\t10.69\t231\t18 \t6  \t81    \t2.35667 \n",
            "232\t74    \t0.825328\t232\t0.848077\t0.695299\t74    \t0.0389336\t10.96\t232\t16 \t6  \t74    \t2.44916 \n",
            "233\t82    \t0.821439\t233\t0.848077\t0.63791 \t82    \t0.0464796\t11.26\t233\t16 \t9  \t82    \t2.46016 \n",
            "234\t80    \t0.814869\t234\t0.848077\t0.570659\t80    \t0.05802  \t11.24\t234\t16 \t6  \t80    \t2.37958 \n",
            "235\t80    \t0.833525\t235\t0.85415 \t0.695299\t80    \t0.0352838\t11.22\t235\t16 \t6  \t80    \t2.34342 \n",
            "236\t84    \t0.83201 \t236\t0.85415 \t0.701732\t84    \t0.0321841\t11.53\t236\t22 \t7  \t84    \t2.62471 \n",
            "237\t80    \t0.817386\t237\t0.85415 \t0.59783 \t80    \t0.0513382\t11.72\t237\t22 \t6  \t80    \t2.89855 \n",
            "238\t84    \t0.823982\t238\t0.85415 \t0.693983\t84    \t0.0475299\t11.28\t238\t22 \t8  \t84    \t2.28945 \n",
            "239\t82    \t0.82308 \t239\t0.85415 \t0.613574\t82    \t0.0500667\t11.54\t239\t22 \t9  \t82    \t2.0021  \n",
            "240\t88    \t0.823768\t240\t0.85415 \t0.680825\t88    \t0.047447 \t11.31\t240\t16 \t8  \t88    \t1.6655  \n",
            "241\t80    \t0.828505\t241\t0.85415 \t0.680825\t80    \t0.0426507\t11.35\t241\t16 \t6  \t80    \t1.65151 \n",
            "242\t85    \t0.808628\t242\t0.85415 \t0.680825\t85    \t0.0575352\t11.63\t242\t18 \t6  \t85    \t1.85825 \n",
            "243\t88    \t0.824422\t243\t0.85415 \t0.676372\t88    \t0.0478028\t11.93\t243\t18 \t9  \t88    \t2.07969 \n",
            "244\t85    \t0.823522\t244\t0.85415 \t0.668983\t85    \t0.0526306\t12.62\t244\t24 \t9  \t85    \t2.5953  \n",
            "245\t83    \t0.824958\t245\t0.85415 \t0.667668\t83    \t0.0546322\t12.67\t245\t20 \t9  \t83    \t2.25856 \n",
            "246\t75    \t0.830541\t246\t0.85415 \t0.680825\t75    \t0.0467388\t12.7 \t246\t19 \t9  \t75    \t1.91572 \n",
            "247\t81    \t0.83109 \t247\t0.867308\t0.680825\t81    \t0.0495713\t12.85\t247\t18 \t9  \t81    \t1.74571 \n",
            "248\t85    \t0.819724\t248\t0.867308\t0.643983\t85    \t0.0580834\t12.77\t248\t18 \t9  \t85    \t1.83769 \n",
            "249\t84    \t0.807151\t249\t0.867308\t0.646547\t84    \t0.0695604\t13.26\t249\t19 \t9  \t84    \t1.93711 \n",
            "250\t84    \t0.832209\t250\t0.867308\t0.680825\t84    \t0.0428347\t13.18\t250\t18 \t9  \t84    \t1.92031 \n",
            "251\t80    \t0.820126\t251\t0.867308\t0.561291\t80    \t0.0649602\t13.59\t251\t24 \t9  \t80    \t2.61952 \n",
            "252\t84    \t0.822212\t252\t0.867308\t0.680825\t84    \t0.0592268\t13.51\t252\t20 \t9  \t84    \t2.13773 \n",
            "253\t86    \t0.833567\t253\t0.867308\t0.680825\t86    \t0.0496813\t13.59\t253\t20 \t9  \t86    \t2.21402 \n",
            "254\t75    \t0.843636\t254\t0.867308\t0.680825\t75    \t0.0453826\t13.72\t254\t18 \t9  \t75    \t1.88722 \n",
            "255\t85    \t0.830264\t255\t0.867308\t0.592364\t85    \t0.057575 \t13.74\t255\t18 \t9  \t85    \t1.35366 \n",
            "256\t80    \t0.835893\t256\t0.867308\t0.599753\t80    \t0.0582098\t13.89\t256\t20 \t9  \t80    \t1.37036 \n",
            "257\t88    \t0.820155\t257\t0.867308\t0.685796\t88    \t0.0595216\t13.99\t257\t20 \t9  \t88    \t1.62785 \n",
            "258\t77    \t0.829806\t258\t0.867308\t0.650056\t77    \t0.054284 \t13.71\t258\t24 \t9  \t77    \t2.15079 \n",
            "259\t84    \t0.835952\t259\t0.867308\t0.643983\t84    \t0.0513134\t13.97\t259\t24 \t9  \t84    \t2.17924 \n",
            "260\t84    \t0.821787\t260\t0.867308\t0.643983\t84    \t0.0658394\t13.83\t260\t22 \t9  \t84    \t1.69148 \n",
            "261\t83    \t0.833969\t261\t0.867308\t0.685436\t83    \t0.0516438\t13.63\t261\t20 \t7  \t83    \t1.68911 \n",
            "262\t85    \t0.831675\t262\t0.867308\t0.688214\t85    \t0.0532509\t13.88\t262\t22 \t7  \t85    \t1.76794 \n",
            "263\t84    \t0.83772 \t263\t0.867308\t0.67365 \t84    \t0.0507576\t13.98\t263\t22 \t10 \t84    \t1.28047 \n",
            "264\t78    \t0.844221\t264\t0.867308\t0.635189\t78    \t0.0487451\t13.94\t264\t18 \t10 \t78    \t1.21507 \n",
            "265\t84    \t0.832409\t265\t0.867308\t0.688214\t84    \t0.0527261\t13.83\t265\t18 \t9  \t84    \t1.48361 \n",
            "266\t84    \t0.841913\t266\t0.867308\t0.643736\t84    \t0.0478848\t13.91\t266\t20 \t9  \t84    \t1.56904 \n",
            "267\t85    \t0.844392\t267\t0.867308\t0.688214\t85    \t0.0430017\t14.07\t267\t26 \t9  \t85    \t1.69266 \n",
            "268\t84    \t0.833425\t268\t0.867308\t0.688214\t84    \t0.0546317\t14   \t268\t18 \t9  \t84    \t0.812404\n",
            "269\t80    \t0.835308\t269\t0.867308\t0.680825\t80    \t0.0554759\t14.04\t269\t18 \t10 \t80    \t0.93723 \n",
            "270\t80    \t0.84468 \t270\t0.867308\t0.705027\t80    \t0.0451995\t14   \t270\t18 \t9  \t80    \t0.707107\n",
            "271\t87    \t0.836335\t271\t0.867308\t0.688214\t87    \t0.053722 \t14.03\t271\t18 \t9  \t87    \t0.853874\n",
            "272\t80    \t0.838743\t272\t0.867308\t0.595963\t80    \t0.0546126\t14.13\t272\t18 \t9  \t80    \t0.912743\n",
            "273\t78    \t0.830218\t273\t0.867308\t0.688214\t78    \t0.0621923\t14.03\t273\t18 \t10 \t78    \t0.83012 \n",
            "274\t80    \t0.836638\t274\t0.867308\t0.570963\t80    \t0.0571903\t14.07\t274\t22 \t9  \t80    \t1.46462 \n",
            "275\t82    \t0.838738\t275\t0.867308\t0.688214\t82    \t0.0500209\t14.1 \t275\t20 \t9  \t82    \t1.28452 \n",
            "276\t84    \t0.82962 \t276\t0.867308\t0.636651\t84    \t0.0546218\t13.94\t276\t20 \t9  \t84    \t1.48876 \n",
            "277\t81    \t0.826736\t277\t0.867308\t0.688214\t81    \t0.0582291\t14   \t277\t26 \t9  \t81    \t1.95448 \n",
            "278\t88    \t0.837127\t278\t0.867308\t0.663214\t88    \t0.0543682\t14.1 \t278\t20 \t9  \t88    \t1.18743 \n",
            "279\t81    \t0.838894\t279\t0.867308\t0.688214\t81    \t0.0518095\t14.04\t279\t26 \t9  \t81    \t1.56154 \n",
            "280\t86    \t0.829073\t280\t0.867308\t0.561291\t86    \t0.0613079\t13.98\t280\t16 \t11 \t86    \t0.647765\n",
            "281\t84    \t0.835442\t281\t0.867308\t0.663214\t84    \t0.0511846\t13.9 \t281\t16 \t11 \t84    \t0.806226\n",
            "282\t81    \t0.831076\t282\t0.867308\t0.636651\t81    \t0.0581075\t13.98\t282\t16 \t11 \t81    \t0.616117\n",
            "283\t81    \t0.826879\t283\t0.867308\t0.568185\t81    \t0.0692795\t13.97\t283\t18 \t9  \t81    \t0.921466\n",
            "284\t86    \t0.823173\t284\t0.867308\t0.638214\t86    \t0.063911 \t13.96\t284\t18 \t9  \t86    \t1.02879 \n",
            "285\t78    \t0.838574\t285\t0.867308\t0.651372\t78    \t0.0497196\t13.95\t285\t18 \t9  \t78    \t1.2278  \n",
            "286\t78    \t0.83669 \t286\t0.867308\t0.638214\t78    \t0.052579 \t13.75\t286\t20 \t9  \t78    \t1.73421 \n",
            "287\t76    \t0.829179\t287\t0.867308\t0.590902\t76    \t0.0670361\t14.05\t287\t20 \t9  \t76    \t1.04283 \n",
            "288\t80    \t0.825858\t288\t0.867308\t0.568185\t80    \t0.067069 \t14.07\t288\t22 \t9  \t80    \t1.65079 \n",
            "289\t82    \t0.83039 \t289\t0.867308\t0.638214\t82    \t0.0542161\t13.94\t289\t24 \t9  \t82    \t1.89642 \n",
            "290\t81    \t0.824969\t290\t0.867308\t0.570963\t81    \t0.065003 \t13.94\t290\t24 \t9  \t81    \t1.49546 \n",
            "291\t83    \t0.835415\t291\t0.867308\t0.686595\t83    \t0.0477537\t13.76\t291\t18 \t9  \t83    \t1.59449 \n",
            "292\t83    \t0.831409\t292\t0.867308\t0.592117\t83    \t0.0606134\t13.9 \t292\t20 \t9  \t83    \t1.21244 \n",
            "293\t85    \t0.835705\t293\t0.867308\t0.663214\t85    \t0.053975 \t14   \t293\t22 \t9  \t85    \t1.61245 \n",
            "294\t78    \t0.83928 \t294\t0.867308\t0.688214\t78    \t0.0465061\t13.76\t294\t19 \t8  \t78    \t1.38651 \n",
            "295\t77    \t0.83939 \t295\t0.867308\t0.638214\t77    \t0.0549232\t13.7 \t295\t18 \t8  \t77    \t1.36015 \n",
            "296\t77    \t0.82243 \t296\t0.867308\t0.638214\t77    \t0.0629523\t13.86\t296\t20 \t9  \t77    \t1.37855 \n",
            "297\t82    \t0.837263\t297\t0.867308\t0.71706 \t82    \t0.0507612\t13.82\t297\t18 \t9  \t82    \t1.06189 \n",
            "298\t85    \t0.828859\t298\t0.867308\t0.638214\t85    \t0.0581741\t13.61\t298\t20 \t9  \t85    \t1.93336 \n",
            "299\t78    \t0.846302\t299\t0.867308\t0.638214\t78    \t0.0412658\t13.46\t299\t20 \t9  \t78    \t1.86773 \n",
            "300\t78    \t0.825042\t300\t0.867308\t0.638214\t78    \t0.0654373\t13.44\t300\t16 \t8  \t78    \t1.69304 \n"
          ]
        }
      ],
      "source": [
        "#  DEBUG : REMOVE THIS !!!\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') \n",
        "\n",
        "def xmate(ind1, ind2):\n",
        "    \"\"\" Reproduction operator for multi-tree GP, where trees are represented as a list.\n",
        "\n",
        "    Crossover happens to a subtree that is selected at random. \n",
        "    Crossover operations are limited to parents from the same tree.\n",
        "\n",
        "    FIXME: Have to compile the trees (manually), which is frustrating. \n",
        "    \n",
        "    Args: \n",
        "        ind1 (Individual): The first parent. \n",
        "        ind2 (Individual): The second parent \n",
        "\n",
        "    Returns:\n",
        "        ind1, ind2 (Individual, Individual): The children from the parents reproduction. \n",
        "    \"\"\"\n",
        "    n = range(len(ind1))\n",
        "    selected_tree_idx = random.choice(n)\n",
        "    for tree_idx in n:\n",
        "        g1, g2 = gp.PrimitiveTree(ind1[tree_idx]), gp.PrimitiveTree(ind2[tree_idx])\n",
        "        if tree_idx == selected_tree_idx:\n",
        "            ind1[tree_idx], ind2[tree_idx] = gp.cxOnePoint(g1, g2)\n",
        "        else: \n",
        "            ind1[tree_idx], ind2[tree_idx] = g1, g2\n",
        "    return ind1, ind2\n",
        "\n",
        "\n",
        "def xmut(ind, expr):\n",
        "    \"\"\" Mutation operator for multi-tree GP, where trees are represented as a list. \n",
        "\n",
        "    Mutation happens to a tree selected at random, when an individual is selected for crossover. \n",
        "\n",
        "    FIXME: Have to compile the trees (manually), which is frustrating. \n",
        "\n",
        "    Args: \n",
        "        ind: The individual, a list of GP trees. \n",
        "    \"\"\"\n",
        "    n = range(len(ind))\n",
        "    selected_tree_idx = random.choice(n)\n",
        "    for tree_idx in n:\n",
        "        g1 = gp.PrimitiveTree(ind[tree_idx])\n",
        "        if tree_idx == selected_tree_idx:\n",
        "            indx = gp.mutUniform(g1, expr, pset)\n",
        "            ind[tree_idx] = indx[0]\n",
        "        else:\n",
        "            ind[tree_idx] = g1\n",
        "    return ind,\n",
        "\n",
        "\n",
        "def balanced_accuracy(individual):\n",
        "    \"\"\" \n",
        "    Evaluate the balacned accuracy of the individul for multi-tree GP multi-class classification. \n",
        "\n",
        "    We measure the balanced accuracy, as not to bias towards the majority class. \n",
        "\n",
        "    Args: \n",
        "        individual (Individual): A candidate solution to find accuracy for. \n",
        "\n",
        "    Returns: \n",
        "        accuracy (tuple): The balanced accuracy for the individual.\n",
        "    \"\"\"\n",
        "    # Perform MCIFC feature construction\n",
        "    funcs = toolbox.compile(expr=individual, pset=pset)\n",
        "    features = []\n",
        "    for x in X: \n",
        "        feature = [func(*x) for func in funcs]\n",
        "        features.append(feature)\n",
        "\n",
        "    # Balanced classification accuracy. \n",
        "    accuracy = wrapper_classification_accuracy(features, verbose=False)\n",
        "\n",
        "    return accuracy,\n",
        "\n",
        "def evaluate_classification(individual, alpha = 0.9):\n",
        "    \"\"\" \n",
        "    Evalautes the fitness of an individual for multi-tree GP multi-class classification.\n",
        "\n",
        "    We maxmimize the fitness when we evaluate the accuracy + regularization term. \n",
        "\n",
        "    Args:  \n",
        "        individual (Individual): A candidate solution to be evaluated. \n",
        "        alpha (float): A parameter that balances the accuracy and regularization term. Defaults to 0.98.\n",
        "\n",
        "    Returns: \n",
        "        accuracy (tuple): The fitness of the individual.\n",
        "    \"\"\"  \n",
        "    \n",
        "    # Perform MCIFC feature construction\n",
        "    funcs = toolbox.compile(expr=individual, pset=pset)\n",
        "    features = []\n",
        "    for x in X: \n",
        "        feature = [func(*x) for func in funcs]\n",
        "        features.append(feature)\n",
        "\n",
        "    # Balanced classification accuracy. \n",
        "    fitness = wrapper_classification_accuracy(features, verbose=False)\n",
        "\n",
        "    return fitness,\n",
        "\n",
        "\n",
        "toolbox.register('evaluate', evaluate_classification)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "toolbox.register(\"mate\", xmate)\n",
        "toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n",
        "toolbox.register(\"mutate\", xmut, expr=toolbox.expr_mut)\n",
        "\n",
        "\n",
        "def staticLimit(key, max_value):\n",
        "    \"\"\"\n",
        "    A variation of gp.staticLimit that works for Multi-tree representation. \n",
        "    This works for our altered xmut and xmate genetic operators for mutli-tree GP. \n",
        "    If tree depth limit is exceeded, the genetic operator is reverted. \n",
        "\n",
        "    When an invalid (over the limit) child is generated,\n",
        "    it is simply replaced by one of its parents, randomly selected.\n",
        "    \n",
        "    Args:\n",
        "        key: The function to use in order the get the wanted value. For\n",
        "             instance, on a GP tree, ``operator.attrgetter('height')`` may\n",
        "             be used to set a depth limit, and ``len`` to set a size limit.\n",
        "        max_value: The maximum value allowed for the given measurement. \n",
        "             Defaults to 17, the suggested value in (Koza 1992)\n",
        "    \n",
        "    Returns: \n",
        "        A decorator that can be applied to a GP operator using \\\n",
        "        :func:`~deap.base.Toolbox.decorate`\n",
        "\n",
        "    References:\n",
        "        1. Koza, J. R. G. P. (1992). On the programming of computers by means \n",
        "            of natural selection. Genetic programming.\n",
        "    \"\"\"\n",
        "\n",
        "    def decorator(func):\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            keep_inds = [[copy.deepcopy(tree) for tree in ind] for ind in args]\n",
        "            new_inds = list(func(*args, **kwargs))\n",
        "            for ind_idx, ind in enumerate(new_inds):\n",
        "                for tree_idx, tree in enumerate(ind):\n",
        "                    if key(tree) > max_value:\n",
        "                        random_parent = random.choice(keep_inds)\n",
        "                        new_inds[ind_idx][tree_idx] = random_parent[tree_idx]\n",
        "            return new_inds\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "# See https://groups.google.com/g/deap-users/c/pWzR_q7mKJ0\n",
        "toolbox.decorate(\"mate\", staticLimit(key=operator.attrgetter(\"height\"), max_value=8))\n",
        "toolbox.decorate(\"mutate\", staticLimit(key=operator.attrgetter(\"height\"), max_value=8))\n",
        "\n",
        "\n",
        "def SimpleGPWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
        "             halloffame=None, verbose=__debug__):\n",
        "    \"\"\"\n",
        "    Elitism for Multi-Tree GP for Multi-Class classification. \n",
        "    A variation of the eaSimple method from the DEAP library that supports \n",
        "\n",
        "    Elitism ensures the best individuals (the elite) from each generation are \n",
        "    carried onto the next without alteration. This ensures the quality of the \n",
        "    best solution monotonically increases over time. \n",
        "    \"\"\"\n",
        "    logbook = tools.Logbook()\n",
        "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
        "\n",
        "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
        "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "    \n",
        "    for ind, fit in zip(invalid_ind, fitnesses):\n",
        "        ind.fitness.values = fit\n",
        "\n",
        "    if halloffame is None:\n",
        "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
        "\n",
        "    halloffame.update(population)\n",
        "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
        "\n",
        "    record = stats.compile(population) if stats else {}\n",
        "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
        "    \n",
        "    if verbose:\n",
        "        print(logbook.stream)\n",
        "\n",
        "    for gen in range(1, ngen + 1):\n",
        "        offspring = toolbox.select(population, len(population) - hof_size)\n",
        "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
        "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "        \n",
        "        for ind, fit in zip(invalid_ind, fitnesses):\n",
        "            ind.fitness.values = fit\n",
        "\n",
        "        offspring.extend(halloffame.items)\n",
        "        halloffame.update(offspring)\n",
        "        population[:] = offspring\n",
        "        \n",
        "        record = stats.compile(population) if stats else {}\n",
        "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
        "        \n",
        "        if verbose:\n",
        "            print(logbook.stream)\n",
        "\n",
        "    return population, logbook\n",
        "\n",
        "\n",
        "def train(generations=100, population=100, elitism=0.1, crossover_rate=0.5, mutation_rate=0.1):\n",
        "    \"\"\"\n",
        "    This is a Multi-tree GP with Elitism for Multi-class classification. \n",
        "\n",
        "    Args:\n",
        "        generations: The number of generations to evolve the populaiton for. \n",
        "        elitism: The ratio of elites to be kept between generations. \n",
        "        crossover_rate: The probability of a crossover between two individuals. \n",
        "        mutation_rate: The probability of a random mutation within an individual.  \n",
        "\n",
        "    Returns:\n",
        "        pop: The final population the algorithm has evolved. \n",
        "        log: The logbook which can record important statistics. \n",
        "        hof: The hall of fame contains the best individual solutions.\n",
        "    \"\"\"\n",
        "    random.seed(420)\n",
        "    pop = toolbox.population(n=population)\n",
        "    \n",
        "    mu = round(elitism * population)\n",
        "    if elitism > 0:\n",
        "        # See https://www.programcreek.com/python/example/107757/deap.tools.HallOfFame\n",
        "        hof = tools.HallOfFame(mu)\n",
        "    else:\n",
        "        hof = None\n",
        "    \n",
        "    # Fitness is a balanced accuracy + hamming distance regularization. \n",
        "    stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "\n",
        "    # Accuracy is the balanced accuracy for the dataset.\n",
        "    # stats_accuracy = tools.Statistics(lambda ind: balanced_accuracy(ind))\n",
        "\n",
        "    # Size, is the tree with the maximum length in the multi-tree\n",
        "    length = lambda a: np.max(list(map(len, a)))\n",
        "    stats_size = tools.Statistics(length)\n",
        "\n",
        "    # mstats = tools.MultiStatistics(accuracy=stats_accuracy, fitness=stats_fit, size=stats_size)\n",
        "    mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)\n",
        "\n",
        "    mstats.register(\"avg\", np.mean)\n",
        "    mstats.register(\"std\", np.std)\n",
        "    mstats.register(\"min\", np.min)\n",
        "    mstats.register(\"max\", np.max)\n",
        "\n",
        "    pop, log = SimpleGPWithElitism(pop, toolbox, crossover_rate, mutation_rate, \n",
        "                                   generations, stats=mstats, halloffame=hof, \n",
        "                                   verbose=True)\n",
        "    return pop, log, hof\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "DeJong (1975), p=50-100, m=0.001, c=0.6 \n",
        "Grefenstette (1986), p=30, m=0.01, c=0.95\n",
        "Schaffer et al., (1989), p=20-30, m=0.005-0.01, c=0.75-0.95\n",
        "\n",
        "References:\n",
        "    1. Patil, V. P., & Pawar, D. D. (2015). The optimal crossover or mutation \n",
        "    rates in genetic algorithm: a review. International Journal of Applied \n",
        "    Engineering and Technology, 5(3), 38-41.\n",
        "\"\"\"\n",
        "\n",
        "generations = 300\n",
        "population = 100\n",
        "elitism = 0.1\n",
        "crossover_rate = 0.9\n",
        "mutation_rate = 0.1\n",
        "\n",
        "pop, log, hof = train(generations, population, elitism, crossover_rate, mutation_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkaU6kAGyBl2"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pEqouLDs4xBJ"
      },
      "outputs": [],
      "source": [
        "from deap import base, creator, gp\n",
        "import pygraphviz as pgv\n",
        "\n",
        "multi_tree = hof[0]\n",
        "for t_idx,tree in enumerate(multi_tree): \n",
        "    nodes, edges, labels = gp.graph(tree)\n",
        "\n",
        "    g = pgv.AGraph()\n",
        "    g.add_nodes_from(nodes)\n",
        "    g.add_edges_from(edges)\n",
        "    g.layout(prog=\"dot\")\n",
        "\n",
        "    for i in nodes:\n",
        "        n = g.get_node(i)\n",
        "        n.attr[\"label\"] = labels[i]\n",
        "\n",
        "    g.draw(f\"tree-{t_idx}.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX_g4MipuQTU"
      },
      "source": [
        "## Changelog \n",
        "\n",
        "| Date | Title | Description | Update | \n",
        "| --- | --- | --- | ---- | \n",
        "| 2022-08-21 17:30 | Multi-Objective - Onehot Encoding | Change to multi-objective problem, one-vs-all with a tree classifier for each class.<br> Y labels are encoded in onehot encodings, error is absolute difference between $|\\hat{y} - y|$| \n",
        "| 2022-08-22 20:44 | Non-linearity |  Introduce $ round . sigmoid $ to evaluate_classification() method.<br>Previously, we push each tree to predict either a 0 or 1 value with the onehot encoding representation.<br>Now, the non-linearity will map any negative value to a negative class 0, and any positive value to positive class 1.|\n",
        "| 2022-08-22 21:06 | ~~Genetic operators for tree with worst fitness~~ | Only apply the genetic operators, crossover and mutation, to the tree with the worst fitness.<br> This guarantees monotonic improvement for the Multi-tree between generations, the best performing tree remain unaltered.| (Update) This was very slow, and inefficient,<br> basically turned the GP into a single objective,<br>that balances multi-objective fitness functions. | \n",
        "| 2022-08-22 21:15 | Halloffame Equality Operator | Numpy equality function (operators.eq) between two arrays returns the equality element wise,<br>which raises an exception in the if similar() check of the hall of fame. <br> Using a different equality function like numpy.array_equal or numpy.allclose solve this issue.| \n",
        "| 2022-08-22 23:22 | Elitism as aggregate best tree | Perform elitsim by constructing the best tree, as the tree with best fitness from each clas.<br>The goal is to have monotonous improvement across the multiple objective functions.| \n",
        "| 2022-08-22 23:32 | Update fitness for elite | The elitism was not working as intended, as the multi-objectives didn't appear to increase monotnously.<br> This was because the aggregate fitness was not being assigned to the best individual after it was created.<br>Therefore the best invidiual was not passed on to the next generation. | \n",
        "| 2022-08-22 02:28 | staticLimit max height | Rewrite the gp.staticLimit decorator function to handle the Multi-tree representation.<br>Note: size and depth are different values!<br>depth is the maximum length of a root-to-leaf traversal,<br>size is the total number of nodes.| \n",
        "| 2022-08-24 9:37 | Evaluate Mutli-tree train accuracy | Take the classification accuracy as the argmax for the aggregate multitree.<br> 74% training accuracy, which is not ideal, but this shall improve with time.| \n",
        "| 2022-08-25 13:30 | Single-objective fitness | Change the fitness function to a single objective fitness function.<br>This forces the multi-tree GP to find the best tree subset for one-vs-rest classification performance.| \n",
        "| 2022-08-25 20:01 | Fitness = Balanced accuracy + distance measure | Implement the fitness function for MCIFC, but for multi-class classification from (Tran 2019) |\n",
        "| 2022-08-26 21:27 | Sklearn Balanced Accuracy | Changed to the balanced accuracy metric from sklearn.<br>This is much easier to use for now, probably faster than the previous method as well. | \n",
        "| 2022-09-05 17:00 | Reject invalid predictions | Change the fitness function to reject invalid predictioctions outright -<br>e.g. multi-label or zero-label predictions<br>- when computing the balanced accuracy for the fitness function. |\n",
        "| 2022-09-13 19:00 | Mutation + Crossover = 100% | Ensure the mutation and crossover rate sum to 100%,<br>not necessary with deap, but good to avoid conference questions |\n",
        "| 2022-09-13 21:00 | Feature Construction | Changed to Wrapper-based Feature Construction with Multi-tree GP.|\n",
        "| 2022-09-13 21:34 | $m = r \\times c$ | Add more trees, following example from (Tran 2019).<br> With 8 trees for a multi-class classification<br> $m = r \\times c = 8$ trees, where number of classes $c = 4$, and reconstruction ratio $r = 2$,  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1Yg4t38NHSYPAlu_099cQeOR-qSwIaaTl",
      "authorship_tag": "ABX9TyODNL1yO28gjxDVnrM1AFQL",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}