{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/woodRock/fishy-business/blob/main/code/gp/notebooks/Multi_tree_Genetic_Program.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAlW5BfrgjQk"
      },
      "source": [
        "# Multi-tree Genetic Program "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLL18yL7WWRt",
        "outputId": "b436160d-05d4-4d0f-bada-95c753644df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting deap\n",
            "  Downloading deap-1.3.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deap) (1.21.6)\n",
            "Installing collected packages: deap\n",
            "Successfully installed deap-1.3.3\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common\n",
            "  libgvc6-plugins-gtk libxdot4\n",
            "Suggested packages:\n",
            "  gvfs\n",
            "The following NEW packages will be installed:\n",
            "  libgail-common libgail18 libgraphviz-dev libgtk2.0-0 libgtk2.0-bin\n",
            "  libgtk2.0-common libgvc6-plugins-gtk libxdot4\n",
            "0 upgraded, 8 newly installed, 0 to remove and 12 not upgraded.\n",
            "Need to get 2,120 kB of archives.\n",
            "After this operation, 7,128 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libxdot4 amd64 2.40.1-2 [15.7 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgvc6-plugins-gtk amd64 2.40.1-2 [18.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgraphviz-dev amd64 2.40.1-2 [57.3 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n",
            "Fetched 2,120 kB in 2s (985 kB/s)\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "(Reading database ... 123934 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../1-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../2-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../3-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Selecting previously unselected package libxdot4.\n",
            "Preparing to unpack .../4-libxdot4_2.40.1-2_amd64.deb ...\n",
            "Unpacking libxdot4 (2.40.1-2) ...\n",
            "Selecting previously unselected package libgvc6-plugins-gtk.\n",
            "Preparing to unpack .../5-libgvc6-plugins-gtk_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgvc6-plugins-gtk (2.40.1-2) ...\n",
            "Selecting previously unselected package libgraphviz-dev.\n",
            "Preparing to unpack .../6-libgraphviz-dev_2.40.1-2_amd64.deb ...\n",
            "Unpacking libgraphviz-dev (2.40.1-2) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../7-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n",
            "Setting up libxdot4 (2.40.1-2) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n",
            "Setting up libgvc6-plugins-gtk (2.40.1-2) ...\n",
            "Setting up libgraphviz-dev (2.40.1-2) ...\n",
            "Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pygraphviz\n",
            "  Downloading pygraphviz-1.7.zip (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 4.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pygraphviz\n",
            "  Building wheel for pygraphviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pygraphviz: filename=pygraphviz-1.7-cp37-cp37m-linux_x86_64.whl size=165760 sha256=a469e3d7ad3810133508044686226f028dda5f1976034f2c360aa9b9d84835ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/bc/0c/ac35392b72556e75107ff610cb31b313e8471918a6d280e34c\n",
            "Successfully built pygraphviz\n",
            "Installing collected packages: pygraphviz\n",
            "Successfully installed pygraphviz-1.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting skfeature-chappers\n",
            "  Downloading skfeature_chappers-1.1.0-py3-none-any.whl (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from skfeature-chappers) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from skfeature-chappers) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from skfeature-chappers) (1.21.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->skfeature-chappers) (2022.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->skfeature-chappers) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->skfeature-chappers) (1.15.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->skfeature-chappers) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->skfeature-chappers) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->skfeature-chappers) (1.2.0)\n",
            "Installing collected packages: skfeature-chappers\n",
            "Successfully installed skfeature-chappers-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install deap\n",
        "!apt install libgraphviz-dev\n",
        "!pip install pygraphviz\n",
        "!pip install skfeature-chappers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCcCiUIvL40G",
        "outputId": "be31ad7f-2c2d-4676-d38b-e0d24626e7bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path_gdrive = '/content/drive/MyDrive/AI/Data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD4BzYVvq9_j"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-0dl8EoqK0T",
        "outputId": "7f07bb92-2b07-4969-dfd8-85b68669feba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Counts: [68 26 31 29], Class Ratios: [0.44155844 0.16883117 0.2012987  0.18831169]\n",
            "Number of features: 4800\n",
            "Number of instances: 154\n",
            "Number of classes 4.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Data - data.py\n",
        "==============\n",
        "\n",
        "This is the data module. It contains the functions for loading, preparing, normalizing and encoding the data.\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import scipy.io\n",
        "\n",
        "\n",
        "def encode_labels(y, y_test=None):\n",
        "    \"\"\"\n",
        "    Convert text labels to numbers.\n",
        "\n",
        "    Args:\n",
        "        y: The labels.\n",
        "        y_test: The test labels. Defaults to None.\n",
        "    \"\"\"\n",
        "    le = preprocessing.LabelEncoder()\n",
        "    y = le.fit_transform(y)\n",
        "    if y_test is not None:\n",
        "        y_test = le.transform(y_test)\n",
        "    return y, y_test, le\n",
        "\n",
        "\n",
        "def load(filename, folder=''):\n",
        "    \"\"\"\n",
        "    Load the data from the mat file.\n",
        "\n",
        "    Args:\n",
        "        filename: The name of the mat file.\n",
        "        folder: The folder where the mat file is located.\n",
        "    \"\"\"\n",
        "    path = folder + \"/\" + filename\n",
        "    mat = scipy.io.loadmat(path)\n",
        "    return mat\n",
        "\n",
        "\n",
        "def prepare(mat):\n",
        "    \"\"\"\n",
        "    Load the data from matlab format into memory. \n",
        "\n",
        "    Args:\n",
        "        mat: The data in matlab format.\n",
        "    \"\"\"\n",
        "    X = mat['X']   \n",
        "    X = X.astype(float)\n",
        "    y = mat['Y']    \n",
        "    y = y[:, 0]\n",
        "    return X,y\n",
        "\n",
        "\n",
        "def normalize(X_train, X_test):\n",
        "    \"\"\"\n",
        "    Normalize the input features within range [0,1].\n",
        "\n",
        "    Args:\n",
        "        X_train: The training data.\n",
        "        X_test: The test data.\n",
        "    \"\"\"\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaler = scaler.fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    return X_train, X_test\n",
        "\n",
        "\n",
        "file = load('Fish.mat', folder=data_path_gdrive)\n",
        "X,y = prepare(file)\n",
        "X,_ = normalize(X,X)\n",
        "y, _, le = encode_labels(y)\n",
        "labels = le.inverse_transform(np.unique(y))\n",
        "classes, class_counts = np.unique(y, return_counts=True)\n",
        "n_features = X.shape[1]\n",
        "n_instances = X.shape[0]\n",
        "n_classes = len(classes)\n",
        "class_ratios = np.array(class_counts) / n_instances\n",
        "\n",
        "print(f\"Class Counts: {class_counts}, Class Ratios: {class_ratios}\")\n",
        "print(f\"Number of features: {n_features}\\nNumber of instances: {n_instances}\\nNumber of classes {n_classes}.\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42, stratify=y)\n",
        "X_train, X_test = normalize(X_train, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eanPjO3KB121"
      },
      "source": [
        "## Activation Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP6upHxeyFX_"
      },
      "source": [
        "## Operators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AQBTITsyEzE"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import copy\n",
        "import random\n",
        "import operator\n",
        "from re import I\n",
        "from operator import attrgetter\n",
        "from functools import wraps, partial\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from deap import algorithms\n",
        "from deap.algorithms import varAnd\n",
        "from deap import base, creator, tools, gp\n",
        "from deap.gp import PrimitiveTree, Primitive, Terminal\n",
        "\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "pset = gp.PrimitiveSet(\"MAIN\", n_features)\n",
        "pset.addPrimitive(operator.add, 2)\n",
        "pset.addPrimitive(operator.sub, 2)\n",
        "pset.addPrimitive(operator.mul, 2)\n",
        "pset.addPrimitive(operator.neg, 1)\n",
        "# pset.addEphemeralConstant(\"rand101\", lambda: random.randint(-1,1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kejku7hWyMbO"
      },
      "source": [
        "## Fitness Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQE3P3qLyMDr"
      },
      "outputs": [],
      "source": [
        "toolbox = base.Toolbox()\n",
        "\n",
        "minimized = False\n",
        "if minimized: \n",
        "    weight = -1.0 \n",
        "else: \n",
        "    weight = 1.0\n",
        "\n",
        "weights = (weight,) \n",
        "\n",
        "if minimized: \n",
        "    creator.create(\"FitnessMin\", base.Fitness, weights=weights)\n",
        "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
        "else:\n",
        "    creator.create(\"FitnessMax\", base.Fitness, weights=weights)\n",
        "    creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "def quick_evaluate(expr: PrimitiveTree, pset, data, prefix='ARG'):\n",
        "    result = None\n",
        "    stack = []\n",
        "    for node in expr:\n",
        "        stack.append((node, []))\n",
        "        while len(stack[-1][1]) == stack[-1][0].arity:\n",
        "            prim, args = stack.pop()\n",
        "            if isinstance(prim, Primitive):\n",
        "                result = pset.context[prim.name](*args)\n",
        "            elif isinstance(prim, Terminal):\n",
        "                if prefix in prim.name:\n",
        "                    result = data[:, int(prim.name.replace(prefix, ''))]\n",
        "                else:\n",
        "                    result = prim.value\n",
        "            else:\n",
        "                raise Exception\n",
        "            if len(stack) == 0:\n",
        "                break # If stack is empty, all nodes should have been seen\n",
        "            stack[-1][1].append(result)\n",
        "    return result\n",
        "\n",
        "def compileMultiTree(expr, pset, data=X_train):\n",
        "    \"\"\"Compile the expression represented by a list of trees. \n",
        "\n",
        "    A variation of the gp.compileADF method, that handles Multi-tree GP. \n",
        "\n",
        "    Args: \n",
        "        expr: Expression to compile. It can either be a PrimitiveTree,\n",
        "                 a string of Python code or any object that when\n",
        "                 converted into string produced a valid Python code\n",
        "                 expression.\n",
        "        pset: Primitive Set\n",
        "\n",
        "    Returns: \n",
        "        A set of functions that correspond for each tree in the Multi-tree. \n",
        "    \"\"\"\n",
        "    funcs = []\n",
        "    gp_tree = None\n",
        "    func = None\n",
        "\n",
        "    for subexpr in expr:\n",
        "        gp_tree = gp.PrimitiveTree(subexpr)\n",
        "        # 5x speedup by manually parsing GP tree (Zhang 2022) https://mail.google.com/mail/u/0/#inbox/FMfcgzGqQmQthcqPCCNmstgLZlKGXvbc\n",
        "        func = quick_evaluate(gp_tree, pset, data, prefix='ARG')\n",
        "        funcs.append(func)\n",
        "\n",
        "    # Hengzhe's method returns the features in the wrong rotation for multi-tree\n",
        "    features = np.array(funcs).T \n",
        "    return features\n",
        "\n",
        "# Class dependent subtrees, one for each class, winner takes all. \n",
        "\n",
        "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=2)\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.expr, n=n_classes)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "toolbox.register(\"compile\", compileMultiTree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vOz-1Oislgd",
        "outputId": "bf98c58b-1a1f-40d0-b552-6cfe410e995f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   \t      \t                                 fitness                                 \t                      size                     \n",
            "   \t      \t-------------------------------------------------------------------------\t-----------------------------------------------\n",
            "gen\tnevals\tavg     \tgen\tmax     \tmin      \tnevals\tstd      \tavg    \tgen\tmax\tmin\tnevals\tstd    \n",
            "0  \t14400 \t0.250606\t0  \t0.554698\t0.0625705\t14400 \t0.0582206\t5.10528\t0  \t7  \t2  \t14400 \t1.75262\n",
            "1  \t10899 \t0.296279\t1  \t0.554698\t0.0776172\t10899 \t0.0549202\t5.2809 \t1  \t13 \t2  \t10899 \t1.84479\n",
            "2  \t10900 \t0.330519\t2  \t0.554698\t0.0700401\t10900 \t0.0566542\t5.40819\t2  \t16 \t2  \t10900 \t1.92312\n",
            "3  \t10840 \t0.35787 \t3  \t0.561365\t0.0943288\t10840 \t0.0585193\t5.52882\t3  \t15 \t2  \t10840 \t1.95966\n",
            "4  \t10823 \t0.381048\t4  \t0.573946\t0.0829071\t10823 \t0.0615795\t5.70958\t4  \t18 \t2  \t10823 \t2.01494\n",
            "5  \t10872 \t0.400599\t5  \t0.578794\t0.108739 \t10872 \t0.0631807\t5.87639\t5  \t19 \t2  \t10872 \t2.08413\n",
            "6  \t10830 \t0.418179\t6  \t0.589807\t0.125099 \t10830 \t0.0652834\t6.00646\t6  \t20 \t3  \t10830 \t2.18391\n",
            "7  \t10984 \t0.433291\t7  \t0.622338\t0.113242 \t10984 \t0.0674524\t6.07056\t7  \t20 \t3  \t10984 \t2.20801\n",
            "8  \t10889 \t0.447569\t8  \t0.622338\t0.130069 \t10889 \t0.0696051\t6.12063\t8  \t19 \t3  \t10889 \t2.25286\n",
            "9  \t10806 \t0.462253\t9  \t0.657019\t0.146832 \t10806 \t0.0699608\t6.20417\t9  \t21 \t3  \t10806 \t2.29918\n",
            "10 \t10873 \t0.476064\t10 \t0.657019\t0.159351 \t10873 \t0.0716972\t6.31528\t10 \t23 \t3  \t10873 \t2.32801\n",
            "11 \t10917 \t0.489587\t11 \t0.697375\t0.169287 \t10917 \t0.0728715\t6.44187\t11 \t21 \t3  \t10917 \t2.35486\n",
            "12 \t10861 \t0.503407\t12 \t0.697375\t0.169129 \t10861 \t0.0740244\t6.52229\t12 \t19 \t3  \t10861 \t2.37181\n",
            "13 \t10882 \t0.516068\t13 \t0.714997\t0.158331 \t10882 \t0.0750722\t6.55611\t13 \t21 \t3  \t10882 \t2.36168\n",
            "14 \t10893 \t0.528741\t14 \t0.730917\t0.170844 \t10893 \t0.0761609\t6.60229\t14 \t21 \t3  \t10893 \t2.35687\n",
            "15 \t10888 \t0.5397  \t15 \t0.742677\t0.198018 \t10888 \t0.0780847\t6.6359 \t15 \t23 \t3  \t10888 \t2.3076 \n",
            "16 \t10983 \t0.551428\t16 \t0.746573\t0.174948 \t10983 \t0.0793782\t6.75667\t16 \t20 \t3  \t10983 \t2.30981\n",
            "17 \t10795 \t0.565467\t17 \t0.746573\t0.159474 \t10795 \t0.0805221\t6.85646\t17 \t19 \t3  \t10795 \t2.26342\n",
            "18 \t10955 \t0.575895\t18 \t0.77596 \t0.1313   \t10955 \t0.0828054\t6.89722\t18 \t19 \t3  \t10955 \t2.23087\n",
            "19 \t10867 \t0.587319\t19 \t0.786994\t0.0915071\t10867 \t0.0844053\t6.93292\t19 \t21 \t3  \t10867 \t2.2149 \n",
            "20 \t10998 \t0.597985\t20 \t0.796091\t0.200123 \t10998 \t0.0852105\t6.96312\t20 \t24 \t3  \t10998 \t2.24214\n",
            "21 \t10925 \t0.606553\t21 \t0.796091\t0.185956 \t10925 \t0.0874102\t6.95486\t21 \t21 \t3  \t10925 \t2.20124\n",
            "22 \t10828 \t0.618031\t22 \t0.796091\t0.24616  \t10828 \t0.0872529\t6.94194\t22 \t21 \t3  \t10828 \t2.20207\n",
            "23 \t10879 \t0.625042\t23 \t0.806027\t0.17849  \t10879 \t0.0891569\t7.01722\t23 \t24 \t3  \t10879 \t2.2516 \n",
            "24 \t10777 \t0.6353  \t24 \t0.806027\t0.237193 \t10777 \t0.089902 \t7.08243\t24 \t20 \t3  \t10777 \t2.25282\n",
            "25 \t10916 \t0.643073\t25 \t0.806027\t0.177325 \t10916 \t0.0901816\t7.14785\t25 \t20 \t3  \t10916 \t2.23306\n",
            "26 \t10837 \t0.651712\t26 \t0.827927\t0.241861 \t10837 \t0.0900914\t7.23583\t26 \t22 \t3  \t10837 \t2.20859\n",
            "27 \t10887 \t0.659848\t27 \t0.827927\t0.241169 \t10887 \t0.0901545\t7.36757\t27 \t24 \t3  \t10887 \t2.26387\n",
            "28 \t10844 \t0.667807\t28 \t0.83001 \t0.206688 \t10844 \t0.091056 \t7.46576\t28 \t22 \t3  \t10844 \t2.29482\n",
            "29 \t10943 \t0.674175\t29 \t0.836939\t0.202318 \t10943 \t0.0916252\t7.53389\t29 \t21 \t3  \t10943 \t2.31624\n",
            "30 \t10875 \t0.681995\t30 \t0.836939\t0.215378 \t10875 \t0.0918339\t7.64368\t30 \t20 \t3  \t10875 \t2.39181\n",
            "31 \t10966 \t0.68997 \t31 \t0.836939\t0.239306 \t10966 \t0.0913449\t7.7516 \t31 \t24 \t3  \t10966 \t2.48678\n",
            "32 \t10711 \t0.698205\t32 \t0.850913\t0.255111 \t10711 \t0.091951 \t7.89972\t32 \t28 \t3  \t10711 \t2.57821\n",
            "33 \t10925 \t0.705292\t33 \t0.850913\t0.263562 \t10925 \t0.0918042\t8.03146\t33 \t24 \t3  \t10925 \t2.63553\n",
            "34 \t10901 \t0.713062\t34 \t0.862151\t0.218972 \t10901 \t0.0904684\t8.11153\t34 \t25 \t3  \t10901 \t2.68461\n",
            "35 \t11004 \t0.717257\t35 \t0.867691\t0.291748 \t11004 \t0.092278 \t8.23111\t35 \t25 \t3  \t11004 \t2.7337 \n",
            "36 \t10943 \t0.723642\t36 \t0.873116\t0.267313 \t10943 \t0.0922667\t8.35847\t36 \t26 \t3  \t10943 \t2.82913\n",
            "37 \t10934 \t0.726385\t37 \t0.873252\t0.256941 \t10934 \t0.0947246\t8.45007\t37 \t26 \t3  \t10934 \t2.90366\n",
            "38 \t10881 \t0.731867\t38 \t0.873252\t0.299628 \t10881 \t0.0947706\t8.55264\t38 \t27 \t3  \t10881 \t2.90438\n",
            "39 \t10972 \t0.735334\t39 \t0.875508\t0.286306 \t10972 \t0.0959197\t8.77319\t39 \t25 \t3  \t10972 \t2.97983\n",
            "40 \t10895 \t0.740447\t40 \t0.875508\t0.212308 \t10895 \t0.0940138\t9.01889\t40 \t23 \t3  \t10895 \t3.02748\n",
            "41 \t10890 \t0.745194\t41 \t0.886384\t0.226029 \t10890 \t0.0947736\t9.25069\t41 \t26 \t3  \t10890 \t3.03769\n",
            "42 \t10795 \t0.749276\t42 \t0.886384\t0.269286 \t10795 \t0.0944523\t9.50535\t42 \t28 \t3  \t10795 \t3.11243\n",
            "43 \t10960 \t0.752134\t43 \t0.886384\t0.268478 \t10960 \t0.0943224\t9.74792\t43 \t28 \t3  \t10960 \t3.13288\n",
            "44 \t10868 \t0.756189\t44 \t0.886384\t0.176899 \t10868 \t0.09378  \t9.94438\t44 \t29 \t3  \t10868 \t3.13092\n",
            "45 \t10911 \t0.759436\t45 \t0.897691\t0.276193 \t10911 \t0.0947914\t10.0843\t45 \t29 \t3  \t10911 \t3.12954\n",
            "46 \t10831 \t0.762593\t46 \t0.897691\t0.282602 \t10831 \t0.0955844\t10.2261\t46 \t29 \t3  \t10831 \t3.13539\n",
            "47 \t10918 \t0.765711\t47 \t0.900503\t0.27049  \t10918 \t0.0959058\t10.4786\t47 \t31 \t3  \t10918 \t3.18607\n",
            "48 \t10907 \t0.77141 \t48 \t0.900503\t0.284621 \t10907 \t0.0946098\t10.6868\t48 \t31 \t3  \t10907 \t3.27386\n",
            "49 \t10901 \t0.77527 \t49 \t0.900503\t0.294763 \t10901 \t0.0946522\t10.9001\t49 \t31 \t3  \t10901 \t3.33143\n",
            "50 \t10903 \t0.781226\t50 \t0.905525\t0.293183 \t10903 \t0.0933757\t11.173 \t50 \t31 \t3  \t10903 \t3.39166\n",
            "51 \t10882 \t0.785923\t51 \t0.905702\t0.296913 \t10882 \t0.0943772\t11.4449\t51 \t31 \t3  \t10882 \t3.48429\n",
            "52 \t10944 \t0.790409\t52 \t0.910382\t0.24143  \t10944 \t0.0937819\t11.7394\t52 \t31 \t3  \t10944 \t3.55481\n",
            "53 \t10870 \t0.794887\t53 \t0.91778 \t0.288509 \t10870 \t0.0925601\t12.1301\t53 \t35 \t5  \t10870 \t3.7218 \n",
            "54 \t10917 \t0.800216\t54 \t0.91778 \t0.258173 \t10917 \t0.0918605\t12.501 \t54 \t35 \t3  \t10917 \t3.84937\n",
            "55 \t10933 \t0.802122\t55 \t0.91778 \t0.286572 \t10933 \t0.0927184\t12.8778\t55 \t35 \t4  \t10933 \t3.97066\n",
            "56 \t10820 \t0.80744 \t56 \t0.91778 \t0.259643 \t10820 \t0.0916886\t13.2735\t56 \t35 \t5  \t10820 \t4.13586\n",
            "57 \t10786 \t0.811439\t57 \t0.91778 \t0.304124 \t10786 \t0.0924341\t13.7726\t57 \t37 \t5  \t10786 \t4.27632\n",
            "58 \t10916 \t0.816142\t58 \t0.91778 \t0.308989 \t10916 \t0.0896298\t14.2601\t58 \t37 \t5  \t10916 \t4.4002 \n",
            "59 \t10902 \t0.818824\t59 \t0.918   \t0.302209 \t10902 \t0.0905727\t14.8324\t59 \t37 \t5  \t10902 \t4.47309\n",
            "60 \t10853 \t0.823022\t60 \t0.925335\t0.267984 \t10853 \t0.0878421\t15.4415\t60 \t41 \t5  \t10853 \t4.53426\n",
            "61 \t10976 \t0.824801\t61 \t0.932355\t0.333783 \t10976 \t0.0889275\t15.8615\t61 \t41 \t3  \t10976 \t4.50822\n",
            "62 \t10925 \t0.826803\t62 \t0.932355\t0.269286 \t10925 \t0.089178 \t16.1788\t62 \t41 \t5  \t10925 \t4.55208\n",
            "63 \t10857 \t0.8296  \t63 \t0.932355\t0.227627 \t10857 \t0.0884717\t16.4574\t63 \t41 \t6  \t10857 \t4.60401\n",
            "64 \t10959 \t0.831816\t64 \t0.932355\t0.340397 \t10959 \t0.0882615\t16.7335\t64 \t41 \t5  \t10959 \t4.67826\n",
            "65 \t10919 \t0.833939\t65 \t0.932355\t0.332621 \t10919 \t0.0885417\t16.999 \t65 \t43 \t5  \t10919 \t4.70718\n",
            "66 \t10858 \t0.838205\t66 \t0.932355\t0.305155 \t10858 \t0.086371 \t17.2754\t66 \t43 \t5  \t10858 \t4.84325\n",
            "67 \t10861 \t0.839967\t67 \t0.936359\t0.330446 \t10861 \t0.0869721\t17.5888\t67 \t47 \t5  \t10861 \t4.86553\n",
            "68 \t10840 \t0.841497\t68 \t0.936359\t0.284322 \t10840 \t0.0883539\t17.9694\t68 \t44 \t5  \t10840 \t4.94525\n",
            "69 \t10792 \t0.844984\t69 \t0.936359\t0.280852 \t10792 \t0.0861399\t18.4257\t69 \t45 \t6  \t10792 \t5.03619\n",
            "70 \t11005 \t0.846032\t70 \t0.93979 \t0.303656 \t11005 \t0.0870289\t18.7302\t70 \t45 \t5  \t11005 \t5.11221\n",
            "71 \t10943 \t0.847762\t71 \t0.93979 \t0.274884 \t10943 \t0.0861578\t18.9367\t71 \t47 \t7  \t10943 \t5.18858\n",
            "72 \t10771 \t0.849599\t72 \t0.93979 \t0.340579 \t10771 \t0.0859697\t18.9966\t72 \t47 \t7  \t10771 \t5.2331 \n",
            "73 \t10876 \t0.850805\t73 \t0.943893\t0.268455 \t10876 \t0.0869001\t19.0835\t73 \t51 \t6  \t10876 \t5.23647\n",
            "74 \t10909 \t0.853811\t74 \t0.947996\t0.286672 \t10909 \t0.0850926\t19.1465\t74 \t47 \t7  \t10909 \t5.1587 \n",
            "75 \t10845 \t0.85745 \t75 \t0.947996\t0.311071 \t10845 \t0.0823973\t19.3577\t75 \t47 \t7  \t10845 \t5.22111\n",
            "76 \t10908 \t0.85891 \t76 \t0.947996\t0.317648 \t10908 \t0.0829494\t19.8478\t76 \t45 \t7  \t10908 \t5.39814\n",
            "77 \t10844 \t0.861713\t77 \t0.947996\t0.344001 \t10844 \t0.0820693\t20.4453\t77 \t47 \t7  \t10844 \t5.57748\n",
            "78 \t10879 \t0.866191\t78 \t0.956159\t0.29206  \t10879 \t0.0808711\t21.2029\t78 \t45 \t7  \t10879 \t5.70457\n",
            "79 \t10957 \t0.868193\t79 \t0.95618 \t0.322272 \t10957 \t0.0808595\t21.8424\t79 \t55 \t8  \t10957 \t5.84287\n",
            "80 \t10959 \t0.872221\t80 \t0.95618 \t0.338303 \t10959 \t0.0790365\t22.7005\t80 \t55 \t7  \t10959 \t6.03412\n",
            "81 \t10898 \t0.875894\t81 \t0.95618 \t0.303755 \t10898 \t0.0786265\t23.6058\t81 \t55 \t8  \t10898 \t6.10361\n",
            "82 \t10866 \t0.880561\t82 \t0.95618 \t0.340001 \t10866 \t0.0777419\t24.5929\t82 \t58 \t9  \t10866 \t6.1056 \n",
            "83 \t10973 \t0.884149\t83 \t0.960262\t0.286435 \t10973 \t0.0768521\t25.5215\t83 \t58 \t9  \t10973 \t6.01796\n",
            "84 \t10943 \t0.888366\t84 \t0.960262\t0.323608 \t10943 \t0.0746556\t26.3689\t84 \t58 \t9  \t10943 \t5.93955\n",
            "85 \t10888 \t0.890473\t85 \t0.960262\t0.363179 \t10888 \t0.0757815\t27.0497\t85 \t58 \t9  \t10888 \t5.94311\n",
            "86 \t10889 \t0.89233 \t86 \t0.960262\t0.294563 \t10889 \t0.0752875\t27.5936\t86 \t62 \t9  \t10889 \t5.93653\n",
            "87 \t10857 \t0.894258\t87 \t0.960283\t0.301604 \t10857 \t0.0758083\t27.9767\t87 \t58 \t9  \t10857 \t6.05745\n",
            "88 \t10901 \t0.894993\t88 \t0.964365\t0.361617 \t10901 \t0.0775324\t28.278 \t88 \t60 \t7  \t10901 \t6.19089\n",
            "89 \t10773 \t0.897383\t89 \t0.964365\t0.373088 \t10773 \t0.0756728\t28.6232\t89 \t63 \t9  \t10773 \t6.43359\n",
            "90 \t10883 \t0.897172\t90 \t0.964365\t0.359724 \t10883 \t0.0775668\t28.9566\t90 \t63 \t9  \t10883 \t6.53616\n",
            "91 \t10773 \t0.899321\t91 \t0.964365\t0.316415 \t10773 \t0.0764239\t29.3347\t91 \t64 \t9  \t10773 \t6.62771\n",
            "92 \t10940 \t0.899597\t92 \t0.968468\t0.412577 \t10940 \t0.0782979\t29.6376\t92 \t67 \t9  \t10940 \t6.67551\n",
            "93 \t10840 \t0.900731\t93 \t0.968468\t0.338133 \t10840 \t0.076484 \t29.8121\t93 \t70 \t9  \t10840 \t6.8492 \n",
            "94 \t10880 \t0.902421\t94 \t0.968468\t0.356613 \t10880 \t0.0762756\t30.2401\t94 \t82 \t9  \t10880 \t7.05275\n",
            "95 \t10943 \t0.902233\t95 \t0.972571\t0.372169 \t10943 \t0.0769113\t30.8981\t95 \t82 \t7  \t10943 \t7.43785\n",
            "96 \t10839 \t0.904194\t96 \t0.972571\t0.365856 \t10839 \t0.075424 \t31.6397\t96 \t82 \t9  \t10839 \t7.80054\n",
            "97 \t10844 \t0.905442\t97 \t0.972571\t0.345601 \t10844 \t0.0748867\t32.4556\t97 \t73 \t10 \t10844 \t8.21065\n",
            "98 \t10897 \t0.906134\t98 \t0.972571\t0.306457 \t10897 \t0.0756697\t33.3653\t98 \t73 \t10 \t10897 \t8.59082\n",
            "99 \t10877 \t0.906626\t99 \t0.972571\t0.371702 \t10877 \t0.0765538\t34.3419\t99 \t82 \t10 \t10877 \t8.90083\n",
            "100\t10939 \t0.90806 \t100\t0.972571\t0.394178 \t10939 \t0.0760227\t35.6699\t100\t82 \t10 \t10939 \t9.31144\n"
          ]
        }
      ],
      "source": [
        "def xmate(ind1, ind2):\n",
        "    \"\"\" Reproduction operator for multi-tree GP, where trees are represented as a list.\n",
        "\n",
        "    Crossover happens to a subtree that is selected at random. \n",
        "    Crossover operations are limited to parents from the same tree.\n",
        "\n",
        "    FIXME: Have to compile the trees (manually), which is frustrating. \n",
        "    \n",
        "    Args: \n",
        "        ind1 (Individual): The first parent. \n",
        "        ind2 (Individual): The second parent \n",
        "\n",
        "    Returns:\n",
        "        ind1, ind2 (Individual, Individual): The children from the parents reproduction. \n",
        "    \"\"\"\n",
        "    n = range(len(ind1))\n",
        "    selected_tree_idx = random.choice(n)\n",
        "    for tree_idx in n:\n",
        "        g1, g2 = gp.PrimitiveTree(ind1[tree_idx]), gp.PrimitiveTree(ind2[tree_idx])\n",
        "        if tree_idx == selected_tree_idx:\n",
        "            ind1[tree_idx], ind2[tree_idx] = gp.cxOnePoint(g1, g2)\n",
        "        else: \n",
        "            ind1[tree_idx], ind2[tree_idx] = g1, g2\n",
        "    return ind1, ind2\n",
        "\n",
        "\n",
        "def xmut(ind, expr):\n",
        "    \"\"\" Mutation operator for multi-tree GP, where trees are represented as a list. \n",
        "\n",
        "    Mutation happens to a tree selected at random, when an individual is selected for crossover. \n",
        "\n",
        "    FIXME: Have to compile the trees (manually), which is frustrating. \n",
        "\n",
        "    Args: \n",
        "        ind: The individual, a list of GP trees. \n",
        "    \"\"\"\n",
        "    n = range(len(ind))\n",
        "    selected_tree_idx = random.choice(n)\n",
        "    for tree_idx in n:\n",
        "        g1 = gp.PrimitiveTree(ind[tree_idx])\n",
        "        if tree_idx == selected_tree_idx:\n",
        "            indx = gp.mutUniform(g1, expr, pset)\n",
        "            ind[tree_idx] = indx[0]\n",
        "        else:\n",
        "            ind[tree_idx] = g1\n",
        "    return ind,\n",
        "\n",
        "\n",
        "def evaluate_classification(individual, X=X_train, y=y_train, verbose=False):    \n",
        "    \"\"\" Evaluate balanced classification accuracy over stratified k-fold cross validation. \"\"\" \n",
        "    def predict(X_idx, y_t):\n",
        "        \"\"\" Winner-takes-all predictions with GP-tree for a dataset.\"\"\"\n",
        "        y_preds = []   \n",
        "        for tree_output in funcs[X_idx]:\n",
        "            winner_takes_all = np.argmax(tree_output)\n",
        "            y_preds.append(winner_takes_all)\n",
        "        accuracy = balanced_accuracy_score(y_t, y_preds)\n",
        "        return accuracy\n",
        "\n",
        "    def cross_validate(X,y,k=5):\n",
        "        \"\"\" Performs k-fold cross validation to evaluate a dataset. \"\"\"\n",
        "        train_accs = []\n",
        "        test_accs = [] \n",
        "        skf = StratifiedKFold(n_splits=k)\n",
        "        for train_idx, test_idx in skf.split(X,y):\n",
        "            X_train, X_test = X[train_idx], X[test_idx]\n",
        "            y_train, y_test = y[train_idx], y[test_idx]\n",
        "            train_acc = predict(train_idx, y_train)\n",
        "            train_accs.append(train_acc)\n",
        "            test_acc = predict(test_idx, y_test)\n",
        "            test_accs.append(test_acc)\n",
        "        avg_train_acc = np.mean(train_accs) \n",
        "        avg_test_acc = np.mean(test_accs)\n",
        "        return avg_train_acc, avg_test_acc\n",
        "\n",
        "    funcs = toolbox.compile(expr=individual, pset=pset)\n",
        "\n",
        "    avg_train_acc, avg_test_acc = cross_validate(X,y)\n",
        "    if verbose:\n",
        "        print(f\"Average train accuracy: {avg_train_acc}, Average test accuracy: {avg_test_acc}\")\n",
        "    return avg_train_acc, \n",
        "\n",
        "\n",
        "toolbox.register('evaluate', evaluate_classification)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "toolbox.register(\"mate\", xmate)\n",
        "toolbox.register(\"expr_mut\", gp.genFull, min_=0, max_=2)\n",
        "toolbox.register(\"mutate\", xmut, expr=toolbox.expr_mut)\n",
        "\n",
        "\n",
        "def staticLimit(key, max_value):\n",
        "    \"\"\"\n",
        "    A variation of gp.staticLimit that works for Multi-tree representation. \n",
        "    This works for our altered xmut and xmate genetic operators for mutli-tree GP. \n",
        "    If tree depth limit is exceeded, the genetic operator is reverted. \n",
        "\n",
        "    When an invalid (over the limit) child is generated,\n",
        "    it is simply replaced by one of its parents, randomly selected.\n",
        "    \n",
        "    Args:\n",
        "        key: The function to use in order the get the wanted value. For\n",
        "             instance, on a GP tree, ``operator.attrgetter('height')`` may\n",
        "             be used to set a depth limit, and ``len`` to set a size limit.\n",
        "        max_value: The maximum value allowed for the given measurement. \n",
        "             Defaults to 17, the suggested value in (Koza 1992)\n",
        "    \n",
        "    Returns: \n",
        "        A decorator that can be applied to a GP operator using \\\n",
        "        :func:`~deap.base.Toolbox.decorate`\n",
        "\n",
        "    References:\n",
        "        1. Koza, J. R. G. P. (1992). On the programming of computers by means \n",
        "            of natural selection. Genetic programming.\n",
        "    \"\"\"\n",
        "\n",
        "    def decorator(func):\n",
        "        @wraps(func)\n",
        "        def wrapper(*args, **kwargs):\n",
        "            keep_inds = [[copy.deepcopy(tree) for tree in ind] for ind in args]\n",
        "            new_inds = list(func(*args, **kwargs))\n",
        "            for ind_idx, ind in enumerate(new_inds):\n",
        "                for tree_idx, tree in enumerate(ind):\n",
        "                    if key(tree) > max_value:\n",
        "                        random_parent = random.choice(keep_inds)\n",
        "                        new_inds[ind_idx][tree_idx] = random_parent[tree_idx]\n",
        "            return new_inds\n",
        "        return wrapper\n",
        "    return decorator\n",
        "\n",
        "# See https://groups.google.com/g/deap-users/c/pWzR_q7mKJ0\n",
        "toolbox.decorate(\"mate\", staticLimit(key=operator.attrgetter(\"height\"), max_value=8))\n",
        "toolbox.decorate(\"mutate\", staticLimit(key=operator.attrgetter(\"height\"), max_value=8))\n",
        "\n",
        "\n",
        "def SimpleGPWithElitism(population, toolbox, cxpb, mutpb, ngen, stats=None,\n",
        "             halloffame=None, verbose=__debug__):\n",
        "    \"\"\"\n",
        "    Elitism for Multi-Tree GP for Multi-Class classification. \n",
        "    A variation of the eaSimple method from the DEAP library that supports \n",
        "\n",
        "    Elitism ensures the best individuals (the elite) from each generation are \n",
        "    carried onto the next without alteration. This ensures the quality of the \n",
        "    best solution monotonically increases over time. \n",
        "    \"\"\"\n",
        "    logbook = tools.Logbook()\n",
        "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
        "\n",
        "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
        "    fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "    \n",
        "    for ind, fit in zip(invalid_ind, fitnesses):\n",
        "        ind.fitness.values = fit\n",
        "\n",
        "    if halloffame is None:\n",
        "        raise ValueError(\"halloffame parameter must not be empty!\")\n",
        "\n",
        "    halloffame.update(population)\n",
        "    hof_size = len(halloffame.items) if halloffame.items else 0\n",
        "\n",
        "    record = stats.compile(population) if stats else {}\n",
        "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
        "    \n",
        "    if verbose:\n",
        "        print(logbook.stream)\n",
        "\n",
        "    for gen in range(1, ngen + 1):\n",
        "        offspring = toolbox.select(population, len(population) - hof_size)\n",
        "        offspring = algorithms.varAnd(offspring, toolbox, cxpb, mutpb)\n",
        "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "        fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
        "        \n",
        "        for ind, fit in zip(invalid_ind, fitnesses):\n",
        "            ind.fitness.values = fit\n",
        "\n",
        "        offspring.extend(halloffame.items)\n",
        "        halloffame.update(offspring)\n",
        "        population[:] = offspring\n",
        "        \n",
        "        record = stats.compile(population) if stats else {}\n",
        "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
        "        \n",
        "        if verbose:\n",
        "            print(logbook.stream)\n",
        "\n",
        "    return population, logbook\n",
        "\n",
        "\n",
        "def train(generations=100, population=100, elitism=0.1, crossover_rate=0.5, mutation_rate=0.1):\n",
        "    \"\"\"\n",
        "    This is a Multi-tree GP with Elitism for Multi-class classification. \n",
        "\n",
        "    Args:\n",
        "        generations: The number of generations to evolve the populaiton for. \n",
        "        elitism: The ratio of elites to be kept between generations. \n",
        "        crossover_rate: The probability of a crossover between two individuals. \n",
        "        mutation_rate: The probability of a random mutation within an individual.  \n",
        "\n",
        "    Returns:\n",
        "        pop: The final population the algorithm has evolved. \n",
        "        log: The logbook which can record important statistics. \n",
        "        hof: The hall of fame contains the best individual solutions.\n",
        "    \"\"\"\n",
        "    random.seed(420)\n",
        "    pop = toolbox.population(n=population)\n",
        "    \n",
        "    mu = round(elitism * population)\n",
        "    if elitism > 0:\n",
        "        # See https://www.programcreek.com/python/example/107757/deap.tools.HallOfFame\n",
        "        hof = tools.HallOfFame(mu)\n",
        "    else:\n",
        "        hof = None\n",
        "    \n",
        "    # Fitness is a balanced accuracy + hamming distance regularization. \n",
        "    stats_fit = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "\n",
        "    # Size, is the tree with the maximum length in the multi-tree\n",
        "    length = lambda a: np.max(list(map(len, a)))\n",
        "    stats_size = tools.Statistics(length)\n",
        "\n",
        "    mstats = tools.MultiStatistics(fitness=stats_fit, size=stats_size)\n",
        "\n",
        "    mstats.register(\"avg\", np.mean)\n",
        "    mstats.register(\"std\", np.std)\n",
        "    mstats.register(\"min\", np.min)\n",
        "    mstats.register(\"max\", np.max)\n",
        "\n",
        "    pop, log = SimpleGPWithElitism(pop, toolbox, crossover_rate, mutation_rate, \n",
        "                                   generations, stats=mstats, halloffame=hof, \n",
        "                                   verbose=True)\n",
        "    return pop, log, hof\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "DeJong (1975), p=50-100, m=0.001, c=0.6 \n",
        "Grefenstette (1986), p=30, m=0.01, c=0.95\n",
        "Schaffer et al., (1989), p=20-30, m=0.005-0.01, c=0.75-0.95\n",
        "\n",
        "References:\n",
        "    1. Patil, V. P., & Pawar, D. D. (2015). The optimal crossover or mutation \n",
        "    rates in genetic algorithm: a review. International Journal of Applied \n",
        "    Engineering and Technology, 5(3), 38-41.\n",
        "\"\"\"\n",
        "\n",
        "beta = 3\n",
        "population = n_features * beta\n",
        "generations = 100\n",
        "elitism = 0.1\n",
        "crossover_rate = 0.8\n",
        "mutation_rate = 0.2\n",
        "\n",
        "assert crossover_rate + mutation_rate == 1, \"Crossover and mutation sums to 1 (to please the Gods!)\"\n",
        "\n",
        "pop, log, hof = train(generations, population, elitism, crossover_rate, mutation_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1Jq2spZMH5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2819001-f4c6-499d-d935-ea55693f7065"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 0.9725274725274726\n",
            "Train accuracy: 0.7261904761904762\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7261904761904762"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "def evaluate_classification(individual, X=X_train, y=y_train, name=\"Train\", alpha = 0.9, verbose=False):    \n",
        "    \"\"\" Evaluate balanced classification accuracy over stratified k-fold cross validation. \"\"\" \n",
        "    def predict(X_idx, y_t):\n",
        "        \"\"\" Winner-takes-all predictions with GP-tree for a dataset.\"\"\"\n",
        "        y_preds = []   \n",
        "        for tree_output in funcs[X_idx]:\n",
        "            winner_takes_all = np.argmax(tree_output)\n",
        "            y_preds.append(winner_takes_all)\n",
        "        accuracy = balanced_accuracy_score(y_t, y_preds)\n",
        "        return accuracy\n",
        "\n",
        "    funcs = toolbox.compile(expr=individual, pset=pset, data=X)\n",
        "    accuracy = predict(range(0,len(X)),y)\n",
        "    if verbose: \n",
        "        print(f\"{name} accuracy: {accuracy}\")\n",
        "    return accuracy\n",
        "\n",
        "# The invidiual with best fitness. \n",
        "best = hof[0]\n",
        "\n",
        "# Classification accuracy for the unseen train set. \n",
        "evaluate_classification(best, X=X_train, y=y_train, verbose=True)\n",
        "\n",
        "# Classification accuracy for the unseen test set. \n",
        "evaluate_classification(best, X=X_test, y=y_test, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkaU6kAGyBl2"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEqouLDs4xBJ"
      },
      "outputs": [],
      "source": [
        "from deap import base, creator, gp\n",
        "import pygraphviz as pgv\n",
        "\n",
        "multi_tree = hof[0]\n",
        "for t_idx,tree in enumerate(multi_tree): \n",
        "    nodes, edges, labels = gp.graph(tree)\n",
        "\n",
        "    g = pgv.AGraph()\n",
        "    g.add_nodes_from(nodes)\n",
        "    g.add_edges_from(edges)\n",
        "    g.layout(prog=\"dot\")\n",
        "\n",
        "    for i in nodes:\n",
        "        n = g.get_node(i)\n",
        "        n.attr[\"label\"] = labels[i]\n",
        "\n",
        "    g.draw(f\"tree-{t_idx}.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX_g4MipuQTU"
      },
      "source": [
        "## Changelog \n",
        "\n",
        "| Date | Title | Description | Update | \n",
        "| --- | --- | --- | ---- | \n",
        "| 2022-08-21 17:30 | Multi-Objective - Onehot Encoding | Change to multi-objective problem, one-vs-all with a tree classifier for each class.<br> Y labels are encoded in onehot encodings, error is absolute difference between $|\\hat{y} - y|$| \n",
        "| 2022-08-22 20:44 | Non-linearity |  Introduce $ round . sigmoid $ to evaluate_classification() method.<br>Previously, we push each tree to predict either a 0 or 1 value with the onehot encoding representation.<br>Now, the non-linearity will map any negative value to a negative class 0, and any positive value to positive class 1.|\n",
        "| 2022-08-22 21:06 | ~~Genetic operators for tree with worst fitness~~ | Only apply the genetic operators, crossover and mutation, to the tree with the worst fitness.<br> This guarantees monotonic improvement for the Multi-tree between generations, the best performing tree remain unaltered.| (Update) This was very slow, and inefficient,<br> basically turned the GP into a single objective,<br>that balances multi-objective fitness functions. | \n",
        "| 2022-08-22 21:15 | Halloffame Equality Operator | Numpy equality function (operators.eq) between two arrays returns the equality element wise,<br>which raises an exception in the if similar() check of the hall of fame. <br> Using a different equality function like numpy.array_equal or numpy.allclose solve this issue.| \n",
        "| 2022-08-22 23:22 | Elitism as aggregate best tree | Perform elitsim by constructing the best tree, as the tree with best fitness from each clas.<br>The goal is to have monotonous improvement across the multiple objective functions.| \n",
        "| 2022-08-22 23:32 | Update fitness for elite | The elitism was not working as intended, as the multi-objectives didn't appear to increase monotnously.<br> This was because the aggregate fitness was not being assigned to the best individual after it was created.<br>Therefore the best invidiual was not passed on to the next generation. | \n",
        "| 2022-08-22 02:28 | staticLimit max height | Rewrite the gp.staticLimit decorator function to handle the Multi-tree representation.<br>Note: size and depth are different values!<br>depth is the maximum length of a root-to-leaf traversal,<br>size is the total number of nodes.| \n",
        "| 2022-08-24 9:37 | Evaluate Mutli-tree train accuracy | Take the classification accuracy as the argmax for the aggregate multitree.<br> 74% training accuracy, which is not ideal, but this shall improve with time.| \n",
        "| 2022-08-25 13:30 | Single-objective fitness | Change the fitness function to a single objective fitness function.<br>This forces the multi-tree GP to find the best tree subset for one-vs-rest classification performance.| \n",
        "| 2022-08-25 20:01 | Fitness = Balanced accuracy + distance measure | Implement the fitness function for MCIFC, but for multi-class classification from (Tran 2019) |\n",
        "| 2022-08-26 21:27 | Sklearn Balanced Accuracy | Changed to the balanced accuracy metric from sklearn.<br>This is much easier to use for now, probably faster than the previous method as well. | \n",
        "| 2022-09-05 17:00 | Reject invalid predictions | Change the fitness function to reject invalid predictioctions outright -<br>e.g. multi-label or zero-label predictions<br>- when computing the balanced accuracy for the fitness function. |\n",
        "| 2022-09-26 | Winner-takes-all | Use a winner-takes-all approach for the prediction.<br>The class depedendent subtree with the largest value is the predicted class. | \n",
        "| 2022-10-14 20:23 | Hengzhe's 5x speedup | Implemented Henzhe's 5x speedup for GP tree compilation with DEAP library. | \n",
        "| 2022-10-14 20:23 | Crossvalidation | Implemented k-fold crossvalidation for assessing the fitness of an indvidual. | \n",
        "| 2022-10-15 02:03 | Train, Validation, Test | The test set is reserved for final comparison, fitness is based on crossvalidation performance on training set only.<br>This gives an accurate evaluation for performance on unseen data (without data leakage).| "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1Yg4t38NHSYPAlu_099cQeOR-qSwIaaTl",
      "authorship_tag": "ABX9TyO6UMAEA+32308vhJQfKqhL",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}