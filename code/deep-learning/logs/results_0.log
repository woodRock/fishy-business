2024-11-02 00:21:34,738 - INFO - Starting training pipeline
2024-11-02 00:21:34,738 - INFO - Creating DataModule with augmentation parameters: {'num_augmentations': 5, 'noise_level': 0.1, 'shift_enabled': False, 'scale_enabled': False}
2024-11-02 00:21:34,738 - INFO - Created augmentation config with 5 augmentations
2024-11-02 00:21:34,738 - INFO - Starting main training phase
2024-11-02 00:21:34,738 - INFO - Loading dataset: oil
2024-11-02 00:21:34,739 - INFO - Loading data from: /home/woodj/Desktop/fishy-business/data/REIMS_data.xlsx
2024-11-02 00:21:37,516 - INFO - Loaded data with shape: (306, 1024)
2024-11-02 00:21:37,518 - INFO - Filtered data shape: (234, 1024)
2024-11-02 00:21:37,518 - INFO - Dataset shape after filtering: (234, 1024)
2024-11-02 00:21:37,520 - INFO - Features shape: (126, 1023), Labels shape: (126, 7)
2024-11-02 00:21:37,520 - INFO - Applying data augmentation with 5 augmentations per sample...
2024-11-02 00:21:37,520 - INFO - Starting data augmentation with 5 augmentations per sample
2024-11-02 00:21:37,551 - INFO - Augmentation complete. Dataset size increased from 126 to 756 samples
2024-11-02 00:21:37,553 - INFO - Dataset size increased from 126 to 756 samples
2024-11-02 00:21:37,558 - INFO - Dataset size verification:
2024-11-02 00:21:37,559 - INFO -   Original size: 126
2024-11-02 00:21:37,559 - INFO -   Expected size: 756
2024-11-02 00:21:37,559 - INFO -   Actual size: 756
2024-11-02 00:21:38,096 - INFO - Created model: Transformer(
  (encoder): Encoder(
    (layers): ModuleList(
      (0-3): 4 x EncoderLayer(
        (self_attention): MultiHeadAttention(
          (query): Linear(in_features=1023, out_features=1023, bias=True)
          (key): Linear(in_features=1023, out_features=1023, bias=True)
          (value): Linear(in_features=1023, out_features=1023, bias=True)
          (fc_out): Linear(in_features=1023, out_features=1023, bias=True)
        )
        (feed_forward): FeedForward(
          (fc1): Linear(in_features=1023, out_features=128, bias=True)
          (fc2): Linear(in_features=128, out_features=1023, bias=True)
          (dropout): Dropout(p=0.2, inplace=False)
        )
        (norm1): LayerNorm((1023,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1023,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.2, inplace=False)
        (dropout2): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (decoder): Decoder(
    (layers): ModuleList(
      (0-3): 4 x DecoderLayer(
        (self_attention): MultiHeadAttention(
          (query): Linear(in_features=1023, out_features=1023, bias=True)
          (key): Linear(in_features=1023, out_features=1023, bias=True)
          (value): Linear(in_features=1023, out_features=1023, bias=True)
          (fc_out): Linear(in_features=1023, out_features=1023, bias=True)
        )
        (cross_attention): MultiHeadAttention(
          (query): Linear(in_features=1023, out_features=1023, bias=True)
          (key): Linear(in_features=1023, out_features=1023, bias=True)
          (value): Linear(in_features=1023, out_features=1023, bias=True)
          (fc_out): Linear(in_features=1023, out_features=1023, bias=True)
        )
        (feed_forward): FeedForward(
          (fc1): Linear(in_features=1023, out_features=128, bias=True)
          (fc2): Linear(in_features=128, out_features=1023, bias=True)
          (dropout): Dropout(p=0.2, inplace=False)
        )
        (norm1): LayerNorm((1023,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((1023,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((1023,), eps=1e-05, elementwise_affine=True)
        (dropout1): Dropout(p=0.2, inplace=False)
        (dropout2): Dropout(p=0.2, inplace=False)
        (dropout3): Dropout(p=0.2, inplace=False)
      )
    )
  )
  (fc): Linear(in_features=1023, out_features=7, bias=True)
)
2024-11-02 00:21:38,875 - INFO - Starting k-fold cross validation training
2024-11-02 00:21:38,902 - INFO - 
Starting Fold 1/5
2024-11-02 00:21:42,145 - INFO - Epoch 1: New best validation accuracy: 0.3426
2024-11-02 00:21:45,411 - INFO - Epoch 2: New best validation accuracy: 0.4545
2024-11-02 00:21:48,865 - INFO - Epoch 3: New best validation accuracy: 0.4944
2024-11-02 00:21:52,411 - INFO - Epoch 4: New best validation accuracy: 0.5529
2024-11-02 00:21:55,906 - INFO - Epoch 5: New best validation accuracy: 0.5597
2024-11-02 00:21:55,906 - INFO - Epoch 5
2024-11-02 00:21:55,906 - INFO - Train Loss: 1.0460
2024-11-02 00:21:55,906 - INFO - Val Loss: 1.3541
2024-11-02 00:21:55,906 - INFO - Current Val Accuracy: 0.5597
2024-11-02 00:21:55,906 - INFO - Best Val Accuracy: 0.5597
2024-11-02 00:21:59,397 - INFO - Epoch 6: New best validation accuracy: 0.5659
2024-11-02 00:22:02,880 - INFO - Epoch 7: New best validation accuracy: 0.5921
2024-11-02 00:22:06,371 - INFO - Epoch 8: New best validation accuracy: 0.6447
2024-11-02 00:22:13,321 - INFO - Epoch 10
2024-11-02 00:22:13,321 - INFO - Train Loss: 0.6481
2024-11-02 00:22:13,321 - INFO - Val Loss: 1.1718
2024-11-02 00:22:13,321 - INFO - Current Val Accuracy: 0.6382
2024-11-02 00:22:13,321 - INFO - Best Val Accuracy: 0.6447
2024-11-02 00:22:16,812 - INFO - Epoch 11: New best validation accuracy: 0.6518
2024-11-02 00:22:27,259 - INFO - Epoch 14: New best validation accuracy: 0.6846
2024-11-02 00:22:30,737 - INFO - Epoch 15
2024-11-02 00:22:30,737 - INFO - Train Loss: 0.5529
2024-11-02 00:22:30,737 - INFO - Val Loss: 1.1099
2024-11-02 00:22:30,737 - INFO - Current Val Accuracy: 0.6515
2024-11-02 00:22:30,737 - INFO - Best Val Accuracy: 0.6846
2024-11-02 00:22:48,226 - INFO - Epoch 20: New best validation accuracy: 0.7103
2024-11-02 00:22:48,227 - INFO - Epoch 20
2024-11-02 00:22:48,227 - INFO - Train Loss: 0.5262
2024-11-02 00:22:48,227 - INFO - Val Loss: 1.0569
2024-11-02 00:22:48,227 - INFO - Current Val Accuracy: 0.7103
2024-11-02 00:22:48,227 - INFO - Best Val Accuracy: 0.7103
2024-11-02 00:22:55,195 - INFO - Epoch 22: New best validation accuracy: 0.7112
2024-11-02 00:22:58,698 - INFO - Epoch 23: New best validation accuracy: 0.7171
2024-11-02 00:23:05,713 - INFO - Epoch 25: New best validation accuracy: 0.7239
2024-11-02 00:23:05,714 - INFO - Epoch 25
2024-11-02 00:23:05,714 - INFO - Train Loss: 0.5121
2024-11-02 00:23:05,714 - INFO - Val Loss: 1.0301
2024-11-02 00:23:05,714 - INFO - Current Val Accuracy: 0.7239
2024-11-02 00:23:05,714 - INFO - Best Val Accuracy: 0.7239
2024-11-02 00:23:12,684 - INFO - Epoch 27: New best validation accuracy: 0.7310
2024-11-02 00:23:16,231 - INFO - Epoch 28: New best validation accuracy: 0.7375
2024-11-02 00:23:23,370 - INFO - Epoch 30
2024-11-02 00:23:23,370 - INFO - Train Loss: 0.5045
2024-11-02 00:23:23,370 - INFO - Val Loss: 0.9952
2024-11-02 00:23:23,370 - INFO - Current Val Accuracy: 0.7242
2024-11-02 00:23:23,370 - INFO - Best Val Accuracy: 0.7375
