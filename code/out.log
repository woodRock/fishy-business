nohup: ignoring input
[I 2025-08-15 22:13:43,463] A new study created in memory with name: contrastive_simclr_transformer_optimization
A new study created in memory with name: contrastive_simclr_transformer_optimization
2025-08-15 22:13:43,503 - INFO - Using device: cuda
2025-08-15 22:13:51,027 - INFO - Data split: 48 train/val samples, 24 test samples.
2025-08-15 22:13:52,013 - INFO - --- Starting Fold 1/2 ---
2025-08-15 22:13:52,015 - INFO - Starting training for fold 1/2
[W 2025-08-15 22:13:52,162] Trial 0 failed with parameters: {'learning_rate': 1.7025710734645884e-05, 'batch_size': 16, 'num_epochs': 925, 'temperature': 0.10164334544100947, 'embedding_dim': 256, 'hidden_dim': 512, 'dropout': 0.4451384132536039, 'num_layers': 3, 'num_heads': 4, 'noise_enabled': False, 'shift_enabled': True, 'scale_enabled': False, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': False} because of the following error: RuntimeError('CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n').
Traceback (most recent call last):
  File "/home/woodj4/.local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/vol/ecrg-solar/woodj4/fishy-business/code/contrastive/run_optuna.py", line 152, in <lambda>
    lambda trial: objective(trial, encoder_type),
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vol/ecrg-solar/woodj4/fishy-business/code/contrastive/run_optuna.py", line 109, in objective
    stats = contrastive_main(config)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vol/ecrg-solar/woodj4/fishy-business/code/contrastive/main.py", line 798, in main
    model, metrics, threshold = run_single_training(
                                ^^^^^^^^^^^^^^^^^^^^
  File "/vol/ecrg-solar/woodj4/fishy-business/code/contrastive/main.py", line 667, in run_single_training
    model = copy.deepcopy(base_model).to(device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1343, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 930, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1329, in convert
    return t.to(
           ^^^^^
RuntimeError: CUDA error: CUDA-capable device(s) is/are busy or unavailable
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 0 failed with parameters: {'learning_rate': 1.7025710734645884e-05, 'batch_size': 16, 'num_epochs': 925, 'temperature': 0.10164334544100947, 'embedding_dim': 256, 'hidden_dim': 512, 'dropout': 0.4451384132536039, 'num_layers': 3, 'num_heads': 4, 'noise_enabled': False, 'shift_enabled': True, 'scale_enabled': False, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': False} because of the following error: RuntimeError('CUDA error: CUDA-capable device(s) is/are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n').
Traceback (most recent call last):
  File "/home/woodj4/.local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/vol/ecrg-solar/woodj4/fishy-business/code/contrastive/run_optuna.py", line 152, in <lambda>
    lambda trial: objective(trial, encoder_type),
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vol/ecrg-solar/woodj4/fishy-business/code/contrastive/run_optuna.py", line 109, in objective
    stats = contrastive_main(config)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vol/ecrg-solar/woodj4/fishy-business/code/contrastive/main.py", line 798, in main
    model, metrics, threshold = run_single_training(
                                ^^^^^^^^^^^^^^^^^^^^
  File "/vol/ecrg-solar/woodj4/fishy-business/code/contrastive/main.py", line 667, in run_single_training
    model = copy.deepcopy(base_model).to(device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1343, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 930, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1329, in convert
    return t.to(
           ^^^^^
RuntimeError: CUDA error: CUDA-capable device(s) is/are busy or unavailable
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

[W 2025-08-15 22:13:52,923] Trial 0 failed with value None.
Trial 0 failed with value None.
Traceback (most recent call last):
  File "/vol/ecrg-solar/woodj4/fishy-business/code/contrastive/run_optuna.py", line 232, in <module>
    main()
  File "/vol/ecrg-solar/woodj4/fishy-business/code/contrastive/run_optuna.py", line 151, in main
    study.optimize(
  File "/home/woodj4/.local/lib/python3.12/site-packages/optuna/study/study.py", line 475, in optimize
    _optimize(
  File "/home/woodj4/.local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 63, in _optimize
    _optimize_sequential(
  File "/home/woodj4/.local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/woodj4/.local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 248, in _run_trial
    raise func_err
  File "/home/woodj4/.local/lib/python3.12/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/vol/ecrg-solar/woodj4/fishy-business/code/contrastive/run_optuna.py", line 152, in <lambda>
    lambda trial: objective(trial, encoder_type),
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vol/ecrg-solar/woodj4/fishy-business/code/contrastive/run_optuna.py", line 109, in objective
    stats = contrastive_main(config)
            ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vol/ecrg-solar/woodj4/fishy-business/code/contrastive/main.py", line 798, in main
    model, metrics, threshold = run_single_training(
                                ^^^^^^^^^^^^^^^^^^^^
  File "/vol/ecrg-solar/woodj4/fishy-business/code/contrastive/main.py", line 667, in run_single_training
    model = copy.deepcopy(base_model).to(device)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1343, in to
    return self._apply(convert)
           ^^^^^^^^^^^^^^^^^^^^
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  [Previous line repeated 1 more time]
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 930, in _apply
    param_applied = fn(param)
                    ^^^^^^^^^
  File "/usr/pkg/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1329, in convert
    return t.to(
           ^^^^^
RuntimeError: CUDA error: CUDA-capable device(s) is/are busy or unavailable
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

