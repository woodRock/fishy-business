nohup: ignoring input
[I 2025-08-14 19:35:32,986] A new study created in memory with name: contrastive_simclr_transformer_optimization
A new study created in memory with name: contrastive_simclr_transformer_optimization
2025-08-14 19:35:33,144 - INFO - Using device: cuda
2025-08-14 19:35:43,346 - INFO - --- Starting Fold 1/3 ---
2025-08-14 19:35:43,348 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:35:43,348 - WARNING - Fold 1 has insufficient pairs to form a batch. Skipping.
2025-08-14 19:35:43,348 - INFO - --- Starting Fold 2/3 ---
2025-08-14 19:35:43,349 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:35:43,349 - WARNING - Fold 2 has insufficient pairs to form a batch. Skipping.
2025-08-14 19:35:43,350 - INFO - --- Starting Fold 3/3 ---
2025-08-14 19:35:43,351 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:35:43,351 - WARNING - Fold 3 has insufficient pairs to form a batch. Skipping.
2025-08-14 19:35:43,351 - WARNING - No folds completed successfully to aggregate metrics.
[I 2025-08-14 19:35:43,354] Trial 0 finished with value: inf and parameters: {'learning_rate': 0.00014957534558131627, 'batch_size': 64, 'num_epochs': 125, 'temperature': 0.2868016815348735, 'embedding_dim': 512, 'hidden_dim': 128, 'dropout': 0.14337063669301872, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.11733579825567615}. Best is trial 0 with value: inf.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 0 finished with value: inf and parameters: {'learning_rate': 0.00014957534558131627, 'batch_size': 64, 'num_epochs': 125, 'temperature': 0.2868016815348735, 'embedding_dim': 512, 'hidden_dim': 128, 'dropout': 0.14337063669301872, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.11733579825567615}. Best is trial 0 with value: inf.
2025-08-14 19:35:43,355 - INFO - Using device: cuda
2025-08-14 19:35:53,355 - INFO - --- Starting Fold 1/3 ---
2025-08-14 19:35:53,356 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:35:53,357 - INFO - Starting training for fold 1/3
2025-08-14 19:36:02,936 - INFO - Fold 1, Epoch 10: Val Acc: 0.44%
2025-08-14 19:36:06,753 - INFO - Fold 1, Epoch 20: Val Acc: 0.48%
2025-08-14 19:36:12,259 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 19:36:17,996 - INFO - Fold 1, Epoch 40: Val Acc: 0.48%
2025-08-14 19:36:21,494 - INFO - Fold 1, Epoch 50: Val Acc: 0.54%
2025-08-14 19:36:24,918 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-14 19:36:28,260 - INFO - Fold 1, Epoch 70: Val Acc: 0.52%
2025-08-14 19:36:31,736 - INFO - Fold 1, Epoch 80: Val Acc: 0.50%
2025-08-14 19:36:35,608 - INFO - Fold 1, Epoch 90: Val Acc: 0.46%
2025-08-14 19:36:39,473 - INFO - Fold 1, Epoch 100: Val Acc: 0.54%
2025-08-14 19:36:43,353 - INFO - Fold 1, Epoch 110: Val Acc: 0.50%
2025-08-14 19:36:49,623 - INFO - --- Starting Fold 2/3 ---
2025-08-14 19:36:49,626 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:36:49,627 - INFO - Starting training for fold 2/3
2025-08-14 19:36:56,191 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-14 19:36:58,862 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-14 19:37:01,828 - INFO - Fold 2, Epoch 30: Val Acc: 0.48%
2025-08-14 19:37:05,561 - INFO - Fold 2, Epoch 40: Val Acc: 0.52%
2025-08-14 19:37:09,289 - INFO - Fold 2, Epoch 50: Val Acc: 0.48%
2025-08-14 19:37:13,021 - INFO - Fold 2, Epoch 60: Val Acc: 0.46%
2025-08-14 19:37:18,348 - INFO - Fold 2, Epoch 70: Val Acc: 0.54%
2025-08-14 19:37:23,512 - INFO - Fold 2, Epoch 80: Val Acc: 0.50%
2025-08-14 19:37:26,943 - INFO - Fold 2, Epoch 90: Val Acc: 0.54%
2025-08-14 19:37:30,619 - INFO - Fold 2, Epoch 100: Val Acc: 0.46%
2025-08-14 19:37:34,344 - INFO - Fold 2, Epoch 110: Val Acc: 0.50%
2025-08-14 19:37:39,889 - INFO - --- Starting Fold 3/3 ---
2025-08-14 19:37:39,893 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:37:39,894 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 19:37:47,998 - INFO - Fold 3, Epoch 10: Val Acc: 0.44%
2025-08-14 19:37:51,735 - INFO - Fold 3, Epoch 20: Val Acc: 0.44%
2025-08-14 19:37:56,933 - INFO - Fold 3, Epoch 30: Val Acc: 0.52%
2025-08-14 19:38:00,706 - INFO - Fold 3, Epoch 40: Val Acc: 0.52%
2025-08-14 19:38:04,443 - INFO - Fold 3, Epoch 50: Val Acc: 0.46%
2025-08-14 19:38:08,162 - INFO - Fold 3, Epoch 60: Val Acc: 0.48%
2025-08-14 19:38:11,900 - INFO - Fold 3, Epoch 70: Val Acc: 0.52%
2025-08-14 19:38:15,642 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-14 19:38:19,371 - INFO - Fold 3, Epoch 90: Val Acc: 0.52%
2025-08-14 19:38:23,114 - INFO - Fold 3, Epoch 100: Val Acc: 0.58%
2025-08-14 19:38:26,869 - INFO - Fold 3, Epoch 110: Val Acc: 0.56%
2025-08-14 19:38:30,571 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.4665134615368314), 'std': np.float64(0.01239832986740185)}, 'train_accuracy': {'mean': np.float64(0.5625), 'std': np.float64(0.008505172717997117)}, 'val_loss': {'mean': np.float64(3.5954787201351586), 'std': np.float64(0.1022141626966569)}, 'val_accuracy': {'mean': np.float64(0.625), 'std': np.float64(0.03402069087198856)}, 'epoch': {'mean': np.float64(44.333333333333336), 'std': np.float64(22.83759084394752)}}
[I 2025-08-14 19:38:30,579] Trial 1 finished with value: -0.625 and parameters: {'learning_rate': 0.0005716911682023929, 'batch_size': 16, 'num_epochs': 117, 'temperature': 0.1501035989224006, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.27964536358488024, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': False, 'shift_enabled': True, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.7434120330168107}. Best is trial 1 with value: -0.625.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 1 finished with value: -0.625 and parameters: {'learning_rate': 0.0005716911682023929, 'batch_size': 16, 'num_epochs': 117, 'temperature': 0.1501035989224006, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.27964536358488024, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': False, 'shift_enabled': True, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.7434120330168107}. Best is trial 1 with value: -0.625.
2025-08-14 19:38:30,581 - INFO - Using device: cuda
2025-08-14 19:38:40,820 - INFO - --- Starting Fold 1/3 ---
2025-08-14 19:38:40,822 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:38:40,822 - WARNING - Fold 1 has insufficient pairs to form a batch. Skipping.
2025-08-14 19:38:40,822 - INFO - --- Starting Fold 2/3 ---
2025-08-14 19:38:40,824 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:38:40,824 - WARNING - Fold 2 has insufficient pairs to form a batch. Skipping.
2025-08-14 19:38:40,824 - INFO - --- Starting Fold 3/3 ---
2025-08-14 19:38:40,826 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:38:40,826 - WARNING - Fold 3 has insufficient pairs to form a batch. Skipping.
2025-08-14 19:38:40,826 - WARNING - No folds completed successfully to aggregate metrics.
[I 2025-08-14 19:38:40,829] Trial 2 finished with value: inf and parameters: {'learning_rate': 0.0007967435340902455, 'batch_size': 64, 'num_epochs': 482, 'temperature': 0.260065198972609, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3891365181093104, 'num_layers': 6, 'num_heads': 4, 'noise_enabled': False, 'shift_enabled': True, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.8274115882112321}. Best is trial 1 with value: -0.625.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 2 finished with value: inf and parameters: {'learning_rate': 0.0007967435340902455, 'batch_size': 64, 'num_epochs': 482, 'temperature': 0.260065198972609, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3891365181093104, 'num_layers': 6, 'num_heads': 4, 'noise_enabled': False, 'shift_enabled': True, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.8274115882112321}. Best is trial 1 with value: -0.625.
2025-08-14 19:38:40,830 - INFO - Using device: cuda
2025-08-14 19:38:50,713 - INFO - --- Starting Fold 1/3 ---
2025-08-14 19:38:50,714 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:38:50,714 - INFO - Starting training for fold 1/3
2025-08-14 19:38:53,883 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-14 19:38:55,814 - INFO - Fold 1, Epoch 20: Val Acc: 0.25%
2025-08-14 19:38:57,035 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 19:38:58,248 - INFO - Fold 1, Epoch 40: Val Acc: 0.44%
2025-08-14 19:38:59,466 - INFO - Fold 1, Epoch 50: Val Acc: 0.50%
2025-08-14 19:39:00,686 - INFO - Fold 1, Epoch 60: Val Acc: 0.41%
2025-08-14 19:39:01,906 - INFO - Fold 1, Epoch 70: Val Acc: 0.59%
2025-08-14 19:39:03,126 - INFO - Fold 1, Epoch 80: Val Acc: 0.59%
2025-08-14 19:39:04,974 - INFO - Fold 1, Epoch 90: Val Acc: 0.53%
2025-08-14 19:39:06,221 - INFO - Fold 1, Epoch 100: Val Acc: 0.47%
2025-08-14 19:39:07,449 - INFO - Fold 1, Epoch 110: Val Acc: 0.59%
2025-08-14 19:39:08,673 - INFO - Fold 1, Epoch 120: Val Acc: 0.44%
2025-08-14 19:39:09,897 - INFO - Fold 1, Epoch 130: Val Acc: 0.41%
2025-08-14 19:39:11,204 - INFO - Fold 1, Epoch 140: Val Acc: 0.50%
2025-08-14 19:39:12,681 - INFO - Fold 1, Epoch 150: Val Acc: 0.50%
2025-08-14 19:39:14,163 - INFO - Fold 1, Epoch 160: Val Acc: 0.62%
2025-08-14 19:39:15,520 - INFO - Fold 1, Epoch 170: Val Acc: 0.53%
2025-08-14 19:39:16,820 - INFO - Fold 1, Epoch 180: Val Acc: 0.56%
2025-08-14 19:39:17,849 - INFO - Early stopping at epoch 187
2025-08-14 19:39:18,868 - INFO - --- Starting Fold 2/3 ---
2025-08-14 19:39:18,871 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:39:18,871 - INFO - Starting training for fold 2/3
2025-08-14 19:39:22,922 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-14 19:39:24,267 - INFO - Fold 2, Epoch 20: Val Acc: 0.56%
2025-08-14 19:39:26,160 - INFO - Fold 2, Epoch 30: Val Acc: 0.66%
2025-08-14 19:39:27,731 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-14 19:39:29,208 - INFO - Fold 2, Epoch 50: Val Acc: 0.59%
2025-08-14 19:39:30,644 - INFO - Fold 2, Epoch 60: Val Acc: 0.56%
2025-08-14 19:39:32,058 - INFO - Fold 2, Epoch 70: Val Acc: 0.50%
2025-08-14 19:39:33,392 - INFO - Fold 2, Epoch 80: Val Acc: 0.50%
2025-08-14 19:39:35,817 - INFO - Fold 2, Epoch 90: Val Acc: 0.50%
2025-08-14 19:39:37,163 - INFO - Fold 2, Epoch 100: Val Acc: 0.56%
2025-08-14 19:39:38,641 - INFO - Fold 2, Epoch 110: Val Acc: 0.56%
2025-08-14 19:39:40,115 - INFO - Fold 2, Epoch 120: Val Acc: 0.47%
2025-08-14 19:39:41,596 - INFO - Fold 2, Epoch 130: Val Acc: 0.47%
2025-08-14 19:39:43,059 - INFO - Fold 2, Epoch 140: Val Acc: 0.53%
2025-08-14 19:39:44,524 - INFO - Fold 2, Epoch 150: Val Acc: 0.59%
2025-08-14 19:39:45,987 - INFO - Fold 2, Epoch 160: Val Acc: 0.56%
2025-08-14 19:39:47,457 - INFO - Fold 2, Epoch 170: Val Acc: 0.59%
2025-08-14 19:39:48,905 - INFO - Fold 2, Epoch 180: Val Acc: 0.53%
2025-08-14 19:39:49,994 - INFO - Early stopping at epoch 188
2025-08-14 19:39:50,791 - INFO - --- Starting Fold 3/3 ---
2025-08-14 19:39:50,801 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:39:50,801 - INFO - Starting training for fold 3/3
2025-08-14 19:39:54,185 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-14 19:39:56,694 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-14 19:39:58,414 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-14 19:39:59,629 - INFO - Fold 3, Epoch 40: Val Acc: 0.50%
2025-08-14 19:40:01,391 - INFO - Fold 3, Epoch 50: Val Acc: 0.44%
2025-08-14 19:40:02,604 - INFO - Fold 3, Epoch 60: Val Acc: 0.50%
2025-08-14 19:40:04,040 - INFO - Fold 3, Epoch 70: Val Acc: 0.50%
2025-08-14 19:40:05,517 - INFO - Fold 3, Epoch 80: Val Acc: 0.47%
2025-08-14 19:40:06,999 - INFO - Fold 3, Epoch 90: Val Acc: 0.50%
2025-08-14 19:40:08,473 - INFO - Fold 3, Epoch 100: Val Acc: 0.47%
2025-08-14 19:40:09,826 - INFO - Fold 3, Epoch 110: Val Acc: 0.41%
2025-08-14 19:40:11,250 - INFO - Fold 3, Epoch 120: Val Acc: 0.59%
2025-08-14 19:40:12,612 - INFO - Fold 3, Epoch 130: Val Acc: 0.50%
2025-08-14 19:40:13,991 - INFO - Fold 3, Epoch 140: Val Acc: 0.50%
2025-08-14 19:40:14,263 - INFO - Early stopping at epoch 142
2025-08-14 19:40:14,533 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.11330435011122), 'std': np.float64(0.0150154791454694)}, 'train_accuracy': {'mean': np.float64(0.5625), 'std': np.float64(0.01473139127471974)}, 'val_loss': {'mean': np.float64(4.182945569356282), 'std': np.float64(0.019263693993240134)}, 'val_accuracy': {'mean': np.float64(0.7083333333333334), 'std': np.float64(0.05311478659992484)}, 'epoch': {'mean': np.float64(71.33333333333333), 'std': np.float64(21.452790546272116)}}
[I 2025-08-14 19:40:14,542] Trial 3 finished with value: -0.7083333333333334 and parameters: {'learning_rate': 0.0004794896972435329, 'batch_size': 32, 'num_epochs': 285, 'temperature': 0.28074402743958643, 'embedding_dim': 512, 'hidden_dim': 512, 'dropout': 0.2689591232886156, 'num_layers': 1, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.09004332365471392, 'crop_size': 0.7618613574545781}. Best is trial 3 with value: -0.7083333333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 3 finished with value: -0.7083333333333334 and parameters: {'learning_rate': 0.0004794896972435329, 'batch_size': 32, 'num_epochs': 285, 'temperature': 0.28074402743958643, 'embedding_dim': 512, 'hidden_dim': 512, 'dropout': 0.2689591232886156, 'num_layers': 1, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.09004332365471392, 'crop_size': 0.7618613574545781}. Best is trial 3 with value: -0.7083333333333334.
2025-08-14 19:40:14,545 - INFO - Using device: cuda
2025-08-14 19:40:25,289 - INFO - --- Starting Fold 1/3 ---
2025-08-14 19:40:25,290 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:40:25,291 - WARNING - Fold 1 has insufficient pairs to form a batch. Skipping.
2025-08-14 19:40:25,291 - INFO - --- Starting Fold 2/3 ---
2025-08-14 19:40:25,292 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:40:25,292 - WARNING - Fold 2 has insufficient pairs to form a batch. Skipping.
2025-08-14 19:40:25,292 - INFO - --- Starting Fold 3/3 ---
2025-08-14 19:40:25,293 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:40:25,294 - WARNING - Fold 3 has insufficient pairs to form a batch. Skipping.
2025-08-14 19:40:25,294 - WARNING - No folds completed successfully to aggregate metrics.
[I 2025-08-14 19:40:25,296] Trial 4 finished with value: inf and parameters: {'learning_rate': 3.951935893041105e-05, 'batch_size': 64, 'num_epochs': 255, 'temperature': 0.14840881478747175, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.27223031783066487, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.024066549217987093, 'crop_size': 0.6841359002704148}. Best is trial 3 with value: -0.7083333333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 4 finished with value: inf and parameters: {'learning_rate': 3.951935893041105e-05, 'batch_size': 64, 'num_epochs': 255, 'temperature': 0.14840881478747175, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.27223031783066487, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.024066549217987093, 'crop_size': 0.6841359002704148}. Best is trial 3 with value: -0.7083333333333334.
2025-08-14 19:40:25,298 - INFO - Using device: cuda
2025-08-14 19:40:35,267 - INFO - --- Starting Fold 1/3 ---
2025-08-14 19:40:35,269 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:40:35,269 - INFO - Starting training for fold 1/3
2025-08-14 19:40:39,966 - INFO - Fold 1, Epoch 10: Val Acc: 0.52%
2025-08-14 19:40:42,827 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-14 19:40:46,321 - INFO - Fold 1, Epoch 30: Val Acc: 0.48%
2025-08-14 19:40:49,291 - INFO - Fold 1, Epoch 40: Val Acc: 0.52%
2025-08-14 19:40:52,442 - INFO - Fold 1, Epoch 50: Val Acc: 0.60%
2025-08-14 19:40:57,893 - INFO - Fold 1, Epoch 60: Val Acc: 0.54%
2025-08-14 19:41:01,243 - INFO - Fold 1, Epoch 70: Val Acc: 0.52%
2025-08-14 19:41:04,632 - INFO - Fold 1, Epoch 80: Val Acc: 0.48%
2025-08-14 19:41:08,024 - INFO - Fold 1, Epoch 90: Val Acc: 0.48%
2025-08-14 19:41:11,409 - INFO - Fold 1, Epoch 100: Val Acc: 0.48%
2025-08-14 19:41:14,761 - INFO - Fold 1, Epoch 110: Val Acc: 0.54%
2025-08-14 19:41:18,130 - INFO - Fold 1, Epoch 120: Val Acc: 0.60%
2025-08-14 19:41:20,773 - INFO - Fold 1, Epoch 130: Val Acc: 0.42%
2025-08-14 19:41:23,509 - INFO - Fold 1, Epoch 140: Val Acc: 0.56%
2025-08-14 19:41:26,241 - INFO - Fold 1, Epoch 150: Val Acc: 0.50%
2025-08-14 19:41:27,074 - INFO - Early stopping at epoch 153
2025-08-14 19:41:29,754 - INFO - --- Starting Fold 2/3 ---
2025-08-14 19:41:29,757 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:41:29,757 - INFO - Starting training for fold 2/3
2025-08-14 19:41:36,858 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-14 19:41:41,710 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-14 19:41:46,310 - INFO - Fold 2, Epoch 30: Val Acc: 0.50%
2025-08-14 19:41:49,805 - INFO - Fold 2, Epoch 40: Val Acc: 0.46%
2025-08-14 19:41:53,319 - INFO - Fold 2, Epoch 50: Val Acc: 0.46%
2025-08-14 19:41:56,693 - INFO - Fold 2, Epoch 60: Val Acc: 0.48%
2025-08-14 19:42:00,207 - INFO - Fold 2, Epoch 70: Val Acc: 0.62%
2025-08-14 19:42:04,870 - INFO - Fold 2, Epoch 80: Val Acc: 0.50%
2025-08-14 19:42:08,388 - INFO - Fold 2, Epoch 90: Val Acc: 0.56%
2025-08-14 19:42:11,832 - INFO - Fold 2, Epoch 100: Val Acc: 0.46%
2025-08-14 19:42:15,223 - INFO - Fold 2, Epoch 110: Val Acc: 0.52%
2025-08-14 19:42:18,245 - INFO - Fold 2, Epoch 120: Val Acc: 0.46%
2025-08-14 19:42:21,107 - INFO - Fold 2, Epoch 130: Val Acc: 0.60%
2025-08-14 19:42:24,253 - INFO - Fold 2, Epoch 140: Val Acc: 0.48%
2025-08-14 19:42:27,485 - INFO - Fold 2, Epoch 150: Val Acc: 0.52%
2025-08-14 19:42:30,865 - INFO - Fold 2, Epoch 160: Val Acc: 0.50%
2025-08-14 19:42:34,257 - INFO - Fold 2, Epoch 170: Val Acc: 0.44%
2025-08-14 19:42:37,299 - INFO - Early stopping at epoch 179
2025-08-14 19:42:40,028 - INFO - --- Starting Fold 3/3 ---
2025-08-14 19:42:40,032 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:42:40,032 - INFO - Starting training for fold 3/3
2025-08-14 19:42:46,029 - INFO - Fold 3, Epoch 10: Val Acc: 0.46%
2025-08-14 19:42:49,381 - INFO - Fold 3, Epoch 20: Val Acc: 0.50%
2025-08-14 19:42:54,105 - INFO - Fold 3, Epoch 30: Val Acc: 0.40%
2025-08-14 19:42:57,483 - INFO - Fold 3, Epoch 40: Val Acc: 0.46%
2025-08-14 19:43:00,863 - INFO - Fold 3, Epoch 50: Val Acc: 0.48%
2025-08-14 19:43:04,219 - INFO - Fold 3, Epoch 60: Val Acc: 0.48%
2025-08-14 19:43:07,585 - INFO - Fold 3, Epoch 70: Val Acc: 0.54%
2025-08-14 19:43:10,964 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-14 19:43:14,315 - INFO - Fold 3, Epoch 90: Val Acc: 0.56%
2025-08-14 19:43:17,675 - INFO - Fold 3, Epoch 100: Val Acc: 0.50%
2025-08-14 19:43:20,829 - INFO - Fold 3, Epoch 110: Val Acc: 0.56%
2025-08-14 19:43:23,323 - INFO - Fold 3, Epoch 120: Val Acc: 0.48%
2025-08-14 19:43:24,536 - INFO - Early stopping at epoch 125
2025-08-14 19:43:25,481 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.3940724664264255), 'std': np.float64(0.020389452318861197)}, 'train_accuracy': {'mean': np.float64(0.5972222222222222), 'std': np.float64(0.025983731852596812)}, 'val_loss': {'mean': np.float64(3.538710673650106), 'std': np.float64(0.05223555037392232)}, 'val_accuracy': {'mean': np.float64(0.6666666666666666), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(51.333333333333336), 'std': np.float64(22.050447211388303)}}
[I 2025-08-14 19:43:25,489] Trial 5 finished with value: -0.6666666666666666 and parameters: {'learning_rate': 4.347436686761643e-05, 'batch_size': 16, 'num_epochs': 288, 'temperature': 0.13529300342393122, 'embedding_dim': 512, 'hidden_dim': 256, 'dropout': 0.2761605074057637, 'num_layers': 4, 'num_heads': 4, 'noise_enabled': False, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'crop_size': 0.8423675532324683}. Best is trial 3 with value: -0.7083333333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 5 finished with value: -0.6666666666666666 and parameters: {'learning_rate': 4.347436686761643e-05, 'batch_size': 16, 'num_epochs': 288, 'temperature': 0.13529300342393122, 'embedding_dim': 512, 'hidden_dim': 256, 'dropout': 0.2761605074057637, 'num_layers': 4, 'num_heads': 4, 'noise_enabled': False, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'crop_size': 0.8423675532324683}. Best is trial 3 with value: -0.7083333333333334.
2025-08-14 19:43:25,490 - INFO - Using device: cuda
2025-08-14 19:43:35,080 - INFO - --- Starting Fold 1/3 ---
2025-08-14 19:43:35,082 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:43:35,082 - INFO - Starting training for fold 1/3
2025-08-14 19:43:38,526 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-14 19:43:39,847 - INFO - Fold 1, Epoch 20: Val Acc: 0.44%
2025-08-14 19:43:41,220 - INFO - Fold 1, Epoch 30: Val Acc: 0.44%
2025-08-14 19:43:42,492 - INFO - Fold 1, Epoch 40: Val Acc: 0.38%
2025-08-14 19:43:43,860 - INFO - Fold 1, Epoch 50: Val Acc: 0.50%
2025-08-14 19:43:45,214 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-14 19:43:46,585 - INFO - Fold 1, Epoch 70: Val Acc: 0.44%
2025-08-14 19:43:48,024 - INFO - Fold 1, Epoch 80: Val Acc: 0.50%
2025-08-14 19:43:49,453 - INFO - Fold 1, Epoch 90: Val Acc: 0.44%
2025-08-14 19:43:50,872 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-14 19:43:51,581 - INFO - Early stopping at epoch 105
2025-08-14 19:43:52,433 - INFO - --- Starting Fold 2/3 ---
2025-08-14 19:43:52,437 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:43:52,437 - INFO - Starting training for fold 2/3
2025-08-14 19:43:55,722 - INFO - Fold 2, Epoch 10: Val Acc: 0.41%
2025-08-14 19:43:57,153 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-14 19:43:58,569 - INFO - Fold 2, Epoch 30: Val Acc: 0.59%
2025-08-14 19:44:00,535 - INFO - Fold 2, Epoch 40: Val Acc: 0.47%
2025-08-14 19:44:02,542 - INFO - Fold 2, Epoch 50: Val Acc: 0.47%
2025-08-14 19:44:03,961 - INFO - Fold 2, Epoch 60: Val Acc: 0.56%
2025-08-14 19:44:05,373 - INFO - Fold 2, Epoch 70: Val Acc: 0.59%
2025-08-14 19:44:06,774 - INFO - Fold 2, Epoch 80: Val Acc: 0.38%
2025-08-14 19:44:08,200 - INFO - Fold 2, Epoch 90: Val Acc: 0.53%
2025-08-14 19:44:09,634 - INFO - Fold 2, Epoch 100: Val Acc: 0.47%
2025-08-14 19:44:11,088 - INFO - Fold 2, Epoch 110: Val Acc: 0.53%
2025-08-14 19:44:12,376 - INFO - Fold 2, Epoch 120: Val Acc: 0.47%
2025-08-14 19:44:13,534 - INFO - Fold 2, Epoch 130: Val Acc: 0.50%
2025-08-14 19:44:14,693 - INFO - Fold 2, Epoch 140: Val Acc: 0.41%
2025-08-14 19:44:15,390 - INFO - Early stopping at epoch 146
2025-08-14 19:44:16,152 - INFO - --- Starting Fold 3/3 ---
2025-08-14 19:44:16,155 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:44:16,156 - INFO - Starting training for fold 3/3
2025-08-14 19:44:19,371 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-14 19:44:21,202 - INFO - Fold 3, Epoch 20: Val Acc: 0.47%
2025-08-14 19:44:22,648 - INFO - Fold 3, Epoch 30: Val Acc: 0.44%
2025-08-14 19:44:24,095 - INFO - Fold 3, Epoch 40: Val Acc: 0.56%
2025-08-14 19:44:25,527 - INFO - Fold 3, Epoch 50: Val Acc: 0.50%
2025-08-14 19:44:26,959 - INFO - Fold 3, Epoch 60: Val Acc: 0.50%
2025-08-14 19:44:28,400 - INFO - Fold 3, Epoch 70: Val Acc: 0.50%
2025-08-14 19:44:29,851 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-14 19:44:31,288 - INFO - Fold 3, Epoch 90: Val Acc: 0.50%
2025-08-14 19:44:32,728 - INFO - Fold 3, Epoch 100: Val Acc: 0.47%
2025-08-14 19:44:34,182 - INFO - Fold 3, Epoch 110: Val Acc: 0.53%
2025-08-14 19:44:34,611 - INFO - Early stopping at epoch 113
2025-08-14 19:44:34,869 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.6141982608371315), 'std': np.float64(0.07340258888758928)}, 'train_accuracy': {'mean': np.float64(0.5659722222222223), 'std': np.float64(0.012991865926298411)}, 'val_loss': {'mean': np.float64(4.993311723073323), 'std': np.float64(0.22851230657152904)}, 'val_accuracy': {'mean': np.float64(0.6875), 'std': np.float64(0.05103103630798288)}, 'epoch': {'mean': np.float64(20.333333333333332), 'std': np.float64(17.745108872274887)}}
[I 2025-08-14 19:44:34,877] Trial 6 finished with value: -0.6875 and parameters: {'learning_rate': 0.00014653810390239495, 'batch_size': 32, 'num_epochs': 935, 'temperature': 0.06277248541586865, 'embedding_dim': 256, 'hidden_dim': 512, 'dropout': 0.1808464141096743, 'num_layers': 1, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': True, 'permutation_enabled': True, 'noise_level': 0.17254733239000994}. Best is trial 3 with value: -0.7083333333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 6 finished with value: -0.6875 and parameters: {'learning_rate': 0.00014653810390239495, 'batch_size': 32, 'num_epochs': 935, 'temperature': 0.06277248541586865, 'embedding_dim': 256, 'hidden_dim': 512, 'dropout': 0.1808464141096743, 'num_layers': 1, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': True, 'permutation_enabled': True, 'noise_level': 0.17254733239000994}. Best is trial 3 with value: -0.7083333333333334.
2025-08-14 19:44:34,880 - INFO - Using device: cuda
2025-08-14 19:44:44,678 - INFO - --- Starting Fold 1/3 ---
2025-08-14 19:44:44,680 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:44:44,680 - INFO - Starting training for fold 1/3
2025-08-14 19:44:48,179 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-14 19:44:50,738 - INFO - Fold 1, Epoch 20: Val Acc: 0.47%
2025-08-14 19:44:53,493 - INFO - Fold 1, Epoch 30: Val Acc: 0.38%
2025-08-14 19:44:55,117 - INFO - Fold 1, Epoch 40: Val Acc: 0.41%
2025-08-14 19:44:56,639 - INFO - Fold 1, Epoch 50: Val Acc: 0.41%
2025-08-14 19:44:58,254 - INFO - Fold 1, Epoch 60: Val Acc: 0.44%
2025-08-14 19:44:59,837 - INFO - Fold 1, Epoch 70: Val Acc: 0.38%
2025-08-14 19:45:01,419 - INFO - Fold 1, Epoch 80: Val Acc: 0.47%
2025-08-14 19:45:03,070 - INFO - Fold 1, Epoch 90: Val Acc: 0.53%
2025-08-14 19:45:05,692 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-14 19:45:07,866 - INFO - --- Starting Fold 2/3 ---
2025-08-14 19:45:07,870 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:45:07,871 - INFO - Starting training for fold 2/3
2025-08-14 19:45:11,038 - INFO - Fold 2, Epoch 10: Val Acc: 0.47%
2025-08-14 19:45:12,666 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-14 19:45:14,292 - INFO - Fold 2, Epoch 30: Val Acc: 0.41%
2025-08-14 19:45:16,746 - INFO - Fold 2, Epoch 40: Val Acc: 0.41%
2025-08-14 19:45:18,333 - INFO - Fold 2, Epoch 50: Val Acc: 0.47%
2025-08-14 19:45:19,907 - INFO - Fold 2, Epoch 60: Val Acc: 0.56%
2025-08-14 19:45:21,492 - INFO - Fold 2, Epoch 70: Val Acc: 0.50%
2025-08-14 19:45:23,072 - INFO - Fold 2, Epoch 80: Val Acc: 0.44%
2025-08-14 19:45:24,658 - INFO - Fold 2, Epoch 90: Val Acc: 0.53%
2025-08-14 19:45:26,237 - INFO - Fold 2, Epoch 100: Val Acc: 0.53%
2025-08-14 19:45:27,335 - INFO - --- Starting Fold 3/3 ---
2025-08-14 19:45:27,338 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:45:27,339 - INFO - Starting training for fold 3/3
2025-08-14 19:45:30,507 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-14 19:45:32,775 - INFO - Fold 3, Epoch 20: Val Acc: 0.66%
2025-08-14 19:45:34,347 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-14 19:45:35,936 - INFO - Fold 3, Epoch 40: Val Acc: 0.69%
2025-08-14 19:45:37,507 - INFO - Fold 3, Epoch 50: Val Acc: 0.44%
2025-08-14 19:45:39,016 - INFO - Fold 3, Epoch 60: Val Acc: 0.50%
2025-08-14 19:45:40,443 - INFO - Fold 3, Epoch 70: Val Acc: 0.47%
2025-08-14 19:45:42,015 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-14 19:45:43,584 - INFO - Fold 3, Epoch 90: Val Acc: 0.53%
2025-08-14 19:45:45,156 - INFO - Fold 3, Epoch 100: Val Acc: 0.66%
2025-08-14 19:45:46,248 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.2697248458862305), 'std': np.float64(0.030837287384702157)}, 'train_accuracy': {'mean': np.float64(0.5625), 'std': np.float64(0.030665836341416113)}, 'val_loss': {'mean': np.float64(4.384115695953369), 'std': np.float64(0.0310073381553191)}, 'val_accuracy': {'mean': np.float64(0.6770833333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(47.333333333333336), 'std': np.float64(37.52628708281999)}}
[I 2025-08-14 19:45:46,266] Trial 7 finished with value: -0.6770833333333334 and parameters: {'learning_rate': 2.1494274040322e-05, 'batch_size': 32, 'num_epochs': 104, 'temperature': 0.16037464736190887, 'embedding_dim': 128, 'hidden_dim': 128, 'dropout': 0.3657269847910106, 'num_layers': 2, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.15116355927051212}. Best is trial 3 with value: -0.7083333333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 7 finished with value: -0.6770833333333334 and parameters: {'learning_rate': 2.1494274040322e-05, 'batch_size': 32, 'num_epochs': 104, 'temperature': 0.16037464736190887, 'embedding_dim': 128, 'hidden_dim': 128, 'dropout': 0.3657269847910106, 'num_layers': 2, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.15116355927051212}. Best is trial 3 with value: -0.7083333333333334.
2025-08-14 19:45:46,267 - INFO - Using device: cuda
2025-08-14 19:45:56,417 - INFO - --- Starting Fold 1/3 ---
2025-08-14 19:45:56,419 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:45:56,419 - WARNING - Fold 1 has insufficient pairs to form a batch. Skipping.
2025-08-14 19:45:56,419 - INFO - --- Starting Fold 2/3 ---
2025-08-14 19:45:56,421 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:45:56,421 - WARNING - Fold 2 has insufficient pairs to form a batch. Skipping.
2025-08-14 19:45:56,421 - INFO - --- Starting Fold 3/3 ---
2025-08-14 19:45:56,422 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:45:56,422 - WARNING - Fold 3 has insufficient pairs to form a batch. Skipping.
2025-08-14 19:45:56,422 - WARNING - No folds completed successfully to aggregate metrics.
[I 2025-08-14 19:45:56,424] Trial 8 finished with value: inf and parameters: {'learning_rate': 1.5601525625755688e-05, 'batch_size': 64, 'num_epochs': 852, 'temperature': 0.3236642761246223, 'embedding_dim': 256, 'hidden_dim': 512, 'dropout': 0.35080262593078937, 'num_layers': 3, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.022025949185146852, 'crop_size': 0.6614795632965551}. Best is trial 3 with value: -0.7083333333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 8 finished with value: inf and parameters: {'learning_rate': 1.5601525625755688e-05, 'batch_size': 64, 'num_epochs': 852, 'temperature': 0.3236642761246223, 'embedding_dim': 256, 'hidden_dim': 512, 'dropout': 0.35080262593078937, 'num_layers': 3, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.022025949185146852, 'crop_size': 0.6614795632965551}. Best is trial 3 with value: -0.7083333333333334.
2025-08-14 19:45:56,426 - INFO - Using device: cuda
2025-08-14 19:46:06,287 - INFO - --- Starting Fold 1/3 ---
2025-08-14 19:46:06,288 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:46:06,288 - INFO - Starting training for fold 1/3
2025-08-14 19:46:15,193 - INFO - Fold 1, Epoch 10: Val Acc: 0.38%
2025-08-14 19:46:19,649 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-14 19:46:26,159 - INFO - Fold 1, Epoch 30: Val Acc: 0.66%
2025-08-14 19:46:35,140 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-14 19:46:37,403 - INFO - Fold 1, Epoch 50: Val Acc: 0.62%
2025-08-14 19:46:39,681 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-14 19:46:44,211 - INFO - Fold 1, Epoch 70: Val Acc: 0.78%
2025-08-14 19:46:46,482 - INFO - Fold 1, Epoch 80: Val Acc: 0.69%
2025-08-14 19:46:51,077 - INFO - Fold 1, Epoch 90: Val Acc: 0.78%
2025-08-14 19:46:53,406 - INFO - Fold 1, Epoch 100: Val Acc: 0.78%
2025-08-14 19:46:55,704 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-14 19:46:57,634 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-14 19:46:59,479 - INFO - Fold 1, Epoch 130: Val Acc: 0.66%
2025-08-14 19:47:01,327 - INFO - Fold 1, Epoch 140: Val Acc: 0.78%
2025-08-14 19:47:03,171 - INFO - Fold 1, Epoch 150: Val Acc: 0.72%
2025-08-14 19:47:05,017 - INFO - Fold 1, Epoch 160: Val Acc: 0.81%
2025-08-14 19:47:06,862 - INFO - Fold 1, Epoch 170: Val Acc: 0.69%
2025-08-14 19:47:08,707 - INFO - Fold 1, Epoch 180: Val Acc: 0.78%
2025-08-14 19:47:09,077 - INFO - Early stopping at epoch 182
2025-08-14 19:47:12,973 - INFO - --- Starting Fold 2/3 ---
2025-08-14 19:47:12,976 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:47:12,977 - INFO - Starting training for fold 2/3
2025-08-14 19:47:19,597 - INFO - Fold 2, Epoch 10: Val Acc: 0.59%
2025-08-14 19:47:23,322 - INFO - Fold 2, Epoch 20: Val Acc: 0.56%
2025-08-14 19:47:25,600 - INFO - Fold 2, Epoch 30: Val Acc: 0.66%
2025-08-14 19:47:32,095 - INFO - Fold 2, Epoch 40: Val Acc: 0.84%
2025-08-14 19:47:34,517 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-14 19:47:36,884 - INFO - Fold 2, Epoch 60: Val Acc: 0.78%
2025-08-14 19:47:39,228 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-14 19:47:42,997 - INFO - Fold 2, Epoch 80: Val Acc: 0.62%
2025-08-14 19:47:45,299 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-14 19:47:47,578 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-14 19:47:49,844 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-14 19:47:52,123 - INFO - Fold 2, Epoch 120: Val Acc: 0.59%
2025-08-14 19:47:54,402 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-14 19:47:56,679 - INFO - Fold 2, Epoch 140: Val Acc: 0.66%
2025-08-14 19:47:58,955 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-14 19:48:01,223 - INFO - Fold 2, Epoch 160: Val Acc: 0.81%
2025-08-14 19:48:03,508 - INFO - Fold 2, Epoch 170: Val Acc: 0.69%
2025-08-14 19:48:04,930 - INFO - Early stopping at epoch 177
2025-08-14 19:48:06,030 - INFO - --- Starting Fold 3/3 ---
2025-08-14 19:48:06,033 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:48:06,033 - INFO - Starting training for fold 3/3
2025-08-14 19:48:11,222 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-14 19:48:15,137 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-14 19:48:19,573 - INFO - Fold 3, Epoch 30: Val Acc: 0.69%
2025-08-14 19:48:23,432 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-14 19:48:27,157 - INFO - Fold 3, Epoch 50: Val Acc: 0.62%
2025-08-14 19:48:29,450 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-14 19:48:31,749 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-14 19:48:35,305 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-14 19:48:37,585 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-14 19:48:39,875 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-14 19:48:42,159 - INFO - Fold 3, Epoch 110: Val Acc: 0.81%
2025-08-14 19:48:44,426 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-14 19:48:46,692 - INFO - Fold 3, Epoch 130: Val Acc: 0.78%
2025-08-14 19:48:48,954 - INFO - Fold 3, Epoch 140: Val Acc: 0.75%
2025-08-14 19:48:51,172 - INFO - Fold 3, Epoch 150: Val Acc: 0.66%
2025-08-14 19:48:53,187 - INFO - Fold 3, Epoch 160: Val Acc: 0.81%
2025-08-14 19:48:55,215 - INFO - Fold 3, Epoch 170: Val Acc: 0.81%
2025-08-14 19:48:55,401 - INFO - Early stopping at epoch 171
2025-08-14 19:48:58,398 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9919493728213844), 'std': np.float64(0.050244580592274865)}, 'train_accuracy': {'mean': np.float64(0.7430555555555557), 'std': np.float64(0.009820927516479791)}, 'val_loss': {'mean': np.float64(4.218350410461426), 'std': np.float64(0.035041253451078294)}, 'val_accuracy': {'mean': np.float64(0.9270833333333334), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(75.66666666666667), 'std': np.float64(4.496912521077347)}}
[I 2025-08-14 19:48:58,412] Trial 9 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0005162280557072889, 'batch_size': 32, 'num_epochs': 983, 'temperature': 0.3589825261161098, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.439518236410986, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19170869921339778, 'crop_size': 0.5511402191808151}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 9 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0005162280557072889, 'batch_size': 32, 'num_epochs': 983, 'temperature': 0.3589825261161098, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.439518236410986, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19170869921339778, 'crop_size': 0.5511402191808151}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 19:48:58,470 - INFO - Using device: cuda
2025-08-14 19:49:09,022 - INFO - --- Starting Fold 1/3 ---
2025-08-14 19:49:09,024 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:49:09,024 - INFO - Starting training for fold 1/3
2025-08-14 19:49:13,777 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-14 19:49:15,779 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-14 19:49:23,316 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 19:49:25,622 - INFO - Fold 1, Epoch 40: Val Acc: 0.50%
2025-08-14 19:49:27,895 - INFO - Fold 1, Epoch 50: Val Acc: 0.50%
2025-08-14 19:49:29,753 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-14 19:49:31,634 - INFO - Fold 1, Epoch 70: Val Acc: 0.50%
2025-08-14 19:49:33,517 - INFO - Fold 1, Epoch 80: Val Acc: 0.50%
2025-08-14 19:49:35,479 - INFO - Fold 1, Epoch 90: Val Acc: 0.62%
2025-08-14 19:49:37,353 - INFO - Fold 1, Epoch 100: Val Acc: 0.50%
2025-08-14 19:49:39,210 - INFO - Fold 1, Epoch 110: Val Acc: 0.50%
2025-08-14 19:49:41,010 - INFO - Fold 1, Epoch 120: Val Acc: 0.50%
2025-08-14 19:49:42,411 - INFO - Early stopping at epoch 127
2025-08-14 19:49:46,308 - INFO - --- Starting Fold 2/3 ---
2025-08-14 19:49:46,310 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:49:46,311 - INFO - Starting training for fold 2/3
2025-08-14 19:49:52,106 - INFO - Fold 2, Epoch 10: Val Acc: 0.53%
2025-08-14 19:49:54,476 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-14 19:49:56,768 - INFO - Fold 2, Epoch 30: Val Acc: 0.50%
2025-08-14 19:50:00,482 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-14 19:50:02,793 - INFO - Fold 2, Epoch 50: Val Acc: 0.50%
2025-08-14 19:50:05,110 - INFO - Fold 2, Epoch 60: Val Acc: 0.50%
2025-08-14 19:50:07,425 - INFO - Fold 2, Epoch 70: Val Acc: 0.50%
2025-08-14 19:50:09,745 - INFO - Fold 2, Epoch 80: Val Acc: 0.50%
2025-08-14 19:50:13,671 - INFO - Fold 2, Epoch 90: Val Acc: 0.50%
2025-08-14 19:50:17,617 - INFO - Fold 2, Epoch 100: Val Acc: 0.50%
2025-08-14 19:50:19,897 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-14 19:50:22,276 - INFO - Fold 2, Epoch 120: Val Acc: 0.50%
2025-08-14 19:50:24,654 - INFO - Fold 2, Epoch 130: Val Acc: 0.50%
2025-08-14 19:50:27,060 - INFO - Fold 2, Epoch 140: Val Acc: 0.50%
2025-08-14 19:50:29,178 - INFO - Fold 2, Epoch 150: Val Acc: 0.50%
2025-08-14 19:50:31,486 - INFO - Fold 2, Epoch 160: Val Acc: 0.50%
2025-08-14 19:50:33,808 - INFO - Fold 2, Epoch 170: Val Acc: 0.50%
2025-08-14 19:50:36,117 - INFO - Fold 2, Epoch 180: Val Acc: 0.50%
2025-08-14 19:50:38,415 - INFO - Fold 2, Epoch 190: Val Acc: 0.50%
2025-08-14 19:50:38,803 - INFO - Early stopping at epoch 192
2025-08-14 19:50:42,120 - INFO - --- Starting Fold 3/3 ---
2025-08-14 19:50:42,124 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:50:42,124 - INFO - Starting training for fold 3/3
2025-08-14 19:50:46,053 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-14 19:50:48,086 - INFO - Fold 3, Epoch 20: Val Acc: 0.50%
2025-08-14 19:50:50,021 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-14 19:50:52,183 - INFO - Fold 3, Epoch 40: Val Acc: 0.50%
2025-08-14 19:50:54,487 - INFO - Fold 3, Epoch 50: Val Acc: 0.50%
2025-08-14 19:50:56,782 - INFO - Fold 3, Epoch 60: Val Acc: 0.50%
2025-08-14 19:50:59,049 - INFO - Fold 3, Epoch 70: Val Acc: 0.50%
2025-08-14 19:51:03,046 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-14 19:51:06,868 - INFO - Fold 3, Epoch 90: Val Acc: 0.50%
2025-08-14 19:51:09,171 - INFO - Fold 3, Epoch 100: Val Acc: 0.50%
2025-08-14 19:51:11,334 - INFO - Fold 3, Epoch 110: Val Acc: 0.50%
2025-08-14 19:51:13,182 - INFO - Fold 3, Epoch 120: Val Acc: 0.50%
2025-08-14 19:51:15,095 - INFO - Fold 3, Epoch 130: Val Acc: 0.50%
2025-08-14 19:51:17,289 - INFO - Fold 3, Epoch 140: Val Acc: 0.50%
2025-08-14 19:51:19,592 - INFO - Fold 3, Epoch 150: Val Acc: 0.50%
2025-08-14 19:51:21,892 - INFO - Fold 3, Epoch 160: Val Acc: 0.50%
2025-08-14 19:51:24,195 - INFO - Fold 3, Epoch 170: Val Acc: 0.50%
2025-08-14 19:51:26,498 - INFO - Fold 3, Epoch 180: Val Acc: 0.50%
2025-08-14 19:51:28,119 - INFO - Early stopping at epoch 187
2025-08-14 19:51:29,416 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9052133560180664), 'std': np.float64(0.04819048019476778)}, 'train_accuracy': {'mean': np.float64(0.8611111111111112), 'std': np.float64(0.04195502074164788)}, 'val_loss': {'mean': np.float64(4.139924208323161), 'std': np.float64(0.08149049331835052)}, 'val_accuracy': {'mean': np.float64(0.7604166666666666), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(67.66666666666667), 'std': np.float64(29.53340857778225)}}
[I 2025-08-14 19:51:29,428] Trial 10 finished with value: -0.7604166666666666 and parameters: {'learning_rate': 0.0002944224841545371, 'batch_size': 32, 'num_epochs': 714, 'temperature': 0.48854593289075116, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.48952393834474456, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': False, 'flip_enabled': True, 'permutation_enabled': False}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 10 finished with value: -0.7604166666666666 and parameters: {'learning_rate': 0.0002944224841545371, 'batch_size': 32, 'num_epochs': 714, 'temperature': 0.48854593289075116, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.48952393834474456, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': False, 'flip_enabled': True, 'permutation_enabled': False}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 19:51:29,449 - INFO - Using device: cuda
2025-08-14 19:51:39,491 - INFO - --- Starting Fold 1/3 ---
2025-08-14 19:51:39,493 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:51:39,493 - INFO - Starting training for fold 1/3
2025-08-14 19:51:44,633 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-14 19:51:46,971 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-14 19:51:49,281 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 19:51:51,597 - INFO - Fold 1, Epoch 40: Val Acc: 0.50%
2025-08-14 19:51:53,910 - INFO - Fold 1, Epoch 50: Val Acc: 0.53%
2025-08-14 19:51:56,212 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-14 19:51:58,523 - INFO - Fold 1, Epoch 70: Val Acc: 0.50%
2025-08-14 19:52:00,833 - INFO - Fold 1, Epoch 80: Val Acc: 0.50%
2025-08-14 19:52:03,149 - INFO - Fold 1, Epoch 90: Val Acc: 0.50%
2025-08-14 19:52:08,115 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-14 19:52:10,423 - INFO - Fold 1, Epoch 110: Val Acc: 0.50%
2025-08-14 19:52:12,742 - INFO - Fold 1, Epoch 120: Val Acc: 0.50%
2025-08-14 19:52:14,797 - INFO - Fold 1, Epoch 130: Val Acc: 0.50%
2025-08-14 19:52:16,718 - INFO - Fold 1, Epoch 140: Val Acc: 0.50%
2025-08-14 19:52:21,461 - INFO - Fold 1, Epoch 150: Val Acc: 0.50%
2025-08-14 19:52:23,481 - INFO - Fold 1, Epoch 160: Val Acc: 0.50%
2025-08-14 19:52:25,727 - INFO - Fold 1, Epoch 170: Val Acc: 0.50%
2025-08-14 19:52:28,036 - INFO - Fold 1, Epoch 180: Val Acc: 0.50%
2025-08-14 19:52:30,345 - INFO - Fold 1, Epoch 190: Val Acc: 0.50%
2025-08-14 19:52:32,508 - INFO - Fold 1, Epoch 200: Val Acc: 0.50%
2025-08-14 19:52:34,453 - INFO - Fold 1, Epoch 210: Val Acc: 0.50%
2025-08-14 19:52:36,647 - INFO - Fold 1, Epoch 220: Val Acc: 0.50%
2025-08-14 19:52:41,590 - INFO - Fold 1, Epoch 230: Val Acc: 0.53%
2025-08-14 19:52:43,687 - INFO - Fold 1, Epoch 240: Val Acc: 0.69%
2025-08-14 19:52:45,990 - INFO - Fold 1, Epoch 250: Val Acc: 0.50%
2025-08-14 19:52:48,294 - INFO - Fold 1, Epoch 260: Val Acc: 0.50%
2025-08-14 19:52:50,603 - INFO - Fold 1, Epoch 270: Val Acc: 0.53%
2025-08-14 19:52:52,905 - INFO - Fold 1, Epoch 280: Val Acc: 0.50%
2025-08-14 19:52:55,253 - INFO - Fold 1, Epoch 290: Val Acc: 0.50%
2025-08-14 19:52:57,296 - INFO - Fold 1, Epoch 300: Val Acc: 0.50%
2025-08-14 19:52:59,363 - INFO - Fold 1, Epoch 310: Val Acc: 0.50%
2025-08-14 19:53:01,345 - INFO - Fold 1, Epoch 320: Val Acc: 0.53%
2025-08-14 19:53:02,273 - INFO - Early stopping at epoch 325
2025-08-14 19:53:05,951 - INFO - --- Starting Fold 2/3 ---
2025-08-14 19:53:05,953 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:53:05,953 - INFO - Starting training for fold 2/3
2025-08-14 19:53:11,592 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-14 19:53:13,912 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-14 19:53:16,239 - INFO - Fold 2, Epoch 30: Val Acc: 0.50%
2025-08-14 19:53:20,148 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-14 19:53:22,476 - INFO - Fold 2, Epoch 50: Val Acc: 0.50%
2025-08-14 19:53:24,815 - INFO - Fold 2, Epoch 60: Val Acc: 0.50%
2025-08-14 19:53:27,202 - INFO - Fold 2, Epoch 70: Val Acc: 0.50%
2025-08-14 19:53:29,603 - INFO - Fold 2, Epoch 80: Val Acc: 0.50%
2025-08-14 19:53:33,677 - INFO - Fold 2, Epoch 90: Val Acc: 0.50%
2025-08-14 19:53:35,814 - INFO - Fold 2, Epoch 100: Val Acc: 0.50%
2025-08-14 19:53:37,842 - INFO - Fold 2, Epoch 110: Val Acc: 0.50%
2025-08-14 19:53:40,103 - INFO - Fold 2, Epoch 120: Val Acc: 0.50%
2025-08-14 19:53:42,490 - INFO - Fold 2, Epoch 130: Val Acc: 0.50%
2025-08-14 19:53:44,821 - INFO - Fold 2, Epoch 140: Val Acc: 0.50%
2025-08-14 19:53:47,126 - INFO - Fold 2, Epoch 150: Val Acc: 0.50%
2025-08-14 19:53:49,398 - INFO - Fold 2, Epoch 160: Val Acc: 0.50%
2025-08-14 19:53:53,415 - INFO - Fold 2, Epoch 170: Val Acc: 0.75%
2025-08-14 19:53:55,721 - INFO - Fold 2, Epoch 180: Val Acc: 0.50%
2025-08-14 19:53:58,027 - INFO - Fold 2, Epoch 190: Val Acc: 0.50%
2025-08-14 19:54:00,349 - INFO - Fold 2, Epoch 200: Val Acc: 0.50%
2025-08-14 19:54:02,664 - INFO - Fold 2, Epoch 210: Val Acc: 0.50%
2025-08-14 19:54:04,980 - INFO - Fold 2, Epoch 220: Val Acc: 0.50%
2025-08-14 19:54:07,290 - INFO - Fold 2, Epoch 230: Val Acc: 0.59%
2025-08-14 19:54:09,612 - INFO - Fold 2, Epoch 240: Val Acc: 0.50%
2025-08-14 19:54:13,596 - INFO - Fold 2, Epoch 250: Val Acc: 0.50%
2025-08-14 19:54:15,920 - INFO - Fold 2, Epoch 260: Val Acc: 0.50%
2025-08-14 19:54:18,239 - INFO - Fold 2, Epoch 270: Val Acc: 0.50%
2025-08-14 19:54:22,114 - INFO - Fold 2, Epoch 280: Val Acc: 0.50%
2025-08-14 19:54:26,040 - INFO - Fold 2, Epoch 290: Val Acc: 0.50%
2025-08-14 19:54:28,355 - INFO - Fold 2, Epoch 300: Val Acc: 0.50%
2025-08-14 19:54:30,660 - INFO - Fold 2, Epoch 310: Val Acc: 0.56%
2025-08-14 19:54:32,968 - INFO - Fold 2, Epoch 320: Val Acc: 0.50%
2025-08-14 19:54:35,280 - INFO - Fold 2, Epoch 330: Val Acc: 0.84%
2025-08-14 19:54:37,596 - INFO - Fold 2, Epoch 340: Val Acc: 0.56%
2025-08-14 19:54:39,894 - INFO - Fold 2, Epoch 350: Val Acc: 0.69%
2025-08-14 19:54:42,160 - INFO - Fold 2, Epoch 360: Val Acc: 0.50%
2025-08-14 19:54:44,260 - INFO - Fold 2, Epoch 370: Val Acc: 0.50%
2025-08-14 19:54:46,251 - INFO - Fold 2, Epoch 380: Val Acc: 0.50%
2025-08-14 19:54:47,110 - INFO - Early stopping at epoch 385
2025-08-14 19:54:50,280 - INFO - --- Starting Fold 3/3 ---
2025-08-14 19:54:50,283 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:54:50,283 - INFO - Starting training for fold 3/3
2025-08-14 19:54:54,552 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-14 19:54:56,870 - INFO - Fold 3, Epoch 20: Val Acc: 0.50%
2025-08-14 19:54:59,107 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-14 19:55:01,332 - INFO - Fold 3, Epoch 40: Val Acc: 0.50%
2025-08-14 19:55:03,716 - INFO - Fold 3, Epoch 50: Val Acc: 0.50%
2025-08-14 19:55:06,116 - INFO - Fold 3, Epoch 60: Val Acc: 0.50%
2025-08-14 19:55:08,384 - INFO - Fold 3, Epoch 70: Val Acc: 0.50%
2025-08-14 19:55:12,442 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-14 19:55:14,821 - INFO - Fold 3, Epoch 90: Val Acc: 0.50%
2025-08-14 19:55:17,127 - INFO - Fold 3, Epoch 100: Val Acc: 0.50%
2025-08-14 19:55:19,430 - INFO - Fold 3, Epoch 110: Val Acc: 0.50%
2025-08-14 19:55:21,718 - INFO - Fold 3, Epoch 120: Val Acc: 0.50%
2025-08-14 19:55:25,427 - INFO - Fold 3, Epoch 130: Val Acc: 0.50%
2025-08-14 19:55:27,750 - INFO - Fold 3, Epoch 140: Val Acc: 0.50%
2025-08-14 19:55:29,972 - INFO - Fold 3, Epoch 150: Val Acc: 0.50%
2025-08-14 19:55:31,697 - INFO - Fold 3, Epoch 160: Val Acc: 0.59%
2025-08-14 19:55:35,232 - INFO - Fold 3, Epoch 170: Val Acc: 0.50%
2025-08-14 19:55:37,533 - INFO - Fold 3, Epoch 180: Val Acc: 0.53%
2025-08-14 19:55:39,842 - INFO - Fold 3, Epoch 190: Val Acc: 0.50%
2025-08-14 19:55:42,140 - INFO - Fold 3, Epoch 200: Val Acc: 0.50%
2025-08-14 19:55:44,455 - INFO - Fold 3, Epoch 210: Val Acc: 0.50%
2025-08-14 19:55:46,586 - INFO - Fold 3, Epoch 220: Val Acc: 0.50%
2025-08-14 19:55:48,643 - INFO - Fold 3, Epoch 230: Val Acc: 0.50%
2025-08-14 19:55:50,962 - INFO - Fold 3, Epoch 240: Val Acc: 0.50%
2025-08-14 19:55:53,310 - INFO - Fold 3, Epoch 250: Val Acc: 0.53%
2025-08-14 19:55:55,668 - INFO - Fold 3, Epoch 260: Val Acc: 0.50%
2025-08-14 19:55:57,072 - INFO - Early stopping at epoch 266
2025-08-14 19:55:58,368 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.6840292612711587), 'std': np.float64(0.07126029856579935)}, 'train_accuracy': {'mean': np.float64(0.9444444444444445), 'std': np.float64(0.02986918495500915)}, 'val_loss': {'mean': np.float64(4.160391648610433), 'std': np.float64(0.03247894799975877)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.0736569563735987)}, 'epoch': {'mean': np.float64(224.33333333333334), 'std': np.float64(48.58211833815218)}}
[I 2025-08-14 19:55:58,377] Trial 11 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.00021167470020458222, 'batch_size': 32, 'num_epochs': 740, 'temperature': 0.4254755618032718, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4948706658930031, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': False, 'flip_enabled': True, 'permutation_enabled': False}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 11 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.00021167470020458222, 'batch_size': 32, 'num_epochs': 740, 'temperature': 0.4254755618032718, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4948706658930031, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': False, 'flip_enabled': True, 'permutation_enabled': False}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 19:55:58,398 - INFO - Using device: cuda
2025-08-14 19:56:08,267 - INFO - --- Starting Fold 1/3 ---
2025-08-14 19:56:08,269 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:56:08,269 - INFO - Starting training for fold 1/3
2025-08-14 19:56:12,420 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-14 19:56:14,150 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-14 19:56:16,320 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 19:56:18,474 - INFO - Fold 1, Epoch 40: Val Acc: 0.50%
2025-08-14 19:56:20,634 - INFO - Fold 1, Epoch 50: Val Acc: 0.50%
2025-08-14 19:56:22,800 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-14 19:56:24,966 - INFO - Fold 1, Epoch 70: Val Acc: 0.50%
2025-08-14 19:56:29,268 - INFO - Fold 1, Epoch 80: Val Acc: 0.50%
2025-08-14 19:56:31,361 - INFO - Fold 1, Epoch 90: Val Acc: 0.50%
2025-08-14 19:56:33,432 - INFO - Fold 1, Epoch 100: Val Acc: 0.50%
2025-08-14 19:56:35,530 - INFO - Fold 1, Epoch 110: Val Acc: 0.53%
2025-08-14 19:56:37,615 - INFO - Fold 1, Epoch 120: Val Acc: 0.50%
2025-08-14 19:56:39,687 - INFO - Fold 1, Epoch 130: Val Acc: 0.56%
2025-08-14 19:56:43,840 - INFO - Fold 1, Epoch 140: Val Acc: 0.53%
2025-08-14 19:56:45,394 - INFO - Fold 1, Epoch 150: Val Acc: 0.50%
2025-08-14 19:56:47,278 - INFO - Fold 1, Epoch 160: Val Acc: 0.50%
2025-08-14 19:56:49,345 - INFO - Fold 1, Epoch 170: Val Acc: 0.53%
2025-08-14 19:56:51,416 - INFO - Fold 1, Epoch 180: Val Acc: 0.50%
2025-08-14 19:56:55,786 - INFO - Fold 1, Epoch 190: Val Acc: 0.50%
2025-08-14 19:56:57,851 - INFO - Fold 1, Epoch 200: Val Acc: 0.50%
2025-08-14 19:56:59,909 - INFO - Fold 1, Epoch 210: Val Acc: 0.50%
2025-08-14 19:57:01,992 - INFO - Fold 1, Epoch 220: Val Acc: 0.62%
2025-08-14 19:57:04,084 - INFO - Fold 1, Epoch 230: Val Acc: 0.56%
2025-08-14 19:57:06,177 - INFO - Fold 1, Epoch 240: Val Acc: 0.56%
2025-08-14 19:57:08,260 - INFO - Fold 1, Epoch 250: Val Acc: 0.50%
2025-08-14 19:57:10,348 - INFO - Fold 1, Epoch 260: Val Acc: 0.53%
2025-08-14 19:57:12,433 - INFO - Fold 1, Epoch 270: Val Acc: 0.50%
2025-08-14 19:57:14,524 - INFO - Fold 1, Epoch 280: Val Acc: 0.50%
2025-08-14 19:57:14,941 - INFO - Early stopping at epoch 282
2025-08-14 19:57:18,607 - INFO - --- Starting Fold 2/3 ---
2025-08-14 19:57:18,609 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:57:18,610 - INFO - Starting training for fold 2/3
2025-08-14 19:57:23,540 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-14 19:57:25,638 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-14 19:57:27,729 - INFO - Fold 2, Epoch 30: Val Acc: 0.50%
2025-08-14 19:57:29,831 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-14 19:57:31,914 - INFO - Fold 2, Epoch 50: Val Acc: 0.50%
2025-08-14 19:57:35,457 - INFO - Fold 2, Epoch 60: Val Acc: 0.50%
2025-08-14 19:57:37,552 - INFO - Fold 2, Epoch 70: Val Acc: 0.50%
2025-08-14 19:57:41,102 - INFO - Fold 2, Epoch 80: Val Acc: 0.50%
2025-08-14 19:57:43,195 - INFO - Fold 2, Epoch 90: Val Acc: 0.50%
2025-08-14 19:57:45,336 - INFO - Fold 2, Epoch 100: Val Acc: 0.50%
2025-08-14 19:57:47,508 - INFO - Fold 2, Epoch 110: Val Acc: 0.53%
2025-08-14 19:57:49,672 - INFO - Fold 2, Epoch 120: Val Acc: 0.50%
2025-08-14 19:57:51,842 - INFO - Fold 2, Epoch 130: Val Acc: 0.50%
2025-08-14 19:57:54,013 - INFO - Fold 2, Epoch 140: Val Acc: 0.50%
2025-08-14 19:57:56,186 - INFO - Fold 2, Epoch 150: Val Acc: 0.50%
2025-08-14 19:58:01,147 - INFO - Fold 2, Epoch 160: Val Acc: 0.69%
2025-08-14 19:58:03,398 - INFO - Fold 2, Epoch 170: Val Acc: 0.50%
2025-08-14 19:58:06,676 - INFO - Fold 2, Epoch 180: Val Acc: 0.50%
2025-08-14 19:58:08,695 - INFO - Fold 2, Epoch 190: Val Acc: 0.50%
2025-08-14 19:58:10,532 - INFO - Fold 2, Epoch 200: Val Acc: 0.50%
2025-08-14 19:58:12,604 - INFO - Fold 2, Epoch 210: Val Acc: 0.50%
2025-08-14 19:58:14,660 - INFO - Fold 2, Epoch 220: Val Acc: 0.50%
2025-08-14 19:58:16,737 - INFO - Fold 2, Epoch 230: Val Acc: 0.56%
2025-08-14 19:58:18,831 - INFO - Fold 2, Epoch 240: Val Acc: 0.53%
2025-08-14 19:58:20,922 - INFO - Fold 2, Epoch 250: Val Acc: 0.50%
2025-08-14 19:58:23,006 - INFO - Fold 2, Epoch 260: Val Acc: 0.50%
2025-08-14 19:58:24,800 - INFO - Fold 2, Epoch 270: Val Acc: 0.50%
2025-08-14 19:58:25,142 - INFO - Early stopping at epoch 272
2025-08-14 19:58:28,406 - INFO - --- Starting Fold 3/3 ---
2025-08-14 19:58:28,410 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:58:28,410 - INFO - Starting training for fold 3/3
2025-08-14 19:58:31,950 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-14 19:58:33,780 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-14 19:58:35,929 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-14 19:58:38,113 - INFO - Fold 3, Epoch 40: Val Acc: 0.53%
2025-08-14 19:58:40,332 - INFO - Fold 3, Epoch 50: Val Acc: 0.50%
2025-08-14 19:58:42,354 - INFO - Fold 3, Epoch 60: Val Acc: 0.53%
2025-08-14 19:58:44,540 - INFO - Fold 3, Epoch 70: Val Acc: 0.50%
2025-08-14 19:58:46,776 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-14 19:58:49,013 - INFO - Fold 3, Epoch 90: Val Acc: 0.50%
2025-08-14 19:58:51,243 - INFO - Fold 3, Epoch 100: Val Acc: 0.50%
2025-08-14 19:58:51,467 - INFO - Early stopping at epoch 101
2025-08-14 19:58:52,498 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.798726797103882), 'std': np.float64(0.23170977802956433)}, 'train_accuracy': {'mean': np.float64(0.8298611111111112), 'std': np.float64(0.1671722655168156)}, 'val_loss': {'mean': np.float64(4.361046473185222), 'std': np.float64(0.39893573260004506)}, 'val_accuracy': {'mean': np.float64(0.75), 'std': np.float64(0.04419417382415922)}, 'epoch': {'mean': np.float64(117.33333333333333), 'std': np.float64(83.06757623900087)}}
[I 2025-08-14 19:58:52,506] Trial 12 finished with value: -0.75 and parameters: {'learning_rate': 0.0002875795230254496, 'batch_size': 32, 'num_epochs': 719, 'temperature': 0.3948521363082242, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4787928951225203, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': False, 'flip_enabled': True, 'permutation_enabled': False}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 12 finished with value: -0.75 and parameters: {'learning_rate': 0.0002875795230254496, 'batch_size': 32, 'num_epochs': 719, 'temperature': 0.3948521363082242, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4787928951225203, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': False, 'flip_enabled': True, 'permutation_enabled': False}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 19:58:52,531 - INFO - Using device: cuda
2025-08-14 19:59:03,658 - INFO - --- Starting Fold 1/3 ---
2025-08-14 19:59:03,660 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 19:59:03,660 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 19:59:08,851 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-14 19:59:11,116 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-14 19:59:13,439 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 19:59:21,024 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-14 19:59:23,335 - INFO - Fold 1, Epoch 50: Val Acc: 0.50%
2025-08-14 19:59:25,644 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-14 19:59:27,928 - INFO - Fold 1, Epoch 70: Val Acc: 0.50%
2025-08-14 19:59:32,881 - INFO - Fold 1, Epoch 80: Val Acc: 0.53%
2025-08-14 19:59:35,203 - INFO - Fold 1, Epoch 90: Val Acc: 0.50%
2025-08-14 19:59:37,519 - INFO - Fold 1, Epoch 100: Val Acc: 0.50%
2025-08-14 19:59:39,831 - INFO - Fold 1, Epoch 110: Val Acc: 0.56%
2025-08-14 19:59:42,139 - INFO - Fold 1, Epoch 120: Val Acc: 0.50%
2025-08-14 19:59:44,455 - INFO - Fold 1, Epoch 130: Val Acc: 0.50%
2025-08-14 19:59:46,771 - INFO - Fold 1, Epoch 140: Val Acc: 0.56%
2025-08-14 19:59:49,034 - INFO - Fold 1, Epoch 150: Val Acc: 0.50%
2025-08-14 19:59:51,286 - INFO - Fold 1, Epoch 160: Val Acc: 0.47%
2025-08-14 19:59:56,262 - INFO - Fold 1, Epoch 170: Val Acc: 0.50%
2025-08-14 19:59:58,585 - INFO - Fold 1, Epoch 180: Val Acc: 0.50%
2025-08-14 20:00:00,924 - INFO - Fold 1, Epoch 190: Val Acc: 0.56%
2025-08-14 20:00:03,254 - INFO - Fold 1, Epoch 200: Val Acc: 0.50%
2025-08-14 20:00:05,579 - INFO - Fold 1, Epoch 210: Val Acc: 0.53%
2025-08-14 20:00:07,906 - INFO - Fold 1, Epoch 220: Val Acc: 0.50%
2025-08-14 20:00:10,228 - INFO - Fold 1, Epoch 230: Val Acc: 0.50%
2025-08-14 20:00:12,555 - INFO - Fold 1, Epoch 240: Val Acc: 0.50%
2025-08-14 20:00:14,871 - INFO - Fold 1, Epoch 250: Val Acc: 0.69%
2025-08-14 20:00:19,792 - INFO - Fold 1, Epoch 260: Val Acc: 0.53%
2025-08-14 20:00:22,120 - INFO - Fold 1, Epoch 270: Val Acc: 0.53%
2025-08-14 20:00:24,443 - INFO - Fold 1, Epoch 280: Val Acc: 0.53%
2025-08-14 20:00:26,772 - INFO - Fold 1, Epoch 290: Val Acc: 0.53%
2025-08-14 20:00:29,098 - INFO - Fold 1, Epoch 300: Val Acc: 0.50%
2025-08-14 20:00:30,982 - INFO - Fold 1, Epoch 310: Val Acc: 0.50%
2025-08-14 20:00:32,701 - INFO - Fold 1, Epoch 320: Val Acc: 0.59%
2025-08-14 20:00:34,553 - INFO - Fold 1, Epoch 330: Val Acc: 0.66%
2025-08-14 20:00:36,330 - INFO - Fold 1, Epoch 340: Val Acc: 0.50%
2025-08-14 20:00:38,183 - INFO - Fold 1, Epoch 350: Val Acc: 0.53%
2025-08-14 20:00:38,542 - INFO - Early stopping at epoch 352
2025-08-14 20:00:42,469 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:00:42,485 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:00:42,485 - INFO - Starting training for fold 2/3
2025-08-14 20:00:46,431 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-14 20:00:50,271 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-14 20:00:52,669 - INFO - Fold 2, Epoch 30: Val Acc: 0.50%
2025-08-14 20:00:55,059 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-14 20:00:59,111 - INFO - Fold 2, Epoch 50: Val Acc: 0.50%
2025-08-14 20:01:01,459 - INFO - Fold 2, Epoch 60: Val Acc: 0.50%
2025-08-14 20:01:03,786 - INFO - Fold 2, Epoch 70: Val Acc: 0.50%
2025-08-14 20:01:06,104 - INFO - Fold 2, Epoch 80: Val Acc: 0.50%
2025-08-14 20:01:08,421 - INFO - Fold 2, Epoch 90: Val Acc: 0.50%
2025-08-14 20:01:12,435 - INFO - Fold 2, Epoch 100: Val Acc: 0.50%
2025-08-14 20:01:16,384 - INFO - Fold 2, Epoch 110: Val Acc: 0.50%
2025-08-14 20:01:18,374 - INFO - Fold 2, Epoch 120: Val Acc: 0.50%
2025-08-14 20:01:20,192 - INFO - Fold 2, Epoch 130: Val Acc: 0.50%
2025-08-14 20:01:22,476 - INFO - Fold 2, Epoch 140: Val Acc: 0.50%
2025-08-14 20:01:24,854 - INFO - Fold 2, Epoch 150: Val Acc: 0.50%
2025-08-14 20:01:29,009 - INFO - Fold 2, Epoch 160: Val Acc: 0.50%
2025-08-14 20:01:31,395 - INFO - Fold 2, Epoch 170: Val Acc: 0.50%
2025-08-14 20:01:33,778 - INFO - Fold 2, Epoch 180: Val Acc: 0.81%
2025-08-14 20:01:36,167 - INFO - Fold 2, Epoch 190: Val Acc: 0.59%
2025-08-14 20:01:38,567 - INFO - Fold 2, Epoch 200: Val Acc: 0.50%
2025-08-14 20:01:40,970 - INFO - Fold 2, Epoch 210: Val Acc: 0.50%
2025-08-14 20:01:43,094 - INFO - Fold 2, Epoch 220: Val Acc: 0.50%
2025-08-14 20:01:45,094 - INFO - Fold 2, Epoch 230: Val Acc: 0.59%
2025-08-14 20:01:47,109 - INFO - Fold 2, Epoch 240: Val Acc: 0.50%
2025-08-14 20:01:49,326 - INFO - Fold 2, Epoch 250: Val Acc: 0.53%
2025-08-14 20:01:50,499 - INFO - Early stopping at epoch 255
2025-08-14 20:01:53,706 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:01:53,709 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:01:53,710 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:02:01,061 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-14 20:02:03,373 - INFO - Fold 3, Epoch 20: Val Acc: 0.50%
2025-08-14 20:02:05,714 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-14 20:02:09,626 - INFO - Fold 3, Epoch 40: Val Acc: 0.50%
2025-08-14 20:02:11,943 - INFO - Fold 3, Epoch 50: Val Acc: 0.53%
2025-08-14 20:02:15,959 - INFO - Fold 3, Epoch 60: Val Acc: 0.50%
2025-08-14 20:02:18,334 - INFO - Fold 3, Epoch 70: Val Acc: 0.50%
2025-08-14 20:02:22,362 - INFO - Fold 3, Epoch 80: Val Acc: 0.56%
2025-08-14 20:02:24,748 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-14 20:02:27,135 - INFO - Fold 3, Epoch 100: Val Acc: 0.53%
2025-08-14 20:02:29,522 - INFO - Fold 3, Epoch 110: Val Acc: 0.50%
2025-08-14 20:02:31,878 - INFO - Fold 3, Epoch 120: Val Acc: 0.50%
2025-08-14 20:02:34,260 - INFO - Fold 3, Epoch 130: Val Acc: 0.50%
2025-08-14 20:02:36,469 - INFO - Fold 3, Epoch 140: Val Acc: 0.53%
2025-08-14 20:02:38,831 - INFO - Fold 3, Epoch 150: Val Acc: 0.50%
2025-08-14 20:02:41,194 - INFO - Fold 3, Epoch 160: Val Acc: 0.53%
2025-08-14 20:02:43,567 - INFO - Fold 3, Epoch 170: Val Acc: 0.50%
2025-08-14 20:02:47,564 - INFO - Fold 3, Epoch 180: Val Acc: 0.50%
2025-08-14 20:02:49,892 - INFO - Fold 3, Epoch 190: Val Acc: 0.50%
2025-08-14 20:02:53,904 - INFO - Fold 3, Epoch 200: Val Acc: 0.50%
2025-08-14 20:02:56,129 - INFO - Fold 3, Epoch 210: Val Acc: 0.50%
2025-08-14 20:02:57,969 - INFO - Fold 3, Epoch 220: Val Acc: 0.53%
2025-08-14 20:02:59,861 - INFO - Fold 3, Epoch 230: Val Acc: 0.53%
2025-08-14 20:03:01,734 - INFO - Fold 3, Epoch 240: Val Acc: 0.50%
2025-08-14 20:03:05,275 - INFO - Fold 3, Epoch 250: Val Acc: 0.50%
2025-08-14 20:03:07,216 - INFO - Fold 3, Epoch 260: Val Acc: 0.56%
2025-08-14 20:03:09,149 - INFO - Fold 3, Epoch 270: Val Acc: 0.50%
2025-08-14 20:03:11,386 - INFO - Fold 3, Epoch 280: Val Acc: 0.50%
2025-08-14 20:03:13,772 - INFO - Fold 3, Epoch 290: Val Acc: 0.53%
2025-08-14 20:03:16,144 - INFO - Fold 3, Epoch 300: Val Acc: 0.50%
2025-08-14 20:03:18,505 - INFO - Fold 3, Epoch 310: Val Acc: 0.66%
2025-08-14 20:03:20,902 - INFO - Fold 3, Epoch 320: Val Acc: 0.50%
2025-08-14 20:03:23,290 - INFO - Fold 3, Epoch 330: Val Acc: 0.50%
2025-08-14 20:03:25,681 - INFO - Fold 3, Epoch 340: Val Acc: 0.50%
2025-08-14 20:03:26,877 - INFO - Early stopping at epoch 345
2025-08-14 20:03:28,193 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.270179006788466), 'std': np.float64(0.05454749570434068)}, 'train_accuracy': {'mean': np.float64(0.9930555555555555), 'std': np.float64(0.004910463758239948)}, 'val_loss': {'mean': np.float64(4.222085952758789), 'std': np.float64(0.05443835187149015)}, 'val_accuracy': {'mean': np.float64(0.8125), 'std': np.float64(0.05103103630798288)}, 'epoch': {'mean': np.float64(216.33333333333334), 'std': np.float64(44.16886786967591)}}
[I 2025-08-14 20:03:28,206] Trial 13 finished with value: -0.8125 and parameters: {'learning_rate': 0.0009905394173820982, 'batch_size': 32, 'num_epochs': 768, 'temperature': 0.20247030075509825, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4325291593208286, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': False, 'flip_enabled': True, 'permutation_enabled': False}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 13 finished with value: -0.8125 and parameters: {'learning_rate': 0.0009905394173820982, 'batch_size': 32, 'num_epochs': 768, 'temperature': 0.20247030075509825, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4325291593208286, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': False, 'flip_enabled': True, 'permutation_enabled': False}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:03:28,257 - INFO - Using device: cuda
2025-08-14 20:03:38,336 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:03:38,338 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:03:38,338 - INFO - Starting training for fold 1/3
2025-08-14 20:03:43,030 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-14 20:03:47,519 - INFO - Fold 1, Epoch 20: Val Acc: 0.44%
2025-08-14 20:03:52,165 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-14 20:03:56,743 - INFO - Fold 1, Epoch 40: Val Acc: 0.66%
2025-08-14 20:04:01,417 - INFO - Fold 1, Epoch 50: Val Acc: 0.78%
2025-08-14 20:04:03,697 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-14 20:04:05,969 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-14 20:04:10,361 - INFO - Fold 1, Epoch 80: Val Acc: 0.78%
2025-08-14 20:04:12,637 - INFO - Fold 1, Epoch 90: Val Acc: 0.66%
2025-08-14 20:04:14,911 - INFO - Fold 1, Epoch 100: Val Acc: 0.78%
2025-08-14 20:04:17,189 - INFO - Fold 1, Epoch 110: Val Acc: 0.78%
2025-08-14 20:04:21,673 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-14 20:04:24,037 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-14 20:04:26,397 - INFO - Fold 1, Epoch 140: Val Acc: 0.66%
2025-08-14 20:04:28,643 - INFO - Fold 1, Epoch 150: Val Acc: 0.78%
2025-08-14 20:04:30,982 - INFO - Fold 1, Epoch 160: Val Acc: 0.75%
2025-08-14 20:04:33,342 - INFO - Fold 1, Epoch 170: Val Acc: 0.78%
2025-08-14 20:04:35,693 - INFO - Fold 1, Epoch 180: Val Acc: 0.81%
2025-08-14 20:04:38,050 - INFO - Fold 1, Epoch 190: Val Acc: 0.62%
2025-08-14 20:04:40,410 - INFO - Fold 1, Epoch 200: Val Acc: 0.75%
2025-08-14 20:04:42,774 - INFO - Fold 1, Epoch 210: Val Acc: 0.75%
2025-08-14 20:04:44,887 - INFO - Early stopping at epoch 219
2025-08-14 20:04:48,617 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:04:48,620 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:04:48,620 - INFO - Starting training for fold 2/3
2025-08-14 20:04:58,227 - INFO - Fold 2, Epoch 10: Val Acc: 0.75%
2025-08-14 20:05:00,620 - INFO - Fold 2, Epoch 20: Val Acc: 0.56%
2025-08-14 20:05:02,993 - INFO - Fold 2, Epoch 30: Val Acc: 0.59%
2025-08-14 20:05:05,361 - INFO - Fold 2, Epoch 40: Val Acc: 0.56%
2025-08-14 20:05:07,525 - INFO - Fold 2, Epoch 50: Val Acc: 0.62%
2025-08-14 20:05:10,967 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-14 20:05:15,198 - INFO - Fold 2, Epoch 70: Val Acc: 0.66%
2025-08-14 20:05:17,392 - INFO - Fold 2, Epoch 80: Val Acc: 0.62%
2025-08-14 20:05:20,981 - INFO - Fold 2, Epoch 90: Val Acc: 0.91%
2025-08-14 20:05:23,211 - INFO - Fold 2, Epoch 100: Val Acc: 0.84%
2025-08-14 20:05:25,446 - INFO - Fold 2, Epoch 110: Val Acc: 0.66%
2025-08-14 20:05:27,385 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-14 20:05:29,264 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-14 20:05:31,335 - INFO - Fold 2, Epoch 140: Val Acc: 0.84%
2025-08-14 20:05:33,610 - INFO - Fold 2, Epoch 150: Val Acc: 0.66%
2025-08-14 20:05:37,264 - INFO - Fold 2, Epoch 160: Val Acc: 0.62%
2025-08-14 20:05:39,552 - INFO - Fold 2, Epoch 170: Val Acc: 0.62%
2025-08-14 20:05:41,846 - INFO - Fold 2, Epoch 180: Val Acc: 0.78%
2025-08-14 20:05:44,145 - INFO - Fold 2, Epoch 190: Val Acc: 0.78%
2025-08-14 20:05:46,352 - INFO - Fold 2, Epoch 200: Val Acc: 0.88%
2025-08-14 20:05:48,641 - INFO - Fold 2, Epoch 210: Val Acc: 0.69%
2025-08-14 20:05:50,937 - INFO - Fold 2, Epoch 220: Val Acc: 0.78%
2025-08-14 20:05:53,189 - INFO - Fold 2, Epoch 230: Val Acc: 0.69%
2025-08-14 20:05:55,448 - INFO - Fold 2, Epoch 240: Val Acc: 0.72%
2025-08-14 20:05:57,738 - INFO - Fold 2, Epoch 250: Val Acc: 0.75%
2025-08-14 20:05:59,562 - INFO - Early stopping at epoch 258
2025-08-14 20:06:02,674 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:06:02,678 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:06:02,678 - INFO - Starting training for fold 3/3
2025-08-14 20:06:07,589 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-14 20:06:09,940 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-14 20:06:12,226 - INFO - Fold 3, Epoch 30: Val Acc: 0.59%
2025-08-14 20:06:15,935 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-14 20:06:18,110 - INFO - Fold 3, Epoch 50: Val Acc: 0.59%
2025-08-14 20:06:19,874 - INFO - Fold 3, Epoch 60: Val Acc: 0.59%
2025-08-14 20:06:23,186 - INFO - Fold 3, Epoch 70: Val Acc: 0.59%
2025-08-14 20:06:27,148 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-14 20:06:29,537 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-14 20:06:31,911 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-14 20:06:34,295 - INFO - Fold 3, Epoch 110: Val Acc: 0.81%
2025-08-14 20:06:37,996 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-14 20:06:40,200 - INFO - Fold 3, Epoch 130: Val Acc: 0.75%
2025-08-14 20:06:42,478 - INFO - Fold 3, Epoch 140: Val Acc: 0.66%
2025-08-14 20:06:44,747 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-14 20:06:47,025 - INFO - Fold 3, Epoch 160: Val Acc: 0.72%
2025-08-14 20:06:49,295 - INFO - Fold 3, Epoch 170: Val Acc: 0.84%
2025-08-14 20:06:51,569 - INFO - Fold 3, Epoch 180: Val Acc: 0.78%
2025-08-14 20:06:53,836 - INFO - Fold 3, Epoch 190: Val Acc: 0.69%
2025-08-14 20:06:56,095 - INFO - Fold 3, Epoch 200: Val Acc: 0.84%
2025-08-14 20:06:58,305 - INFO - Fold 3, Epoch 210: Val Acc: 0.75%
2025-08-14 20:07:00,351 - INFO - Early stopping at epoch 219
2025-08-14 20:07:01,405 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9825677076975503), 'std': np.float64(0.017273589563367393)}, 'train_accuracy': {'mean': np.float64(0.763888888888889), 'std': np.float64(0.021404215288086736)}, 'val_loss': {'mean': np.float64(4.200973033905029), 'std': np.float64(0.08779293926367314)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(131.0), 'std': np.float64(18.384776310850235)}}
[I 2025-08-14 20:07:01,414] Trial 14 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.00027008062223619287, 'batch_size': 32, 'num_epochs': 982, 'temperature': 0.4805659862433591, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.43869981937716873, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19759250728070285, 'crop_size': 0.5269498526849873}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 14 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.00027008062223619287, 'batch_size': 32, 'num_epochs': 982, 'temperature': 0.4805659862433591, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.43869981937716873, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19759250728070285, 'crop_size': 0.5269498526849873}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:07:01,441 - INFO - Using device: cuda
2025-08-14 20:07:11,375 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:07:11,381 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:07:11,382 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:07:17,900 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-14 20:07:19,740 - INFO - Fold 1, Epoch 20: Val Acc: 0.47%
2025-08-14 20:07:21,578 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 20:07:24,742 - INFO - Fold 1, Epoch 40: Val Acc: 0.47%
2025-08-14 20:07:26,579 - INFO - Fold 1, Epoch 50: Val Acc: 0.59%
2025-08-14 20:07:28,417 - INFO - Fold 1, Epoch 60: Val Acc: 0.47%
2025-08-14 20:07:30,094 - INFO - Fold 1, Epoch 70: Val Acc: 0.38%
2025-08-14 20:07:31,686 - INFO - Fold 1, Epoch 80: Val Acc: 0.56%
2025-08-14 20:07:33,509 - INFO - Fold 1, Epoch 90: Val Acc: 0.53%
2025-08-14 20:07:35,336 - INFO - Fold 1, Epoch 100: Val Acc: 0.44%
2025-08-14 20:07:37,161 - INFO - Fold 1, Epoch 110: Val Acc: 0.53%
2025-08-14 20:07:38,948 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-14 20:07:40,610 - INFO - Fold 1, Epoch 130: Val Acc: 0.56%
2025-08-14 20:07:41,293 - INFO - Early stopping at epoch 134
2025-08-14 20:07:43,533 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:07:43,536 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:07:43,537 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:07:48,400 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-14 20:07:50,325 - INFO - Fold 2, Epoch 20: Val Acc: 0.44%
2025-08-14 20:07:52,262 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-14 20:07:54,003 - INFO - Fold 2, Epoch 40: Val Acc: 0.53%
2025-08-14 20:07:55,887 - INFO - Fold 2, Epoch 50: Val Acc: 0.53%
2025-08-14 20:07:57,337 - INFO - Fold 2, Epoch 60: Val Acc: 0.41%
2025-08-14 20:07:58,772 - INFO - Fold 2, Epoch 70: Val Acc: 0.69%
2025-08-14 20:08:00,288 - INFO - Fold 2, Epoch 80: Val Acc: 0.66%
2025-08-14 20:08:01,735 - INFO - Fold 2, Epoch 90: Val Acc: 0.56%
2025-08-14 20:08:03,167 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-14 20:08:05,718 - INFO - Fold 2, Epoch 110: Val Acc: 0.59%
2025-08-14 20:08:07,544 - INFO - Fold 2, Epoch 120: Val Acc: 0.59%
2025-08-14 20:08:09,366 - INFO - Fold 2, Epoch 130: Val Acc: 0.47%
2025-08-14 20:08:11,181 - INFO - Fold 2, Epoch 140: Val Acc: 0.62%
2025-08-14 20:08:12,959 - INFO - Fold 2, Epoch 150: Val Acc: 0.44%
2025-08-14 20:08:14,819 - INFO - Fold 2, Epoch 160: Val Acc: 0.62%
2025-08-14 20:08:18,094 - INFO - Fold 2, Epoch 170: Val Acc: 0.62%
2025-08-14 20:08:19,782 - INFO - Fold 2, Epoch 180: Val Acc: 0.72%
2025-08-14 20:08:21,607 - INFO - Fold 2, Epoch 190: Val Acc: 0.72%
2025-08-14 20:08:23,446 - INFO - Fold 2, Epoch 200: Val Acc: 0.62%
2025-08-14 20:08:26,092 - INFO - Fold 2, Epoch 210: Val Acc: 0.66%
2025-08-14 20:08:27,935 - INFO - Fold 2, Epoch 220: Val Acc: 0.59%
2025-08-14 20:08:29,849 - INFO - Fold 2, Epoch 230: Val Acc: 0.56%
2025-08-14 20:08:32,672 - INFO - Fold 2, Epoch 240: Val Acc: 0.84%
2025-08-14 20:08:34,562 - INFO - Fold 2, Epoch 250: Val Acc: 0.69%
2025-08-14 20:08:36,394 - INFO - Fold 2, Epoch 260: Val Acc: 0.62%
2025-08-14 20:08:38,232 - INFO - Fold 2, Epoch 270: Val Acc: 0.75%
2025-08-14 20:08:40,068 - INFO - Fold 2, Epoch 280: Val Acc: 0.62%
2025-08-14 20:08:41,708 - INFO - Fold 2, Epoch 290: Val Acc: 0.69%
2025-08-14 20:08:43,535 - INFO - Fold 2, Epoch 300: Val Acc: 0.75%
2025-08-14 20:08:45,363 - INFO - Fold 2, Epoch 310: Val Acc: 0.75%
2025-08-14 20:08:47,185 - INFO - Fold 2, Epoch 320: Val Acc: 0.84%
2025-08-14 20:08:49,025 - INFO - Fold 2, Epoch 330: Val Acc: 0.75%
2025-08-14 20:08:50,857 - INFO - Early stopping at epoch 340
2025-08-14 20:08:52,743 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:08:52,746 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:08:52,746 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:08:58,499 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-14 20:09:02,304 - INFO - Fold 3, Epoch 20: Val Acc: 0.41%
2025-08-14 20:09:04,115 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-14 20:09:05,953 - INFO - Fold 3, Epoch 40: Val Acc: 0.47%
2025-08-14 20:09:07,768 - INFO - Fold 3, Epoch 50: Val Acc: 0.47%
2025-08-14 20:09:09,597 - INFO - Fold 3, Epoch 60: Val Acc: 0.56%
2025-08-14 20:09:11,436 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-14 20:09:13,269 - INFO - Fold 3, Epoch 80: Val Acc: 0.38%
2025-08-14 20:09:15,087 - INFO - Fold 3, Epoch 90: Val Acc: 0.47%
2025-08-14 20:09:16,914 - INFO - Fold 3, Epoch 100: Val Acc: 0.50%
2025-08-14 20:09:18,746 - INFO - Fold 3, Epoch 110: Val Acc: 0.56%
2025-08-14 20:09:20,383 - INFO - Early stopping at epoch 119
2025-08-14 20:09:21,055 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(5.13862673441569), 'std': np.float64(0.5754814619821922)}, 'train_accuracy': {'mean': np.float64(0.6354166666666667), 'std': np.float64(0.02551551815399144)}, 'val_loss': {'mean': np.float64(5.1293684641520185), 'std': np.float64(0.533920544212345)}, 'val_accuracy': {'mean': np.float64(0.7708333333333334), 'std': np.float64(0.05311478659992484)}, 'epoch': {'mean': np.float64(96.66666666666667), 'std': np.float64(100.83099170834772)}}
[I 2025-08-14 20:09:21,063] Trial 15 finished with value: -0.7708333333333334 and parameters: {'learning_rate': 7.664486865746752e-05, 'batch_size': 32, 'num_epochs': 986, 'temperature': 0.08899625688700061, 'embedding_dim': 256, 'hidden_dim': 128, 'dropout': 0.4366128874963628, 'num_layers': 3, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19605325840337098, 'crop_size': 0.5194691795700757}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 15 finished with value: -0.7708333333333334 and parameters: {'learning_rate': 7.664486865746752e-05, 'batch_size': 32, 'num_epochs': 986, 'temperature': 0.08899625688700061, 'embedding_dim': 256, 'hidden_dim': 128, 'dropout': 0.4366128874963628, 'num_layers': 3, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19605325840337098, 'crop_size': 0.5194691795700757}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:09:21,091 - INFO - Using device: cuda
2025-08-14 20:09:31,149 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:09:31,151 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:09:31,151 - INFO - Starting training for fold 1/3
2025-08-14 20:09:40,246 - INFO - Fold 1, Epoch 10: Val Acc: 0.52%
2025-08-14 20:09:43,615 - INFO - Fold 1, Epoch 20: Val Acc: 0.54%
2025-08-14 20:09:48,927 - INFO - Fold 1, Epoch 30: Val Acc: 0.48%
2025-08-14 20:09:54,268 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-14 20:09:57,821 - INFO - Fold 1, Epoch 50: Val Acc: 0.81%
2025-08-14 20:10:01,322 - INFO - Fold 1, Epoch 60: Val Acc: 0.73%
2025-08-14 20:10:04,845 - INFO - Fold 1, Epoch 70: Val Acc: 0.67%
2025-08-14 20:10:08,352 - INFO - Fold 1, Epoch 80: Val Acc: 0.81%
2025-08-14 20:10:11,913 - INFO - Fold 1, Epoch 90: Val Acc: 0.83%
2025-08-14 20:10:15,462 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-14 20:10:19,006 - INFO - Fold 1, Epoch 110: Val Acc: 0.67%
2025-08-14 20:10:22,535 - INFO - Fold 1, Epoch 120: Val Acc: 0.62%
2025-08-14 20:10:26,013 - INFO - Fold 1, Epoch 130: Val Acc: 0.75%
2025-08-14 20:10:27,733 - INFO - Early stopping at epoch 135
2025-08-14 20:10:30,663 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:10:30,666 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:10:30,667 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:10:40,490 - INFO - Fold 2, Epoch 10: Val Acc: 0.60%
2025-08-14 20:10:46,407 - INFO - Fold 2, Epoch 20: Val Acc: 0.54%
2025-08-14 20:10:49,485 - INFO - Fold 2, Epoch 30: Val Acc: 0.71%
2025-08-14 20:10:52,562 - INFO - Fold 2, Epoch 40: Val Acc: 0.71%
2025-08-14 20:10:55,990 - INFO - Fold 2, Epoch 50: Val Acc: 0.65%
2025-08-14 20:10:59,437 - INFO - Fold 2, Epoch 60: Val Acc: 0.62%
2025-08-14 20:11:06,495 - INFO - Fold 2, Epoch 70: Val Acc: 0.62%
2025-08-14 20:11:11,124 - INFO - Fold 2, Epoch 80: Val Acc: 0.90%
2025-08-14 20:11:14,687 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-14 20:11:18,169 - INFO - Fold 2, Epoch 100: Val Acc: 0.67%
2025-08-14 20:11:21,624 - INFO - Fold 2, Epoch 110: Val Acc: 0.79%
2025-08-14 20:11:25,021 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-14 20:11:28,294 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-14 20:11:30,800 - INFO - Fold 2, Epoch 140: Val Acc: 0.81%
2025-08-14 20:11:33,560 - INFO - Fold 2, Epoch 150: Val Acc: 0.65%
2025-08-14 20:11:36,377 - INFO - Fold 2, Epoch 160: Val Acc: 0.77%
2025-08-14 20:11:39,369 - INFO - Fold 2, Epoch 170: Val Acc: 0.77%
2025-08-14 20:11:42,303 - INFO - Early stopping at epoch 180
2025-08-14 20:11:44,885 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:11:44,889 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:11:44,889 - INFO - Starting training for fold 3/3
2025-08-14 20:11:51,492 - INFO - Fold 3, Epoch 10: Val Acc: 0.60%
2025-08-14 20:11:57,073 - INFO - Fold 3, Epoch 20: Val Acc: 0.65%
2025-08-14 20:12:01,599 - INFO - Fold 3, Epoch 30: Val Acc: 0.67%
2025-08-14 20:12:07,373 - INFO - Fold 3, Epoch 40: Val Acc: 0.71%
2025-08-14 20:12:10,796 - INFO - Fold 3, Epoch 50: Val Acc: 0.77%
2025-08-14 20:12:14,225 - INFO - Fold 3, Epoch 60: Val Acc: 0.71%
2025-08-14 20:12:18,937 - INFO - Fold 3, Epoch 70: Val Acc: 0.67%
2025-08-14 20:12:22,368 - INFO - Fold 3, Epoch 80: Val Acc: 0.67%
2025-08-14 20:12:25,804 - INFO - Fold 3, Epoch 90: Val Acc: 0.71%
2025-08-14 20:12:29,232 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-14 20:12:32,663 - INFO - Fold 3, Epoch 110: Val Acc: 0.77%
2025-08-14 20:12:36,091 - INFO - Fold 3, Epoch 120: Val Acc: 0.79%
2025-08-14 20:12:39,539 - INFO - Fold 3, Epoch 130: Val Acc: 0.75%
2025-08-14 20:12:42,976 - INFO - Fold 3, Epoch 140: Val Acc: 0.79%
2025-08-14 20:12:46,435 - INFO - Fold 3, Epoch 150: Val Acc: 0.67%
2025-08-14 20:12:49,780 - INFO - Fold 3, Epoch 160: Val Acc: 0.75%
2025-08-14 20:12:52,951 - INFO - Early stopping at epoch 169
2025-08-14 20:12:53,821 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.2823999457889133), 'std': np.float64(0.06845681790553304)}, 'train_accuracy': {'mean': np.float64(0.7777777777777777), 'std': np.float64(0.021404215288086698)}, 'val_loss': {'mean': np.float64(3.4695017337799072), 'std': np.float64(0.06935307685249215)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(6.409875621278546e-17)}, 'epoch': {'mean': np.float64(60.333333333333336), 'std': np.float64(19.154343864744856)}}
[I 2025-08-14 20:12:53,829] Trial 16 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.00047232344074810335, 'batch_size': 16, 'num_epochs': 568, 'temperature': 0.3700121654523003, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.42179779125289274, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19431380064658488, 'crop_size': 0.5009640289127966}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 16 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.00047232344074810335, 'batch_size': 16, 'num_epochs': 568, 'temperature': 0.3700121654523003, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.42179779125289274, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19431380064658488, 'crop_size': 0.5009640289127966}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:12:53,856 - INFO - Using device: cuda
2025-08-14 20:13:04,307 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:13:04,309 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:13:04,309 - INFO - Starting training for fold 1/3
2025-08-14 20:13:13,481 - INFO - Fold 1, Epoch 10: Val Acc: 0.69%
2025-08-14 20:13:15,484 - INFO - Fold 1, Epoch 20: Val Acc: 0.47%
2025-08-14 20:13:17,280 - INFO - Fold 1, Epoch 30: Val Acc: 0.53%
2025-08-14 20:13:19,029 - INFO - Fold 1, Epoch 40: Val Acc: 0.53%
2025-08-14 20:13:20,787 - INFO - Fold 1, Epoch 50: Val Acc: 0.53%
2025-08-14 20:13:22,538 - INFO - Fold 1, Epoch 60: Val Acc: 0.53%
2025-08-14 20:13:24,404 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-14 20:13:26,528 - INFO - Fold 1, Epoch 80: Val Acc: 0.53%
2025-08-14 20:13:31,064 - INFO - Fold 1, Epoch 90: Val Acc: 0.56%
2025-08-14 20:13:33,561 - INFO - Fold 1, Epoch 100: Val Acc: 0.53%
2025-08-14 20:13:35,926 - INFO - Fold 1, Epoch 110: Val Acc: 0.59%
2025-08-14 20:13:38,224 - INFO - Fold 1, Epoch 120: Val Acc: 0.59%
2025-08-14 20:13:40,481 - INFO - Fold 1, Epoch 130: Val Acc: 0.47%
2025-08-14 20:13:42,663 - INFO - Fold 1, Epoch 140: Val Acc: 0.41%
2025-08-14 20:13:47,108 - INFO - Fold 1, Epoch 150: Val Acc: 0.75%
2025-08-14 20:13:49,395 - INFO - Fold 1, Epoch 160: Val Acc: 0.47%
2025-08-14 20:13:51,691 - INFO - Fold 1, Epoch 170: Val Acc: 0.47%
2025-08-14 20:13:54,032 - INFO - Fold 1, Epoch 180: Val Acc: 0.59%
2025-08-14 20:13:56,313 - INFO - Fold 1, Epoch 190: Val Acc: 0.66%
2025-08-14 20:13:58,606 - INFO - Fold 1, Epoch 200: Val Acc: 0.56%
2025-08-14 20:14:00,731 - INFO - Fold 1, Epoch 210: Val Acc: 0.44%
2025-08-14 20:14:02,490 - INFO - Fold 1, Epoch 220: Val Acc: 0.66%
2025-08-14 20:14:04,400 - INFO - Fold 1, Epoch 230: Val Acc: 0.69%
2025-08-14 20:14:08,613 - INFO - Fold 1, Epoch 240: Val Acc: 0.69%
2025-08-14 20:14:10,380 - INFO - Fold 1, Epoch 250: Val Acc: 0.66%
2025-08-14 20:14:12,247 - INFO - Fold 1, Epoch 260: Val Acc: 0.81%
2025-08-14 20:14:14,011 - INFO - Fold 1, Epoch 270: Val Acc: 0.72%
2025-08-14 20:14:15,982 - INFO - Fold 1, Epoch 280: Val Acc: 0.59%
2025-08-14 20:14:18,193 - INFO - Fold 1, Epoch 290: Val Acc: 0.62%
2025-08-14 20:14:20,083 - INFO - Fold 1, Epoch 300: Val Acc: 0.75%
2025-08-14 20:14:22,122 - INFO - Fold 1, Epoch 310: Val Acc: 0.59%
2025-08-14 20:14:24,243 - INFO - Fold 1, Epoch 320: Val Acc: 0.72%
2025-08-14 20:14:26,624 - INFO - Fold 1, Epoch 330: Val Acc: 0.59%
2025-08-14 20:14:28,480 - INFO - Early stopping at epoch 338
2025-08-14 20:14:32,208 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:14:32,211 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:14:32,212 - INFO - Starting training for fold 2/3
2025-08-14 20:14:38,746 - INFO - Fold 2, Epoch 10: Val Acc: 0.47%
2025-08-14 20:14:40,526 - INFO - Fold 2, Epoch 20: Val Acc: 0.62%
2025-08-14 20:14:42,461 - INFO - Fold 2, Epoch 30: Val Acc: 0.62%
2025-08-14 20:14:44,775 - INFO - Fold 2, Epoch 40: Val Acc: 0.62%
2025-08-14 20:14:48,207 - INFO - Fold 2, Epoch 50: Val Acc: 0.41%
2025-08-14 20:14:50,074 - INFO - Fold 2, Epoch 60: Val Acc: 0.69%
2025-08-14 20:14:51,944 - INFO - Fold 2, Epoch 70: Val Acc: 0.62%
2025-08-14 20:14:53,819 - INFO - Fold 2, Epoch 80: Val Acc: 0.56%
2025-08-14 20:14:55,691 - INFO - Fold 2, Epoch 90: Val Acc: 0.47%
2025-08-14 20:14:57,711 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-14 20:15:00,001 - INFO - Fold 2, Epoch 110: Val Acc: 0.59%
2025-08-14 20:15:02,256 - INFO - Fold 2, Epoch 120: Val Acc: 0.62%
2025-08-14 20:15:04,642 - INFO - Fold 2, Epoch 130: Val Acc: 0.53%
2025-08-14 20:15:07,012 - INFO - Fold 2, Epoch 140: Val Acc: 0.62%
2025-08-14 20:15:07,496 - INFO - Early stopping at epoch 142
2025-08-14 20:15:08,566 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:15:08,568 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:15:08,568 - INFO - Starting training for fold 3/3
2025-08-14 20:15:17,969 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-14 20:15:20,139 - INFO - Fold 3, Epoch 20: Val Acc: 0.56%
2025-08-14 20:15:22,505 - INFO - Fold 3, Epoch 30: Val Acc: 0.44%
2025-08-14 20:15:24,855 - INFO - Fold 3, Epoch 40: Val Acc: 0.38%
2025-08-14 20:15:27,240 - INFO - Fold 3, Epoch 50: Val Acc: 0.53%
2025-08-14 20:15:31,014 - INFO - Fold 3, Epoch 60: Val Acc: 0.53%
2025-08-14 20:15:34,660 - INFO - Fold 3, Epoch 70: Val Acc: 0.59%
2025-08-14 20:15:36,640 - INFO - Fold 3, Epoch 80: Val Acc: 0.53%
2025-08-14 20:15:38,664 - INFO - Fold 3, Epoch 90: Val Acc: 0.66%
2025-08-14 20:15:40,726 - INFO - Fold 3, Epoch 100: Val Acc: 0.50%
2025-08-14 20:15:43,005 - INFO - Fold 3, Epoch 110: Val Acc: 0.59%
2025-08-14 20:15:45,310 - INFO - Fold 3, Epoch 120: Val Acc: 0.59%
2025-08-14 20:15:47,668 - INFO - Fold 3, Epoch 130: Val Acc: 0.50%
2025-08-14 20:15:50,039 - INFO - Fold 3, Epoch 140: Val Acc: 0.56%
2025-08-14 20:15:52,423 - INFO - Fold 3, Epoch 150: Val Acc: 0.59%
2025-08-14 20:15:56,122 - INFO - Fold 3, Epoch 160: Val Acc: 0.78%
2025-08-14 20:15:58,388 - INFO - Fold 3, Epoch 170: Val Acc: 0.59%
2025-08-14 20:16:00,381 - INFO - Fold 3, Epoch 180: Val Acc: 0.72%
2025-08-14 20:16:02,517 - INFO - Fold 3, Epoch 190: Val Acc: 0.62%
2025-08-14 20:16:04,628 - INFO - Fold 3, Epoch 200: Val Acc: 0.56%
2025-08-14 20:16:06,840 - INFO - Fold 3, Epoch 210: Val Acc: 0.66%
2025-08-14 20:16:09,005 - INFO - Fold 3, Epoch 220: Val Acc: 0.62%
2025-08-14 20:16:11,081 - INFO - Fold 3, Epoch 230: Val Acc: 0.56%
2025-08-14 20:16:13,188 - INFO - Fold 3, Epoch 240: Val Acc: 0.81%
2025-08-14 20:16:15,473 - INFO - Fold 3, Epoch 250: Val Acc: 0.56%
2025-08-14 20:16:15,710 - INFO - Early stopping at epoch 251
2025-08-14 20:16:16,758 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.0802698665195045), 'std': np.float64(0.03546915312881182)}, 'train_accuracy': {'mean': np.float64(0.6458333333333334), 'std': np.float64(0.07266822755714007)}, 'val_loss': {'mean': np.float64(4.137480735778809), 'std': np.float64(0.023522275086331625)}, 'val_accuracy': {'mean': np.float64(0.8333333333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(142.66666666666666), 'std': np.float64(80.18450944886771)}}
[I 2025-08-14 20:16:16,765] Trial 17 finished with value: -0.8333333333333334 and parameters: {'learning_rate': 8.499212888479729e-05, 'batch_size': 32, 'num_epochs': 872, 'temperature': 0.4844418552105284, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3294008178026585, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.13904693353640224, 'crop_size': 0.5865355174793682}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 17 finished with value: -0.8333333333333334 and parameters: {'learning_rate': 8.499212888479729e-05, 'batch_size': 32, 'num_epochs': 872, 'temperature': 0.4844418552105284, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3294008178026585, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.13904693353640224, 'crop_size': 0.5865355174793682}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:16:16,793 - INFO - Using device: cuda
2025-08-14 20:16:27,062 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:16:27,063 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:16:27,064 - INFO - Starting training for fold 1/3
2025-08-14 20:16:36,174 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-14 20:16:42,764 - INFO - Fold 1, Epoch 20: Val Acc: 0.34%
2025-08-14 20:16:44,969 - INFO - Fold 1, Epoch 30: Val Acc: 0.41%
2025-08-14 20:16:49,001 - INFO - Fold 1, Epoch 40: Val Acc: 0.50%
2025-08-14 20:16:51,049 - INFO - Fold 1, Epoch 50: Val Acc: 0.47%
2025-08-14 20:16:53,213 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-14 20:16:55,381 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-14 20:16:57,433 - INFO - Fold 1, Epoch 80: Val Acc: 0.38%
2025-08-14 20:16:59,286 - INFO - Fold 1, Epoch 90: Val Acc: 0.50%
2025-08-14 20:17:01,139 - INFO - Fold 1, Epoch 100: Val Acc: 0.41%
2025-08-14 20:17:03,220 - INFO - Fold 1, Epoch 110: Val Acc: 0.44%
2025-08-14 20:17:05,356 - INFO - Fold 1, Epoch 120: Val Acc: 0.62%
2025-08-14 20:17:07,395 - INFO - Fold 1, Epoch 130: Val Acc: 0.50%
2025-08-14 20:17:08,634 - INFO - Early stopping at epoch 136
2025-08-14 20:17:11,949 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:17:11,952 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:17:11,953 - INFO - Starting training for fold 2/3
2025-08-14 20:17:18,970 - INFO - Fold 2, Epoch 10: Val Acc: 0.47%
2025-08-14 20:17:21,239 - INFO - Fold 2, Epoch 20: Val Acc: 0.53%
2025-08-14 20:17:23,350 - INFO - Fold 2, Epoch 30: Val Acc: 0.59%
2025-08-14 20:17:25,829 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-14 20:17:28,293 - INFO - Fold 2, Epoch 50: Val Acc: 0.50%
2025-08-14 20:17:30,758 - INFO - Fold 2, Epoch 60: Val Acc: 0.56%
2025-08-14 20:17:33,153 - INFO - Fold 2, Epoch 70: Val Acc: 0.53%
2025-08-14 20:17:35,614 - INFO - Fold 2, Epoch 80: Val Acc: 0.53%
2025-08-14 20:17:38,073 - INFO - Fold 2, Epoch 90: Val Acc: 0.41%
2025-08-14 20:17:40,536 - INFO - Fold 2, Epoch 100: Val Acc: 0.50%
2025-08-14 20:17:42,010 - INFO - Early stopping at epoch 106
2025-08-14 20:17:43,087 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:17:43,090 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:17:43,091 - INFO - Starting training for fold 3/3
2025-08-14 20:17:49,957 - INFO - Fold 3, Epoch 10: Val Acc: 0.66%
2025-08-14 20:17:52,427 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-14 20:17:54,745 - INFO - Fold 3, Epoch 30: Val Acc: 0.44%
2025-08-14 20:17:57,123 - INFO - Fold 3, Epoch 40: Val Acc: 0.53%
2025-08-14 20:17:59,222 - INFO - Fold 3, Epoch 50: Val Acc: 0.44%
2025-08-14 20:18:02,995 - INFO - Fold 3, Epoch 60: Val Acc: 0.56%
2025-08-14 20:18:05,024 - INFO - Fold 3, Epoch 70: Val Acc: 0.50%
2025-08-14 20:18:06,900 - INFO - Fold 3, Epoch 80: Val Acc: 0.66%
2025-08-14 20:18:09,264 - INFO - Fold 3, Epoch 90: Val Acc: 0.53%
2025-08-14 20:18:11,625 - INFO - Fold 3, Epoch 100: Val Acc: 0.56%
2025-08-14 20:18:14,000 - INFO - Fold 3, Epoch 110: Val Acc: 0.59%
2025-08-14 20:18:16,377 - INFO - Fold 3, Epoch 120: Val Acc: 0.44%
2025-08-14 20:18:18,832 - INFO - Fold 3, Epoch 130: Val Acc: 0.44%
2025-08-14 20:18:21,295 - INFO - Fold 3, Epoch 140: Val Acc: 0.53%
2025-08-14 20:18:23,771 - INFO - Fold 3, Epoch 150: Val Acc: 0.44%
2025-08-14 20:18:25,759 - INFO - Early stopping at epoch 158
2025-08-14 20:18:29,044 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.128691514333089), 'std': np.float64(0.012337247278851037)}, 'train_accuracy': {'mean': np.float64(0.5798611111111112), 'std': np.float64(0.04684283876122233)}, 'val_loss': {'mean': np.float64(4.2372846603393555), 'std': np.float64(0.03103401581559036)}, 'val_accuracy': {'mean': np.float64(0.6666666666666666), 'std': np.float64(0.06421264586426018)}, 'epoch': {'mean': np.float64(32.333333333333336), 'std': np.float64(21.312489817527705)}}
[I 2025-08-14 20:18:29,066] Trial 18 finished with value: -0.6666666666666666 and parameters: {'learning_rate': 0.0003034568475363462, 'batch_size': 32, 'num_epochs': 542, 'temperature': 0.23223622059307988, 'embedding_dim': 256, 'hidden_dim': 128, 'dropout': 0.2132267591126318, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.07594341607863495, 'crop_size': 0.5897060370464998}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 18 finished with value: -0.6666666666666666 and parameters: {'learning_rate': 0.0003034568475363462, 'batch_size': 32, 'num_epochs': 542, 'temperature': 0.23223622059307988, 'embedding_dim': 256, 'hidden_dim': 128, 'dropout': 0.2132267591126318, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.07594341607863495, 'crop_size': 0.5897060370464998}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:18:29,141 - INFO - Using device: cuda
2025-08-14 20:18:40,197 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:18:40,206 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:18:40,206 - INFO - Starting training for fold 1/3
2025-08-14 20:18:50,691 - INFO - Fold 1, Epoch 10: Val Acc: 0.46%
2025-08-14 20:18:57,814 - INFO - Fold 1, Epoch 20: Val Acc: 0.42%
2025-08-14 20:19:00,824 - INFO - Fold 1, Epoch 30: Val Acc: 0.69%
2025-08-14 20:19:03,832 - INFO - Fold 1, Epoch 40: Val Acc: 0.75%
2025-08-14 20:19:06,851 - INFO - Fold 1, Epoch 50: Val Acc: 0.71%
2025-08-14 20:19:12,732 - INFO - Fold 1, Epoch 60: Val Acc: 0.85%
2025-08-14 20:19:15,855 - INFO - Fold 1, Epoch 70: Val Acc: 0.71%
2025-08-14 20:19:20,324 - INFO - Fold 1, Epoch 80: Val Acc: 0.77%
2025-08-14 20:19:23,163 - INFO - Fold 1, Epoch 90: Val Acc: 0.73%
2025-08-14 20:19:25,501 - INFO - Fold 1, Epoch 100: Val Acc: 0.77%
2025-08-14 20:19:28,328 - INFO - Fold 1, Epoch 110: Val Acc: 0.73%
2025-08-14 20:19:30,936 - INFO - Fold 1, Epoch 120: Val Acc: 0.71%
2025-08-14 20:19:33,588 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-14 20:19:36,302 - INFO - Fold 1, Epoch 140: Val Acc: 0.77%
2025-08-14 20:19:39,286 - INFO - Fold 1, Epoch 150: Val Acc: 0.81%
2025-08-14 20:19:42,319 - INFO - Fold 1, Epoch 160: Val Acc: 0.71%
2025-08-14 20:19:45,432 - INFO - Fold 1, Epoch 170: Val Acc: 0.77%
2025-08-14 20:19:46,363 - INFO - Early stopping at epoch 173
2025-08-14 20:19:48,598 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:19:48,616 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:19:48,616 - INFO - Starting training for fold 2/3
2025-08-14 20:19:53,968 - INFO - Fold 2, Epoch 10: Val Acc: 0.48%
2025-08-14 20:19:57,080 - INFO - Fold 2, Epoch 20: Val Acc: 0.58%
2025-08-14 20:20:00,179 - INFO - Fold 2, Epoch 30: Val Acc: 0.54%
2025-08-14 20:20:03,297 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-14 20:20:08,230 - INFO - Fold 2, Epoch 50: Val Acc: 0.77%
2025-08-14 20:20:12,170 - INFO - Fold 2, Epoch 60: Val Acc: 0.73%
2025-08-14 20:20:14,367 - INFO - Fold 2, Epoch 70: Val Acc: 0.71%
2025-08-14 20:20:17,035 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-14 20:20:20,037 - INFO - Fold 2, Epoch 90: Val Acc: 0.73%
2025-08-14 20:20:23,042 - INFO - Fold 2, Epoch 100: Val Acc: 0.77%
2025-08-14 20:20:27,061 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-14 20:20:30,050 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-14 20:20:33,102 - INFO - Fold 2, Epoch 130: Val Acc: 0.56%
2025-08-14 20:20:36,024 - INFO - Fold 2, Epoch 140: Val Acc: 0.79%
2025-08-14 20:20:39,160 - INFO - Fold 2, Epoch 150: Val Acc: 0.79%
2025-08-14 20:20:42,292 - INFO - Fold 2, Epoch 160: Val Acc: 0.90%
2025-08-14 20:20:45,400 - INFO - Fold 2, Epoch 170: Val Acc: 0.79%
2025-08-14 20:20:48,396 - INFO - Fold 2, Epoch 180: Val Acc: 0.77%
2025-08-14 20:20:51,396 - INFO - Fold 2, Epoch 190: Val Acc: 0.77%
2025-08-14 20:20:53,711 - INFO - Fold 2, Epoch 200: Val Acc: 0.77%
2025-08-14 20:20:53,935 - INFO - Early stopping at epoch 201
2025-08-14 20:20:55,940 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:20:55,958 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:20:55,959 - INFO - Starting training for fold 3/3
2025-08-14 20:21:02,671 - INFO - Fold 3, Epoch 10: Val Acc: 0.48%
2025-08-14 20:21:07,755 - INFO - Fold 3, Epoch 20: Val Acc: 0.54%
2025-08-14 20:21:10,439 - INFO - Fold 3, Epoch 30: Val Acc: 0.65%
2025-08-14 20:21:13,506 - INFO - Fold 3, Epoch 40: Val Acc: 0.71%
2025-08-14 20:21:16,513 - INFO - Fold 3, Epoch 50: Val Acc: 0.60%
2025-08-14 20:21:20,578 - INFO - Fold 3, Epoch 60: Val Acc: 0.81%
2025-08-14 20:21:23,724 - INFO - Fold 3, Epoch 70: Val Acc: 0.75%
2025-08-14 20:21:26,724 - INFO - Fold 3, Epoch 80: Val Acc: 0.67%
2025-08-14 20:21:29,717 - INFO - Fold 3, Epoch 90: Val Acc: 0.77%
2025-08-14 20:21:32,615 - INFO - Fold 3, Epoch 100: Val Acc: 0.67%
2025-08-14 20:21:36,664 - INFO - Fold 3, Epoch 110: Val Acc: 0.71%
2025-08-14 20:21:39,393 - INFO - Fold 3, Epoch 120: Val Acc: 0.71%
2025-08-14 20:21:42,262 - INFO - Fold 3, Epoch 130: Val Acc: 0.83%
2025-08-14 20:21:45,283 - INFO - Fold 3, Epoch 140: Val Acc: 0.79%
2025-08-14 20:21:48,293 - INFO - Fold 3, Epoch 150: Val Acc: 0.75%
2025-08-14 20:21:51,040 - INFO - Fold 3, Epoch 160: Val Acc: 0.75%
2025-08-14 20:21:54,039 - INFO - Fold 3, Epoch 170: Val Acc: 0.75%
2025-08-14 20:21:57,055 - INFO - Fold 3, Epoch 180: Val Acc: 0.67%
2025-08-14 20:22:00,086 - INFO - Fold 3, Epoch 190: Val Acc: 0.75%
2025-08-14 20:22:03,085 - INFO - Fold 3, Epoch 200: Val Acc: 0.71%
2025-08-14 20:22:03,982 - INFO - Early stopping at epoch 203
2025-08-14 20:22:04,669 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.1444162262810598), 'std': np.float64(0.008941380455830558)}, 'train_accuracy': {'mean': np.float64(0.75), 'std': np.float64(0.01473139127471974)}, 'val_loss': {'mean': np.float64(3.526452991697523), 'std': np.float64(0.009614225018206425)}, 'val_accuracy': {'mean': np.float64(0.875), 'std': np.float64(0.01701034543599428)}, 'epoch': {'mean': np.float64(91.33333333333333), 'std': np.float64(13.695092389449425)}}
[I 2025-08-14 20:22:04,677] Trial 19 finished with value: -0.875 and parameters: {'learning_rate': 0.00015064643145299277, 'batch_size': 16, 'num_epochs': 1000, 'temperature': 0.21235176850774493, 'embedding_dim': 512, 'hidden_dim': 512, 'dropout': 0.39711822220109877, 'num_layers': 3, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.16386573749212538, 'crop_size': 0.5861100191320092}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 19 finished with value: -0.875 and parameters: {'learning_rate': 0.00015064643145299277, 'batch_size': 16, 'num_epochs': 1000, 'temperature': 0.21235176850774493, 'embedding_dim': 512, 'hidden_dim': 512, 'dropout': 0.39711822220109877, 'num_layers': 3, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.16386573749212538, 'crop_size': 0.5861100191320092}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:22:04,704 - INFO - Using device: cuda
2025-08-14 20:22:14,662 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:22:14,664 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:22:14,664 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:22:22,214 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-14 20:22:26,259 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-14 20:22:28,322 - INFO - Fold 1, Epoch 30: Val Acc: 0.56%
2025-08-14 20:22:30,378 - INFO - Fold 1, Epoch 40: Val Acc: 0.56%
2025-08-14 20:22:34,190 - INFO - Fold 1, Epoch 50: Val Acc: 0.56%
2025-08-14 20:22:36,249 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-14 20:22:38,300 - INFO - Fold 1, Epoch 70: Val Acc: 0.53%
2025-08-14 20:22:42,309 - INFO - Fold 1, Epoch 80: Val Acc: 0.62%
2025-08-14 20:22:44,292 - INFO - Fold 1, Epoch 90: Val Acc: 0.62%
2025-08-14 20:22:46,354 - INFO - Fold 1, Epoch 100: Val Acc: 0.66%
2025-08-14 20:22:48,420 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-14 20:22:50,473 - INFO - Fold 1, Epoch 120: Val Acc: 0.72%
2025-08-14 20:22:52,531 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-14 20:22:54,585 - INFO - Fold 1, Epoch 140: Val Acc: 0.69%
2025-08-14 20:22:58,447 - INFO - Fold 1, Epoch 150: Val Acc: 0.62%
2025-08-14 20:23:00,237 - INFO - Fold 1, Epoch 160: Val Acc: 0.69%
2025-08-14 20:23:02,157 - INFO - Fold 1, Epoch 170: Val Acc: 0.81%
2025-08-14 20:23:04,209 - INFO - Fold 1, Epoch 180: Val Acc: 0.66%
2025-08-14 20:23:06,259 - INFO - Fold 1, Epoch 190: Val Acc: 0.66%
2025-08-14 20:23:08,325 - INFO - Fold 1, Epoch 200: Val Acc: 0.72%
2025-08-14 20:23:10,386 - INFO - Fold 1, Epoch 210: Val Acc: 0.53%
2025-08-14 20:23:12,445 - INFO - Fold 1, Epoch 220: Val Acc: 0.81%
2025-08-14 20:23:14,499 - INFO - Fold 1, Epoch 230: Val Acc: 0.69%
2025-08-14 20:23:16,547 - INFO - Fold 1, Epoch 240: Val Acc: 0.69%
2025-08-14 20:23:17,168 - INFO - Early stopping at epoch 243
2025-08-14 20:23:20,021 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:23:20,036 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:23:20,036 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:23:29,189 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-14 20:23:32,459 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-14 20:23:35,673 - INFO - Fold 2, Epoch 30: Val Acc: 0.59%
2025-08-14 20:23:38,866 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-14 20:23:40,914 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-14 20:23:42,953 - INFO - Fold 2, Epoch 60: Val Acc: 0.62%
2025-08-14 20:23:44,996 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-14 20:23:47,040 - INFO - Fold 2, Epoch 80: Val Acc: 0.72%
2025-08-14 20:23:49,094 - INFO - Fold 2, Epoch 90: Val Acc: 0.75%
2025-08-14 20:23:51,150 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-14 20:23:53,203 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-14 20:23:55,239 - INFO - Fold 2, Epoch 120: Val Acc: 0.59%
2025-08-14 20:23:57,286 - INFO - Fold 2, Epoch 130: Val Acc: 0.62%
2025-08-14 20:23:58,513 - INFO - Early stopping at epoch 136
2025-08-14 20:24:01,219 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:24:01,222 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:24:01,222 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:24:05,839 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-14 20:24:09,079 - INFO - Fold 3, Epoch 20: Val Acc: 0.47%
2025-08-14 20:24:12,077 - INFO - Fold 3, Epoch 30: Val Acc: 0.56%
2025-08-14 20:24:14,121 - INFO - Fold 3, Epoch 40: Val Acc: 0.62%
2025-08-14 20:24:18,469 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-14 20:24:20,500 - INFO - Fold 3, Epoch 60: Val Acc: 0.66%
2025-08-14 20:24:22,522 - INFO - Fold 3, Epoch 70: Val Acc: 0.78%
2025-08-14 20:24:24,246 - INFO - Fold 3, Epoch 80: Val Acc: 0.66%
2025-08-14 20:24:26,206 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-14 20:24:28,234 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-14 20:24:30,286 - INFO - Fold 3, Epoch 110: Val Acc: 0.59%
2025-08-14 20:24:33,613 - INFO - Fold 3, Epoch 120: Val Acc: 0.66%
2025-08-14 20:24:35,669 - INFO - Fold 3, Epoch 130: Val Acc: 0.62%
2025-08-14 20:24:37,727 - INFO - Fold 3, Epoch 140: Val Acc: 0.66%
2025-08-14 20:24:39,789 - INFO - Fold 3, Epoch 150: Val Acc: 0.84%
2025-08-14 20:24:41,856 - INFO - Fold 3, Epoch 160: Val Acc: 0.81%
2025-08-14 20:24:43,912 - INFO - Fold 3, Epoch 170: Val Acc: 0.78%
2025-08-14 20:24:45,783 - INFO - Fold 3, Epoch 180: Val Acc: 0.78%
2025-08-14 20:24:47,580 - INFO - Fold 3, Epoch 190: Val Acc: 0.66%
2025-08-14 20:24:49,542 - INFO - Fold 3, Epoch 200: Val Acc: 0.66%
2025-08-14 20:24:51,579 - INFO - Fold 3, Epoch 210: Val Acc: 0.62%
2025-08-14 20:24:52,397 - INFO - Early stopping at epoch 214
2025-08-14 20:24:53,280 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.0732035636901855), 'std': np.float64(0.23421708583366607)}, 'train_accuracy': {'mean': np.float64(0.7465277777777777), 'std': np.float64(0.0597383699100183)}, 'val_loss': {'mean': np.float64(4.538129806518555), 'std': np.float64(0.047938560144346866)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(96.66666666666667), 'std': np.float64(45.18357617050199)}}
[I 2025-08-14 20:24:53,289] Trial 20 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0005291319140340516, 'batch_size': 32, 'num_epochs': 843, 'temperature': 0.10022138225048215, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.31993271959326175, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19776714085468816, 'crop_size': 0.5511637379978878}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 20 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0005291319140340516, 'batch_size': 32, 'num_epochs': 843, 'temperature': 0.10022138225048215, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.31993271959326175, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19776714085468816, 'crop_size': 0.5511637379978878}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:24:53,318 - INFO - Using device: cuda
2025-08-14 20:25:03,490 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:25:03,491 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:25:03,491 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:25:12,980 - INFO - Fold 1, Epoch 10: Val Acc: 0.62%
2025-08-14 20:25:19,147 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-14 20:25:21,082 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-14 20:25:24,926 - INFO - Fold 1, Epoch 40: Val Acc: 0.66%
2025-08-14 20:25:26,976 - INFO - Fold 1, Epoch 50: Val Acc: 0.69%
2025-08-14 20:25:29,045 - INFO - Fold 1, Epoch 60: Val Acc: 0.56%
2025-08-14 20:25:30,787 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-14 20:25:32,659 - INFO - Fold 1, Epoch 80: Val Acc: 0.59%
2025-08-14 20:25:34,692 - INFO - Fold 1, Epoch 90: Val Acc: 0.66%
2025-08-14 20:25:36,767 - INFO - Fold 1, Epoch 100: Val Acc: 0.66%
2025-08-14 20:25:38,845 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-14 20:25:40,925 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-14 20:25:43,003 - INFO - Fold 1, Epoch 130: Val Acc: 0.66%
2025-08-14 20:25:46,883 - INFO - Fold 1, Epoch 140: Val Acc: 0.62%
2025-08-14 20:25:50,634 - INFO - Fold 1, Epoch 150: Val Acc: 0.56%
2025-08-14 20:25:52,639 - INFO - Fold 1, Epoch 160: Val Acc: 0.62%
2025-08-14 20:25:54,625 - INFO - Fold 1, Epoch 170: Val Acc: 0.62%
2025-08-14 20:25:56,655 - INFO - Fold 1, Epoch 180: Val Acc: 0.59%
2025-08-14 20:25:58,665 - INFO - Fold 1, Epoch 190: Val Acc: 0.78%
2025-08-14 20:26:00,723 - INFO - Fold 1, Epoch 200: Val Acc: 0.66%
2025-08-14 20:26:02,779 - INFO - Fold 1, Epoch 210: Val Acc: 0.78%
2025-08-14 20:26:04,831 - INFO - Fold 1, Epoch 220: Val Acc: 0.56%
2025-08-14 20:26:06,807 - INFO - Fold 1, Epoch 230: Val Acc: 0.69%
2025-08-14 20:26:08,665 - INFO - Fold 1, Epoch 240: Val Acc: 0.66%
2025-08-14 20:26:09,363 - INFO - Early stopping at epoch 244
2025-08-14 20:26:12,161 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:26:12,164 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:26:12,165 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:26:18,016 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-14 20:26:20,083 - INFO - Fold 2, Epoch 20: Val Acc: 0.53%
2025-08-14 20:26:23,272 - INFO - Fold 2, Epoch 30: Val Acc: 0.66%
2025-08-14 20:26:25,102 - INFO - Fold 2, Epoch 40: Val Acc: 0.62%
2025-08-14 20:26:28,077 - INFO - Fold 2, Epoch 50: Val Acc: 0.66%
2025-08-14 20:26:30,145 - INFO - Fold 2, Epoch 60: Val Acc: 0.81%
2025-08-14 20:26:33,513 - INFO - Fold 2, Epoch 70: Val Acc: 0.69%
2025-08-14 20:26:35,565 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-14 20:26:37,634 - INFO - Fold 2, Epoch 90: Val Acc: 0.66%
2025-08-14 20:26:39,696 - INFO - Fold 2, Epoch 100: Val Acc: 0.69%
2025-08-14 20:26:41,767 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-14 20:26:43,838 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-14 20:26:47,107 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-14 20:26:49,137 - INFO - Fold 2, Epoch 140: Val Acc: 0.69%
2025-08-14 20:26:51,197 - INFO - Fold 2, Epoch 150: Val Acc: 0.81%
2025-08-14 20:26:53,343 - INFO - Fold 2, Epoch 160: Val Acc: 0.62%
2025-08-14 20:26:56,396 - INFO - Fold 2, Epoch 170: Val Acc: 0.72%
2025-08-14 20:26:58,259 - INFO - Fold 2, Epoch 180: Val Acc: 0.75%
2025-08-14 20:27:00,201 - INFO - Fold 2, Epoch 190: Val Acc: 0.75%
2025-08-14 20:27:02,339 - INFO - Fold 2, Epoch 200: Val Acc: 0.72%
2025-08-14 20:27:04,336 - INFO - Fold 2, Epoch 210: Val Acc: 0.84%
2025-08-14 20:27:06,034 - INFO - Fold 2, Epoch 220: Val Acc: 0.75%
2025-08-14 20:27:07,729 - INFO - Fold 2, Epoch 230: Val Acc: 0.81%
2025-08-14 20:27:09,530 - INFO - Fold 2, Epoch 240: Val Acc: 0.66%
2025-08-14 20:27:11,343 - INFO - Fold 2, Epoch 250: Val Acc: 0.75%
2025-08-14 20:27:13,161 - INFO - Fold 2, Epoch 260: Val Acc: 0.75%
2025-08-14 20:27:14,023 - INFO - Early stopping at epoch 265
2025-08-14 20:27:14,907 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:27:14,909 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:27:14,909 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:27:19,664 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-14 20:27:23,930 - INFO - Fold 3, Epoch 20: Val Acc: 0.56%
2025-08-14 20:27:25,683 - INFO - Fold 3, Epoch 30: Val Acc: 0.59%
2025-08-14 20:27:27,494 - INFO - Fold 3, Epoch 40: Val Acc: 0.59%
2025-08-14 20:27:29,530 - INFO - Fold 3, Epoch 50: Val Acc: 0.53%
2025-08-14 20:27:32,622 - INFO - Fold 3, Epoch 60: Val Acc: 0.56%
2025-08-14 20:27:34,672 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-14 20:27:38,025 - INFO - Fold 3, Epoch 80: Val Acc: 0.69%
2025-08-14 20:27:40,072 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-14 20:27:42,128 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-14 20:27:46,572 - INFO - Fold 3, Epoch 110: Val Acc: 0.59%
2025-08-14 20:27:48,598 - INFO - Fold 3, Epoch 120: Val Acc: 0.66%
2025-08-14 20:27:50,732 - INFO - Fold 3, Epoch 130: Val Acc: 0.69%
2025-08-14 20:27:52,859 - INFO - Fold 3, Epoch 140: Val Acc: 0.75%
2025-08-14 20:27:54,799 - INFO - Fold 3, Epoch 150: Val Acc: 0.56%
2025-08-14 20:27:56,746 - INFO - Fold 3, Epoch 160: Val Acc: 0.72%
2025-08-14 20:27:58,792 - INFO - Fold 3, Epoch 170: Val Acc: 0.81%
2025-08-14 20:28:00,830 - INFO - Fold 3, Epoch 180: Val Acc: 0.69%
2025-08-14 20:28:02,467 - INFO - Fold 3, Epoch 190: Val Acc: 0.69%
2025-08-14 20:28:04,479 - INFO - Fold 3, Epoch 200: Val Acc: 0.66%
2025-08-14 20:28:06,121 - INFO - Early stopping at epoch 208
2025-08-14 20:28:06,996 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.8776485919952393), 'std': np.float64(0.0014288457205491138)}, 'train_accuracy': {'mean': np.float64(0.8229166666666666), 'std': np.float64(0.0450051437389435)}, 'val_loss': {'mean': np.float64(4.416365146636963), 'std': np.float64(0.22936109642320218)}, 'val_accuracy': {'mean': np.float64(0.9270833333333334), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(138.0), 'std': np.float64(23.53720459187964)}}
[I 2025-08-14 20:28:07,003] Trial 21 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0006299556639204547, 'batch_size': 32, 'num_epochs': 865, 'temperature': 0.1042463129778088, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.45396241867321213, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1991060996194559, 'crop_size': 0.5527884560050629}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 21 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0006299556639204547, 'batch_size': 32, 'num_epochs': 865, 'temperature': 0.1042463129778088, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.45396241867321213, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1991060996194559, 'crop_size': 0.5527884560050629}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:28:07,031 - INFO - Using device: cuda
2025-08-14 20:28:17,281 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:28:17,283 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:28:17,283 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:28:28,901 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-14 20:28:32,967 - INFO - Fold 1, Epoch 20: Val Acc: 0.53%
2025-08-14 20:28:34,872 - INFO - Fold 1, Epoch 30: Val Acc: 0.59%
2025-08-14 20:28:40,384 - INFO - Fold 1, Epoch 40: Val Acc: 0.56%
2025-08-14 20:28:42,461 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-14 20:28:46,407 - INFO - Fold 1, Epoch 60: Val Acc: 0.66%
2025-08-14 20:28:48,467 - INFO - Fold 1, Epoch 70: Val Acc: 0.62%
2025-08-14 20:28:50,528 - INFO - Fold 1, Epoch 80: Val Acc: 0.75%
2025-08-14 20:28:52,565 - INFO - Fold 1, Epoch 90: Val Acc: 0.62%
2025-08-14 20:28:54,598 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-14 20:28:56,626 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-14 20:28:58,757 - INFO - Fold 1, Epoch 120: Val Acc: 0.56%
2025-08-14 20:29:00,675 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-14 20:29:02,497 - INFO - Fold 1, Epoch 140: Val Acc: 0.59%
2025-08-14 20:29:04,327 - INFO - Fold 1, Epoch 150: Val Acc: 0.59%
2025-08-14 20:29:05,194 - INFO - Early stopping at epoch 155
2025-08-14 20:29:08,500 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:29:08,503 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:29:08,503 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:29:15,568 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-14 20:29:18,570 - INFO - Fold 2, Epoch 20: Val Acc: 0.62%
2025-08-14 20:29:20,296 - INFO - Fold 2, Epoch 30: Val Acc: 0.66%
2025-08-14 20:29:24,479 - INFO - Fold 2, Epoch 40: Val Acc: 0.62%
2025-08-14 20:29:26,298 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-14 20:29:29,602 - INFO - Fold 2, Epoch 60: Val Acc: 0.59%
2025-08-14 20:29:31,733 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-14 20:29:33,836 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-14 20:29:35,901 - INFO - Fold 2, Epoch 90: Val Acc: 0.66%
2025-08-14 20:29:37,980 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-14 20:29:39,780 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-14 20:29:41,828 - INFO - Fold 2, Epoch 120: Val Acc: 0.88%
2025-08-14 20:29:43,960 - INFO - Fold 2, Epoch 130: Val Acc: 0.88%
2025-08-14 20:29:47,328 - INFO - Fold 2, Epoch 140: Val Acc: 0.69%
2025-08-14 20:29:49,273 - INFO - Fold 2, Epoch 150: Val Acc: 0.78%
2025-08-14 20:29:51,164 - INFO - Fold 2, Epoch 160: Val Acc: 0.81%
2025-08-14 20:29:53,180 - INFO - Fold 2, Epoch 170: Val Acc: 0.81%
2025-08-14 20:29:55,223 - INFO - Fold 2, Epoch 180: Val Acc: 0.84%
2025-08-14 20:29:57,268 - INFO - Fold 2, Epoch 190: Val Acc: 0.66%
2025-08-14 20:29:59,163 - INFO - Fold 2, Epoch 200: Val Acc: 0.84%
2025-08-14 20:30:00,765 - INFO - Fold 2, Epoch 210: Val Acc: 0.84%
2025-08-14 20:30:02,517 - INFO - Fold 2, Epoch 220: Val Acc: 0.59%
2025-08-14 20:30:04,370 - INFO - Fold 2, Epoch 230: Val Acc: 0.84%
2025-08-14 20:30:05,497 - INFO - Early stopping at epoch 236
2025-08-14 20:30:08,037 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:30:08,040 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:30:08,040 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:30:14,889 - INFO - Fold 3, Epoch 10: Val Acc: 0.66%
2025-08-14 20:30:18,291 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-14 20:30:21,605 - INFO - Fold 3, Epoch 30: Val Acc: 0.62%
2025-08-14 20:30:23,437 - INFO - Fold 3, Epoch 40: Val Acc: 0.72%
2025-08-14 20:30:25,254 - INFO - Fold 3, Epoch 50: Val Acc: 0.59%
2025-08-14 20:30:27,079 - INFO - Fold 3, Epoch 60: Val Acc: 0.56%
2025-08-14 20:30:30,264 - INFO - Fold 3, Epoch 70: Val Acc: 0.78%
2025-08-14 20:30:32,247 - INFO - Fold 3, Epoch 80: Val Acc: 0.81%
2025-08-14 20:30:34,175 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-14 20:30:36,088 - INFO - Fold 3, Epoch 100: Val Acc: 0.84%
2025-08-14 20:30:38,115 - INFO - Fold 3, Epoch 110: Val Acc: 0.72%
2025-08-14 20:30:40,175 - INFO - Fold 3, Epoch 120: Val Acc: 0.69%
2025-08-14 20:30:42,226 - INFO - Fold 3, Epoch 130: Val Acc: 0.78%
2025-08-14 20:30:44,285 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-14 20:30:46,256 - INFO - Fold 3, Epoch 150: Val Acc: 0.66%
2025-08-14 20:30:48,257 - INFO - Fold 3, Epoch 160: Val Acc: 0.84%
2025-08-14 20:30:49,286 - INFO - Early stopping at epoch 165
2025-08-14 20:30:50,167 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.880262560314602), 'std': np.float64(0.14568756520916698)}, 'train_accuracy': {'mean': np.float64(0.7777777777777777), 'std': np.float64(0.06874649261535878)}, 'val_loss': {'mean': np.float64(4.414842923482259), 'std': np.float64(0.17986804902766723)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.05311478659992484)}, 'epoch': {'mean': np.float64(84.33333333333333), 'std': np.float64(36.058594290712755)}}
[I 2025-08-14 20:30:50,174] Trial 22 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0008172970405324826, 'batch_size': 32, 'num_epochs': 938, 'temperature': 0.10057828938337642, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4479329644496811, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.17267383356703042, 'crop_size': 0.6258811334801759}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 22 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0008172970405324826, 'batch_size': 32, 'num_epochs': 938, 'temperature': 0.10057828938337642, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4479329644496811, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.17267383356703042, 'crop_size': 0.6258811334801759}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:30:50,202 - INFO - Using device: cuda
2025-08-14 20:31:00,338 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:31:00,340 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:31:00,340 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:31:09,784 - INFO - Fold 1, Epoch 10: Val Acc: 0.62%
2025-08-14 20:31:12,054 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-14 20:31:14,315 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 20:31:18,893 - INFO - Fold 1, Epoch 40: Val Acc: 0.44%
2025-08-14 20:31:21,226 - INFO - Fold 1, Epoch 50: Val Acc: 0.53%
2025-08-14 20:31:23,570 - INFO - Fold 1, Epoch 60: Val Acc: 0.62%
2025-08-14 20:31:25,857 - INFO - Fold 1, Epoch 70: Val Acc: 0.59%
2025-08-14 20:31:30,243 - INFO - Fold 1, Epoch 80: Val Acc: 0.56%
2025-08-14 20:31:32,513 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-14 20:31:34,879 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-14 20:31:37,242 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-14 20:31:39,610 - INFO - Fold 1, Epoch 120: Val Acc: 0.53%
2025-08-14 20:31:41,951 - INFO - Fold 1, Epoch 130: Val Acc: 0.47%
2025-08-14 20:31:44,285 - INFO - Fold 1, Epoch 140: Val Acc: 0.62%
2025-08-14 20:31:48,393 - INFO - Fold 1, Epoch 150: Val Acc: 0.50%
2025-08-14 20:31:50,133 - INFO - Fold 1, Epoch 160: Val Acc: 0.59%
2025-08-14 20:31:51,882 - INFO - Fold 1, Epoch 170: Val Acc: 0.56%
2025-08-14 20:31:53,937 - INFO - Fold 1, Epoch 180: Val Acc: 0.75%
2025-08-14 20:31:56,185 - INFO - Fold 1, Epoch 190: Val Acc: 0.59%
2025-08-14 20:31:58,427 - INFO - Fold 1, Epoch 200: Val Acc: 0.56%
2025-08-14 20:32:00,700 - INFO - Fold 1, Epoch 210: Val Acc: 0.59%
2025-08-14 20:32:02,970 - INFO - Fold 1, Epoch 220: Val Acc: 0.62%
2025-08-14 20:32:04,919 - INFO - Fold 1, Epoch 230: Val Acc: 0.72%
2025-08-14 20:32:06,654 - INFO - Fold 1, Epoch 240: Val Acc: 0.50%
2025-08-14 20:32:07,403 - INFO - Early stopping at epoch 244
2025-08-14 20:32:11,149 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:32:11,151 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:32:11,151 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:32:18,507 - INFO - Fold 2, Epoch 10: Val Acc: 0.44%
2025-08-14 20:32:20,819 - INFO - Fold 2, Epoch 20: Val Acc: 0.53%
2025-08-14 20:32:23,091 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-14 20:32:25,354 - INFO - Fold 2, Epoch 40: Val Acc: 0.53%
2025-08-14 20:32:27,713 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-14 20:32:31,561 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-14 20:32:33,843 - INFO - Fold 2, Epoch 70: Val Acc: 0.47%
2025-08-14 20:32:36,138 - INFO - Fold 2, Epoch 80: Val Acc: 0.62%
2025-08-14 20:32:38,420 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-14 20:32:40,691 - INFO - Fold 2, Epoch 100: Val Acc: 0.69%
2025-08-14 20:32:42,962 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-14 20:32:46,120 - INFO - Fold 2, Epoch 120: Val Acc: 0.84%
2025-08-14 20:32:48,108 - INFO - Fold 2, Epoch 130: Val Acc: 0.62%
2025-08-14 20:32:50,060 - INFO - Fold 2, Epoch 140: Val Acc: 0.66%
2025-08-14 20:32:52,171 - INFO - Fold 2, Epoch 150: Val Acc: 0.78%
2025-08-14 20:32:54,441 - INFO - Fold 2, Epoch 160: Val Acc: 0.56%
2025-08-14 20:32:56,705 - INFO - Fold 2, Epoch 170: Val Acc: 0.72%
2025-08-14 20:32:58,970 - INFO - Fold 2, Epoch 180: Val Acc: 0.72%
2025-08-14 20:33:01,150 - INFO - Fold 2, Epoch 190: Val Acc: 0.75%
2025-08-14 20:33:02,940 - INFO - Fold 2, Epoch 200: Val Acc: 0.69%
2025-08-14 20:33:04,897 - INFO - Fold 2, Epoch 210: Val Acc: 0.72%
2025-08-14 20:33:06,838 - INFO - Early stopping at epoch 220
2025-08-14 20:33:07,907 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:33:07,909 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:33:07,909 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:33:12,672 - INFO - Fold 3, Epoch 10: Val Acc: 0.38%
2025-08-14 20:33:16,394 - INFO - Fold 3, Epoch 20: Val Acc: 0.56%
2025-08-14 20:33:19,740 - INFO - Fold 3, Epoch 30: Val Acc: 0.62%
2025-08-14 20:33:21,696 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-14 20:33:25,151 - INFO - Fold 3, Epoch 50: Val Acc: 0.59%
2025-08-14 20:33:28,802 - INFO - Fold 3, Epoch 60: Val Acc: 0.62%
2025-08-14 20:33:31,085 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-14 20:33:33,401 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-14 20:33:35,710 - INFO - Fold 3, Epoch 90: Val Acc: 0.53%
2025-08-14 20:33:39,460 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-14 20:33:41,725 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-14 20:33:44,000 - INFO - Fold 3, Epoch 120: Val Acc: 0.66%
2025-08-14 20:33:47,593 - INFO - Fold 3, Epoch 130: Val Acc: 0.59%
2025-08-14 20:33:49,865 - INFO - Fold 3, Epoch 140: Val Acc: 0.62%
2025-08-14 20:33:52,139 - INFO - Fold 3, Epoch 150: Val Acc: 0.59%
2025-08-14 20:33:54,419 - INFO - Fold 3, Epoch 160: Val Acc: 0.69%
2025-08-14 20:33:56,572 - INFO - Fold 3, Epoch 170: Val Acc: 0.59%
2025-08-14 20:33:58,758 - INFO - Fold 3, Epoch 180: Val Acc: 0.66%
2025-08-14 20:34:01,034 - INFO - Fold 3, Epoch 190: Val Acc: 0.62%
2025-08-14 20:34:03,197 - INFO - Fold 3, Epoch 200: Val Acc: 0.66%
2025-08-14 20:34:05,464 - INFO - Fold 3, Epoch 210: Val Acc: 0.66%
2025-08-14 20:34:07,735 - INFO - Fold 3, Epoch 220: Val Acc: 0.66%
2025-08-14 20:34:07,961 - INFO - Early stopping at epoch 221
2025-08-14 20:34:11,007 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.283098936080933), 'std': np.float64(0.09763004598883294)}, 'train_accuracy': {'mean': np.float64(0.6527777777777778), 'std': np.float64(0.04280843057617342)}, 'val_loss': {'mean': np.float64(4.9662472407023115), 'std': np.float64(0.0019312658151345234)}, 'val_accuracy': {'mean': np.float64(0.8541666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(127.33333333333333), 'std': np.float64(11.08552609887726)}}
[I 2025-08-14 20:34:11,020] Trial 23 finished with value: -0.8541666666666666 and parameters: {'learning_rate': 0.0003722951980070698, 'batch_size': 32, 'num_epochs': 901, 'temperature': 0.05926235249521605, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.45673479459022837, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1995440643166886, 'crop_size': 0.5556122047437086}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 23 finished with value: -0.8541666666666666 and parameters: {'learning_rate': 0.0003722951980070698, 'batch_size': 32, 'num_epochs': 901, 'temperature': 0.05926235249521605, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.45673479459022837, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1995440643166886, 'crop_size': 0.5556122047437086}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:34:11,091 - INFO - Using device: cuda
2025-08-14 20:34:21,216 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:34:21,217 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:34:21,218 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:34:25,304 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-14 20:34:26,916 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-14 20:34:28,533 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 20:34:31,067 - INFO - Fold 1, Epoch 40: Val Acc: 0.78%
2025-08-14 20:34:32,778 - INFO - Fold 1, Epoch 50: Val Acc: 0.62%
2025-08-14 20:34:34,394 - INFO - Fold 1, Epoch 60: Val Acc: 0.62%
2025-08-14 20:34:35,998 - INFO - Fold 1, Epoch 70: Val Acc: 0.75%
2025-08-14 20:34:37,600 - INFO - Fold 1, Epoch 80: Val Acc: 0.53%
2025-08-14 20:34:39,201 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-14 20:34:40,809 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-14 20:34:42,413 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-14 20:34:44,019 - INFO - Fold 1, Epoch 120: Val Acc: 0.53%
2025-08-14 20:34:45,622 - INFO - Fold 1, Epoch 130: Val Acc: 0.50%
2025-08-14 20:34:47,233 - INFO - Early stopping at epoch 140
2025-08-14 20:34:48,744 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:34:48,748 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:34:48,749 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:34:53,351 - INFO - Fold 2, Epoch 10: Val Acc: 0.53%
2025-08-14 20:34:56,344 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-14 20:34:57,949 - INFO - Fold 2, Epoch 30: Val Acc: 0.47%
2025-08-14 20:35:00,356 - INFO - Fold 2, Epoch 40: Val Acc: 0.53%
2025-08-14 20:35:01,972 - INFO - Fold 2, Epoch 50: Val Acc: 0.62%
2025-08-14 20:35:03,612 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-14 20:35:05,272 - INFO - Fold 2, Epoch 70: Val Acc: 0.66%
2025-08-14 20:35:06,891 - INFO - Fold 2, Epoch 80: Val Acc: 0.72%
2025-08-14 20:35:08,301 - INFO - Fold 2, Epoch 90: Val Acc: 0.59%
2025-08-14 20:35:09,884 - INFO - Fold 2, Epoch 100: Val Acc: 0.53%
2025-08-14 20:35:11,481 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-14 20:35:12,947 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-14 20:35:14,490 - INFO - Fold 2, Epoch 130: Val Acc: 0.66%
2025-08-14 20:35:15,507 - INFO - Early stopping at epoch 138
2025-08-14 20:35:17,423 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:35:17,426 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:35:17,426 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:35:22,185 - INFO - Fold 3, Epoch 10: Val Acc: 0.44%
2025-08-14 20:35:25,163 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-14 20:35:26,781 - INFO - Fold 3, Epoch 30: Val Acc: 0.53%
2025-08-14 20:35:28,392 - INFO - Fold 3, Epoch 40: Val Acc: 0.47%
2025-08-14 20:35:30,002 - INFO - Fold 3, Epoch 50: Val Acc: 0.53%
2025-08-14 20:35:32,352 - INFO - Fold 3, Epoch 60: Val Acc: 0.50%
2025-08-14 20:35:33,955 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-14 20:35:35,576 - INFO - Fold 3, Epoch 80: Val Acc: 0.59%
2025-08-14 20:35:37,191 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-14 20:35:38,526 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-14 20:35:40,082 - INFO - Fold 3, Epoch 110: Val Acc: 0.53%
2025-08-14 20:35:41,683 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-14 20:35:44,058 - INFO - Fold 3, Epoch 130: Val Acc: 0.69%
2025-08-14 20:35:45,653 - INFO - Fold 3, Epoch 140: Val Acc: 0.62%
2025-08-14 20:35:47,139 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-14 20:35:48,674 - INFO - Fold 3, Epoch 160: Val Acc: 0.66%
2025-08-14 20:35:50,168 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-14 20:35:52,461 - INFO - Fold 3, Epoch 180: Val Acc: 0.50%
2025-08-14 20:35:54,066 - INFO - Fold 3, Epoch 190: Val Acc: 0.69%
2025-08-14 20:35:55,663 - INFO - Fold 3, Epoch 200: Val Acc: 0.56%
2025-08-14 20:35:57,257 - INFO - Fold 3, Epoch 210: Val Acc: 0.50%
2025-08-14 20:35:58,849 - INFO - Fold 3, Epoch 220: Val Acc: 0.72%
2025-08-14 20:36:00,455 - INFO - Fold 3, Epoch 230: Val Acc: 0.66%
2025-08-14 20:36:01,961 - INFO - Fold 3, Epoch 240: Val Acc: 0.84%
2025-08-14 20:36:03,560 - INFO - Fold 3, Epoch 250: Val Acc: 0.69%
2025-08-14 20:36:05,177 - INFO - Fold 3, Epoch 260: Val Acc: 0.72%
2025-08-14 20:36:06,788 - INFO - Fold 3, Epoch 270: Val Acc: 0.56%
2025-08-14 20:36:07,280 - INFO - Early stopping at epoch 273
2025-08-14 20:36:08,741 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.704151736365424), 'std': np.float64(0.3161554718777273)}, 'train_accuracy': {'mean': np.float64(0.6527777777777778), 'std': np.float64(0.0893380578490875)}, 'val_loss': {'mean': np.float64(5.397029717763265), 'std': np.float64(0.4586565803547559)}, 'val_accuracy': {'mean': np.float64(0.8229166666666666), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(82.66666666666667), 'std': np.float64(63.17348248188387)}}
[I 2025-08-14 20:36:08,750] Trial 24 finished with value: -0.8229166666666666 and parameters: {'learning_rate': 0.00022019747544827962, 'batch_size': 32, 'num_epochs': 638, 'temperature': 0.08354835007581063, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.39786596324610757, 'num_layers': 2, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1269493266591164, 'crop_size': 0.6312201793799115}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 24 finished with value: -0.8229166666666666 and parameters: {'learning_rate': 0.00022019747544827962, 'batch_size': 32, 'num_epochs': 638, 'temperature': 0.08354835007581063, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.39786596324610757, 'num_layers': 2, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1269493266591164, 'crop_size': 0.6312201793799115}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:36:08,823 - INFO - Using device: cuda
2025-08-14 20:36:19,189 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:36:19,190 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:36:19,190 - INFO - Starting training for fold 1/3
2025-08-14 20:36:26,035 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-14 20:36:30,507 - INFO - Fold 1, Epoch 20: Val Acc: 0.78%
2025-08-14 20:36:35,001 - INFO - Fold 1, Epoch 30: Val Acc: 0.66%
2025-08-14 20:36:37,261 - INFO - Fold 1, Epoch 40: Val Acc: 0.81%
2025-08-14 20:36:39,522 - INFO - Fold 1, Epoch 50: Val Acc: 0.62%
2025-08-14 20:36:41,635 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-14 20:36:43,902 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-14 20:36:46,186 - INFO - Fold 1, Epoch 80: Val Acc: 0.75%
2025-08-14 20:36:48,461 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-14 20:36:50,650 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-14 20:36:52,906 - INFO - Fold 1, Epoch 110: Val Acc: 0.75%
2025-08-14 20:36:55,172 - INFO - Fold 1, Epoch 120: Val Acc: 0.62%
2025-08-14 20:36:56,591 - INFO - Early stopping at epoch 126
2025-08-14 20:37:00,088 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:37:00,090 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:37:00,091 - INFO - Starting training for fold 2/3
2025-08-14 20:37:06,799 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-14 20:37:11,736 - INFO - Fold 2, Epoch 20: Val Acc: 0.62%
2025-08-14 20:37:14,009 - INFO - Fold 2, Epoch 30: Val Acc: 0.75%
2025-08-14 20:37:16,283 - INFO - Fold 2, Epoch 40: Val Acc: 0.78%
2025-08-14 20:37:19,976 - INFO - Fold 2, Epoch 50: Val Acc: 0.66%
2025-08-14 20:37:22,246 - INFO - Fold 2, Epoch 60: Val Acc: 0.78%
2025-08-14 20:37:25,922 - INFO - Fold 2, Epoch 70: Val Acc: 0.53%
2025-08-14 20:37:27,867 - INFO - Fold 2, Epoch 80: Val Acc: 0.81%
2025-08-14 20:37:29,601 - INFO - Fold 2, Epoch 90: Val Acc: 0.75%
2025-08-14 20:37:31,537 - INFO - Fold 2, Epoch 100: Val Acc: 0.88%
2025-08-14 20:37:33,792 - INFO - Fold 2, Epoch 110: Val Acc: 0.84%
2025-08-14 20:37:37,453 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-14 20:37:39,721 - INFO - Fold 2, Epoch 130: Val Acc: 0.72%
2025-08-14 20:37:41,998 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-14 20:37:43,966 - INFO - Fold 2, Epoch 150: Val Acc: 0.59%
2025-08-14 20:37:45,909 - INFO - Fold 2, Epoch 160: Val Acc: 0.75%
2025-08-14 20:37:47,848 - INFO - Fold 2, Epoch 170: Val Acc: 0.66%
2025-08-14 20:37:49,768 - INFO - Fold 2, Epoch 180: Val Acc: 0.72%
2025-08-14 20:37:51,681 - INFO - Fold 2, Epoch 190: Val Acc: 0.75%
2025-08-14 20:37:53,651 - INFO - Fold 2, Epoch 200: Val Acc: 0.66%
2025-08-14 20:37:55,592 - INFO - Fold 2, Epoch 210: Val Acc: 0.69%
2025-08-14 20:37:57,163 - INFO - Early stopping at epoch 219
2025-08-14 20:38:00,204 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:38:00,227 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:38:00,227 - INFO - Starting training for fold 3/3
2025-08-14 20:38:09,913 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-14 20:38:13,692 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-14 20:38:18,532 - INFO - Fold 3, Epoch 30: Val Acc: 0.75%
2025-08-14 20:38:20,782 - INFO - Fold 3, Epoch 40: Val Acc: 0.56%
2025-08-14 20:38:23,130 - INFO - Fold 3, Epoch 50: Val Acc: 0.75%
2025-08-14 20:38:25,415 - INFO - Fold 3, Epoch 60: Val Acc: 0.84%
2025-08-14 20:38:27,218 - INFO - Fold 3, Epoch 70: Val Acc: 0.78%
2025-08-14 20:38:30,469 - INFO - Fold 3, Epoch 80: Val Acc: 0.88%
2025-08-14 20:38:32,282 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-14 20:38:34,032 - INFO - Fold 3, Epoch 100: Val Acc: 0.66%
2025-08-14 20:38:35,777 - INFO - Fold 3, Epoch 110: Val Acc: 0.84%
2025-08-14 20:38:37,530 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-14 20:38:39,274 - INFO - Fold 3, Epoch 130: Val Acc: 0.78%
2025-08-14 20:38:41,183 - INFO - Fold 3, Epoch 140: Val Acc: 0.66%
2025-08-14 20:38:43,544 - INFO - Fold 3, Epoch 150: Val Acc: 0.66%
2025-08-14 20:38:45,898 - INFO - Fold 3, Epoch 160: Val Acc: 0.62%
2025-08-14 20:38:49,722 - INFO - Fold 3, Epoch 170: Val Acc: 0.59%
2025-08-14 20:38:52,085 - INFO - Fold 3, Epoch 180: Val Acc: 0.69%
2025-08-14 20:38:54,433 - INFO - Fold 3, Epoch 190: Val Acc: 0.88%
2025-08-14 20:38:56,793 - INFO - Fold 3, Epoch 200: Val Acc: 0.69%
2025-08-14 20:38:59,131 - INFO - Fold 3, Epoch 210: Val Acc: 0.69%
2025-08-14 20:39:01,274 - INFO - Fold 3, Epoch 220: Val Acc: 0.81%
2025-08-14 20:39:03,604 - INFO - Fold 3, Epoch 230: Val Acc: 0.66%
2025-08-14 20:39:05,610 - INFO - Fold 3, Epoch 240: Val Acc: 0.69%
2025-08-14 20:39:07,615 - INFO - Fold 3, Epoch 250: Val Acc: 0.62%
2025-08-14 20:39:09,633 - INFO - Fold 3, Epoch 260: Val Acc: 0.69%
2025-08-14 20:39:10,086 - INFO - Early stopping at epoch 262
2025-08-14 20:39:11,143 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.876043452156915), 'std': np.float64(0.11772121949948489)}, 'train_accuracy': {'mean': np.float64(0.7430555555555557), 'std': np.float64(0.06874649261535885)}, 'val_loss': {'mean': np.float64(4.2420417467753095), 'std': np.float64(0.0774372536896673)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(101.33333333333333), 'std': np.float64(56.75874871379351)}}
[I 2025-08-14 20:39:11,151] Trial 25 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0006456769080588797, 'batch_size': 32, 'num_epochs': 777, 'temperature': 0.3439774834639394, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4674775199638847, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.17459260164434315, 'crop_size': 0.5347984837854495}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 25 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0006456769080588797, 'batch_size': 32, 'num_epochs': 777, 'temperature': 0.3439774834639394, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4674775199638847, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.17459260164434315, 'crop_size': 0.5347984837854495}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:39:11,180 - INFO - Using device: cuda
2025-08-14 20:39:21,390 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:39:21,391 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:39:21,392 - INFO - Starting training for fold 1/3
2025-08-14 20:39:27,542 - INFO - Fold 1, Epoch 10: Val Acc: 0.44%
2025-08-14 20:39:29,654 - INFO - Fold 1, Epoch 20: Val Acc: 0.41%
2025-08-14 20:39:31,757 - INFO - Fold 1, Epoch 30: Val Acc: 0.53%
2025-08-14 20:39:33,884 - INFO - Fold 1, Epoch 40: Val Acc: 0.53%
2025-08-14 20:39:37,876 - INFO - Fold 1, Epoch 50: Val Acc: 0.50%
2025-08-14 20:39:40,042 - INFO - Fold 1, Epoch 60: Val Acc: 0.53%
2025-08-14 20:39:42,202 - INFO - Fold 1, Epoch 70: Val Acc: 0.44%
2025-08-14 20:39:44,369 - INFO - Fold 1, Epoch 80: Val Acc: 0.38%
2025-08-14 20:39:46,546 - INFO - Fold 1, Epoch 90: Val Acc: 0.50%
2025-08-14 20:39:48,804 - INFO - Fold 1, Epoch 100: Val Acc: 0.44%
2025-08-14 20:39:50,857 - INFO - Fold 1, Epoch 110: Val Acc: 0.44%
2025-08-14 20:39:52,713 - INFO - Fold 1, Epoch 120: Val Acc: 0.47%
2025-08-14 20:39:54,549 - INFO - Fold 1, Epoch 130: Val Acc: 0.38%
2025-08-14 20:39:56,636 - INFO - Fold 1, Epoch 140: Val Acc: 0.47%
2025-08-14 20:39:56,871 - INFO - Early stopping at epoch 141
2025-08-14 20:39:59,818 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:39:59,821 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:39:59,822 - INFO - Starting training for fold 2/3
2025-08-14 20:40:08,900 - INFO - Fold 2, Epoch 10: Val Acc: 0.47%
2025-08-14 20:40:10,928 - INFO - Fold 2, Epoch 20: Val Acc: 0.47%
2025-08-14 20:40:13,049 - INFO - Fold 2, Epoch 30: Val Acc: 0.50%
2025-08-14 20:40:16,217 - INFO - Fold 2, Epoch 40: Val Acc: 0.53%
2025-08-14 20:40:18,175 - INFO - Fold 2, Epoch 50: Val Acc: 0.62%
2025-08-14 20:40:21,423 - INFO - Fold 2, Epoch 60: Val Acc: 0.47%
2025-08-14 20:40:23,562 - INFO - Fold 2, Epoch 70: Val Acc: 0.59%
2025-08-14 20:40:25,511 - INFO - Fold 2, Epoch 80: Val Acc: 0.50%
2025-08-14 20:40:27,680 - INFO - Fold 2, Epoch 90: Val Acc: 0.59%
2025-08-14 20:40:29,892 - INFO - Fold 2, Epoch 100: Val Acc: 0.50%
2025-08-14 20:40:32,102 - INFO - Fold 2, Epoch 110: Val Acc: 0.59%
2025-08-14 20:40:34,315 - INFO - Fold 2, Epoch 120: Val Acc: 0.47%
2025-08-14 20:40:36,534 - INFO - Fold 2, Epoch 130: Val Acc: 0.56%
2025-08-14 20:40:38,602 - INFO - Fold 2, Epoch 140: Val Acc: 0.47%
2025-08-14 20:40:40,749 - INFO - Fold 2, Epoch 150: Val Acc: 0.47%
2025-08-14 20:40:40,963 - INFO - Early stopping at epoch 151
2025-08-14 20:40:41,920 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:40:41,921 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:40:41,922 - INFO - Starting training for fold 3/3
2025-08-14 20:40:50,414 - INFO - Fold 3, Epoch 10: Val Acc: 0.41%
2025-08-14 20:40:52,622 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-14 20:40:54,839 - INFO - Fold 3, Epoch 30: Val Acc: 0.53%
2025-08-14 20:40:56,983 - INFO - Fold 3, Epoch 40: Val Acc: 0.50%
2025-08-14 20:40:59,122 - INFO - Fold 3, Epoch 50: Val Acc: 0.44%
2025-08-14 20:41:01,270 - INFO - Fold 3, Epoch 60: Val Acc: 0.66%
2025-08-14 20:41:03,418 - INFO - Fold 3, Epoch 70: Val Acc: 0.44%
2025-08-14 20:41:05,235 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-14 20:41:07,368 - INFO - Fold 3, Epoch 90: Val Acc: 0.56%
2025-08-14 20:41:09,497 - INFO - Fold 3, Epoch 100: Val Acc: 0.56%
2025-08-14 20:41:11,205 - INFO - Early stopping at epoch 108
2025-08-14 20:41:12,116 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.368350929684109), 'std': np.float64(0.0939032186935982)}, 'train_accuracy': {'mean': np.float64(0.576388888888889), 'std': np.float64(0.03437324630767941)}, 'val_loss': {'mean': np.float64(4.5522074699401855), 'std': np.float64(0.027046499502346177)}, 'val_accuracy': {'mean': np.float64(0.6979166666666666), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(32.333333333333336), 'std': np.float64(18.372685039360892)}}
[I 2025-08-14 20:41:12,157] Trial 26 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 0.00041082557100710447, 'batch_size': 32, 'num_epochs': 823, 'temperature': 0.11762146618490442, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4065678962856345, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.15735284710071745, 'crop_size': 0.503652869769149}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 26 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 0.00041082557100710447, 'batch_size': 32, 'num_epochs': 823, 'temperature': 0.11762146618490442, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4065678962856345, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.15735284710071745, 'crop_size': 0.503652869769149}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:41:12,209 - INFO - Using device: cuda
2025-08-14 20:41:22,703 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:41:22,705 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:41:22,705 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:41:33,440 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-14 20:41:38,700 - INFO - Fold 1, Epoch 20: Val Acc: 0.69%
2025-08-14 20:41:41,251 - INFO - Fold 1, Epoch 30: Val Acc: 0.69%
2025-08-14 20:41:46,323 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-14 20:41:48,762 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-14 20:41:51,302 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-14 20:41:53,847 - INFO - Fold 1, Epoch 70: Val Acc: 0.59%
2025-08-14 20:41:56,343 - INFO - Fold 1, Epoch 80: Val Acc: 0.69%
2025-08-14 20:41:58,815 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-14 20:42:01,292 - INFO - Fold 1, Epoch 100: Val Acc: 0.62%
2025-08-14 20:42:03,767 - INFO - Fold 1, Epoch 110: Val Acc: 0.53%
2025-08-14 20:42:05,936 - INFO - Fold 1, Epoch 120: Val Acc: 0.66%
2025-08-14 20:42:11,031 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-14 20:42:13,540 - INFO - Fold 1, Epoch 140: Val Acc: 0.75%
2025-08-14 20:42:16,041 - INFO - Fold 1, Epoch 150: Val Acc: 0.66%
2025-08-14 20:42:18,511 - INFO - Fold 1, Epoch 160: Val Acc: 0.56%
2025-08-14 20:42:20,772 - INFO - Fold 1, Epoch 170: Val Acc: 0.62%
2025-08-14 20:42:22,958 - INFO - Fold 1, Epoch 180: Val Acc: 0.59%
2025-08-14 20:42:25,358 - INFO - Fold 1, Epoch 190: Val Acc: 0.66%
2025-08-14 20:42:27,864 - INFO - Fold 1, Epoch 200: Val Acc: 0.78%
2025-08-14 20:42:30,371 - INFO - Fold 1, Epoch 210: Val Acc: 0.69%
2025-08-14 20:42:32,891 - INFO - Fold 1, Epoch 220: Val Acc: 0.59%
2025-08-14 20:42:34,394 - INFO - Early stopping at epoch 226
2025-08-14 20:42:38,466 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:42:38,469 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:42:38,469 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:42:47,848 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-14 20:42:50,352 - INFO - Fold 2, Epoch 20: Val Acc: 0.56%
2025-08-14 20:42:52,860 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-14 20:42:56,929 - INFO - Fold 2, Epoch 40: Val Acc: 0.66%
2025-08-14 20:42:59,422 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-14 20:43:01,922 - INFO - Fold 2, Epoch 60: Val Acc: 0.88%
2025-08-14 20:43:04,484 - INFO - Fold 2, Epoch 70: Val Acc: 0.84%
2025-08-14 20:43:07,044 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-14 20:43:09,511 - INFO - Fold 2, Epoch 90: Val Acc: 0.84%
2025-08-14 20:43:11,914 - INFO - Fold 2, Epoch 100: Val Acc: 0.69%
2025-08-14 20:43:16,085 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-14 20:43:18,552 - INFO - Fold 2, Epoch 120: Val Acc: 0.94%
2025-08-14 20:43:20,912 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-14 20:43:23,413 - INFO - Fold 2, Epoch 140: Val Acc: 0.81%
2025-08-14 20:43:25,913 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-14 20:43:28,407 - INFO - Fold 2, Epoch 160: Val Acc: 0.88%
2025-08-14 20:43:30,911 - INFO - Fold 2, Epoch 170: Val Acc: 0.78%
2025-08-14 20:43:33,411 - INFO - Fold 2, Epoch 180: Val Acc: 0.75%
2025-08-14 20:43:35,912 - INFO - Fold 2, Epoch 190: Val Acc: 0.75%
2025-08-14 20:43:40,149 - INFO - Fold 2, Epoch 200: Val Acc: 0.88%
2025-08-14 20:43:42,450 - INFO - Fold 2, Epoch 210: Val Acc: 0.66%
2025-08-14 20:43:44,935 - INFO - Fold 2, Epoch 220: Val Acc: 0.81%
2025-08-14 20:43:47,432 - INFO - Fold 2, Epoch 230: Val Acc: 0.72%
2025-08-14 20:43:49,933 - INFO - Fold 2, Epoch 240: Val Acc: 0.75%
2025-08-14 20:43:52,419 - INFO - Fold 2, Epoch 250: Val Acc: 0.72%
2025-08-14 20:43:54,905 - INFO - Fold 2, Epoch 260: Val Acc: 0.81%
2025-08-14 20:43:57,372 - INFO - Fold 2, Epoch 270: Val Acc: 0.75%
2025-08-14 20:43:59,848 - INFO - Fold 2, Epoch 280: Val Acc: 0.78%
2025-08-14 20:44:02,337 - INFO - Fold 2, Epoch 290: Val Acc: 0.84%
2025-08-14 20:44:02,831 - INFO - Early stopping at epoch 292
2025-08-14 20:44:06,067 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:44:06,069 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:44:06,070 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:44:15,300 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-14 20:44:19,320 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-14 20:44:23,350 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-14 20:44:27,659 - INFO - Fold 3, Epoch 40: Val Acc: 0.81%
2025-08-14 20:44:30,223 - INFO - Fold 3, Epoch 50: Val Acc: 0.66%
2025-08-14 20:44:32,799 - INFO - Fold 3, Epoch 60: Val Acc: 0.72%
2025-08-14 20:44:35,379 - INFO - Fold 3, Epoch 70: Val Acc: 0.50%
2025-08-14 20:44:37,778 - INFO - Fold 3, Epoch 80: Val Acc: 0.69%
2025-08-14 20:44:39,945 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-14 20:44:42,203 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-14 20:44:44,391 - INFO - Fold 3, Epoch 110: Val Acc: 0.69%
2025-08-14 20:44:46,576 - INFO - Fold 3, Epoch 120: Val Acc: 0.66%
2025-08-14 20:44:48,759 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-14 20:44:48,971 - INFO - Early stopping at epoch 131
2025-08-14 20:44:50,293 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.7772328853607178), 'std': np.float64(0.17215733128865843)}, 'train_accuracy': {'mean': np.float64(0.8402777777777777), 'std': np.float64(0.0743088005521969)}, 'val_loss': {'mean': np.float64(4.313275496164958), 'std': np.float64(0.12231041875145407)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.05892556509887896)}, 'epoch': {'mean': np.float64(115.33333333333333), 'std': np.float64(66.08244009484585)}}
[I 2025-08-14 20:44:50,306] Trial 27 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.00021192033260971922, 'batch_size': 32, 'num_epochs': 924, 'temperature': 0.18940435417109208, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.34647329757148604, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18088631583986903, 'crop_size': 0.8971980342960614}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 27 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.00021192033260971922, 'batch_size': 32, 'num_epochs': 924, 'temperature': 0.18940435417109208, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.34647329757148604, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18088631583986903, 'crop_size': 0.8971980342960614}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:44:50,357 - INFO - Using device: cuda
2025-08-14 20:45:00,041 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:45:00,046 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:45:00,047 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:45:10,436 - INFO - Fold 1, Epoch 10: Val Acc: 0.44%
2025-08-14 20:45:15,127 - INFO - Fold 1, Epoch 20: Val Acc: 0.60%
2025-08-14 20:45:18,082 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-14 20:45:21,060 - INFO - Fold 1, Epoch 40: Val Acc: 0.58%
2025-08-14 20:45:24,024 - INFO - Fold 1, Epoch 50: Val Acc: 0.65%
2025-08-14 20:45:28,345 - INFO - Fold 1, Epoch 60: Val Acc: 0.67%
2025-08-14 20:45:31,296 - INFO - Fold 1, Epoch 70: Val Acc: 0.60%
2025-08-14 20:45:33,790 - INFO - Fold 1, Epoch 80: Val Acc: 0.73%
2025-08-14 20:45:36,583 - INFO - Fold 1, Epoch 90: Val Acc: 0.60%
2025-08-14 20:45:39,175 - INFO - Fold 1, Epoch 100: Val Acc: 0.65%
2025-08-14 20:45:41,472 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-14 20:45:44,444 - INFO - Fold 1, Epoch 120: Val Acc: 0.67%
2025-08-14 20:45:47,395 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-14 20:45:50,347 - INFO - Fold 1, Epoch 140: Val Acc: 0.77%
2025-08-14 20:45:53,309 - INFO - Fold 1, Epoch 150: Val Acc: 0.65%
2025-08-14 20:45:53,606 - INFO - Early stopping at epoch 151
2025-08-14 20:45:55,829 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:45:55,831 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:45:55,832 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:46:01,468 - INFO - Fold 2, Epoch 10: Val Acc: 0.67%
2025-08-14 20:46:06,353 - INFO - Fold 2, Epoch 20: Val Acc: 0.67%
2025-08-14 20:46:09,328 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-14 20:46:12,282 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-14 20:46:16,240 - INFO - Fold 2, Epoch 50: Val Acc: 0.65%
2025-08-14 20:46:20,246 - INFO - Fold 2, Epoch 60: Val Acc: 0.71%
2025-08-14 20:46:23,152 - INFO - Fold 2, Epoch 70: Val Acc: 0.69%
2025-08-14 20:46:26,128 - INFO - Fold 2, Epoch 80: Val Acc: 0.77%
2025-08-14 20:46:29,079 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-14 20:46:32,926 - INFO - Fold 2, Epoch 100: Val Acc: 0.85%
2025-08-14 20:46:35,844 - INFO - Fold 2, Epoch 110: Val Acc: 0.73%
2025-08-14 20:46:38,528 - INFO - Fold 2, Epoch 120: Val Acc: 0.60%
2025-08-14 20:46:41,299 - INFO - Fold 2, Epoch 130: Val Acc: 0.77%
2025-08-14 20:46:44,234 - INFO - Fold 2, Epoch 140: Val Acc: 0.81%
2025-08-14 20:46:47,133 - INFO - Fold 2, Epoch 150: Val Acc: 0.73%
2025-08-14 20:46:50,040 - INFO - Fold 2, Epoch 160: Val Acc: 0.67%
2025-08-14 20:46:52,982 - INFO - Fold 2, Epoch 170: Val Acc: 0.81%
2025-08-14 20:46:55,931 - INFO - Fold 2, Epoch 180: Val Acc: 0.73%
2025-08-14 20:46:59,921 - INFO - Fold 2, Epoch 190: Val Acc: 0.73%
2025-08-14 20:47:02,833 - INFO - Fold 2, Epoch 200: Val Acc: 0.67%
2025-08-14 20:47:05,678 - INFO - Fold 2, Epoch 210: Val Acc: 0.69%
2025-08-14 20:47:08,621 - INFO - Fold 2, Epoch 220: Val Acc: 0.75%
2025-08-14 20:47:11,301 - INFO - Fold 2, Epoch 230: Val Acc: 0.79%
2025-08-14 20:47:14,204 - INFO - Fold 2, Epoch 240: Val Acc: 0.79%
2025-08-14 20:47:17,025 - INFO - Fold 2, Epoch 250: Val Acc: 0.75%
2025-08-14 20:47:19,554 - INFO - Fold 2, Epoch 260: Val Acc: 0.69%
2025-08-14 20:47:22,500 - INFO - Fold 2, Epoch 270: Val Acc: 0.67%
2025-08-14 20:47:25,262 - INFO - Fold 2, Epoch 280: Val Acc: 0.79%
2025-08-14 20:47:26,310 - INFO - Early stopping at epoch 284
2025-08-14 20:47:26,981 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:47:26,983 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:47:26,983 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:47:31,824 - INFO - Fold 3, Epoch 10: Val Acc: 0.54%
2025-08-14 20:47:34,155 - INFO - Fold 3, Epoch 20: Val Acc: 0.56%
2025-08-14 20:47:37,297 - INFO - Fold 3, Epoch 30: Val Acc: 0.67%
2025-08-14 20:47:40,687 - INFO - Fold 3, Epoch 40: Val Acc: 0.77%
2025-08-14 20:47:44,646 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-14 20:47:47,558 - INFO - Fold 3, Epoch 60: Val Acc: 0.77%
2025-08-14 20:47:50,287 - INFO - Fold 3, Epoch 70: Val Acc: 0.77%
2025-08-14 20:47:53,013 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-14 20:47:55,708 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-14 20:47:58,734 - INFO - Fold 3, Epoch 100: Val Acc: 0.65%
2025-08-14 20:48:01,585 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-14 20:48:05,556 - INFO - Fold 3, Epoch 120: Val Acc: 0.60%
2025-08-14 20:48:08,488 - INFO - Fold 3, Epoch 130: Val Acc: 0.79%
2025-08-14 20:48:11,501 - INFO - Fold 3, Epoch 140: Val Acc: 0.73%
2025-08-14 20:48:14,584 - INFO - Fold 3, Epoch 150: Val Acc: 0.81%
2025-08-14 20:48:18,216 - INFO - Fold 3, Epoch 160: Val Acc: 0.67%
2025-08-14 20:48:20,883 - INFO - Fold 3, Epoch 170: Val Acc: 0.77%
2025-08-14 20:48:23,614 - INFO - Fold 3, Epoch 180: Val Acc: 0.85%
2025-08-14 20:48:26,207 - INFO - Fold 3, Epoch 190: Val Acc: 0.71%
2025-08-14 20:48:29,691 - INFO - Fold 3, Epoch 200: Val Acc: 0.67%
2025-08-14 20:48:32,430 - INFO - Fold 3, Epoch 210: Val Acc: 0.71%
2025-08-14 20:48:35,126 - INFO - Fold 3, Epoch 220: Val Acc: 0.69%
2025-08-14 20:48:38,201 - INFO - Fold 3, Epoch 230: Val Acc: 0.71%
2025-08-14 20:48:41,268 - INFO - Fold 3, Epoch 240: Val Acc: 0.69%
2025-08-14 20:48:44,354 - INFO - Fold 3, Epoch 250: Val Acc: 0.71%
2025-08-14 20:48:47,318 - INFO - Fold 3, Epoch 260: Val Acc: 0.73%
2025-08-14 20:48:50,344 - INFO - Fold 3, Epoch 270: Val Acc: 0.60%
2025-08-14 20:48:53,312 - INFO - Fold 3, Epoch 280: Val Acc: 0.88%
2025-08-14 20:48:56,288 - INFO - Fold 3, Epoch 290: Val Acc: 0.77%
2025-08-14 20:48:58,892 - INFO - Early stopping at epoch 299
2025-08-14 20:48:59,583 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(2.932838042577108), 'std': np.float64(0.2483211959808916)}, 'train_accuracy': {'mean': np.float64(0.857638888888889), 'std': np.float64(0.039283710065919374)}, 'val_loss': {'mean': np.float64(3.710013230641683), 'std': np.float64(0.17226853801295386)}, 'val_accuracy': {'mean': np.float64(0.875), 'std': np.float64(0.0)}, 'epoch': {'mean': np.float64(143.66666666666666), 'std': np.float64(66.51482708556208)}}
[I 2025-08-14 20:48:59,590] Trial 28 finished with value: -0.875 and parameters: {'learning_rate': 0.0007693385750395794, 'batch_size': 16, 'num_epochs': 993, 'temperature': 0.051735589327389205, 'embedding_dim': 256, 'hidden_dim': 128, 'dropout': 0.10080780072617918, 'num_layers': 3, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.059133514804361687, 'crop_size': 0.6190498390393434}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 28 finished with value: -0.875 and parameters: {'learning_rate': 0.0007693385750395794, 'batch_size': 16, 'num_epochs': 993, 'temperature': 0.051735589327389205, 'embedding_dim': 256, 'hidden_dim': 128, 'dropout': 0.10080780072617918, 'num_layers': 3, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.059133514804361687, 'crop_size': 0.6190498390393434}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:48:59,616 - INFO - Using device: cuda
2025-08-14 20:49:09,287 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:49:09,298 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:49:09,298 - WARNING - Fold 1 has insufficient pairs to form a batch. Skipping.
2025-08-14 20:49:09,299 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:49:09,308 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:49:09,308 - WARNING - Fold 2 has insufficient pairs to form a batch. Skipping.
2025-08-14 20:49:09,308 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:49:09,309 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:49:09,309 - WARNING - Fold 3 has insufficient pairs to form a batch. Skipping.
2025-08-14 20:49:09,309 - WARNING - No folds completed successfully to aggregate metrics.
[I 2025-08-14 20:49:09,312] Trial 29 finished with value: inf and parameters: {'learning_rate': 0.00011748905714946802, 'batch_size': 64, 'num_epochs': 656, 'temperature': 0.30637086244029904, 'embedding_dim': 512, 'hidden_dim': 512, 'dropout': 0.37403512436889225, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.14839325742066975, 'crop_size': 0.5533462879486104}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 29 finished with value: inf and parameters: {'learning_rate': 0.00011748905714946802, 'batch_size': 64, 'num_epochs': 656, 'temperature': 0.30637086244029904, 'embedding_dim': 512, 'hidden_dim': 512, 'dropout': 0.37403512436889225, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.14839325742066975, 'crop_size': 0.5533462879486104}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:49:09,340 - INFO - Using device: cuda
2025-08-14 20:49:19,146 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:49:19,147 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:49:19,147 - WARNING - Fold 1 has insufficient pairs to form a batch. Skipping.
2025-08-14 20:49:19,147 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:49:19,149 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:49:19,149 - WARNING - Fold 2 has insufficient pairs to form a batch. Skipping.
2025-08-14 20:49:19,149 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:49:19,150 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:49:19,150 - WARNING - Fold 3 has insufficient pairs to form a batch. Skipping.
2025-08-14 20:49:19,150 - WARNING - No folds completed successfully to aggregate metrics.
[I 2025-08-14 20:49:19,152] Trial 30 finished with value: inf and parameters: {'learning_rate': 0.0003631474007707104, 'batch_size': 64, 'num_epochs': 445, 'temperature': 0.405714233730752, 'embedding_dim': 512, 'hidden_dim': 128, 'dropout': 0.23518877371390884, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18448809843781475, 'crop_size': 0.5792031910344055}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 30 finished with value: inf and parameters: {'learning_rate': 0.0003631474007707104, 'batch_size': 64, 'num_epochs': 445, 'temperature': 0.405714233730752, 'embedding_dim': 512, 'hidden_dim': 128, 'dropout': 0.23518877371390884, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18448809843781475, 'crop_size': 0.5792031910344055}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:49:19,181 - INFO - Using device: cuda
2025-08-14 20:49:28,918 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:49:28,919 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:49:28,920 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:49:32,938 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-14 20:49:38,692 - INFO - Fold 1, Epoch 20: Val Acc: 0.47%
2025-08-14 20:49:42,449 - INFO - Fold 1, Epoch 30: Val Acc: 0.66%
2025-08-14 20:49:44,433 - INFO - Fold 1, Epoch 40: Val Acc: 0.62%
2025-08-14 20:49:46,494 - INFO - Fold 1, Epoch 50: Val Acc: 0.62%
2025-08-14 20:49:48,149 - INFO - Fold 1, Epoch 60: Val Acc: 0.59%
2025-08-14 20:49:50,149 - INFO - Fold 1, Epoch 70: Val Acc: 0.53%
2025-08-14 20:49:52,238 - INFO - Fold 1, Epoch 80: Val Acc: 0.53%
2025-08-14 20:49:54,334 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-14 20:49:58,170 - INFO - Fold 1, Epoch 100: Val Acc: 0.53%
2025-08-14 20:50:02,201 - INFO - Fold 1, Epoch 110: Val Acc: 0.50%
2025-08-14 20:50:04,187 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-14 20:50:06,159 - INFO - Fold 1, Epoch 130: Val Acc: 0.66%
2025-08-14 20:50:08,168 - INFO - Fold 1, Epoch 140: Val Acc: 0.59%
2025-08-14 20:50:10,173 - INFO - Fold 1, Epoch 150: Val Acc: 0.66%
2025-08-14 20:50:12,191 - INFO - Fold 1, Epoch 160: Val Acc: 0.75%
2025-08-14 20:50:14,205 - INFO - Fold 1, Epoch 170: Val Acc: 0.69%
2025-08-14 20:50:16,301 - INFO - Fold 1, Epoch 180: Val Acc: 0.59%
2025-08-14 20:50:18,395 - INFO - Fold 1, Epoch 190: Val Acc: 0.78%
2025-08-14 20:50:20,499 - INFO - Fold 1, Epoch 200: Val Acc: 0.59%
2025-08-14 20:50:21,764 - INFO - Early stopping at epoch 206
2025-08-14 20:50:25,020 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:50:25,023 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:50:25,024 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:50:30,843 - INFO - Fold 2, Epoch 10: Val Acc: 0.62%
2025-08-14 20:50:35,302 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-14 20:50:38,332 - INFO - Fold 2, Epoch 30: Val Acc: 0.78%
2025-08-14 20:50:40,365 - INFO - Fold 2, Epoch 40: Val Acc: 0.56%
2025-08-14 20:50:43,561 - INFO - Fold 2, Epoch 50: Val Acc: 0.59%
2025-08-14 20:50:45,574 - INFO - Fold 2, Epoch 60: Val Acc: 0.62%
2025-08-14 20:50:47,601 - INFO - Fold 2, Epoch 70: Val Acc: 0.66%
2025-08-14 20:50:49,624 - INFO - Fold 2, Epoch 80: Val Acc: 0.59%
2025-08-14 20:50:51,578 - INFO - Fold 2, Epoch 90: Val Acc: 0.59%
2025-08-14 20:50:53,631 - INFO - Fold 2, Epoch 100: Val Acc: 0.62%
2025-08-14 20:50:55,643 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-14 20:50:57,659 - INFO - Fold 2, Epoch 120: Val Acc: 0.62%
2025-08-14 20:50:59,684 - INFO - Fold 2, Epoch 130: Val Acc: 0.62%
2025-08-14 20:51:01,702 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-14 20:51:01,901 - INFO - Early stopping at epoch 141
2025-08-14 20:51:04,404 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:51:04,407 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:51:04,408 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:51:10,157 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-14 20:51:12,170 - INFO - Fold 3, Epoch 20: Val Acc: 0.56%
2025-08-14 20:51:16,654 - INFO - Fold 3, Epoch 30: Val Acc: 0.53%
2025-08-14 20:51:18,456 - INFO - Fold 3, Epoch 40: Val Acc: 0.53%
2025-08-14 20:51:20,531 - INFO - Fold 3, Epoch 50: Val Acc: 0.62%
2025-08-14 20:51:22,554 - INFO - Fold 3, Epoch 60: Val Acc: 0.62%
2025-08-14 20:51:24,586 - INFO - Fold 3, Epoch 70: Val Acc: 0.66%
2025-08-14 20:51:27,754 - INFO - Fold 3, Epoch 80: Val Acc: 0.66%
2025-08-14 20:51:29,755 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-14 20:51:31,783 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-14 20:51:33,792 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-14 20:51:35,810 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-14 20:51:39,167 - INFO - Fold 3, Epoch 130: Val Acc: 0.59%
2025-08-14 20:51:41,211 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-14 20:51:44,513 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-14 20:51:46,362 - INFO - Fold 3, Epoch 160: Val Acc: 0.78%
2025-08-14 20:51:47,999 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-14 20:51:49,557 - INFO - Fold 3, Epoch 180: Val Acc: 0.81%
2025-08-14 20:51:51,410 - INFO - Fold 3, Epoch 190: Val Acc: 0.62%
2025-08-14 20:51:53,417 - INFO - Fold 3, Epoch 200: Val Acc: 0.66%
2025-08-14 20:51:55,432 - INFO - Fold 3, Epoch 210: Val Acc: 0.78%
2025-08-14 20:51:58,659 - INFO - Fold 3, Epoch 220: Val Acc: 0.72%
2025-08-14 20:52:00,671 - INFO - Fold 3, Epoch 230: Val Acc: 0.75%
2025-08-14 20:52:02,706 - INFO - Fold 3, Epoch 240: Val Acc: 0.66%
2025-08-14 20:52:04,726 - INFO - Fold 3, Epoch 250: Val Acc: 0.62%
2025-08-14 20:52:06,753 - INFO - Fold 3, Epoch 260: Val Acc: 0.75%
2025-08-14 20:52:08,568 - INFO - Fold 3, Epoch 270: Val Acc: 0.66%
2025-08-14 20:52:10,557 - INFO - Fold 3, Epoch 280: Val Acc: 0.50%
2025-08-14 20:52:12,565 - INFO - Fold 3, Epoch 290: Val Acc: 0.72%
2025-08-14 20:52:14,582 - INFO - Fold 3, Epoch 300: Val Acc: 0.50%
2025-08-14 20:52:16,598 - INFO - Fold 3, Epoch 310: Val Acc: 0.69%
2025-08-14 20:52:16,801 - INFO - Early stopping at epoch 311
2025-08-14 20:52:17,667 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.091479937235514), 'std': np.float64(0.38874013928193707)}, 'train_accuracy': {'mean': np.float64(0.71875), 'std': np.float64(0.047354797558978645)}, 'val_loss': {'mean': np.float64(4.967770576477051), 'std': np.float64(0.4154638547240472)}, 'val_accuracy': {'mean': np.float64(0.8645833333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(118.33333333333333), 'std': np.float64(70.03967129816898)}}
[I 2025-08-14 20:52:17,673] Trial 31 finished with value: -0.8645833333333334 and parameters: {'learning_rate': 0.0005693421897671817, 'batch_size': 32, 'num_epochs': 829, 'temperature': 0.07622737043651254, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3163771894147607, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19398623968528433, 'crop_size': 0.5462769400448599}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 31 finished with value: -0.8645833333333334 and parameters: {'learning_rate': 0.0005693421897671817, 'batch_size': 32, 'num_epochs': 829, 'temperature': 0.07622737043651254, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3163771894147607, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19398623968528433, 'crop_size': 0.5462769400448599}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:52:17,701 - INFO - Using device: cuda
2025-08-14 20:52:27,469 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:52:27,471 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:52:27,471 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:52:33,524 - INFO - Fold 1, Epoch 10: Val Acc: 0.62%
2025-08-14 20:52:37,515 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-14 20:52:39,362 - INFO - Fold 1, Epoch 30: Val Acc: 0.59%
2025-08-14 20:52:45,015 - INFO - Fold 1, Epoch 40: Val Acc: 0.66%
2025-08-14 20:52:47,034 - INFO - Fold 1, Epoch 50: Val Acc: 0.53%
2025-08-14 20:52:49,062 - INFO - Fold 1, Epoch 60: Val Acc: 0.66%
2025-08-14 20:52:51,075 - INFO - Fold 1, Epoch 70: Val Acc: 0.59%
2025-08-14 20:52:53,104 - INFO - Fold 1, Epoch 80: Val Acc: 0.56%
2025-08-14 20:52:55,127 - INFO - Fold 1, Epoch 90: Val Acc: 0.62%
2025-08-14 20:52:57,150 - INFO - Fold 1, Epoch 100: Val Acc: 0.78%
2025-08-14 20:52:59,167 - INFO - Fold 1, Epoch 110: Val Acc: 0.84%
2025-08-14 20:53:01,179 - INFO - Fold 1, Epoch 120: Val Acc: 0.62%
2025-08-14 20:53:03,131 - INFO - Fold 1, Epoch 130: Val Acc: 0.75%
2025-08-14 20:53:04,828 - INFO - Early stopping at epoch 139
2025-08-14 20:53:07,899 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:53:07,902 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:53:07,902 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:53:15,151 - INFO - Fold 2, Epoch 10: Val Acc: 0.53%
2025-08-14 20:53:17,175 - INFO - Fold 2, Epoch 20: Val Acc: 0.62%
2025-08-14 20:53:19,268 - INFO - Fold 2, Epoch 30: Val Acc: 0.59%
2025-08-14 20:53:22,545 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-14 20:53:24,639 - INFO - Fold 2, Epoch 50: Val Acc: 0.72%
2025-08-14 20:53:26,754 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-14 20:53:28,848 - INFO - Fold 2, Epoch 70: Val Acc: 0.69%
2025-08-14 20:53:30,928 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-14 20:53:34,103 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-14 20:53:36,121 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-14 20:53:38,144 - INFO - Fold 2, Epoch 110: Val Acc: 0.81%
2025-08-14 20:53:40,174 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-14 20:53:42,200 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-14 20:53:44,189 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-14 20:53:46,128 - INFO - Fold 2, Epoch 150: Val Acc: 0.81%
2025-08-14 20:53:48,156 - INFO - Fold 2, Epoch 160: Val Acc: 0.75%
2025-08-14 20:53:50,065 - INFO - Fold 2, Epoch 170: Val Acc: 0.81%
2025-08-14 20:53:52,052 - INFO - Fold 2, Epoch 180: Val Acc: 0.75%
2025-08-14 20:53:53,775 - INFO - Early stopping at epoch 189
2025-08-14 20:53:56,363 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:53:56,367 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:53:56,367 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:54:04,662 - INFO - Fold 3, Epoch 10: Val Acc: 0.47%
2025-08-14 20:54:09,104 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-14 20:54:10,963 - INFO - Fold 3, Epoch 30: Val Acc: 0.59%
2025-08-14 20:54:14,289 - INFO - Fold 3, Epoch 40: Val Acc: 0.72%
2025-08-14 20:54:16,230 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-14 20:54:18,226 - INFO - Fold 3, Epoch 60: Val Acc: 0.56%
2025-08-14 20:54:20,174 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-14 20:54:23,388 - INFO - Fold 3, Epoch 80: Val Acc: 0.69%
2025-08-14 20:54:24,989 - INFO - Fold 3, Epoch 90: Val Acc: 0.66%
2025-08-14 20:54:26,961 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-14 20:54:28,731 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-14 20:54:30,541 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-14 20:54:32,438 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-14 20:54:34,307 - INFO - Fold 3, Epoch 140: Val Acc: 0.84%
2025-08-14 20:54:36,211 - INFO - Fold 3, Epoch 150: Val Acc: 0.66%
2025-08-14 20:54:38,056 - INFO - Fold 3, Epoch 160: Val Acc: 0.78%
2025-08-14 20:54:39,884 - INFO - Fold 3, Epoch 170: Val Acc: 0.59%
2025-08-14 20:54:41,430 - INFO - Early stopping at epoch 178
2025-08-14 20:54:42,266 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9954262044694686), 'std': np.float64(0.09895383295740148)}, 'train_accuracy': {'mean': np.float64(0.7777777777777778), 'std': np.float64(0.06383602885711888)}, 'val_loss': {'mean': np.float64(4.4729851086934405), 'std': np.float64(0.012179363918803318)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(67.66666666666667), 'std': np.float64(21.452790546272116)}}
[I 2025-08-14 20:54:42,274] Trial 32 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0009805692338122225, 'batch_size': 32, 'num_epochs': 878, 'temperature': 0.11074237687431833, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.42544385438781207, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18680626565154754, 'crop_size': 0.5433297173042284}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 32 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0009805692338122225, 'batch_size': 32, 'num_epochs': 878, 'temperature': 0.11074237687431833, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.42544385438781207, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18680626565154754, 'crop_size': 0.5433297173042284}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:54:42,310 - INFO - Using device: cuda
2025-08-14 20:54:52,311 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:54:52,313 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:54:52,313 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:55:01,181 - INFO - Fold 1, Epoch 10: Val Acc: 0.44%
2025-08-14 20:55:03,423 - INFO - Fold 1, Epoch 20: Val Acc: 0.44%
2025-08-14 20:55:05,627 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-14 20:55:09,768 - INFO - Fold 1, Epoch 40: Val Acc: 0.62%
2025-08-14 20:55:12,014 - INFO - Fold 1, Epoch 50: Val Acc: 0.62%
2025-08-14 20:55:14,247 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-14 20:55:16,409 - INFO - Fold 1, Epoch 70: Val Acc: 0.75%
2025-08-14 20:55:20,824 - INFO - Fold 1, Epoch 80: Val Acc: 0.56%
2025-08-14 20:55:23,060 - INFO - Fold 1, Epoch 90: Val Acc: 0.81%
2025-08-14 20:55:25,199 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-14 20:55:27,272 - INFO - Fold 1, Epoch 110: Val Acc: 0.72%
2025-08-14 20:55:31,655 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-14 20:55:33,739 - INFO - Fold 1, Epoch 130: Val Acc: 0.72%
2025-08-14 20:55:35,751 - INFO - Fold 1, Epoch 140: Val Acc: 0.59%
2025-08-14 20:55:37,670 - INFO - Fold 1, Epoch 150: Val Acc: 0.56%
2025-08-14 20:55:41,710 - INFO - Fold 1, Epoch 160: Val Acc: 0.91%
2025-08-14 20:55:43,976 - INFO - Fold 1, Epoch 170: Val Acc: 0.75%
2025-08-14 20:55:46,224 - INFO - Fold 1, Epoch 180: Val Acc: 0.66%
2025-08-14 20:55:48,427 - INFO - Fold 1, Epoch 190: Val Acc: 0.62%
2025-08-14 20:55:50,621 - INFO - Fold 1, Epoch 200: Val Acc: 0.66%
2025-08-14 20:55:52,860 - INFO - Fold 1, Epoch 210: Val Acc: 0.72%
2025-08-14 20:55:55,110 - INFO - Fold 1, Epoch 220: Val Acc: 0.53%
2025-08-14 20:55:57,354 - INFO - Fold 1, Epoch 230: Val Acc: 0.59%
2025-08-14 20:55:59,295 - INFO - Fold 1, Epoch 240: Val Acc: 0.62%
2025-08-14 20:56:01,081 - INFO - Fold 1, Epoch 250: Val Acc: 0.66%
2025-08-14 20:56:03,022 - INFO - Early stopping at epoch 260
2025-08-14 20:56:06,676 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:56:06,679 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:56:06,679 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:56:13,184 - INFO - Fold 2, Epoch 10: Val Acc: 0.59%
2025-08-14 20:56:18,130 - INFO - Fold 2, Epoch 20: Val Acc: 0.62%
2025-08-14 20:56:21,805 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-14 20:56:24,129 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-14 20:56:26,469 - INFO - Fold 2, Epoch 50: Val Acc: 0.66%
2025-08-14 20:56:28,752 - INFO - Fold 2, Epoch 60: Val Acc: 0.84%
2025-08-14 20:56:30,576 - INFO - Fold 2, Epoch 70: Val Acc: 0.69%
2025-08-14 20:56:32,725 - INFO - Fold 2, Epoch 80: Val Acc: 0.66%
2025-08-14 20:56:35,050 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-14 20:56:37,383 - INFO - Fold 2, Epoch 100: Val Acc: 0.72%
2025-08-14 20:56:40,991 - INFO - Fold 2, Epoch 110: Val Acc: 0.59%
2025-08-14 20:56:43,306 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-14 20:56:45,576 - INFO - Fold 2, Epoch 130: Val Acc: 0.66%
2025-08-14 20:56:47,887 - INFO - Fold 2, Epoch 140: Val Acc: 0.69%
2025-08-14 20:56:50,222 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-14 20:56:54,018 - INFO - Fold 2, Epoch 160: Val Acc: 0.84%
2025-08-14 20:56:56,302 - INFO - Fold 2, Epoch 170: Val Acc: 0.88%
2025-08-14 20:56:58,545 - INFO - Fold 2, Epoch 180: Val Acc: 0.69%
2025-08-14 20:57:00,783 - INFO - Fold 2, Epoch 190: Val Acc: 0.81%
2025-08-14 20:57:03,028 - INFO - Fold 2, Epoch 200: Val Acc: 0.69%
2025-08-14 20:57:05,261 - INFO - Fold 2, Epoch 210: Val Acc: 0.75%
2025-08-14 20:57:07,505 - INFO - Fold 2, Epoch 220: Val Acc: 0.69%
2025-08-14 20:57:09,742 - INFO - Fold 2, Epoch 230: Val Acc: 0.94%
2025-08-14 20:57:11,985 - INFO - Fold 2, Epoch 240: Val Acc: 0.69%
2025-08-14 20:57:14,220 - INFO - Fold 2, Epoch 250: Val Acc: 0.78%
2025-08-14 20:57:15,453 - INFO - Early stopping at epoch 256
2025-08-14 20:57:18,450 - INFO - --- Starting Fold 3/3 ---
2025-08-14 20:57:18,452 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:57:18,453 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 20:57:23,566 - INFO - Fold 3, Epoch 10: Val Acc: 0.66%
2025-08-14 20:57:25,814 - INFO - Fold 3, Epoch 20: Val Acc: 0.38%
2025-08-14 20:57:29,579 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-14 20:57:34,757 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-14 20:57:36,978 - INFO - Fold 3, Epoch 50: Val Acc: 0.59%
2025-08-14 20:57:40,702 - INFO - Fold 3, Epoch 60: Val Acc: 0.69%
2025-08-14 20:57:42,940 - INFO - Fold 3, Epoch 70: Val Acc: 0.59%
2025-08-14 20:57:45,175 - INFO - Fold 3, Epoch 80: Val Acc: 0.66%
2025-08-14 20:57:47,406 - INFO - Fold 3, Epoch 90: Val Acc: 0.59%
2025-08-14 20:57:49,636 - INFO - Fold 3, Epoch 100: Val Acc: 0.81%
2025-08-14 20:57:53,285 - INFO - Fold 3, Epoch 110: Val Acc: 0.59%
2025-08-14 20:57:55,483 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-14 20:57:57,708 - INFO - Fold 3, Epoch 130: Val Acc: 0.62%
2025-08-14 20:58:01,399 - INFO - Fold 3, Epoch 140: Val Acc: 0.69%
2025-08-14 20:58:03,379 - INFO - Fold 3, Epoch 150: Val Acc: 0.62%
2025-08-14 20:58:05,523 - INFO - Fold 3, Epoch 160: Val Acc: 0.72%
2025-08-14 20:58:07,768 - INFO - Fold 3, Epoch 170: Val Acc: 0.75%
2025-08-14 20:58:10,011 - INFO - Fold 3, Epoch 180: Val Acc: 0.62%
2025-08-14 20:58:12,247 - INFO - Fold 3, Epoch 190: Val Acc: 0.78%
2025-08-14 20:58:14,480 - INFO - Fold 3, Epoch 200: Val Acc: 0.62%
2025-08-14 20:58:16,710 - INFO - Fold 3, Epoch 210: Val Acc: 0.81%
2025-08-14 20:58:18,934 - INFO - Fold 3, Epoch 220: Val Acc: 0.62%
2025-08-14 20:58:21,161 - INFO - Fold 3, Epoch 230: Val Acc: 0.66%
2025-08-14 20:58:21,828 - INFO - Early stopping at epoch 233
2025-08-14 20:58:22,895 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.79510956340366), 'std': np.float64(0.07619733325360846)}, 'train_accuracy': {'mean': np.float64(0.8333333333333334), 'std': np.float64(0.04735479755897863)}, 'val_loss': {'mean': np.float64(4.355800628662109), 'std': np.float64(0.08280076806907871)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(148.66666666666666), 'std': np.float64(11.897712198383164)}}
[I 2025-08-14 20:58:22,902] Trial 33 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0005982735082200832, 'batch_size': 32, 'num_epochs': 806, 'temperature': 0.12200837092406006, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.45739224203597856, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.16976370821381043, 'crop_size': 0.6161720570336626}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 33 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0005982735082200832, 'batch_size': 32, 'num_epochs': 806, 'temperature': 0.12200837092406006, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.45739224203597856, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.16976370821381043, 'crop_size': 0.6161720570336626}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 20:58:22,930 - INFO - Using device: cuda
2025-08-14 20:58:32,856 - INFO - --- Starting Fold 1/3 ---
2025-08-14 20:58:32,857 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:58:32,858 - INFO - Starting training for fold 1/3
2025-08-14 20:58:39,186 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-14 20:58:41,248 - INFO - Fold 1, Epoch 20: Val Acc: 0.44%
2025-08-14 20:58:46,908 - INFO - Fold 1, Epoch 30: Val Acc: 0.56%
2025-08-14 20:58:48,968 - INFO - Fold 1, Epoch 40: Val Acc: 0.41%
2025-08-14 20:58:53,038 - INFO - Fold 1, Epoch 50: Val Acc: 0.47%
2025-08-14 20:58:55,144 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-14 20:58:57,254 - INFO - Fold 1, Epoch 70: Val Acc: 0.50%
2025-08-14 20:59:01,019 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-14 20:59:03,248 - INFO - Fold 1, Epoch 90: Val Acc: 0.44%
2025-08-14 20:59:05,317 - INFO - Fold 1, Epoch 100: Val Acc: 0.44%
2025-08-14 20:59:07,381 - INFO - Fold 1, Epoch 110: Val Acc: 0.72%
2025-08-14 20:59:09,441 - INFO - Fold 1, Epoch 120: Val Acc: 0.50%
2025-08-14 20:59:11,497 - INFO - Fold 1, Epoch 130: Val Acc: 0.53%
2025-08-14 20:59:13,479 - INFO - Fold 1, Epoch 140: Val Acc: 0.50%
2025-08-14 20:59:15,536 - INFO - Fold 1, Epoch 150: Val Acc: 0.41%
2025-08-14 20:59:17,593 - INFO - Fold 1, Epoch 160: Val Acc: 0.56%
2025-08-14 20:59:19,277 - INFO - Fold 1, Epoch 170: Val Acc: 0.56%
2025-08-14 20:59:21,292 - INFO - Early stopping at epoch 180
2025-08-14 20:59:24,417 - INFO - --- Starting Fold 2/3 ---
2025-08-14 20:59:24,420 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 20:59:24,420 - INFO - Starting training for fold 2/3
2025-08-14 20:59:29,473 - INFO - Fold 2, Epoch 10: Val Acc: 0.31%
2025-08-14 20:59:33,965 - INFO - Fold 2, Epoch 20: Val Acc: 0.47%
2025-08-14 20:59:36,096 - INFO - Fold 2, Epoch 30: Val Acc: 0.47%
2025-08-14 20:59:39,374 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-14 20:59:41,477 - INFO - Fold 2, Epoch 50: Val Acc: 0.59%
2025-08-14 20:59:43,526 - INFO - Fold 2, Epoch 60: Val Acc: 0.50%
2025-08-14 20:59:45,628 - INFO - Fold 2, Epoch 70: Val Acc: 0.47%
2025-08-14 20:59:47,767 - INFO - Fold 2, Epoch 80: Val Acc: 0.47%
2025-08-14 20:59:49,905 - INFO - Fold 2, Epoch 90: Val Acc: 0.44%
2025-08-14 20:59:52,061 - INFO - Fold 2, Epoch 100: Val Acc: 0.47%
2025-08-14 20:59:53,953 - INFO - Fold 2, Epoch 110: Val Acc: 0.47%
2025-08-14 20:59:56,972 - INFO - Fold 2, Epoch 120: Val Acc: 0.56%
2025-08-14 20:59:59,042 - INFO - Fold 2, Epoch 130: Val Acc: 0.47%
2025-08-14 21:00:01,112 - INFO - Fold 2, Epoch 140: Val Acc: 0.50%
2025-08-14 21:00:03,140 - INFO - Fold 2, Epoch 150: Val Acc: 0.44%
2025-08-14 21:00:05,289 - INFO - Fold 2, Epoch 160: Val Acc: 0.44%
2025-08-14 21:00:07,450 - INFO - Fold 2, Epoch 170: Val Acc: 0.44%
2025-08-14 21:00:09,614 - INFO - Fold 2, Epoch 180: Val Acc: 0.53%
2025-08-14 21:00:11,776 - INFO - Fold 2, Epoch 190: Val Acc: 0.59%
2025-08-14 21:00:13,674 - INFO - Fold 2, Epoch 200: Val Acc: 0.41%
2025-08-14 21:00:15,402 - INFO - Fold 2, Epoch 210: Val Acc: 0.53%
2025-08-14 21:00:16,220 - INFO - Early stopping at epoch 214
2025-08-14 21:00:17,077 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:00:17,079 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:00:17,079 - INFO - Starting training for fold 3/3
2025-08-14 21:00:23,037 - INFO - Fold 3, Epoch 10: Val Acc: 0.28%
2025-08-14 21:00:27,498 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-14 21:00:29,551 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-14 21:00:31,611 - INFO - Fold 3, Epoch 40: Val Acc: 0.53%
2025-08-14 21:00:33,667 - INFO - Fold 3, Epoch 50: Val Acc: 0.44%
2025-08-14 21:00:35,792 - INFO - Fold 3, Epoch 60: Val Acc: 0.47%
2025-08-14 21:00:37,927 - INFO - Fold 3, Epoch 70: Val Acc: 0.47%
2025-08-14 21:00:41,281 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-14 21:00:43,419 - INFO - Fold 3, Epoch 90: Val Acc: 0.53%
2025-08-14 21:00:45,503 - INFO - Fold 3, Epoch 100: Val Acc: 0.44%
2025-08-14 21:00:47,566 - INFO - Fold 3, Epoch 110: Val Acc: 0.50%
2025-08-14 21:00:49,603 - INFO - Fold 3, Epoch 120: Val Acc: 0.44%
2025-08-14 21:00:51,554 - INFO - Fold 3, Epoch 130: Val Acc: 0.44%
2025-08-14 21:00:53,594 - INFO - Fold 3, Epoch 140: Val Acc: 0.44%
2025-08-14 21:00:55,664 - INFO - Fold 3, Epoch 150: Val Acc: 0.44%
2025-08-14 21:00:57,717 - INFO - Fold 3, Epoch 160: Val Acc: 0.53%
2025-08-14 21:00:59,771 - INFO - Fold 3, Epoch 170: Val Acc: 0.56%
2025-08-14 21:01:00,193 - INFO - Early stopping at epoch 172
2025-08-14 21:01:01,035 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.392748249901665), 'std': np.float64(0.02541356024069151)}, 'train_accuracy': {'mean': np.float64(0.59375), 'std': np.float64(0.0)}, 'val_loss': {'mean': np.float64(4.482504049936931), 'std': np.float64(0.07098864073716435)}, 'val_accuracy': {'mean': np.float64(0.7083333333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(87.66666666666667), 'std': np.float64(18.208667044996883)}}
[I 2025-08-14 21:01:01,043] Trial 34 finished with value: -0.7083333333333334 and parameters: {'learning_rate': 0.0005253216406581674, 'batch_size': 32, 'num_epochs': 956, 'temperature': 0.09083538228350878, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3766696789985169, 'num_layers': 4, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18556081928345614, 'crop_size': 0.5679279096523825}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 34 finished with value: -0.7083333333333334 and parameters: {'learning_rate': 0.0005253216406581674, 'batch_size': 32, 'num_epochs': 956, 'temperature': 0.09083538228350878, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3766696789985169, 'num_layers': 4, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18556081928345614, 'crop_size': 0.5679279096523825}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:01:01,074 - INFO - Using device: cuda
2025-08-14 21:01:10,958 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:01:10,959 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:01:10,960 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 21:01:19,933 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-14 21:01:22,276 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-14 21:01:24,589 - INFO - Fold 1, Epoch 30: Val Acc: 0.47%
2025-08-14 21:01:29,124 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-14 21:01:31,433 - INFO - Fold 1, Epoch 50: Val Acc: 0.78%
2025-08-14 21:01:33,719 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-14 21:01:36,006 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-14 21:01:38,313 - INFO - Fold 1, Epoch 80: Val Acc: 0.59%
2025-08-14 21:01:40,567 - INFO - Fold 1, Epoch 90: Val Acc: 0.78%
2025-08-14 21:01:46,296 - INFO - Fold 1, Epoch 100: Val Acc: 0.62%
2025-08-14 21:01:48,507 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-14 21:01:50,834 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-14 21:01:52,855 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-14 21:01:54,872 - INFO - Fold 1, Epoch 140: Val Acc: 0.69%
2025-08-14 21:01:56,804 - INFO - Fold 1, Epoch 150: Val Acc: 0.72%
2025-08-14 21:02:01,287 - INFO - Fold 1, Epoch 160: Val Acc: 0.72%
2025-08-14 21:02:03,325 - INFO - Fold 1, Epoch 170: Val Acc: 0.81%
2025-08-14 21:02:05,181 - INFO - Fold 1, Epoch 180: Val Acc: 0.69%
2025-08-14 21:02:07,332 - INFO - Fold 1, Epoch 190: Val Acc: 0.62%
2025-08-14 21:02:09,573 - INFO - Fold 1, Epoch 200: Val Acc: 0.78%
2025-08-14 21:02:11,792 - INFO - Fold 1, Epoch 210: Val Acc: 0.50%
2025-08-14 21:02:14,009 - INFO - Fold 1, Epoch 220: Val Acc: 0.69%
2025-08-14 21:02:16,254 - INFO - Fold 1, Epoch 230: Val Acc: 0.66%
2025-08-14 21:02:18,480 - INFO - Fold 1, Epoch 240: Val Acc: 0.75%
2025-08-14 21:02:20,720 - INFO - Fold 1, Epoch 250: Val Acc: 0.62%
2025-08-14 21:02:20,945 - INFO - Early stopping at epoch 251
2025-08-14 21:02:24,680 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:02:24,692 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:02:24,693 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 21:02:32,908 - INFO - Fold 2, Epoch 10: Val Acc: 0.53%
2025-08-14 21:02:37,585 - INFO - Fold 2, Epoch 20: Val Acc: 0.78%
2025-08-14 21:02:39,664 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-14 21:02:41,638 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-14 21:02:44,967 - INFO - Fold 2, Epoch 50: Val Acc: 0.62%
2025-08-14 21:02:46,993 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-14 21:02:49,245 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-14 21:02:52,979 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-14 21:02:54,993 - INFO - Fold 2, Epoch 90: Val Acc: 0.75%
2025-08-14 21:02:57,208 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-14 21:02:59,460 - INFO - Fold 2, Epoch 110: Val Acc: 0.78%
2025-08-14 21:03:01,484 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-14 21:03:03,685 - INFO - Fold 2, Epoch 130: Val Acc: 0.81%
2025-08-14 21:03:05,915 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-14 21:03:08,150 - INFO - Fold 2, Epoch 150: Val Acc: 0.81%
2025-08-14 21:03:10,378 - INFO - Fold 2, Epoch 160: Val Acc: 0.75%
2025-08-14 21:03:12,602 - INFO - Fold 2, Epoch 170: Val Acc: 0.69%
2025-08-14 21:03:14,162 - INFO - Early stopping at epoch 177
2025-08-14 21:03:17,169 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:03:17,172 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:03:17,172 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 21:03:23,757 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-14 21:03:27,726 - INFO - Fold 3, Epoch 20: Val Acc: 0.47%
2025-08-14 21:03:31,096 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-14 21:03:33,242 - INFO - Fold 3, Epoch 40: Val Acc: 0.56%
2025-08-14 21:03:35,462 - INFO - Fold 3, Epoch 50: Val Acc: 0.47%
2025-08-14 21:03:39,147 - INFO - Fold 3, Epoch 60: Val Acc: 0.81%
2025-08-14 21:03:42,893 - INFO - Fold 3, Epoch 70: Val Acc: 0.56%
2025-08-14 21:03:45,137 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-14 21:03:47,381 - INFO - Fold 3, Epoch 90: Val Acc: 0.56%
2025-08-14 21:03:49,665 - INFO - Fold 3, Epoch 100: Val Acc: 0.62%
2025-08-14 21:03:51,972 - INFO - Fold 3, Epoch 110: Val Acc: 0.69%
2025-08-14 21:03:54,279 - INFO - Fold 3, Epoch 120: Val Acc: 0.69%
2025-08-14 21:03:56,513 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-14 21:03:58,575 - INFO - Fold 3, Epoch 140: Val Acc: 0.75%
2025-08-14 21:04:00,812 - INFO - Fold 3, Epoch 150: Val Acc: 0.78%
2025-08-14 21:04:03,046 - INFO - Fold 3, Epoch 160: Val Acc: 0.66%
2025-08-14 21:04:03,710 - INFO - Early stopping at epoch 163
2025-08-14 21:04:04,797 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.8855384455786806), 'std': np.float64(0.06435272077519251)}, 'train_accuracy': {'mean': np.float64(0.7534722222222222), 'std': np.float64(0.05196746370519368)}, 'val_loss': {'mean': np.float64(4.288410186767578), 'std': np.float64(0.12662566343376216)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(96.0), 'std': np.float64(38.60915262818736)}}
[I 2025-08-14 21:04:04,803] Trial 35 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0006955947627571872, 'batch_size': 32, 'num_epochs': 890, 'temperature': 0.1784051117002504, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.29454528435837884, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.13487415766762056, 'crop_size': 0.5233657434029177}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 35 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0006955947627571872, 'batch_size': 32, 'num_epochs': 890, 'temperature': 0.1784051117002504, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.29454528435837884, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.13487415766762056, 'crop_size': 0.5233657434029177}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:04:04,832 - INFO - Using device: cuda
2025-08-14 21:04:14,621 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:04:14,622 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:04:14,622 - INFO - Starting training for fold 1/3
2025-08-14 21:04:20,792 - INFO - Fold 1, Epoch 10: Val Acc: 0.38%
2025-08-14 21:04:25,278 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-14 21:04:27,943 - INFO - Fold 1, Epoch 30: Val Acc: 0.54%
2025-08-14 21:04:30,904 - INFO - Fold 1, Epoch 40: Val Acc: 0.60%
2025-08-14 21:04:33,959 - INFO - Fold 1, Epoch 50: Val Acc: 0.48%
2025-08-14 21:04:37,016 - INFO - Fold 1, Epoch 60: Val Acc: 0.52%
2025-08-14 21:04:41,592 - INFO - Fold 1, Epoch 70: Val Acc: 0.44%
2025-08-14 21:04:44,482 - INFO - Fold 1, Epoch 80: Val Acc: 0.50%
2025-08-14 21:04:47,058 - INFO - Fold 1, Epoch 90: Val Acc: 0.48%
2025-08-14 21:04:49,817 - INFO - Fold 1, Epoch 100: Val Acc: 0.56%
2025-08-14 21:04:52,370 - INFO - Fold 1, Epoch 110: Val Acc: 0.50%
2025-08-14 21:04:55,437 - INFO - Fold 1, Epoch 120: Val Acc: 0.52%
2025-08-14 21:04:58,504 - INFO - Fold 1, Epoch 130: Val Acc: 0.50%
2025-08-14 21:05:01,562 - INFO - Fold 1, Epoch 140: Val Acc: 0.52%
2025-08-14 21:05:04,639 - INFO - Fold 1, Epoch 150: Val Acc: 0.42%
2025-08-14 21:05:07,539 - INFO - Fold 1, Epoch 160: Val Acc: 0.50%
2025-08-14 21:05:08,769 - INFO - Early stopping at epoch 164
2025-08-14 21:05:11,145 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:05:11,149 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:05:11,149 - INFO - Starting training for fold 2/3
2025-08-14 21:05:15,811 - INFO - Fold 2, Epoch 10: Val Acc: 0.38%
2025-08-14 21:05:20,114 - INFO - Fold 2, Epoch 20: Val Acc: 0.58%
2025-08-14 21:05:23,444 - INFO - Fold 2, Epoch 30: Val Acc: 0.44%
2025-08-14 21:05:27,790 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-14 21:05:31,088 - INFO - Fold 2, Epoch 50: Val Acc: 0.58%
2025-08-14 21:05:35,252 - INFO - Fold 2, Epoch 60: Val Acc: 0.50%
2025-08-14 21:05:38,430 - INFO - Fold 2, Epoch 70: Val Acc: 0.52%
2025-08-14 21:05:41,691 - INFO - Fold 2, Epoch 80: Val Acc: 0.62%
2025-08-14 21:05:45,101 - INFO - Fold 2, Epoch 90: Val Acc: 0.44%
2025-08-14 21:05:48,385 - INFO - Fold 2, Epoch 100: Val Acc: 0.44%
2025-08-14 21:05:51,653 - INFO - Fold 2, Epoch 110: Val Acc: 0.46%
2025-08-14 21:05:54,940 - INFO - Fold 2, Epoch 120: Val Acc: 0.52%
2025-08-14 21:05:58,213 - INFO - Fold 2, Epoch 130: Val Acc: 0.54%
2025-08-14 21:06:02,519 - INFO - Fold 2, Epoch 140: Val Acc: 0.44%
2025-08-14 21:06:05,797 - INFO - Fold 2, Epoch 150: Val Acc: 0.54%
2025-08-14 21:06:09,071 - INFO - Fold 2, Epoch 160: Val Acc: 0.54%
2025-08-14 21:06:12,418 - INFO - Fold 2, Epoch 170: Val Acc: 0.42%
2025-08-14 21:06:15,705 - INFO - Fold 2, Epoch 180: Val Acc: 0.48%
2025-08-14 21:06:19,011 - INFO - Fold 2, Epoch 190: Val Acc: 0.50%
2025-08-14 21:06:22,113 - INFO - Fold 2, Epoch 200: Val Acc: 0.46%
2025-08-14 21:06:25,420 - INFO - Fold 2, Epoch 210: Val Acc: 0.58%
2025-08-14 21:06:28,557 - INFO - Fold 2, Epoch 220: Val Acc: 0.54%
2025-08-14 21:06:31,163 - INFO - Fold 2, Epoch 230: Val Acc: 0.44%
2025-08-14 21:06:32,077 - INFO - Early stopping at epoch 234
2025-08-14 21:06:34,096 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:06:34,098 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:06:34,099 - INFO - Starting training for fold 3/3
2025-08-14 21:06:38,226 - INFO - Fold 3, Epoch 10: Val Acc: 0.44%
2025-08-14 21:06:40,969 - INFO - Fold 3, Epoch 20: Val Acc: 0.52%
2025-08-14 21:06:44,505 - INFO - Fold 3, Epoch 30: Val Acc: 0.52%
2025-08-14 21:06:47,233 - INFO - Fold 3, Epoch 40: Val Acc: 0.52%
2025-08-14 21:06:50,249 - INFO - Fold 3, Epoch 50: Val Acc: 0.46%
2025-08-14 21:06:53,136 - INFO - Fold 3, Epoch 60: Val Acc: 0.46%
2025-08-14 21:06:55,953 - INFO - Fold 3, Epoch 70: Val Acc: 0.50%
2025-08-14 21:06:58,537 - INFO - Fold 3, Epoch 80: Val Acc: 0.54%
2025-08-14 21:07:01,124 - INFO - Fold 3, Epoch 90: Val Acc: 0.52%
2025-08-14 21:07:03,381 - INFO - Fold 3, Epoch 100: Val Acc: 0.54%
2025-08-14 21:07:06,352 - INFO - Fold 3, Epoch 110: Val Acc: 0.44%
2025-08-14 21:07:09,406 - INFO - Fold 3, Epoch 120: Val Acc: 0.54%
2025-08-14 21:07:11,493 - INFO - Early stopping at epoch 128
2025-08-14 21:07:12,197 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.434370146857368), 'std': np.float64(0.020377625093812548)}, 'train_accuracy': {'mean': np.float64(0.5486111111111112), 'std': np.float64(0.027340305118096604)}, 'val_loss': {'mean': np.float64(3.5149272282918296), 'std': np.float64(0.07296063820168389)}, 'val_accuracy': {'mean': np.float64(0.6875), 'std': np.float64(0.017010345435994233)}, 'epoch': {'mean': np.float64(74.33333333333333), 'std': np.float64(44.01009985093068)}}
[I 2025-08-14 21:07:12,205] Trial 36 finished with value: -0.6875 and parameters: {'learning_rate': 0.00042633659489552366, 'batch_size': 16, 'num_epochs': 663, 'temperature': 0.23988107452968058, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4988095039112975, 'num_layers': 3, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.19979089858190144, 'crop_size': 0.644869933684464}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 36 finished with value: -0.6875 and parameters: {'learning_rate': 0.00042633659489552366, 'batch_size': 16, 'num_epochs': 663, 'temperature': 0.23988107452968058, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4988095039112975, 'num_layers': 3, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.19979089858190144, 'crop_size': 0.644869933684464}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:07:12,252 - INFO - Using device: cuda
2025-08-14 21:07:22,116 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:07:22,118 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:07:22,118 - WARNING - Fold 1 has insufficient pairs to form a batch. Skipping.
2025-08-14 21:07:22,118 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:07:22,120 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:07:22,120 - WARNING - Fold 2 has insufficient pairs to form a batch. Skipping.
2025-08-14 21:07:22,120 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:07:22,121 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:07:22,121 - WARNING - Fold 3 has insufficient pairs to form a batch. Skipping.
2025-08-14 21:07:22,121 - WARNING - No folds completed successfully to aggregate metrics.
[I 2025-08-14 21:07:22,124] Trial 37 finished with value: inf and parameters: {'learning_rate': 0.0001971559604531772, 'batch_size': 64, 'num_epochs': 949, 'temperature': 0.07447547160382667, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.2387977143389387, 'num_layers': 4, 'num_heads': 2, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.5949563670578477}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 37 finished with value: inf and parameters: {'learning_rate': 0.0001971559604531772, 'batch_size': 64, 'num_epochs': 949, 'temperature': 0.07447547160382667, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.2387977143389387, 'num_layers': 4, 'num_heads': 2, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.5949563670578477}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:07:22,160 - INFO - Using device: cuda
2025-08-14 21:07:32,074 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:07:32,076 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:07:32,076 - INFO - Starting training for fold 1/3
2025-08-14 21:07:35,897 - INFO - Fold 1, Epoch 10: Val Acc: 0.44%
2025-08-14 21:07:38,514 - INFO - Fold 1, Epoch 20: Val Acc: 0.38%
2025-08-14 21:07:40,009 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 21:07:41,505 - INFO - Fold 1, Epoch 40: Val Acc: 0.56%
2025-08-14 21:07:43,012 - INFO - Fold 1, Epoch 50: Val Acc: 0.47%
2025-08-14 21:07:44,524 - INFO - Fold 1, Epoch 60: Val Acc: 0.44%
2025-08-14 21:07:46,014 - INFO - Fold 1, Epoch 70: Val Acc: 0.47%
2025-08-14 21:07:47,530 - INFO - Fold 1, Epoch 80: Val Acc: 0.47%
2025-08-14 21:07:49,073 - INFO - Fold 1, Epoch 90: Val Acc: 0.47%
2025-08-14 21:07:50,564 - INFO - Fold 1, Epoch 100: Val Acc: 0.44%
2025-08-14 21:07:53,226 - INFO - Fold 1, Epoch 110: Val Acc: 0.34%
2025-08-14 21:07:54,747 - INFO - Fold 1, Epoch 120: Val Acc: 0.47%
2025-08-14 21:07:56,328 - INFO - Fold 1, Epoch 130: Val Acc: 0.44%
2025-08-14 21:07:57,942 - INFO - Fold 1, Epoch 140: Val Acc: 0.34%
2025-08-14 21:07:59,492 - INFO - Fold 1, Epoch 150: Val Acc: 0.53%
2025-08-14 21:08:00,803 - INFO - Fold 1, Epoch 160: Val Acc: 0.53%
2025-08-14 21:08:02,111 - INFO - Fold 1, Epoch 170: Val Acc: 0.44%
2025-08-14 21:08:03,535 - INFO - Fold 1, Epoch 180: Val Acc: 0.38%
2025-08-14 21:08:05,189 - INFO - Fold 1, Epoch 190: Val Acc: 0.50%
2025-08-14 21:08:06,814 - INFO - Fold 1, Epoch 200: Val Acc: 0.56%
2025-08-14 21:08:07,461 - INFO - Early stopping at epoch 204
2025-08-14 21:08:09,195 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:08:09,212 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:08:09,213 - INFO - Starting training for fold 2/3
2025-08-14 21:08:12,502 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-14 21:08:13,973 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-14 21:08:15,459 - INFO - Fold 2, Epoch 30: Val Acc: 0.50%
2025-08-14 21:08:16,943 - INFO - Fold 2, Epoch 40: Val Acc: 0.53%
2025-08-14 21:08:18,551 - INFO - Fold 2, Epoch 50: Val Acc: 0.47%
2025-08-14 21:08:20,181 - INFO - Fold 2, Epoch 60: Val Acc: 0.59%
2025-08-14 21:08:21,874 - INFO - Fold 2, Epoch 70: Val Acc: 0.56%
2025-08-14 21:08:23,539 - INFO - Fold 2, Epoch 80: Val Acc: 0.44%
2025-08-14 21:08:25,029 - INFO - Fold 2, Epoch 90: Val Acc: 0.34%
2025-08-14 21:08:26,586 - INFO - Fold 2, Epoch 100: Val Acc: 0.53%
2025-08-14 21:08:26,904 - INFO - Early stopping at epoch 102
2025-08-14 21:08:28,284 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:08:28,286 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:08:28,286 - INFO - Starting training for fold 3/3
2025-08-14 21:08:32,064 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-14 21:08:34,365 - INFO - Fold 3, Epoch 20: Val Acc: 0.50%
2025-08-14 21:08:36,690 - INFO - Fold 3, Epoch 30: Val Acc: 0.53%
2025-08-14 21:08:38,297 - INFO - Fold 3, Epoch 40: Val Acc: 0.53%
2025-08-14 21:08:39,923 - INFO - Fold 3, Epoch 50: Val Acc: 0.50%
2025-08-14 21:08:41,538 - INFO - Fold 3, Epoch 60: Val Acc: 0.50%
2025-08-14 21:08:42,906 - INFO - Fold 3, Epoch 70: Val Acc: 0.38%
2025-08-14 21:08:44,198 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-14 21:08:45,488 - INFO - Fold 3, Epoch 90: Val Acc: 0.50%
2025-08-14 21:08:46,778 - INFO - Fold 3, Epoch 100: Val Acc: 0.47%
2025-08-14 21:08:48,070 - INFO - Fold 3, Epoch 110: Val Acc: 0.56%
2025-08-14 21:08:49,361 - INFO - Fold 3, Epoch 120: Val Acc: 0.50%
2025-08-14 21:08:49,620 - INFO - Early stopping at epoch 122
2025-08-14 21:08:50,114 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.20694965786404), 'std': np.float64(0.004198635322057283)}, 'train_accuracy': {'mean': np.float64(0.5868055555555556), 'std': np.float64(0.027340305118096552)}, 'val_loss': {'mean': np.float64(4.279623349507649), 'std': np.float64(0.08743686783812742)}, 'val_accuracy': {'mean': np.float64(0.6979166666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(41.666666666666664), 'std': np.float64(44.13111776916097)}}
[I 2025-08-14 21:08:50,120] Trial 38 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 0.0002822819034812803, 'batch_size': 32, 'num_epochs': 345, 'temperature': 0.13535483074494314, 'embedding_dim': 512, 'hidden_dim': 512, 'dropout': 0.41601163299623356, 'num_layers': 2, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.11327721675621537, 'crop_size': 0.704870903821857}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 38 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 0.0002822819034812803, 'batch_size': 32, 'num_epochs': 345, 'temperature': 0.13535483074494314, 'embedding_dim': 512, 'hidden_dim': 512, 'dropout': 0.41601163299623356, 'num_layers': 2, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.11327721675621537, 'crop_size': 0.704870903821857}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:08:50,146 - INFO - Using device: cuda
2025-08-14 21:08:59,782 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:08:59,783 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:08:59,783 - INFO - Starting training for fold 1/3
2025-08-14 21:09:09,075 - INFO - Fold 1, Epoch 10: Val Acc: 0.34%
2025-08-14 21:09:11,324 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-14 21:09:13,566 - INFO - Fold 1, Epoch 30: Val Acc: 0.44%
2025-08-14 21:09:15,824 - INFO - Fold 1, Epoch 40: Val Acc: 0.53%
2025-08-14 21:09:18,081 - INFO - Fold 1, Epoch 50: Val Acc: 0.44%
2025-08-14 21:09:20,337 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-14 21:09:22,599 - INFO - Fold 1, Epoch 70: Val Acc: 0.50%
2025-08-14 21:09:24,854 - INFO - Fold 1, Epoch 80: Val Acc: 0.50%
2025-08-14 21:09:27,099 - INFO - Fold 1, Epoch 90: Val Acc: 0.56%
2025-08-14 21:09:29,354 - INFO - Fold 1, Epoch 100: Val Acc: 0.44%
2025-08-14 21:09:30,705 - INFO - Early stopping at epoch 106
2025-08-14 21:09:34,244 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:09:34,246 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:09:34,247 - INFO - Starting training for fold 2/3
2025-08-14 21:09:41,316 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-14 21:09:43,394 - INFO - Fold 2, Epoch 20: Val Acc: 0.47%
2025-08-14 21:09:45,452 - INFO - Fold 2, Epoch 30: Val Acc: 0.50%
2025-08-14 21:09:47,471 - INFO - Fold 2, Epoch 40: Val Acc: 0.56%
2025-08-14 21:09:49,673 - INFO - Fold 2, Epoch 50: Val Acc: 0.56%
2025-08-14 21:09:51,950 - INFO - Fold 2, Epoch 60: Val Acc: 0.47%
2025-08-14 21:09:54,211 - INFO - Fold 2, Epoch 70: Val Acc: 0.56%
2025-08-14 21:09:56,474 - INFO - Fold 2, Epoch 80: Val Acc: 0.56%
2025-08-14 21:09:58,723 - INFO - Fold 2, Epoch 90: Val Acc: 0.53%
2025-08-14 21:10:00,987 - INFO - Fold 2, Epoch 100: Val Acc: 0.53%
2025-08-14 21:10:02,453 - INFO - Early stopping at epoch 107
2025-08-14 21:10:03,524 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:10:03,526 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:10:03,526 - INFO - Starting training for fold 3/3
2025-08-14 21:10:13,944 - INFO - Fold 3, Epoch 10: Val Acc: 0.44%
2025-08-14 21:10:16,291 - INFO - Fold 3, Epoch 20: Val Acc: 0.50%
2025-08-14 21:10:18,634 - INFO - Fold 3, Epoch 30: Val Acc: 0.62%
2025-08-14 21:10:20,968 - INFO - Fold 3, Epoch 40: Val Acc: 0.22%
2025-08-14 21:10:23,058 - INFO - Fold 3, Epoch 50: Val Acc: 0.62%
2025-08-14 21:10:25,138 - INFO - Fold 3, Epoch 60: Val Acc: 0.47%
2025-08-14 21:10:27,238 - INFO - Fold 3, Epoch 70: Val Acc: 0.41%
2025-08-14 21:10:29,087 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-14 21:10:31,132 - INFO - Fold 3, Epoch 90: Val Acc: 0.50%
2025-08-14 21:10:33,304 - INFO - Fold 3, Epoch 100: Val Acc: 0.41%
2025-08-14 21:10:34,951 - INFO - Early stopping at epoch 109
2025-08-14 21:10:37,826 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.37966791788737), 'std': np.float64(0.10963865114827852)}, 'train_accuracy': {'mean': np.float64(0.5798611111111112), 'std': np.float64(0.01770492886664164)}, 'val_loss': {'mean': np.float64(4.506174405415853), 'std': np.float64(0.045021354456439795)}, 'val_accuracy': {'mean': np.float64(0.6875), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(6.333333333333333), 'std': np.float64(1.247219128924647)}}
[I 2025-08-14 21:10:37,838] Trial 39 finished with value: -0.6875 and parameters: {'learning_rate': 0.00016129674306002663, 'batch_size': 32, 'num_epochs': 837, 'temperature': 0.10444285969569325, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4735947825000902, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.15961648659285416}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 39 finished with value: -0.6875 and parameters: {'learning_rate': 0.00016129674306002663, 'batch_size': 32, 'num_epochs': 837, 'temperature': 0.10444285969569325, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4735947825000902, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.15961648659285416}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:10:37,910 - INFO - Using device: cuda
2025-08-14 21:10:47,832 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:10:47,834 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:10:47,834 - WARNING - Fold 1 has insufficient pairs to form a batch. Skipping.
2025-08-14 21:10:47,834 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:10:47,836 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:10:47,836 - WARNING - Fold 2 has insufficient pairs to form a batch. Skipping.
2025-08-14 21:10:47,836 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:10:47,837 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:10:47,837 - WARNING - Fold 3 has insufficient pairs to form a batch. Skipping.
2025-08-14 21:10:47,838 - WARNING - No folds completed successfully to aggregate metrics.
[I 2025-08-14 21:10:47,841] Trial 40 finished with value: inf and parameters: {'learning_rate': 4.300376557453301e-05, 'batch_size': 64, 'num_epochs': 208, 'temperature': 0.2752649199199903, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.35229226292957655, 'num_layers': 6, 'num_heads': 2, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'crop_size': 0.7313569525510863}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 40 finished with value: inf and parameters: {'learning_rate': 4.300376557453301e-05, 'batch_size': 64, 'num_epochs': 208, 'temperature': 0.2752649199199903, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.35229226292957655, 'num_layers': 6, 'num_heads': 2, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'crop_size': 0.7313569525510863}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:10:47,874 - INFO - Using device: cuda
2025-08-14 21:10:57,839 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:10:57,842 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:10:57,842 - INFO - Starting training for fold 1/3
2025-08-14 21:11:06,863 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-14 21:11:11,158 - INFO - Fold 1, Epoch 20: Val Acc: 0.72%
2025-08-14 21:11:13,503 - INFO - Fold 1, Epoch 30: Val Acc: 0.69%
2025-08-14 21:11:19,697 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-14 21:11:24,220 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-14 21:11:29,017 - INFO - Fold 1, Epoch 60: Val Acc: 0.81%
2025-08-14 21:11:33,364 - INFO - Fold 1, Epoch 70: Val Acc: 0.78%
2025-08-14 21:11:35,581 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-14 21:11:37,800 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-14 21:11:40,021 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-14 21:11:42,248 - INFO - Fold 1, Epoch 110: Val Acc: 0.72%
2025-08-14 21:11:44,461 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-14 21:11:46,670 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-14 21:11:48,889 - INFO - Fold 1, Epoch 140: Val Acc: 0.72%
2025-08-14 21:11:51,060 - INFO - Fold 1, Epoch 150: Val Acc: 0.69%
2025-08-14 21:11:55,573 - INFO - Fold 1, Epoch 160: Val Acc: 0.66%
2025-08-14 21:11:57,796 - INFO - Fold 1, Epoch 170: Val Acc: 0.53%
2025-08-14 21:12:00,013 - INFO - Fold 1, Epoch 180: Val Acc: 0.75%
2025-08-14 21:12:02,208 - INFO - Fold 1, Epoch 190: Val Acc: 0.62%
2025-08-14 21:12:04,502 - INFO - Fold 1, Epoch 200: Val Acc: 0.75%
2025-08-14 21:12:06,803 - INFO - Fold 1, Epoch 210: Val Acc: 0.62%
2025-08-14 21:12:09,057 - INFO - Fold 1, Epoch 220: Val Acc: 0.88%
2025-08-14 21:12:11,342 - INFO - Fold 1, Epoch 230: Val Acc: 0.72%
2025-08-14 21:12:13,568 - INFO - Fold 1, Epoch 240: Val Acc: 0.66%
2025-08-14 21:12:15,791 - INFO - Fold 1, Epoch 250: Val Acc: 0.72%
2025-08-14 21:12:17,800 - INFO - Early stopping at epoch 259
2025-08-14 21:12:21,414 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:12:21,417 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:12:21,418 - INFO - Starting training for fold 2/3
2025-08-14 21:12:26,867 - INFO - Fold 2, Epoch 10: Val Acc: 0.62%
2025-08-14 21:12:32,057 - INFO - Fold 2, Epoch 20: Val Acc: 0.75%
2025-08-14 21:12:34,321 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-14 21:12:39,483 - INFO - Fold 2, Epoch 40: Val Acc: 0.62%
2025-08-14 21:12:41,411 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-14 21:12:43,285 - INFO - Fold 2, Epoch 60: Val Acc: 0.69%
2025-08-14 21:12:45,487 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-14 21:12:47,708 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-14 21:12:49,929 - INFO - Fold 2, Epoch 90: Val Acc: 0.62%
2025-08-14 21:12:52,108 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-14 21:12:54,098 - INFO - Fold 2, Epoch 110: Val Acc: 0.78%
2025-08-14 21:12:56,026 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-14 21:12:58,072 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-14 21:13:06,931 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-14 21:13:09,245 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-14 21:13:11,570 - INFO - Fold 2, Epoch 160: Val Acc: 0.81%
2025-08-14 21:13:13,759 - INFO - Fold 2, Epoch 170: Val Acc: 0.69%
2025-08-14 21:13:15,980 - INFO - Fold 2, Epoch 180: Val Acc: 0.72%
2025-08-14 21:13:18,214 - INFO - Fold 2, Epoch 190: Val Acc: 0.78%
2025-08-14 21:13:20,383 - INFO - Fold 2, Epoch 200: Val Acc: 0.66%
2025-08-14 21:13:22,369 - INFO - Fold 2, Epoch 210: Val Acc: 0.78%
2025-08-14 21:13:24,594 - INFO - Fold 2, Epoch 220: Val Acc: 0.78%
2025-08-14 21:13:26,866 - INFO - Fold 2, Epoch 230: Val Acc: 0.62%
2025-08-14 21:13:27,763 - INFO - Early stopping at epoch 234
2025-08-14 21:13:30,935 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:13:30,938 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:13:30,939 - INFO - Starting training for fold 3/3
2025-08-14 21:13:36,171 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-14 21:13:38,384 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-14 21:13:40,245 - INFO - Fold 3, Epoch 30: Val Acc: 0.69%
2025-08-14 21:13:43,537 - INFO - Fold 3, Epoch 40: Val Acc: 0.59%
2025-08-14 21:13:47,109 - INFO - Fold 3, Epoch 50: Val Acc: 0.56%
2025-08-14 21:13:49,109 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-14 21:13:51,120 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-14 21:13:53,346 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-14 21:13:55,529 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-14 21:13:57,413 - INFO - Fold 3, Epoch 100: Val Acc: 0.84%
2025-08-14 21:13:59,481 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-14 21:14:01,712 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-14 21:14:03,941 - INFO - Fold 3, Epoch 130: Val Acc: 0.59%
2025-08-14 21:14:06,156 - INFO - Fold 3, Epoch 140: Val Acc: 0.81%
2025-08-14 21:14:06,818 - INFO - Early stopping at epoch 143
2025-08-14 21:14:07,896 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9150839911566844), 'std': np.float64(0.05397183794236344)}, 'train_accuracy': {'mean': np.float64(0.7986111111111112), 'std': np.float64(0.055338116147601465)}, 'val_loss': {'mean': np.float64(4.188106218973796), 'std': np.float64(0.14277403085523696)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(111.0), 'std': np.float64(49.846430831772366)}}
[I 2025-08-14 21:14:07,905] Trial 41 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0006550955477461384, 'batch_size': 32, 'num_epochs': 783, 'temperature': 0.345507539860811, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4624982597705408, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.17889261102684437, 'crop_size': 0.5244282707407575}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 41 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0006550955477461384, 'batch_size': 32, 'num_epochs': 783, 'temperature': 0.345507539860811, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4624982597705408, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.17889261102684437, 'crop_size': 0.5244282707407575}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:14:07,934 - INFO - Using device: cuda
2025-08-14 21:14:17,731 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:14:17,733 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:14:17,733 - INFO - Starting training for fold 1/3
2025-08-14 21:14:22,472 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-14 21:14:26,792 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-14 21:14:31,372 - INFO - Fold 1, Epoch 30: Val Acc: 0.53%
2025-08-14 21:14:38,340 - INFO - Fold 1, Epoch 40: Val Acc: 0.66%
2025-08-14 21:14:42,787 - INFO - Fold 1, Epoch 50: Val Acc: 0.69%
2025-08-14 21:14:47,391 - INFO - Fold 1, Epoch 60: Val Acc: 0.62%
2025-08-14 21:14:51,821 - INFO - Fold 1, Epoch 70: Val Acc: 0.94%
2025-08-14 21:14:54,087 - INFO - Fold 1, Epoch 80: Val Acc: 0.84%
2025-08-14 21:14:56,303 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-14 21:14:58,530 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-14 21:15:00,764 - INFO - Fold 1, Epoch 110: Val Acc: 0.78%
2025-08-14 21:15:02,993 - INFO - Fold 1, Epoch 120: Val Acc: 0.62%
2025-08-14 21:15:05,217 - INFO - Fold 1, Epoch 130: Val Acc: 0.72%
2025-08-14 21:15:07,427 - INFO - Fold 1, Epoch 140: Val Acc: 0.78%
2025-08-14 21:15:09,645 - INFO - Fold 1, Epoch 150: Val Acc: 0.56%
2025-08-14 21:15:11,859 - INFO - Fold 1, Epoch 160: Val Acc: 0.66%
2025-08-14 21:15:14,088 - INFO - Early stopping at epoch 170
2025-08-14 21:15:17,827 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:15:17,829 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:15:17,830 - INFO - Starting training for fold 2/3
2025-08-14 21:15:24,616 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-14 21:15:26,938 - INFO - Fold 2, Epoch 20: Val Acc: 0.56%
2025-08-14 21:15:30,767 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-14 21:15:36,018 - INFO - Fold 2, Epoch 40: Val Acc: 0.81%
2025-08-14 21:15:38,014 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-14 21:15:41,331 - INFO - Fold 2, Epoch 60: Val Acc: 0.81%
2025-08-14 21:15:43,656 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-14 21:15:45,873 - INFO - Fold 2, Epoch 80: Val Acc: 0.62%
2025-08-14 21:15:48,092 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-14 21:15:50,318 - INFO - Fold 2, Epoch 100: Val Acc: 0.69%
2025-08-14 21:15:52,525 - INFO - Fold 2, Epoch 110: Val Acc: 0.78%
2025-08-14 21:15:54,751 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-14 21:15:58,498 - INFO - Fold 2, Epoch 130: Val Acc: 0.84%
2025-08-14 21:16:00,737 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-14 21:16:04,469 - INFO - Fold 2, Epoch 150: Val Acc: 0.66%
2025-08-14 21:16:06,705 - INFO - Fold 2, Epoch 160: Val Acc: 0.81%
2025-08-14 21:16:08,936 - INFO - Fold 2, Epoch 170: Val Acc: 0.72%
2025-08-14 21:16:11,169 - INFO - Fold 2, Epoch 180: Val Acc: 0.84%
2025-08-14 21:16:13,408 - INFO - Fold 2, Epoch 190: Val Acc: 0.72%
2025-08-14 21:16:15,643 - INFO - Fold 2, Epoch 200: Val Acc: 0.81%
2025-08-14 21:16:17,869 - INFO - Fold 2, Epoch 210: Val Acc: 0.78%
2025-08-14 21:16:20,093 - INFO - Fold 2, Epoch 220: Val Acc: 0.81%
2025-08-14 21:16:22,323 - INFO - Fold 2, Epoch 230: Val Acc: 0.81%
2025-08-14 21:16:24,553 - INFO - Fold 2, Epoch 240: Val Acc: 0.81%
2025-08-14 21:16:26,564 - INFO - Early stopping at epoch 249
2025-08-14 21:16:27,661 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:16:27,662 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:16:27,663 - INFO - Starting training for fold 3/3
2025-08-14 21:16:37,126 - INFO - Fold 3, Epoch 10: Val Acc: 0.66%
2025-08-14 21:16:40,837 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-14 21:16:44,064 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-14 21:16:47,181 - INFO - Fold 3, Epoch 40: Val Acc: 0.72%
2025-08-14 21:16:48,937 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-14 21:16:52,556 - INFO - Fold 3, Epoch 60: Val Acc: 0.72%
2025-08-14 21:16:54,772 - INFO - Fold 3, Epoch 70: Val Acc: 0.62%
2025-08-14 21:16:56,940 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-14 21:16:59,157 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-14 21:17:01,336 - INFO - Fold 3, Epoch 100: Val Acc: 0.78%
2025-08-14 21:17:03,546 - INFO - Fold 3, Epoch 110: Val Acc: 0.84%
2025-08-14 21:17:07,184 - INFO - Fold 3, Epoch 120: Val Acc: 0.84%
2025-08-14 21:17:09,411 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-14 21:17:11,637 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-14 21:17:13,870 - INFO - Fold 3, Epoch 150: Val Acc: 0.81%
2025-08-14 21:17:16,114 - INFO - Fold 3, Epoch 160: Val Acc: 0.59%
2025-08-14 21:17:18,356 - INFO - Fold 3, Epoch 170: Val Acc: 0.81%
2025-08-14 21:17:20,502 - INFO - Fold 3, Epoch 180: Val Acc: 0.72%
2025-08-14 21:17:22,739 - INFO - Fold 3, Epoch 190: Val Acc: 0.78%
2025-08-14 21:17:25,037 - INFO - Fold 3, Epoch 200: Val Acc: 0.84%
2025-08-14 21:17:27,346 - INFO - Fold 3, Epoch 210: Val Acc: 0.72%
2025-08-14 21:17:28,971 - INFO - Early stopping at epoch 218
2025-08-14 21:17:30,049 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.918392605251736), 'std': np.float64(0.01273904240183942)}, 'train_accuracy': {'mean': np.float64(0.7534722222222222), 'std': np.float64(0.038351947976344655)}, 'val_loss': {'mean': np.float64(4.147323290506999), 'std': np.float64(0.06581395072366839)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(111.33333333333333), 'std': np.float64(32.49957264676295)}}
[I 2025-08-14 21:17:30,057] Trial 42 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0005192713725677051, 'batch_size': 32, 'num_epochs': 917, 'temperature': 0.4244034461680719, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.47069132583378237, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1835741046016601, 'crop_size': 0.5434292518082771}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 42 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0005192713725677051, 'batch_size': 32, 'num_epochs': 917, 'temperature': 0.4244034461680719, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.47069132583378237, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1835741046016601, 'crop_size': 0.5434292518082771}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:17:30,086 - INFO - Using device: cuda
2025-08-14 21:17:39,603 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:17:39,605 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:17:39,605 - INFO - Starting training for fold 1/3
2025-08-14 21:17:47,398 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-14 21:17:51,313 - INFO - Fold 1, Epoch 20: Val Acc: 0.69%
2025-08-14 21:17:54,734 - INFO - Fold 1, Epoch 30: Val Acc: 0.75%
2025-08-14 21:17:58,615 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-14 21:18:02,251 - INFO - Fold 1, Epoch 50: Val Acc: 0.91%
2025-08-14 21:18:04,167 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-14 21:18:05,927 - INFO - Fold 1, Epoch 70: Val Acc: 0.69%
2025-08-14 21:18:07,780 - INFO - Fold 1, Epoch 80: Val Acc: 0.75%
2025-08-14 21:18:09,634 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-14 21:18:11,430 - INFO - Fold 1, Epoch 100: Val Acc: 0.53%
2025-08-14 21:18:13,352 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-14 21:18:15,231 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-14 21:18:17,059 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-14 21:18:19,051 - INFO - Fold 1, Epoch 140: Val Acc: 0.75%
2025-08-14 21:18:20,742 - INFO - Early stopping at epoch 150
2025-08-14 21:18:23,762 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:18:23,764 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:18:23,765 - INFO - Starting training for fold 2/3
2025-08-14 21:18:31,095 - INFO - Fold 2, Epoch 10: Val Acc: 0.47%
2025-08-14 21:18:32,930 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-14 21:18:37,078 - INFO - Fold 2, Epoch 30: Val Acc: 0.81%
2025-08-14 21:18:38,829 - INFO - Fold 2, Epoch 40: Val Acc: 0.84%
2025-08-14 21:18:40,526 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-14 21:18:43,240 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-14 21:18:45,079 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-14 21:18:47,078 - INFO - Fold 2, Epoch 80: Val Acc: 0.84%
2025-08-14 21:18:50,296 - INFO - Fold 2, Epoch 90: Val Acc: 0.84%
2025-08-14 21:18:52,308 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-14 21:18:54,316 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-14 21:18:56,315 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-14 21:18:58,310 - INFO - Fold 2, Epoch 130: Val Acc: 0.91%
2025-08-14 21:19:00,313 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-14 21:19:02,313 - INFO - Fold 2, Epoch 150: Val Acc: 0.81%
2025-08-14 21:19:04,317 - INFO - Fold 2, Epoch 160: Val Acc: 0.81%
2025-08-14 21:19:06,327 - INFO - Fold 2, Epoch 170: Val Acc: 0.81%
2025-08-14 21:19:08,321 - INFO - Fold 2, Epoch 180: Val Acc: 0.81%
2025-08-14 21:19:08,525 - INFO - Early stopping at epoch 181
2025-08-14 21:19:11,300 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:19:11,303 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:19:11,304 - INFO - Starting training for fold 3/3
2025-08-14 21:19:15,880 - INFO - Fold 3, Epoch 10: Val Acc: 0.66%
2025-08-14 21:19:18,990 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-14 21:19:22,226 - INFO - Fold 3, Epoch 30: Val Acc: 0.69%
2025-08-14 21:19:26,763 - INFO - Fold 3, Epoch 40: Val Acc: 0.78%
2025-08-14 21:19:29,974 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-14 21:19:31,970 - INFO - Fold 3, Epoch 60: Val Acc: 0.81%
2025-08-14 21:19:35,186 - INFO - Fold 3, Epoch 70: Val Acc: 0.81%
2025-08-14 21:19:37,182 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-14 21:19:39,184 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-14 21:19:41,192 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-14 21:19:43,201 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-14 21:19:45,209 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-14 21:19:47,208 - INFO - Fold 3, Epoch 130: Val Acc: 0.75%
2025-08-14 21:19:49,197 - INFO - Fold 3, Epoch 140: Val Acc: 0.75%
2025-08-14 21:19:51,205 - INFO - Fold 3, Epoch 150: Val Acc: 0.62%
2025-08-14 21:19:55,078 - INFO - Fold 3, Epoch 160: Val Acc: 0.69%
2025-08-14 21:19:57,088 - INFO - Fold 3, Epoch 170: Val Acc: 0.88%
2025-08-14 21:19:59,095 - INFO - Fold 3, Epoch 180: Val Acc: 0.84%
2025-08-14 21:20:01,091 - INFO - Fold 3, Epoch 190: Val Acc: 0.75%
2025-08-14 21:20:03,080 - INFO - Fold 3, Epoch 200: Val Acc: 0.72%
2025-08-14 21:20:05,089 - INFO - Fold 3, Epoch 210: Val Acc: 0.56%
2025-08-14 21:20:07,095 - INFO - Fold 3, Epoch 220: Val Acc: 0.66%
2025-08-14 21:20:08,962 - INFO - Fold 3, Epoch 230: Val Acc: 0.78%
2025-08-14 21:20:10,778 - INFO - Fold 3, Epoch 240: Val Acc: 0.59%
2025-08-14 21:20:12,567 - INFO - Fold 3, Epoch 250: Val Acc: 0.66%
2025-08-14 21:20:13,135 - INFO - Early stopping at epoch 253
2025-08-14 21:20:14,023 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9100026554531517), 'std': np.float64(0.06944080088803402)}, 'train_accuracy': {'mean': np.float64(0.7881944444444445), 'std': np.float64(0.021404215288086746)}, 'val_loss': {'mean': np.float64(4.191848436991374), 'std': np.float64(0.008553074334658808)}, 'val_accuracy': {'mean': np.float64(0.9270833333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(93.66666666666667), 'std': np.float64(43.14574782705192)}}
[I 2025-08-14 21:20:14,030] Trial 43 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0007795985470354467, 'batch_size': 32, 'num_epochs': 765, 'temperature': 0.4797017641365143, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.44630206835843894, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.17142492413689533, 'crop_size': 0.5372269564364432}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 43 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0007795985470354467, 'batch_size': 32, 'num_epochs': 765, 'temperature': 0.4797017641365143, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.44630206835843894, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.17142492413689533, 'crop_size': 0.5372269564364432}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:20:14,061 - INFO - Using device: cuda
2025-08-14 21:20:23,474 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:20:23,475 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:20:23,475 - INFO - Starting training for fold 1/3
2025-08-14 21:20:31,494 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-14 21:20:37,053 - INFO - Fold 1, Epoch 20: Val Acc: 0.75%
2025-08-14 21:20:39,064 - INFO - Fold 1, Epoch 30: Val Acc: 0.75%
2025-08-14 21:20:41,077 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-14 21:20:43,088 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-14 21:20:45,088 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-14 21:20:47,095 - INFO - Fold 1, Epoch 70: Val Acc: 0.78%
2025-08-14 21:20:49,100 - INFO - Fold 1, Epoch 80: Val Acc: 0.69%
2025-08-14 21:20:51,115 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-14 21:20:53,125 - INFO - Fold 1, Epoch 100: Val Acc: 0.81%
2025-08-14 21:20:55,138 - INFO - Fold 1, Epoch 110: Val Acc: 0.78%
2025-08-14 21:20:56,931 - INFO - Early stopping at epoch 119
2025-08-14 21:20:59,995 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:20:59,997 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:20:59,998 - INFO - Starting training for fold 2/3
2025-08-14 21:21:04,434 - INFO - Fold 2, Epoch 10: Val Acc: 0.69%
2025-08-14 21:21:09,002 - INFO - Fold 2, Epoch 20: Val Acc: 0.72%
2025-08-14 21:21:12,201 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-14 21:21:14,201 - INFO - Fold 2, Epoch 40: Val Acc: 0.66%
2025-08-14 21:21:17,455 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-14 21:21:19,320 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-14 21:21:21,141 - INFO - Fold 2, Epoch 70: Val Acc: 0.66%
2025-08-14 21:21:22,951 - INFO - Fold 2, Epoch 80: Val Acc: 0.72%
2025-08-14 21:21:24,801 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-14 21:21:26,660 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-14 21:21:28,498 - INFO - Fold 2, Epoch 110: Val Acc: 0.84%
2025-08-14 21:21:30,364 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-14 21:21:31,898 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-14 21:21:33,441 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-14 21:21:34,368 - INFO - Early stopping at epoch 146
2025-08-14 21:21:37,005 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:21:37,016 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:21:37,017 - INFO - Starting training for fold 3/3
2025-08-14 21:21:46,916 - INFO - Fold 3, Epoch 10: Val Acc: 0.69%
2025-08-14 21:21:50,225 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-14 21:21:53,494 - INFO - Fold 3, Epoch 30: Val Acc: 0.69%
2025-08-14 21:21:57,673 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-14 21:21:59,684 - INFO - Fold 3, Epoch 50: Val Acc: 0.75%
2025-08-14 21:22:01,699 - INFO - Fold 3, Epoch 60: Val Acc: 0.81%
2025-08-14 21:22:03,707 - INFO - Fold 3, Epoch 70: Val Acc: 0.88%
2025-08-14 21:22:05,721 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-14 21:22:07,797 - INFO - Fold 3, Epoch 90: Val Acc: 0.62%
2025-08-14 21:22:09,872 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-14 21:22:11,954 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-14 21:22:14,032 - INFO - Fold 3, Epoch 120: Val Acc: 0.62%
2025-08-14 21:22:16,096 - INFO - Fold 3, Epoch 130: Val Acc: 0.69%
2025-08-14 21:22:17,344 - INFO - Early stopping at epoch 136
2025-08-14 21:22:19,684 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.0080159240298805), 'std': np.float64(0.04590448603618426)}, 'train_accuracy': {'mean': np.float64(0.71875), 'std': np.float64(0.05577214723683687)}, 'val_loss': {'mean': np.float64(4.181942145029704), 'std': np.float64(0.014756073307036642)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(32.666666666666664), 'std': np.float64(11.145502331533658)}}
[I 2025-08-14 21:22:19,694] Trial 44 finished with value: -0.90625 and parameters: {'learning_rate': 0.0008472483346066593, 'batch_size': 32, 'num_epochs': 867, 'temperature': 0.4451018876959691, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.44215126906931956, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.09412193871549904, 'crop_size': 0.5677833122476417}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 44 finished with value: -0.90625 and parameters: {'learning_rate': 0.0008472483346066593, 'batch_size': 32, 'num_epochs': 867, 'temperature': 0.4451018876959691, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.44215126906931956, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.09412193871549904, 'crop_size': 0.5677833122476417}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:22:19,767 - INFO - Using device: cuda
2025-08-14 21:22:29,559 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:22:29,560 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:22:29,561 - INFO - Starting training for fold 1/3
2025-08-14 21:22:36,152 - INFO - Fold 1, Epoch 10: Val Acc: 0.62%
2025-08-14 21:22:40,523 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-14 21:22:42,308 - INFO - Fold 1, Epoch 30: Val Acc: 0.66%
2025-08-14 21:22:44,000 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-14 21:22:45,647 - INFO - Fold 1, Epoch 50: Val Acc: 0.56%
2025-08-14 21:22:47,369 - INFO - Fold 1, Epoch 60: Val Acc: 0.56%
2025-08-14 21:22:49,085 - INFO - Fold 1, Epoch 70: Val Acc: 0.50%
2025-08-14 21:22:50,810 - INFO - Fold 1, Epoch 80: Val Acc: 0.56%
2025-08-14 21:22:52,529 - INFO - Fold 1, Epoch 90: Val Acc: 0.62%
2025-08-14 21:22:54,000 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-14 21:22:55,333 - INFO - Fold 1, Epoch 110: Val Acc: 0.41%
2025-08-14 21:22:55,733 - INFO - Early stopping at epoch 113
2025-08-14 21:22:58,072 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:22:58,074 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:22:58,075 - INFO - Starting training for fold 2/3
2025-08-14 21:23:06,828 - INFO - Fold 2, Epoch 10: Val Acc: 0.78%
2025-08-14 21:23:08,551 - INFO - Fold 2, Epoch 20: Val Acc: 0.84%
2025-08-14 21:23:09,993 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-14 21:23:11,333 - INFO - Fold 2, Epoch 40: Val Acc: 0.81%
2025-08-14 21:23:13,651 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-14 21:23:15,285 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-14 21:23:16,747 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-14 21:23:18,441 - INFO - Fold 2, Epoch 80: Val Acc: 0.72%
2025-08-14 21:23:20,157 - INFO - Fold 2, Epoch 90: Val Acc: 0.88%
2025-08-14 21:23:21,893 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-14 21:23:23,608 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-14 21:23:25,328 - INFO - Fold 2, Epoch 120: Val Acc: 0.66%
2025-08-14 21:23:27,053 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-14 21:23:28,771 - INFO - Fold 2, Epoch 140: Val Acc: 0.69%
2025-08-14 21:23:29,464 - INFO - Early stopping at epoch 144
2025-08-14 21:23:31,383 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:23:31,391 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:23:31,392 - INFO - Starting training for fold 3/3
2025-08-14 21:23:37,235 - INFO - Fold 3, Epoch 10: Val Acc: 0.72%
2025-08-14 21:23:38,946 - INFO - Fold 3, Epoch 20: Val Acc: 0.78%
2025-08-14 21:23:40,669 - INFO - Fold 3, Epoch 30: Val Acc: 0.78%
2025-08-14 21:23:42,378 - INFO - Fold 3, Epoch 40: Val Acc: 0.69%
2025-08-14 21:23:44,079 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-14 21:23:45,711 - INFO - Fold 3, Epoch 60: Val Acc: 0.72%
2025-08-14 21:23:47,365 - INFO - Fold 3, Epoch 70: Val Acc: 0.66%
2025-08-14 21:23:48,899 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-14 21:23:50,586 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-14 21:23:52,229 - INFO - Fold 3, Epoch 100: Val Acc: 0.66%
2025-08-14 21:23:53,431 - INFO - Early stopping at epoch 107
2025-08-14 21:23:55,284 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.8906439940134683), 'std': np.float64(0.09008600583528725)}, 'train_accuracy': {'mean': np.float64(0.795138888888889), 'std': np.float64(0.07081971546656642)}, 'val_loss': {'mean': np.float64(4.1513298352559405), 'std': np.float64(0.09819794895667634)}, 'val_accuracy': {'mean': np.float64(0.8333333333333334), 'std': np.float64(0.0820209153542897)}, 'epoch': {'mean': np.float64(20.333333333333332), 'std': np.float64(16.21384867602041)}}
[I 2025-08-14 21:23:55,293] Trial 45 finished with value: -0.8333333333333334 and parameters: {'learning_rate': 0.0003097450741023774, 'batch_size': 32, 'num_epochs': 956, 'temperature': 0.48337808193679566, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.16484570747743485, 'num_layers': 3, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1670914089702276}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 45 finished with value: -0.8333333333333334 and parameters: {'learning_rate': 0.0003097450741023774, 'batch_size': 32, 'num_epochs': 956, 'temperature': 0.48337808193679566, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.16484570747743485, 'num_layers': 3, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1670914089702276}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:23:55,368 - INFO - Using device: cuda
2025-08-14 21:24:04,973 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:24:04,978 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:24:04,978 - INFO - Starting training for fold 1/3
2025-08-14 21:24:12,491 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-14 21:24:14,436 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-14 21:24:18,131 - INFO - Fold 1, Epoch 30: Val Acc: 0.66%
2025-08-14 21:24:20,253 - INFO - Fold 1, Epoch 40: Val Acc: 0.50%
2025-08-14 21:24:22,275 - INFO - Fold 1, Epoch 50: Val Acc: 0.50%
2025-08-14 21:24:24,349 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-14 21:24:26,433 - INFO - Fold 1, Epoch 70: Val Acc: 0.41%
2025-08-14 21:24:28,531 - INFO - Fold 1, Epoch 80: Val Acc: 0.56%
2025-08-14 21:24:30,646 - INFO - Fold 1, Epoch 90: Val Acc: 0.53%
2025-08-14 21:24:32,730 - INFO - Fold 1, Epoch 100: Val Acc: 0.56%
2025-08-14 21:24:34,469 - INFO - Fold 1, Epoch 110: Val Acc: 0.47%
2025-08-14 21:24:36,427 - INFO - Fold 1, Epoch 120: Val Acc: 0.62%
2025-08-14 21:24:38,477 - INFO - Early stopping at epoch 130
2025-08-14 21:24:41,454 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:24:41,456 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:24:41,457 - INFO - Starting training for fold 2/3
2025-08-14 21:24:46,215 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-14 21:24:48,327 - INFO - Fold 2, Epoch 20: Val Acc: 0.47%
2025-08-14 21:24:52,717 - INFO - Fold 2, Epoch 30: Val Acc: 0.50%
2025-08-14 21:24:55,819 - INFO - Fold 2, Epoch 40: Val Acc: 0.59%
2025-08-14 21:24:57,865 - INFO - Fold 2, Epoch 50: Val Acc: 0.53%
2025-08-14 21:24:59,969 - INFO - Fold 2, Epoch 60: Val Acc: 0.47%
2025-08-14 21:25:02,088 - INFO - Fold 2, Epoch 70: Val Acc: 0.56%
2025-08-14 21:25:04,202 - INFO - Fold 2, Epoch 80: Val Acc: 0.41%
2025-08-14 21:25:07,548 - INFO - Fold 2, Epoch 90: Val Acc: 0.44%
2025-08-14 21:25:09,592 - INFO - Fold 2, Epoch 100: Val Acc: 0.59%
2025-08-14 21:25:11,637 - INFO - Fold 2, Epoch 110: Val Acc: 0.53%
2025-08-14 21:25:13,360 - INFO - Fold 2, Epoch 120: Val Acc: 0.44%
2025-08-14 21:25:15,103 - INFO - Fold 2, Epoch 130: Val Acc: 0.50%
2025-08-14 21:25:17,154 - INFO - Fold 2, Epoch 140: Val Acc: 0.44%
2025-08-14 21:25:19,193 - INFO - Fold 2, Epoch 150: Val Acc: 0.50%
2025-08-14 21:25:21,228 - INFO - Fold 2, Epoch 160: Val Acc: 0.53%
2025-08-14 21:25:23,327 - INFO - Fold 2, Epoch 170: Val Acc: 0.59%
2025-08-14 21:25:25,429 - INFO - Fold 2, Epoch 180: Val Acc: 0.50%
2025-08-14 21:25:26,802 - INFO - Early stopping at epoch 187
2025-08-14 21:25:29,316 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:25:29,319 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:25:29,320 - INFO - Starting training for fold 3/3
2025-08-14 21:25:34,000 - INFO - Fold 3, Epoch 10: Val Acc: 0.41%
2025-08-14 21:25:37,297 - INFO - Fold 3, Epoch 20: Val Acc: 0.47%
2025-08-14 21:25:40,569 - INFO - Fold 3, Epoch 30: Val Acc: 0.53%
2025-08-14 21:25:42,659 - INFO - Fold 3, Epoch 40: Val Acc: 0.50%
2025-08-14 21:25:44,757 - INFO - Fold 3, Epoch 50: Val Acc: 0.53%
2025-08-14 21:25:46,825 - INFO - Fold 3, Epoch 60: Val Acc: 0.47%
2025-08-14 21:25:48,762 - INFO - Fold 3, Epoch 70: Val Acc: 0.50%
2025-08-14 21:25:50,570 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-14 21:25:52,607 - INFO - Fold 3, Epoch 90: Val Acc: 0.53%
2025-08-14 21:25:54,638 - INFO - Fold 3, Epoch 100: Val Acc: 0.62%
2025-08-14 21:25:56,679 - INFO - Fold 3, Epoch 110: Val Acc: 0.50%
2025-08-14 21:25:58,716 - INFO - Fold 3, Epoch 120: Val Acc: 0.59%
2025-08-14 21:26:00,264 - INFO - Early stopping at epoch 129
2025-08-14 21:26:02,697 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.246293677224053), 'std': np.float64(0.03468551537302175)}, 'train_accuracy': {'mean': np.float64(0.5520833333333333), 'std': np.float64(0.008505172717997162)}, 'val_loss': {'mean': np.float64(4.3475661277771), 'std': np.float64(0.10656299014455659)}, 'val_accuracy': {'mean': np.float64(0.6979166666666666), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(47.666666666666664), 'std': np.float64(27.10883414846328)}}
[I 2025-08-14 21:26:02,706] Trial 46 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 1.1552449595058517e-05, 'batch_size': 32, 'num_epochs': 700, 'temperature': 0.15874242434890476, 'embedding_dim': 128, 'hidden_dim': 512, 'dropout': 0.3813964018343766, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.18863065477667687, 'crop_size': 0.503000471865898}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 46 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 1.1552449595058517e-05, 'batch_size': 32, 'num_epochs': 700, 'temperature': 0.15874242434890476, 'embedding_dim': 128, 'hidden_dim': 512, 'dropout': 0.3813964018343766, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.18863065477667687, 'crop_size': 0.503000471865898}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:26:02,776 - INFO - Using device: cuda
2025-08-14 21:26:12,466 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:26:12,467 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:26:12,467 - INFO - Starting training for fold 1/3
2025-08-14 21:26:17,135 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-14 21:26:20,249 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-14 21:26:21,962 - INFO - Fold 1, Epoch 30: Val Acc: 0.47%
2025-08-14 21:26:23,685 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-14 21:26:25,261 - INFO - Fold 1, Epoch 50: Val Acc: 0.47%
2025-08-14 21:26:26,803 - INFO - Fold 1, Epoch 60: Val Acc: 0.41%
2025-08-14 21:26:29,737 - INFO - Fold 1, Epoch 70: Val Acc: 0.59%
2025-08-14 21:26:31,319 - INFO - Fold 1, Epoch 80: Val Acc: 0.53%
2025-08-14 21:26:32,922 - INFO - Fold 1, Epoch 90: Val Acc: 0.50%
2025-08-14 21:26:34,782 - INFO - Fold 1, Epoch 100: Val Acc: 0.50%
2025-08-14 21:26:36,649 - INFO - Fold 1, Epoch 110: Val Acc: 0.53%
2025-08-14 21:26:38,504 - INFO - Fold 1, Epoch 120: Val Acc: 0.53%
2025-08-14 21:26:40,355 - INFO - Fold 1, Epoch 130: Val Acc: 0.44%
2025-08-14 21:26:42,218 - INFO - Fold 1, Epoch 140: Val Acc: 0.66%
2025-08-14 21:26:43,962 - INFO - Fold 1, Epoch 150: Val Acc: 0.44%
2025-08-14 21:26:45,629 - INFO - Fold 1, Epoch 160: Val Acc: 0.56%
2025-08-14 21:26:45,811 - INFO - Early stopping at epoch 161
2025-08-14 21:26:48,134 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:26:48,138 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:26:48,138 - INFO - Starting training for fold 2/3
2025-08-14 21:26:53,664 - INFO - Fold 2, Epoch 10: Val Acc: 0.69%
2025-08-14 21:26:55,608 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-14 21:26:57,447 - INFO - Fold 2, Epoch 30: Val Acc: 0.53%
2025-08-14 21:26:59,293 - INFO - Fold 2, Epoch 40: Val Acc: 0.53%
2025-08-14 21:27:01,138 - INFO - Fold 2, Epoch 50: Val Acc: 0.38%
2025-08-14 21:27:02,932 - INFO - Fold 2, Epoch 60: Val Acc: 0.50%
2025-08-14 21:27:04,771 - INFO - Fold 2, Epoch 70: Val Acc: 0.53%
2025-08-14 21:27:06,616 - INFO - Fold 2, Epoch 80: Val Acc: 0.50%
2025-08-14 21:27:08,386 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-14 21:27:10,149 - INFO - Fold 2, Epoch 100: Val Acc: 0.50%
2025-08-14 21:27:11,911 - INFO - Early stopping at epoch 110
2025-08-14 21:27:12,579 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:27:12,580 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:27:12,581 - INFO - Starting training for fold 3/3
2025-08-14 21:27:18,442 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-14 21:27:21,304 - INFO - Fold 3, Epoch 20: Val Acc: 0.50%
2025-08-14 21:27:23,065 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-14 21:27:25,756 - INFO - Fold 3, Epoch 40: Val Acc: 0.50%
2025-08-14 21:27:27,519 - INFO - Fold 3, Epoch 50: Val Acc: 0.53%
2025-08-14 21:27:29,284 - INFO - Fold 3, Epoch 60: Val Acc: 0.50%
2025-08-14 21:27:31,047 - INFO - Fold 3, Epoch 70: Val Acc: 0.56%
2025-08-14 21:27:32,831 - INFO - Fold 3, Epoch 80: Val Acc: 0.47%
2025-08-14 21:27:34,601 - INFO - Fold 3, Epoch 90: Val Acc: 0.66%
2025-08-14 21:27:36,375 - INFO - Fold 3, Epoch 100: Val Acc: 0.50%
2025-08-14 21:27:38,151 - INFO - Fold 3, Epoch 110: Val Acc: 0.44%
2025-08-14 21:27:39,918 - INFO - Fold 3, Epoch 120: Val Acc: 0.62%
2025-08-14 21:27:41,752 - INFO - Fold 3, Epoch 130: Val Acc: 0.41%
2025-08-14 21:27:43,403 - INFO - Early stopping at epoch 139
2025-08-14 21:27:44,110 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.147909641265869), 'std': np.float64(0.004761714595918521)}, 'train_accuracy': {'mean': np.float64(0.5729166666666666), 'std': np.float64(0.02250257186947174)}, 'val_loss': {'mean': np.float64(4.168127536773682), 'std': np.float64(0.04075175245000332)}, 'val_accuracy': {'mean': np.float64(0.6875), 'std': np.float64(0.0)}, 'epoch': {'mean': np.float64(35.666666666666664), 'std': np.float64(20.885933597094056)}}
[I 2025-08-14 21:27:44,116] Trial 47 finished with value: -0.6875 and parameters: {'learning_rate': 0.0004688530821249759, 'batch_size': 32, 'num_epochs': 759, 'temperature': 0.38641244630422933, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4371317937784402, 'num_layers': 3, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'crop_size': 0.7892515074723868}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 47 finished with value: -0.6875 and parameters: {'learning_rate': 0.0004688530821249759, 'batch_size': 32, 'num_epochs': 759, 'temperature': 0.38641244630422933, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4371317937784402, 'num_layers': 3, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'crop_size': 0.7892515074723868}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:27:44,143 - INFO - Using device: cuda
2025-08-14 21:27:53,872 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:27:53,873 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:27:53,874 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 21:28:03,229 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-14 21:28:06,159 - INFO - Fold 1, Epoch 20: Val Acc: 0.65%
2025-08-14 21:28:08,933 - INFO - Fold 1, Epoch 30: Val Acc: 0.52%
2025-08-14 21:28:11,290 - INFO - Fold 1, Epoch 40: Val Acc: 0.50%
2025-08-14 21:28:13,876 - INFO - Fold 1, Epoch 50: Val Acc: 0.58%
2025-08-14 21:28:16,643 - INFO - Fold 1, Epoch 60: Val Acc: 0.58%
2025-08-14 21:28:19,662 - INFO - Fold 1, Epoch 70: Val Acc: 0.52%
2025-08-14 21:28:22,986 - INFO - Fold 1, Epoch 80: Val Acc: 0.54%
2025-08-14 21:28:26,256 - INFO - Fold 1, Epoch 90: Val Acc: 0.54%
2025-08-14 21:28:29,566 - INFO - Fold 1, Epoch 100: Val Acc: 0.52%
2025-08-14 21:28:31,877 - INFO - Early stopping at epoch 107
2025-08-14 21:28:35,015 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:28:35,034 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:28:35,034 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 21:28:42,051 - INFO - Fold 2, Epoch 10: Val Acc: 0.73%
2025-08-14 21:28:47,692 - INFO - Fold 2, Epoch 20: Val Acc: 0.90%
2025-08-14 21:28:50,889 - INFO - Fold 2, Epoch 30: Val Acc: 0.77%
2025-08-14 21:28:55,072 - INFO - Fold 2, Epoch 40: Val Acc: 0.81%
2025-08-14 21:28:58,369 - INFO - Fold 2, Epoch 50: Val Acc: 0.77%
2025-08-14 21:29:01,669 - INFO - Fold 2, Epoch 60: Val Acc: 0.85%
2025-08-14 21:29:04,973 - INFO - Fold 2, Epoch 70: Val Acc: 0.77%
2025-08-14 21:29:08,265 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-14 21:29:11,456 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-14 21:29:14,317 - INFO - Fold 2, Epoch 100: Val Acc: 0.73%
2025-08-14 21:29:17,594 - INFO - Fold 2, Epoch 110: Val Acc: 0.73%
2025-08-14 21:29:20,863 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-14 21:29:24,153 - INFO - Fold 2, Epoch 130: Val Acc: 0.73%
2025-08-14 21:29:25,149 - INFO - Early stopping at epoch 133
2025-08-14 21:29:27,801 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:29:27,804 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:29:27,805 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 21:29:37,407 - INFO - Fold 3, Epoch 10: Val Acc: 0.73%
2025-08-14 21:29:41,530 - INFO - Fold 3, Epoch 20: Val Acc: 0.79%
2025-08-14 21:29:44,185 - INFO - Fold 3, Epoch 30: Val Acc: 0.81%
2025-08-14 21:29:47,283 - INFO - Fold 3, Epoch 40: Val Acc: 0.79%
2025-08-14 21:29:50,569 - INFO - Fold 3, Epoch 50: Val Acc: 0.75%
2025-08-14 21:29:53,362 - INFO - Fold 3, Epoch 60: Val Acc: 0.79%
2025-08-14 21:29:56,598 - INFO - Fold 3, Epoch 70: Val Acc: 0.73%
2025-08-14 21:29:59,873 - INFO - Fold 3, Epoch 80: Val Acc: 0.73%
2025-08-14 21:30:02,841 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-14 21:30:06,222 - INFO - Fold 3, Epoch 100: Val Acc: 0.71%
2025-08-14 21:30:08,934 - INFO - Fold 3, Epoch 110: Val Acc: 0.77%
2025-08-14 21:30:10,556 - INFO - Early stopping at epoch 116
2025-08-14 21:30:11,436 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.149533364507887), 'std': np.float64(0.10107169298756595)}, 'train_accuracy': {'mean': np.float64(0.8159722222222222), 'std': np.float64(0.012991865926298363)}, 'val_loss': {'mean': np.float64(3.635895676083035), 'std': np.float64(0.17700297159177278)}, 'val_accuracy': {'mean': np.float64(0.8333333333333334), 'std': np.float64(0.10346989184549539)}, 'epoch': {'mean': np.float64(17.666666666666668), 'std': np.float64(10.780641085864152)}}
[I 2025-08-14 21:30:11,443] Trial 48 finished with value: -0.8333333333333334 and parameters: {'learning_rate': 0.0002456132855936577, 'batch_size': 16, 'num_epochs': 973, 'temperature': 0.3054523201354772, 'embedding_dim': 128, 'hidden_dim': 128, 'dropout': 0.41174687824212053, 'num_layers': 4, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19966013098963262}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 48 finished with value: -0.8333333333333334 and parameters: {'learning_rate': 0.0002456132855936577, 'batch_size': 16, 'num_epochs': 973, 'temperature': 0.3054523201354772, 'embedding_dim': 128, 'hidden_dim': 128, 'dropout': 0.41174687824212053, 'num_layers': 4, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19966013098963262}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:30:11,472 - INFO - Using device: cuda
2025-08-14 21:30:21,123 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:30:21,125 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:30:21,125 - INFO - Starting training for fold 1/3
2025-08-14 21:30:31,456 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-14 21:30:33,862 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-14 21:30:36,305 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 21:30:38,753 - INFO - Fold 1, Epoch 40: Val Acc: 0.50%
2025-08-14 21:30:41,190 - INFO - Fold 1, Epoch 50: Val Acc: 0.50%
2025-08-14 21:30:43,632 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-14 21:30:46,087 - INFO - Fold 1, Epoch 70: Val Acc: 0.56%
2025-08-14 21:30:48,361 - INFO - Fold 1, Epoch 80: Val Acc: 0.50%
2025-08-14 21:30:52,927 - INFO - Fold 1, Epoch 90: Val Acc: 0.50%
2025-08-14 21:30:55,373 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-14 21:30:57,830 - INFO - Fold 1, Epoch 110: Val Acc: 0.50%
2025-08-14 21:31:00,041 - INFO - Fold 1, Epoch 120: Val Acc: 0.50%
2025-08-14 21:31:01,895 - INFO - Fold 1, Epoch 130: Val Acc: 0.50%
2025-08-14 21:31:03,751 - INFO - Fold 1, Epoch 140: Val Acc: 0.50%
2025-08-14 21:31:05,885 - INFO - Fold 1, Epoch 150: Val Acc: 0.50%
2025-08-14 21:31:08,315 - INFO - Fold 1, Epoch 160: Val Acc: 0.47%
2025-08-14 21:31:10,729 - INFO - Fold 1, Epoch 170: Val Acc: 0.50%
2025-08-14 21:31:13,166 - INFO - Fold 1, Epoch 180: Val Acc: 0.50%
2025-08-14 21:31:15,118 - INFO - Early stopping at epoch 188
2025-08-14 21:31:18,787 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:31:18,790 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:31:18,790 - INFO - Starting training for fold 2/3
2025-08-14 21:31:26,499 - INFO - Fold 2, Epoch 10: Val Acc: 0.53%
2025-08-14 21:31:30,708 - INFO - Fold 2, Epoch 20: Val Acc: 0.53%
2025-08-14 21:31:33,158 - INFO - Fold 2, Epoch 30: Val Acc: 0.50%
2025-08-14 21:31:35,627 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-14 21:31:41,955 - INFO - Fold 2, Epoch 50: Val Acc: 0.56%
2025-08-14 21:31:44,280 - INFO - Fold 2, Epoch 60: Val Acc: 0.50%
2025-08-14 21:31:46,738 - INFO - Fold 2, Epoch 70: Val Acc: 0.50%
2025-08-14 21:31:49,192 - INFO - Fold 2, Epoch 80: Val Acc: 0.50%
2025-08-14 21:31:51,364 - INFO - Fold 2, Epoch 90: Val Acc: 0.59%
2025-08-14 21:31:53,438 - INFO - Fold 2, Epoch 100: Val Acc: 0.50%
2025-08-14 21:31:55,505 - INFO - Fold 2, Epoch 110: Val Acc: 0.53%
2025-08-14 21:31:57,554 - INFO - Fold 2, Epoch 120: Val Acc: 0.53%
2025-08-14 21:31:59,631 - INFO - Fold 2, Epoch 130: Val Acc: 0.47%
2025-08-14 21:32:01,677 - INFO - Fold 2, Epoch 140: Val Acc: 0.50%
2025-08-14 21:32:03,684 - INFO - Early stopping at epoch 148
2025-08-14 21:32:06,985 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:32:07,000 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:32:07,000 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 21:32:13,097 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-14 21:32:15,628 - INFO - Fold 3, Epoch 20: Val Acc: 0.50%
2025-08-14 21:32:19,861 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-14 21:32:22,403 - INFO - Fold 3, Epoch 40: Val Acc: 0.47%
2025-08-14 21:32:24,974 - INFO - Fold 3, Epoch 50: Val Acc: 0.44%
2025-08-14 21:32:27,500 - INFO - Fold 3, Epoch 60: Val Acc: 0.50%
2025-08-14 21:32:31,602 - INFO - Fold 3, Epoch 70: Val Acc: 0.47%
2025-08-14 21:32:34,067 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-14 21:32:36,531 - INFO - Fold 3, Epoch 90: Val Acc: 0.50%
2025-08-14 21:32:38,987 - INFO - Fold 3, Epoch 100: Val Acc: 0.53%
2025-08-14 21:32:41,437 - INFO - Fold 3, Epoch 110: Val Acc: 0.50%
2025-08-14 21:32:43,890 - INFO - Fold 3, Epoch 120: Val Acc: 0.50%
2025-08-14 21:32:46,344 - INFO - Fold 3, Epoch 130: Val Acc: 0.50%
2025-08-14 21:32:48,794 - INFO - Fold 3, Epoch 140: Val Acc: 0.62%
2025-08-14 21:32:51,245 - INFO - Fold 3, Epoch 150: Val Acc: 0.56%
2025-08-14 21:32:53,679 - INFO - Fold 3, Epoch 160: Val Acc: 0.50%
2025-08-14 21:32:55,135 - INFO - Early stopping at epoch 166
2025-08-14 21:32:56,477 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.33192597495185), 'std': np.float64(0.020922166708926774)}, 'train_accuracy': {'mean': np.float64(0.545138888888889), 'std': np.float64(0.017704928866641604)}, 'val_loss': {'mean': np.float64(5.150932947794597), 'std': np.float64(0.7641169279664488)}, 'val_accuracy': {'mean': np.float64(0.6979166666666666), 'std': np.float64(0.05311478659992484)}, 'epoch': {'mean': np.float64(66.33333333333333), 'std': np.float64(16.35712552851373)}}
[I 2025-08-14 21:32:56,484] Trial 49 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 6.034365861718279e-05, 'batch_size': 32, 'num_epochs': 907, 'temperature': 0.14024472150134223, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4821409482325718, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.1487199524934017, 'crop_size': 0.6063217491132818}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 49 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 6.034365861718279e-05, 'batch_size': 32, 'num_epochs': 907, 'temperature': 0.14024472150134223, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4821409482325718, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.1487199524934017, 'crop_size': 0.6063217491132818}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:32:56,511 - INFO - Using device: cuda
2025-08-14 21:33:06,161 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:33:06,162 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:33:06,163 - INFO - Starting training for fold 1/3
2025-08-14 21:33:18,153 - INFO - Fold 1, Epoch 10: Val Acc: 0.69%
2025-08-14 21:33:25,017 - INFO - Fold 1, Epoch 20: Val Acc: 0.78%
2025-08-14 21:33:27,223 - INFO - Fold 1, Epoch 30: Val Acc: 0.78%
2025-08-14 21:33:29,430 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-14 21:33:31,630 - INFO - Fold 1, Epoch 50: Val Acc: 0.69%
2025-08-14 21:33:33,825 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-14 21:33:35,952 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-14 21:33:37,867 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-14 21:33:40,015 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-14 21:33:41,610 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-14 21:33:43,205 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-14 21:33:44,004 - INFO - Early stopping at epoch 115
2025-08-14 21:33:47,737 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:33:47,740 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:33:47,740 - INFO - Starting training for fold 2/3
2025-08-14 21:33:57,701 - INFO - Fold 2, Epoch 10: Val Acc: 0.75%
2025-08-14 21:33:59,901 - INFO - Fold 2, Epoch 20: Val Acc: 0.84%
2025-08-14 21:34:02,088 - INFO - Fold 2, Epoch 30: Val Acc: 0.78%
2025-08-14 21:34:04,275 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-14 21:34:06,451 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-14 21:34:08,310 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-14 21:34:10,001 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-14 21:34:13,549 - INFO - Fold 2, Epoch 80: Val Acc: 0.81%
2025-08-14 21:34:15,753 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-14 21:34:17,922 - INFO - Fold 2, Epoch 100: Val Acc: 0.69%
2025-08-14 21:34:20,026 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-14 21:34:22,120 - INFO - Fold 2, Epoch 120: Val Acc: 0.84%
2025-08-14 21:34:24,176 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-14 21:34:25,947 - INFO - Fold 2, Epoch 140: Val Acc: 0.88%
2025-08-14 21:34:27,744 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-14 21:34:29,820 - INFO - Fold 2, Epoch 160: Val Acc: 0.69%
2025-08-14 21:34:33,457 - INFO - Fold 2, Epoch 170: Val Acc: 0.72%
2025-08-14 21:34:35,564 - INFO - Fold 2, Epoch 180: Val Acc: 0.72%
2025-08-14 21:34:37,679 - INFO - Fold 2, Epoch 190: Val Acc: 0.84%
2025-08-14 21:34:39,792 - INFO - Fold 2, Epoch 200: Val Acc: 0.69%
2025-08-14 21:34:41,910 - INFO - Fold 2, Epoch 210: Val Acc: 0.88%
2025-08-14 21:34:44,030 - INFO - Fold 2, Epoch 220: Val Acc: 0.72%
2025-08-14 21:34:46,139 - INFO - Fold 2, Epoch 230: Val Acc: 0.66%
2025-08-14 21:34:48,247 - INFO - Fold 2, Epoch 240: Val Acc: 0.69%
2025-08-14 21:34:50,358 - INFO - Fold 2, Epoch 250: Val Acc: 0.62%
2025-08-14 21:34:52,366 - INFO - Fold 2, Epoch 260: Val Acc: 0.72%
2025-08-14 21:34:53,696 - INFO - Early stopping at epoch 267
2025-08-14 21:34:56,686 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:34:56,688 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:34:56,689 - INFO - Starting training for fold 3/3
2025-08-14 21:35:04,812 - INFO - Fold 3, Epoch 10: Val Acc: 0.72%
2025-08-14 21:35:08,260 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-14 21:35:10,372 - INFO - Fold 3, Epoch 30: Val Acc: 0.81%
2025-08-14 21:35:15,580 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-14 21:35:19,140 - INFO - Fold 3, Epoch 50: Val Acc: 0.66%
2025-08-14 21:35:21,253 - INFO - Fold 3, Epoch 60: Val Acc: 0.59%
2025-08-14 21:35:23,374 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-14 21:35:25,488 - INFO - Fold 3, Epoch 80: Val Acc: 0.69%
2025-08-14 21:35:27,595 - INFO - Fold 3, Epoch 90: Val Acc: 0.78%
2025-08-14 21:35:29,787 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-14 21:35:31,987 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-14 21:35:33,718 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-14 21:35:35,405 - INFO - Fold 3, Epoch 130: Val Acc: 0.62%
2025-08-14 21:35:37,181 - INFO - Fold 3, Epoch 140: Val Acc: 0.69%
2025-08-14 21:35:37,614 - INFO - Early stopping at epoch 142
2025-08-14 21:35:38,720 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.8157455126444497), 'std': np.float64(0.1742147104174867)}, 'train_accuracy': {'mean': np.float64(0.8298611111111112), 'std': np.float64(0.09820927516479823)}, 'val_loss': {'mean': np.float64(4.186012903849284), 'std': np.float64(0.06738690273710739)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.05311478659992484)}, 'epoch': {'mean': np.float64(73.66666666666667), 'std': np.float64(66.21345952464817)}}
[I 2025-08-14 21:35:38,730] Trial 50 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0008664934484649898, 'batch_size': 32, 'num_epochs': 856, 'temperature': 0.4456095518703027, 'embedding_dim': 512, 'hidden_dim': 256, 'dropout': 0.3309726831366322, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.6681581253880233}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 50 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0008664934484649898, 'batch_size': 32, 'num_epochs': 856, 'temperature': 0.4456095518703027, 'embedding_dim': 512, 'hidden_dim': 256, 'dropout': 0.3309726831366322, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.6681581253880233}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:35:38,777 - INFO - Using device: cuda
2025-08-14 21:35:48,575 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:35:48,577 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:35:48,577 - INFO - Starting training for fold 1/3
2025-08-14 21:35:57,614 - INFO - Fold 1, Epoch 10: Val Acc: 0.66%
2025-08-14 21:35:59,864 - INFO - Fold 1, Epoch 20: Val Acc: 0.44%
2025-08-14 21:36:03,867 - INFO - Fold 1, Epoch 30: Val Acc: 0.53%
2025-08-14 21:36:08,326 - INFO - Fold 1, Epoch 40: Val Acc: 0.56%
2025-08-14 21:36:10,565 - INFO - Fold 1, Epoch 50: Val Acc: 0.72%
2025-08-14 21:36:14,935 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-14 21:36:19,422 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-14 21:36:23,904 - INFO - Fold 1, Epoch 80: Val Acc: 0.78%
2025-08-14 21:36:26,165 - INFO - Fold 1, Epoch 90: Val Acc: 0.84%
2025-08-14 21:36:28,404 - INFO - Fold 1, Epoch 100: Val Acc: 0.78%
2025-08-14 21:36:30,430 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-14 21:36:32,398 - INFO - Fold 1, Epoch 120: Val Acc: 0.78%
2025-08-14 21:36:34,570 - INFO - Fold 1, Epoch 130: Val Acc: 0.72%
2025-08-14 21:36:36,792 - INFO - Fold 1, Epoch 140: Val Acc: 0.69%
2025-08-14 21:36:38,926 - INFO - Fold 1, Epoch 150: Val Acc: 0.75%
2025-08-14 21:36:41,158 - INFO - Fold 1, Epoch 160: Val Acc: 0.66%
2025-08-14 21:36:43,380 - INFO - Fold 1, Epoch 170: Val Acc: 0.72%
2025-08-14 21:36:44,246 - INFO - Early stopping at epoch 174
2025-08-14 21:36:47,910 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:36:47,912 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:36:47,913 - INFO - Starting training for fold 2/3
2025-08-14 21:36:53,375 - INFO - Fold 2, Epoch 10: Val Acc: 0.62%
2025-08-14 21:36:58,636 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-14 21:37:00,910 - INFO - Fold 2, Epoch 30: Val Acc: 0.59%
2025-08-14 21:37:04,714 - INFO - Fold 2, Epoch 40: Val Acc: 0.59%
2025-08-14 21:37:06,994 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-14 21:37:10,640 - INFO - Fold 2, Epoch 60: Val Acc: 0.84%
2025-08-14 21:37:12,924 - INFO - Fold 2, Epoch 70: Val Acc: 0.81%
2025-08-14 21:37:16,555 - INFO - Fold 2, Epoch 80: Val Acc: 0.88%
2025-08-14 21:37:18,771 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-14 21:37:20,992 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-14 21:37:23,213 - INFO - Fold 2, Epoch 110: Val Acc: 0.78%
2025-08-14 21:37:25,433 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-14 21:37:27,649 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-14 21:37:29,868 - INFO - Fold 2, Epoch 140: Val Acc: 0.62%
2025-08-14 21:37:32,076 - INFO - Fold 2, Epoch 150: Val Acc: 0.81%
2025-08-14 21:37:34,293 - INFO - Fold 2, Epoch 160: Val Acc: 0.72%
2025-08-14 21:37:36,393 - INFO - Fold 2, Epoch 170: Val Acc: 0.75%
2025-08-14 21:37:37,581 - INFO - Early stopping at epoch 177
2025-08-14 21:37:38,674 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:37:38,676 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:37:38,676 - INFO - Starting training for fold 3/3
2025-08-14 21:37:45,415 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-14 21:37:49,086 - INFO - Fold 3, Epoch 20: Val Acc: 0.56%
2025-08-14 21:37:52,786 - INFO - Fold 3, Epoch 30: Val Acc: 0.53%
2025-08-14 21:37:56,187 - INFO - Fold 3, Epoch 40: Val Acc: 0.72%
2025-08-14 21:38:02,680 - INFO - Fold 3, Epoch 50: Val Acc: 0.62%
2025-08-14 21:38:04,731 - INFO - Fold 3, Epoch 60: Val Acc: 0.69%
2025-08-14 21:38:06,443 - INFO - Fold 3, Epoch 70: Val Acc: 0.81%
2025-08-14 21:38:08,154 - INFO - Fold 3, Epoch 80: Val Acc: 0.78%
2025-08-14 21:38:11,247 - INFO - Fold 3, Epoch 90: Val Acc: 0.91%
2025-08-14 21:38:13,062 - INFO - Fold 3, Epoch 100: Val Acc: 0.66%
2025-08-14 21:38:14,764 - INFO - Fold 3, Epoch 110: Val Acc: 0.59%
2025-08-14 21:38:16,477 - INFO - Fold 3, Epoch 120: Val Acc: 0.59%
2025-08-14 21:38:18,254 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-14 21:38:20,567 - INFO - Fold 3, Epoch 140: Val Acc: 0.78%
2025-08-14 21:38:22,540 - INFO - Fold 3, Epoch 150: Val Acc: 0.75%
2025-08-14 21:38:24,314 - INFO - Fold 3, Epoch 160: Val Acc: 0.62%
2025-08-14 21:38:26,243 - INFO - Fold 3, Epoch 170: Val Acc: 0.78%
2025-08-14 21:38:27,952 - INFO - Fold 3, Epoch 180: Val Acc: 0.66%
2025-08-14 21:38:29,807 - INFO - Early stopping at epoch 190
2025-08-14 21:38:30,920 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9503609339396157), 'std': np.float64(0.05035342299254417)}, 'train_accuracy': {'mean': np.float64(0.7534722222222223), 'std': np.float64(0.02986918495500915)}, 'val_loss': {'mean': np.float64(4.24318281809489), 'std': np.float64(0.0361394129633195)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(79.33333333333333), 'std': np.float64(6.944222218666553)}}
[I 2025-08-14 21:38:30,929] Trial 51 finished with value: -0.90625 and parameters: {'learning_rate': 0.0006784949410020316, 'batch_size': 32, 'num_epochs': 796, 'temperature': 0.351009344504597, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4475697090915519, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1769915320498106, 'crop_size': 0.5266311857762614}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 51 finished with value: -0.90625 and parameters: {'learning_rate': 0.0006784949410020316, 'batch_size': 32, 'num_epochs': 796, 'temperature': 0.351009344504597, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4475697090915519, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1769915320498106, 'crop_size': 0.5266311857762614}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:38:30,959 - INFO - Using device: cuda
2025-08-14 21:38:40,741 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:38:40,742 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:38:40,742 - INFO - Starting training for fold 1/3
2025-08-14 21:38:50,400 - INFO - Fold 1, Epoch 10: Val Acc: 0.75%
2025-08-14 21:38:53,852 - INFO - Fold 1, Epoch 20: Val Acc: 0.81%
2025-08-14 21:38:55,961 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-14 21:38:58,027 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-14 21:39:00,088 - INFO - Fold 1, Epoch 50: Val Acc: 0.56%
2025-08-14 21:39:02,162 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-14 21:39:04,020 - INFO - Fold 1, Epoch 70: Val Acc: 0.59%
2025-08-14 21:39:07,814 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-14 21:39:09,808 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-14 21:39:11,790 - INFO - Fold 1, Epoch 100: Val Acc: 0.56%
2025-08-14 21:39:13,762 - INFO - Fold 1, Epoch 110: Val Acc: 0.78%
2025-08-14 21:39:17,275 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-14 21:39:18,965 - INFO - Fold 1, Epoch 130: Val Acc: 0.72%
2025-08-14 21:39:20,711 - INFO - Fold 1, Epoch 140: Val Acc: 0.66%
2025-08-14 21:39:22,407 - INFO - Fold 1, Epoch 150: Val Acc: 0.78%
2025-08-14 21:39:24,230 - INFO - Fold 1, Epoch 160: Val Acc: 0.72%
2025-08-14 21:39:27,774 - INFO - Fold 1, Epoch 170: Val Acc: 0.69%
2025-08-14 21:39:29,607 - INFO - Fold 1, Epoch 180: Val Acc: 0.72%
2025-08-14 21:39:31,553 - INFO - Fold 1, Epoch 190: Val Acc: 0.72%
2025-08-14 21:39:33,543 - INFO - Fold 1, Epoch 200: Val Acc: 0.69%
2025-08-14 21:39:35,347 - INFO - Fold 1, Epoch 210: Val Acc: 0.72%
2025-08-14 21:39:37,160 - INFO - Fold 1, Epoch 220: Val Acc: 0.88%
2025-08-14 21:39:39,067 - INFO - Fold 1, Epoch 230: Val Acc: 0.62%
2025-08-14 21:39:41,059 - INFO - Fold 1, Epoch 240: Val Acc: 0.75%
2025-08-14 21:39:43,056 - INFO - Fold 1, Epoch 250: Val Acc: 0.66%
2025-08-14 21:39:45,049 - INFO - Fold 1, Epoch 260: Val Acc: 0.62%
2025-08-14 21:39:45,652 - INFO - Early stopping at epoch 263
2025-08-14 21:39:48,804 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:39:48,810 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:39:48,811 - INFO - Starting training for fold 2/3
2025-08-14 21:39:54,608 - INFO - Fold 2, Epoch 10: Val Acc: 0.44%
2025-08-14 21:39:56,607 - INFO - Fold 2, Epoch 20: Val Acc: 0.53%
2025-08-14 21:40:00,859 - INFO - Fold 2, Epoch 30: Val Acc: 0.81%
2025-08-14 21:40:02,861 - INFO - Fold 2, Epoch 40: Val Acc: 0.78%
2025-08-14 21:40:04,872 - INFO - Fold 2, Epoch 50: Val Acc: 0.66%
2025-08-14 21:40:06,890 - INFO - Fold 2, Epoch 60: Val Acc: 0.53%
2025-08-14 21:40:08,896 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-14 21:40:10,914 - INFO - Fold 2, Epoch 80: Val Acc: 0.84%
2025-08-14 21:40:12,944 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-14 21:40:14,963 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-14 21:40:18,188 - INFO - Fold 2, Epoch 110: Val Acc: 0.91%
2025-08-14 21:40:20,312 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-14 21:40:22,382 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-14 21:40:24,463 - INFO - Fold 2, Epoch 140: Val Acc: 0.81%
2025-08-14 21:40:26,549 - INFO - Fold 2, Epoch 150: Val Acc: 0.81%
2025-08-14 21:40:28,620 - INFO - Fold 2, Epoch 160: Val Acc: 0.78%
2025-08-14 21:40:30,420 - INFO - Fold 2, Epoch 170: Val Acc: 0.81%
2025-08-14 21:40:32,104 - INFO - Fold 2, Epoch 180: Val Acc: 0.78%
2025-08-14 21:40:33,792 - INFO - Fold 2, Epoch 190: Val Acc: 0.66%
2025-08-14 21:40:35,488 - INFO - Fold 2, Epoch 200: Val Acc: 0.72%
2025-08-14 21:40:37,487 - INFO - Early stopping at epoch 210
2025-08-14 21:40:38,389 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:40:38,393 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:40:38,393 - INFO - Starting training for fold 3/3
2025-08-14 21:40:44,025 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-14 21:40:47,171 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-14 21:40:50,286 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-14 21:40:52,359 - INFO - Fold 3, Epoch 40: Val Acc: 0.62%
2025-08-14 21:40:54,433 - INFO - Fold 3, Epoch 50: Val Acc: 0.81%
2025-08-14 21:40:56,463 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-14 21:40:58,286 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-14 21:41:00,288 - INFO - Fold 3, Epoch 80: Val Acc: 0.78%
2025-08-14 21:41:02,335 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-14 21:41:04,399 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-14 21:41:06,410 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-14 21:41:08,416 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-14 21:41:09,628 - INFO - Early stopping at epoch 126
2025-08-14 21:41:10,518 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9773979716830787), 'std': np.float64(0.05482351504966611)}, 'train_accuracy': {'mean': np.float64(0.7222222222222223), 'std': np.float64(0.06383602885711888)}, 'val_loss': {'mean': np.float64(4.183364232381185), 'std': np.float64(0.058021250568668074)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(98.66666666666667), 'std': np.float64(56.405279500730735)}}
[I 2025-08-14 21:41:10,530] Trial 52 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0003551974230631874, 'batch_size': 32, 'num_epochs': 743, 'temperature': 0.35713467247234604, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.48565925587997966, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.03717203755432058, 'crop_size': 0.5378245186252557}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 52 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0003551974230631874, 'batch_size': 32, 'num_epochs': 743, 'temperature': 0.35713467247234604, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.48565925587997966, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.03717203755432058, 'crop_size': 0.5378245186252557}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:41:10,563 - INFO - Using device: cuda
2025-08-14 21:41:20,521 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:41:20,522 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:41:20,523 - INFO - Starting training for fold 1/3
2025-08-14 21:41:27,688 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-14 21:41:33,923 - INFO - Fold 1, Epoch 20: Val Acc: 0.72%
2025-08-14 21:41:38,438 - INFO - Fold 1, Epoch 30: Val Acc: 0.75%
2025-08-14 21:41:40,737 - INFO - Fold 1, Epoch 40: Val Acc: 0.56%
2025-08-14 21:41:42,997 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-14 21:41:47,530 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-14 21:41:49,726 - INFO - Fold 1, Epoch 70: Val Acc: 0.81%
2025-08-14 21:41:51,732 - INFO - Fold 1, Epoch 80: Val Acc: 0.81%
2025-08-14 21:41:53,731 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-14 21:41:55,710 - INFO - Fold 1, Epoch 100: Val Acc: 0.66%
2025-08-14 21:41:57,964 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-14 21:41:59,977 - INFO - Fold 1, Epoch 120: Val Acc: 0.81%
2025-08-14 21:42:01,931 - INFO - Fold 1, Epoch 130: Val Acc: 0.78%
2025-08-14 21:42:06,217 - INFO - Fold 1, Epoch 140: Val Acc: 0.62%
2025-08-14 21:42:08,189 - INFO - Fold 1, Epoch 150: Val Acc: 0.69%
2025-08-14 21:42:10,170 - INFO - Fold 1, Epoch 160: Val Acc: 0.72%
2025-08-14 21:42:12,158 - INFO - Fold 1, Epoch 170: Val Acc: 0.75%
2025-08-14 21:42:14,242 - INFO - Fold 1, Epoch 180: Val Acc: 0.62%
2025-08-14 21:42:16,555 - INFO - Fold 1, Epoch 190: Val Acc: 0.66%
2025-08-14 21:42:18,731 - INFO - Fold 1, Epoch 200: Val Acc: 0.66%
2025-08-14 21:42:21,048 - INFO - Fold 1, Epoch 210: Val Acc: 0.78%
2025-08-14 21:42:23,323 - INFO - Fold 1, Epoch 220: Val Acc: 0.75%
2025-08-14 21:42:25,393 - INFO - Fold 1, Epoch 230: Val Acc: 0.72%
2025-08-14 21:42:25,564 - INFO - Early stopping at epoch 231
2025-08-14 21:42:29,371 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:42:29,373 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:42:29,374 - INFO - Starting training for fold 2/3
2025-08-14 21:42:37,343 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-14 21:42:41,046 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-14 21:42:44,507 - INFO - Fold 2, Epoch 30: Val Acc: 0.62%
2025-08-14 21:42:48,105 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-14 21:42:51,572 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-14 21:42:53,567 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-14 21:42:56,739 - INFO - Fold 2, Epoch 70: Val Acc: 0.88%
2025-08-14 21:42:58,786 - INFO - Fold 2, Epoch 80: Val Acc: 0.66%
2025-08-14 21:43:00,840 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-14 21:43:04,593 - INFO - Fold 2, Epoch 100: Val Acc: 0.84%
2025-08-14 21:43:06,825 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-14 21:43:09,050 - INFO - Fold 2, Epoch 120: Val Acc: 0.78%
2025-08-14 21:43:11,284 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-14 21:43:13,509 - INFO - Fold 2, Epoch 140: Val Acc: 0.69%
2025-08-14 21:43:15,684 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-14 21:43:17,853 - INFO - Fold 2, Epoch 160: Val Acc: 0.69%
2025-08-14 21:43:19,845 - INFO - Fold 2, Epoch 170: Val Acc: 0.72%
2025-08-14 21:43:21,603 - INFO - Fold 2, Epoch 180: Val Acc: 0.75%
2025-08-14 21:43:23,298 - INFO - Fold 2, Epoch 190: Val Acc: 0.72%
2025-08-14 21:43:23,977 - INFO - Early stopping at epoch 194
2025-08-14 21:43:25,073 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:43:25,079 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:43:25,080 - INFO - Starting training for fold 3/3
2025-08-14 21:43:30,473 - INFO - Fold 3, Epoch 10: Val Acc: 0.38%
2025-08-14 21:43:32,664 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-14 21:43:37,184 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-14 21:43:40,779 - INFO - Fold 3, Epoch 40: Val Acc: 0.69%
2025-08-14 21:43:42,811 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-14 21:43:46,532 - INFO - Fold 3, Epoch 60: Val Acc: 0.66%
2025-08-14 21:43:50,127 - INFO - Fold 3, Epoch 70: Val Acc: 0.81%
2025-08-14 21:43:52,363 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-14 21:43:55,974 - INFO - Fold 3, Epoch 90: Val Acc: 0.56%
2025-08-14 21:43:58,209 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-14 21:44:00,449 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-14 21:44:02,663 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-14 21:44:04,879 - INFO - Fold 3, Epoch 130: Val Acc: 0.66%
2025-08-14 21:44:07,097 - INFO - Fold 3, Epoch 140: Val Acc: 0.66%
2025-08-14 21:44:09,320 - INFO - Fold 3, Epoch 150: Val Acc: 0.75%
2025-08-14 21:44:11,544 - INFO - Fold 3, Epoch 160: Val Acc: 0.75%
2025-08-14 21:44:13,768 - INFO - Fold 3, Epoch 170: Val Acc: 0.69%
2025-08-14 21:44:15,989 - INFO - Fold 3, Epoch 180: Val Acc: 0.56%
2025-08-14 21:44:17,100 - INFO - Early stopping at epoch 185
2025-08-14 21:44:18,218 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.8707498709360757), 'std': np.float64(0.04043617214117235)}, 'train_accuracy': {'mean': np.float64(0.7708333333333334), 'std': np.float64(0.03707318837510874)}, 'val_loss': {'mean': np.float64(4.181634426116943), 'std': np.float64(0.09778021104182402)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.0)}, 'epoch': {'mean': np.float64(102.33333333333333), 'std': np.float64(19.90533150244482)}}
[I 2025-08-14 21:44:18,229] Trial 53 finished with value: -0.90625 and parameters: {'learning_rate': 0.0005929208910595332, 'batch_size': 32, 'num_epochs': 716, 'temperature': 0.32791533354885427, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.42875296049776745, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19110964664908642, 'crop_size': 0.5659229465455194}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 53 finished with value: -0.90625 and parameters: {'learning_rate': 0.0005929208910595332, 'batch_size': 32, 'num_epochs': 716, 'temperature': 0.32791533354885427, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.42875296049776745, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19110964664908642, 'crop_size': 0.5659229465455194}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:44:18,259 - INFO - Using device: cuda
2025-08-14 21:44:28,025 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:44:28,027 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:44:28,027 - INFO - Starting training for fold 1/3
2025-08-14 21:44:38,296 - INFO - Fold 1, Epoch 10: Val Acc: 0.72%
2025-08-14 21:44:43,236 - INFO - Fold 1, Epoch 20: Val Acc: 0.72%
2025-08-14 21:44:45,103 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-14 21:44:47,317 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-14 21:44:54,980 - INFO - Fold 1, Epoch 50: Val Acc: 0.62%
2025-08-14 21:44:57,422 - INFO - Fold 1, Epoch 60: Val Acc: 0.75%
2025-08-14 21:45:02,515 - INFO - Fold 1, Epoch 70: Val Acc: 0.75%
2025-08-14 21:45:04,966 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-14 21:45:07,422 - INFO - Fold 1, Epoch 90: Val Acc: 0.78%
2025-08-14 21:45:09,871 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-14 21:45:11,803 - INFO - Fold 1, Epoch 110: Val Acc: 0.72%
2025-08-14 21:45:13,938 - INFO - Fold 1, Epoch 120: Val Acc: 0.78%
2025-08-14 21:45:16,394 - INFO - Fold 1, Epoch 130: Val Acc: 0.66%
2025-08-14 21:45:18,819 - INFO - Fold 1, Epoch 140: Val Acc: 0.56%
2025-08-14 21:45:21,271 - INFO - Fold 1, Epoch 150: Val Acc: 0.72%
2025-08-14 21:45:23,710 - INFO - Fold 1, Epoch 160: Val Acc: 0.66%
2025-08-14 21:45:23,964 - INFO - Early stopping at epoch 161
2025-08-14 21:45:28,049 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:45:28,053 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:45:28,054 - INFO - Starting training for fold 2/3
2025-08-14 21:45:37,312 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-14 21:45:44,956 - INFO - Fold 2, Epoch 20: Val Acc: 0.75%
2025-08-14 21:45:49,241 - INFO - Fold 2, Epoch 30: Val Acc: 0.78%
2025-08-14 21:45:51,687 - INFO - Fold 2, Epoch 40: Val Acc: 0.81%
2025-08-14 21:45:54,144 - INFO - Fold 2, Epoch 50: Val Acc: 0.84%
2025-08-14 21:45:56,649 - INFO - Fold 2, Epoch 60: Val Acc: 0.88%
2025-08-14 21:45:59,042 - INFO - Fold 2, Epoch 70: Val Acc: 0.84%
2025-08-14 21:46:02,495 - INFO - Fold 2, Epoch 80: Val Acc: 0.91%
2025-08-14 21:46:06,177 - INFO - Fold 2, Epoch 90: Val Acc: 0.66%
2025-08-14 21:46:08,636 - INFO - Fold 2, Epoch 100: Val Acc: 0.69%
2025-08-14 21:46:11,100 - INFO - Fold 2, Epoch 110: Val Acc: 0.81%
2025-08-14 21:46:13,558 - INFO - Fold 2, Epoch 120: Val Acc: 0.88%
2025-08-14 21:46:16,006 - INFO - Fold 2, Epoch 130: Val Acc: 0.81%
2025-08-14 21:46:18,468 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-14 21:46:20,911 - INFO - Fold 2, Epoch 150: Val Acc: 0.69%
2025-08-14 21:46:23,381 - INFO - Fold 2, Epoch 160: Val Acc: 0.78%
2025-08-14 21:46:25,837 - INFO - Fold 2, Epoch 170: Val Acc: 0.69%
2025-08-14 21:46:28,289 - INFO - Fold 2, Epoch 180: Val Acc: 0.66%
2025-08-14 21:46:30,496 - INFO - Early stopping at epoch 189
2025-08-14 21:46:33,755 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:46:33,758 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:46:33,758 - INFO - Starting training for fold 3/3
2025-08-14 21:46:43,125 - INFO - Fold 3, Epoch 10: Val Acc: 0.75%
2025-08-14 21:46:45,658 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-14 21:46:48,193 - INFO - Fold 3, Epoch 30: Val Acc: 0.59%
2025-08-14 21:46:52,300 - INFO - Fold 3, Epoch 40: Val Acc: 0.72%
2025-08-14 21:46:54,746 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-14 21:46:58,931 - INFO - Fold 3, Epoch 60: Val Acc: 0.84%
2025-08-14 21:47:01,216 - INFO - Fold 3, Epoch 70: Val Acc: 0.81%
2025-08-14 21:47:03,624 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-14 21:47:06,173 - INFO - Fold 3, Epoch 90: Val Acc: 0.78%
2025-08-14 21:47:08,696 - INFO - Fold 3, Epoch 100: Val Acc: 0.84%
2025-08-14 21:47:11,222 - INFO - Fold 3, Epoch 110: Val Acc: 0.62%
2025-08-14 21:47:13,758 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-14 21:47:16,302 - INFO - Fold 3, Epoch 130: Val Acc: 0.75%
2025-08-14 21:47:18,842 - INFO - Fold 3, Epoch 140: Val Acc: 0.62%
2025-08-14 21:47:21,379 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-14 21:47:22,649 - INFO - Early stopping at epoch 155
2025-08-14 21:47:23,934 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.960854636298286), 'std': np.float64(0.006980862216528223)}, 'train_accuracy': {'mean': np.float64(0.7118055555555557), 'std': np.float64(0.01299186592629842)}, 'val_loss': {'mean': np.float64(4.233368714650472), 'std': np.float64(0.08769145406745935)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(67.33333333333333), 'std': np.float64(14.817407180595247)}}
[I 2025-08-14 21:47:23,941] Trial 54 finished with value: -0.90625 and parameters: {'learning_rate': 0.0007340519950666874, 'batch_size': 32, 'num_epochs': 602, 'temperature': 0.4838432671520784, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.38964462901374897, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1745905720053316, 'crop_size': 0.5188991044585726}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 54 finished with value: -0.90625 and parameters: {'learning_rate': 0.0007340519950666874, 'batch_size': 32, 'num_epochs': 602, 'temperature': 0.4838432671520784, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.38964462901374897, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1745905720053316, 'crop_size': 0.5188991044585726}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:47:23,972 - INFO - Using device: cuda
2025-08-14 21:47:33,555 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:47:33,556 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:47:33,557 - INFO - Starting training for fold 1/3
2025-08-14 21:47:44,937 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-14 21:47:49,335 - INFO - Fold 1, Epoch 20: Val Acc: 0.47%
2025-08-14 21:47:51,571 - INFO - Fold 1, Epoch 30: Val Acc: 0.38%
2025-08-14 21:47:53,880 - INFO - Fold 1, Epoch 40: Val Acc: 0.56%
2025-08-14 21:47:56,112 - INFO - Fold 1, Epoch 50: Val Acc: 0.56%
2025-08-14 21:47:58,426 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-14 21:48:00,751 - INFO - Fold 1, Epoch 70: Val Acc: 0.62%
2025-08-14 21:48:03,086 - INFO - Fold 1, Epoch 80: Val Acc: 0.56%
2025-08-14 21:48:05,406 - INFO - Fold 1, Epoch 90: Val Acc: 0.50%
2025-08-14 21:48:07,673 - INFO - Fold 1, Epoch 100: Val Acc: 0.62%
2025-08-14 21:48:09,896 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-14 21:48:10,782 - INFO - Early stopping at epoch 114
2025-08-14 21:48:14,302 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:48:14,314 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:48:14,315 - INFO - Starting training for fold 2/3
2025-08-14 21:48:22,275 - INFO - Fold 2, Epoch 10: Val Acc: 0.47%
2025-08-14 21:48:24,512 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-14 21:48:26,748 - INFO - Fold 2, Epoch 30: Val Acc: 0.44%
2025-08-14 21:48:28,984 - INFO - Fold 2, Epoch 40: Val Acc: 0.53%
2025-08-14 21:48:31,217 - INFO - Fold 2, Epoch 50: Val Acc: 0.56%
2025-08-14 21:48:33,459 - INFO - Fold 2, Epoch 60: Val Acc: 0.50%
2025-08-14 21:48:35,696 - INFO - Fold 2, Epoch 70: Val Acc: 0.56%
2025-08-14 21:48:37,409 - INFO - Fold 2, Epoch 80: Val Acc: 0.53%
2025-08-14 21:48:39,512 - INFO - Fold 2, Epoch 90: Val Acc: 0.41%
2025-08-14 21:48:41,746 - INFO - Fold 2, Epoch 100: Val Acc: 0.56%
2025-08-14 21:48:42,421 - INFO - Early stopping at epoch 103
2025-08-14 21:48:45,273 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:48:45,276 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:48:45,276 - INFO - Starting training for fold 3/3
2025-08-14 21:48:55,581 - INFO - Fold 3, Epoch 10: Val Acc: 0.47%
2025-08-14 21:48:57,852 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-14 21:49:00,044 - INFO - Fold 3, Epoch 30: Val Acc: 0.47%
2025-08-14 21:49:02,270 - INFO - Fold 3, Epoch 40: Val Acc: 0.50%
2025-08-14 21:49:04,495 - INFO - Fold 3, Epoch 50: Val Acc: 0.56%
2025-08-14 21:49:06,725 - INFO - Fold 3, Epoch 60: Val Acc: 0.66%
2025-08-14 21:49:10,273 - INFO - Fold 3, Epoch 70: Val Acc: 0.53%
2025-08-14 21:49:12,487 - INFO - Fold 3, Epoch 80: Val Acc: 0.38%
2025-08-14 21:49:14,693 - INFO - Fold 3, Epoch 90: Val Acc: 0.53%
2025-08-14 21:49:16,910 - INFO - Fold 3, Epoch 100: Val Acc: 0.50%
2025-08-14 21:49:19,133 - INFO - Fold 3, Epoch 110: Val Acc: 0.50%
2025-08-14 21:49:22,909 - INFO - Fold 3, Epoch 120: Val Acc: 0.47%
2025-08-14 21:49:25,119 - INFO - Fold 3, Epoch 130: Val Acc: 0.56%
2025-08-14 21:49:27,328 - INFO - Fold 3, Epoch 140: Val Acc: 0.66%
2025-08-14 21:49:29,539 - INFO - Fold 3, Epoch 150: Val Acc: 0.44%
2025-08-14 21:49:31,710 - INFO - Fold 3, Epoch 160: Val Acc: 0.62%
2025-08-14 21:49:33,412 - INFO - Fold 3, Epoch 170: Val Acc: 0.66%
2025-08-14 21:49:35,348 - INFO - Fold 3, Epoch 180: Val Acc: 0.62%
2025-08-14 21:49:37,569 - INFO - Fold 3, Epoch 190: Val Acc: 0.53%
2025-08-14 21:49:39,779 - INFO - Fold 3, Epoch 200: Val Acc: 0.53%
2025-08-14 21:49:41,997 - INFO - Fold 3, Epoch 210: Val Acc: 0.66%
2025-08-14 21:49:42,218 - INFO - Early stopping at epoch 211
2025-08-14 21:49:45,105 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.231067763434516), 'std': np.float64(0.011852523254783788)}, 'train_accuracy': {'mean': np.float64(0.5972222222222222), 'std': np.float64(0.03220006422047118)}, 'val_loss': {'mean': np.float64(4.17744239171346), 'std': np.float64(0.07006442366653147)}, 'val_accuracy': {'mean': np.float64(0.7291666666666666), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(41.666666666666664), 'std': np.float64(48.52719741432519)}}
[I 2025-08-14 21:49:45,117] Trial 55 finished with value: -0.7291666666666666 and parameters: {'learning_rate': 3.175042662222715e-05, 'batch_size': 32, 'num_epochs': 806, 'temperature': 0.39044895075987895, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4592872037716423, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18996856289001957, 'crop_size': 0.5689987040716477}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 55 finished with value: -0.7291666666666666 and parameters: {'learning_rate': 3.175042662222715e-05, 'batch_size': 32, 'num_epochs': 806, 'temperature': 0.39044895075987895, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4592872037716423, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18996856289001957, 'crop_size': 0.5689987040716477}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:49:45,183 - INFO - Using device: cuda
2025-08-14 21:49:54,631 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:49:54,633 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:49:54,633 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 21:49:58,887 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-14 21:50:00,835 - INFO - Fold 1, Epoch 20: Val Acc: 0.66%
2025-08-14 21:50:02,125 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 21:50:03,415 - INFO - Fold 1, Epoch 40: Val Acc: 0.53%
2025-08-14 21:50:04,697 - INFO - Fold 1, Epoch 50: Val Acc: 0.59%
2025-08-14 21:50:05,978 - INFO - Fold 1, Epoch 60: Val Acc: 0.47%
2025-08-14 21:50:07,255 - INFO - Fold 1, Epoch 70: Val Acc: 0.53%
2025-08-14 21:50:08,542 - INFO - Fold 1, Epoch 80: Val Acc: 0.59%
2025-08-14 21:50:09,838 - INFO - Fold 1, Epoch 90: Val Acc: 0.56%
2025-08-14 21:50:11,126 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-14 21:50:12,417 - INFO - Fold 1, Epoch 110: Val Acc: 0.59%
2025-08-14 21:50:13,322 - INFO - Early stopping at epoch 117
2025-08-14 21:50:14,231 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:50:14,243 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:50:14,244 - INFO - Starting training for fold 2/3
2025-08-14 21:50:17,922 - INFO - Fold 2, Epoch 10: Val Acc: 0.75%
2025-08-14 21:50:19,686 - INFO - Fold 2, Epoch 20: Val Acc: 0.72%
2025-08-14 21:50:21,345 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-14 21:50:22,375 - INFO - Fold 2, Epoch 40: Val Acc: 0.81%
2025-08-14 21:50:23,622 - INFO - Fold 2, Epoch 50: Val Acc: 0.84%
2025-08-14 21:50:24,957 - INFO - Fold 2, Epoch 60: Val Acc: 0.84%
2025-08-14 21:50:26,817 - INFO - Fold 2, Epoch 70: Val Acc: 0.88%
2025-08-14 21:50:28,170 - INFO - Fold 2, Epoch 80: Val Acc: 0.81%
2025-08-14 21:50:29,526 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-14 21:50:30,870 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-14 21:50:32,222 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-14 21:50:33,570 - INFO - Fold 2, Epoch 120: Val Acc: 0.84%
2025-08-14 21:50:34,924 - INFO - Fold 2, Epoch 130: Val Acc: 0.84%
2025-08-14 21:50:36,278 - INFO - Fold 2, Epoch 140: Val Acc: 0.66%
2025-08-14 21:50:37,628 - INFO - Fold 2, Epoch 150: Val Acc: 0.78%
2025-08-14 21:50:38,967 - INFO - Fold 2, Epoch 160: Val Acc: 0.62%
2025-08-14 21:50:39,635 - INFO - Early stopping at epoch 165
2025-08-14 21:50:40,289 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:50:40,292 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:50:40,292 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 21:50:43,860 - INFO - Fold 3, Epoch 10: Val Acc: 0.72%
2025-08-14 21:50:45,629 - INFO - Fold 3, Epoch 20: Val Acc: 0.84%
2025-08-14 21:50:46,903 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-14 21:50:48,173 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-14 21:50:49,451 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-14 21:50:50,727 - INFO - Fold 3, Epoch 60: Val Acc: 0.66%
2025-08-14 21:50:52,010 - INFO - Fold 3, Epoch 70: Val Acc: 0.62%
2025-08-14 21:50:53,286 - INFO - Fold 3, Epoch 80: Val Acc: 0.56%
2025-08-14 21:50:54,577 - INFO - Fold 3, Epoch 90: Val Acc: 0.59%
2025-08-14 21:50:55,844 - INFO - Fold 3, Epoch 100: Val Acc: 0.62%
2025-08-14 21:50:57,114 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-14 21:50:57,240 - INFO - Early stopping at epoch 111
2025-08-14 21:50:57,533 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.777627680036757), 'std': np.float64(0.16718483032020962)}, 'train_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.06804138174397716)}, 'val_loss': {'mean': np.float64(4.350818316141765), 'std': np.float64(0.20640676014740603)}, 'val_accuracy': {'mean': np.float64(0.8645833333333334), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(30.0), 'std': np.float64(24.166091947189145)}}
[I 2025-08-14 21:50:57,538] Trial 56 finished with value: -0.8645833333333334 and parameters: {'learning_rate': 0.00045018929739661323, 'batch_size': 32, 'num_epochs': 475, 'temperature': 0.2558912064301839, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4102411249264261, 'num_layers': 1, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.16555123189345128}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 56 finished with value: -0.8645833333333334 and parameters: {'learning_rate': 0.00045018929739661323, 'batch_size': 32, 'num_epochs': 475, 'temperature': 0.2558912064301839, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4102411249264261, 'num_layers': 1, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.16555123189345128}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:50:57,568 - INFO - Using device: cuda
2025-08-14 21:51:07,467 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:51:07,468 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:51:07,468 - INFO - Starting training for fold 1/3
2025-08-14 21:51:15,629 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-14 21:51:17,720 - INFO - Fold 1, Epoch 20: Val Acc: 0.44%
2025-08-14 21:51:19,831 - INFO - Fold 1, Epoch 30: Val Acc: 0.41%
2025-08-14 21:51:21,947 - INFO - Fold 1, Epoch 40: Val Acc: 0.56%
2025-08-14 21:51:24,060 - INFO - Fold 1, Epoch 50: Val Acc: 0.47%
2025-08-14 21:51:26,170 - INFO - Fold 1, Epoch 60: Val Acc: 0.47%
2025-08-14 21:51:28,271 - INFO - Fold 1, Epoch 70: Val Acc: 0.50%
2025-08-14 21:51:30,113 - INFO - Fold 1, Epoch 80: Val Acc: 0.53%
2025-08-14 21:51:31,897 - INFO - Fold 1, Epoch 90: Val Acc: 0.47%
2025-08-14 21:51:34,019 - INFO - Fold 1, Epoch 100: Val Acc: 0.53%
2025-08-14 21:51:35,102 - INFO - Early stopping at epoch 105
2025-08-14 21:51:38,164 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:51:38,168 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:51:38,168 - INFO - Starting training for fold 2/3
2025-08-14 21:51:42,961 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-14 21:51:45,058 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-14 21:51:48,508 - INFO - Fold 2, Epoch 30: Val Acc: 0.66%
2025-08-14 21:51:50,692 - INFO - Fold 2, Epoch 40: Val Acc: 0.47%
2025-08-14 21:51:54,128 - INFO - Fold 2, Epoch 50: Val Acc: 0.47%
2025-08-14 21:51:56,309 - INFO - Fold 2, Epoch 60: Val Acc: 0.44%
2025-08-14 21:51:58,493 - INFO - Fold 2, Epoch 70: Val Acc: 0.47%
2025-08-14 21:52:00,629 - INFO - Fold 2, Epoch 80: Val Acc: 0.50%
2025-08-14 21:52:03,988 - INFO - Fold 2, Epoch 90: Val Acc: 0.47%
2025-08-14 21:52:06,084 - INFO - Fold 2, Epoch 100: Val Acc: 0.50%
2025-08-14 21:52:08,178 - INFO - Fold 2, Epoch 110: Val Acc: 0.47%
2025-08-14 21:52:10,285 - INFO - Fold 2, Epoch 120: Val Acc: 0.44%
2025-08-14 21:52:12,387 - INFO - Fold 2, Epoch 130: Val Acc: 0.38%
2025-08-14 21:52:14,480 - INFO - Fold 2, Epoch 140: Val Acc: 0.44%
2025-08-14 21:52:16,593 - INFO - Fold 2, Epoch 150: Val Acc: 0.66%
2025-08-14 21:52:18,691 - INFO - Fold 2, Epoch 160: Val Acc: 0.38%
2025-08-14 21:52:20,790 - INFO - Fold 2, Epoch 170: Val Acc: 0.44%
2025-08-14 21:52:22,885 - INFO - Fold 2, Epoch 180: Val Acc: 0.53%
2025-08-14 21:52:23,727 - INFO - Early stopping at epoch 184
2025-08-14 21:52:26,262 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:52:26,265 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:52:26,266 - INFO - Starting training for fold 3/3
2025-08-14 21:52:29,374 - INFO - Fold 3, Epoch 10: Val Acc: 0.47%
2025-08-14 21:52:31,022 - INFO - Fold 3, Epoch 20: Val Acc: 0.56%
2025-08-14 21:52:35,593 - INFO - Fold 3, Epoch 30: Val Acc: 0.47%
2025-08-14 21:52:37,698 - INFO - Fold 3, Epoch 40: Val Acc: 0.53%
2025-08-14 21:52:40,971 - INFO - Fold 3, Epoch 50: Val Acc: 0.47%
2025-08-14 21:52:43,072 - INFO - Fold 3, Epoch 60: Val Acc: 0.50%
2025-08-14 21:52:45,181 - INFO - Fold 3, Epoch 70: Val Acc: 0.53%
2025-08-14 21:52:47,283 - INFO - Fold 3, Epoch 80: Val Acc: 0.44%
2025-08-14 21:52:49,391 - INFO - Fold 3, Epoch 90: Val Acc: 0.56%
2025-08-14 21:52:51,499 - INFO - Fold 3, Epoch 100: Val Acc: 0.50%
2025-08-14 21:52:53,606 - INFO - Fold 3, Epoch 110: Val Acc: 0.47%
2025-08-14 21:52:55,711 - INFO - Fold 3, Epoch 120: Val Acc: 0.41%
2025-08-14 21:52:57,817 - INFO - Fold 3, Epoch 130: Val Acc: 0.38%
2025-08-14 21:52:59,914 - INFO - Fold 3, Epoch 140: Val Acc: 0.50%
2025-08-14 21:53:00,959 - INFO - Early stopping at epoch 145
2025-08-14 21:53:01,834 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.144975821177165), 'std': np.float64(0.01714757826574046)}, 'train_accuracy': {'mean': np.float64(0.6111111111111112), 'std': np.float64(0.03437324630767936)}, 'val_loss': {'mean': np.float64(4.195650577545166), 'std': np.float64(0.014194494809960307)}, 'val_accuracy': {'mean': np.float64(0.6979166666666666), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(43.666666666666664), 'std': np.float64(32.25247621845836)}}
[I 2025-08-14 21:53:01,840] Trial 57 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 0.0009185240850466351, 'batch_size': 32, 'num_epochs': 924, 'temperature': 0.44939346410353764, 'embedding_dim': 128, 'hidden_dim': 512, 'dropout': 0.4980145325694322, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': True, 'noise_level': 0.17292654516131645, 'crop_size': 0.5993862225613618}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 57 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 0.0009185240850466351, 'batch_size': 32, 'num_epochs': 924, 'temperature': 0.44939346410353764, 'embedding_dim': 128, 'hidden_dim': 512, 'dropout': 0.4980145325694322, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': True, 'noise_level': 0.17292654516131645, 'crop_size': 0.5993862225613618}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:53:01,871 - INFO - Using device: cuda
2025-08-14 21:53:11,554 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:53:11,555 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:53:11,556 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 21:53:20,159 - INFO - Fold 1, Epoch 10: Val Acc: 0.46%
2025-08-14 21:53:28,004 - INFO - Fold 1, Epoch 20: Val Acc: 0.54%
2025-08-14 21:53:31,771 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 21:53:35,529 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-14 21:53:39,304 - INFO - Fold 1, Epoch 50: Val Acc: 0.58%
2025-08-14 21:53:43,105 - INFO - Fold 1, Epoch 60: Val Acc: 0.73%
2025-08-14 21:53:46,892 - INFO - Fold 1, Epoch 70: Val Acc: 0.67%
2025-08-14 21:53:50,683 - INFO - Fold 1, Epoch 80: Val Acc: 0.67%
2025-08-14 21:53:54,482 - INFO - Fold 1, Epoch 90: Val Acc: 0.50%
2025-08-14 21:53:57,956 - INFO - Fold 1, Epoch 100: Val Acc: 0.65%
2025-08-14 21:54:00,701 - INFO - Fold 1, Epoch 110: Val Acc: 0.65%
2025-08-14 21:54:02,551 - INFO - Early stopping at epoch 115
2025-08-14 21:54:06,506 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:54:06,509 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:54:06,510 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 21:54:14,879 - INFO - Fold 2, Epoch 10: Val Acc: 0.52%
2025-08-14 21:54:20,900 - INFO - Fold 2, Epoch 20: Val Acc: 0.71%
2025-08-14 21:54:27,625 - INFO - Fold 2, Epoch 30: Val Acc: 0.52%
2025-08-14 21:54:31,362 - INFO - Fold 2, Epoch 40: Val Acc: 0.73%
2025-08-14 21:54:35,013 - INFO - Fold 2, Epoch 50: Val Acc: 0.71%
2025-08-14 21:54:38,288 - INFO - Fold 2, Epoch 60: Val Acc: 0.67%
2025-08-14 21:54:41,025 - INFO - Fold 2, Epoch 70: Val Acc: 0.71%
2025-08-14 21:54:43,755 - INFO - Fold 2, Epoch 80: Val Acc: 0.67%
2025-08-14 21:54:47,942 - INFO - Fold 2, Epoch 90: Val Acc: 0.77%
2025-08-14 21:54:51,532 - INFO - Fold 2, Epoch 100: Val Acc: 0.71%
2025-08-14 21:54:55,317 - INFO - Fold 2, Epoch 110: Val Acc: 0.83%
2025-08-14 21:54:59,081 - INFO - Fold 2, Epoch 120: Val Acc: 0.73%
2025-08-14 21:55:01,818 - INFO - Fold 2, Epoch 130: Val Acc: 0.71%
2025-08-14 21:55:05,414 - INFO - Fold 2, Epoch 140: Val Acc: 0.77%
2025-08-14 21:55:09,205 - INFO - Fold 2, Epoch 150: Val Acc: 0.62%
2025-08-14 21:55:13,016 - INFO - Fold 2, Epoch 160: Val Acc: 0.77%
2025-08-14 21:55:18,263 - INFO - Fold 2, Epoch 170: Val Acc: 0.81%
2025-08-14 21:55:22,052 - INFO - Fold 2, Epoch 180: Val Acc: 0.62%
2025-08-14 21:55:25,941 - INFO - Fold 2, Epoch 190: Val Acc: 0.77%
2025-08-14 21:55:29,832 - INFO - Fold 2, Epoch 200: Val Acc: 0.73%
2025-08-14 21:55:33,753 - INFO - Fold 2, Epoch 210: Val Acc: 0.77%
2025-08-14 21:55:37,647 - INFO - Fold 2, Epoch 220: Val Acc: 0.75%
2025-08-14 21:55:41,570 - INFO - Fold 2, Epoch 230: Val Acc: 0.73%
2025-08-14 21:55:45,407 - INFO - Fold 2, Epoch 240: Val Acc: 0.77%
2025-08-14 21:55:49,306 - INFO - Fold 2, Epoch 250: Val Acc: 0.75%
2025-08-14 21:55:53,117 - INFO - Fold 2, Epoch 260: Val Acc: 0.75%
2025-08-14 21:55:54,625 - INFO - Early stopping at epoch 264
2025-08-14 21:55:57,575 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:55:57,578 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:55:57,578 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 21:56:07,206 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-14 21:56:12,326 - INFO - Fold 3, Epoch 20: Val Acc: 0.58%
2025-08-14 21:56:19,011 - INFO - Fold 3, Epoch 30: Val Acc: 0.67%
2025-08-14 21:56:24,275 - INFO - Fold 3, Epoch 40: Val Acc: 0.60%
2025-08-14 21:56:28,083 - INFO - Fold 3, Epoch 50: Val Acc: 0.58%
2025-08-14 21:56:31,875 - INFO - Fold 3, Epoch 60: Val Acc: 0.62%
2025-08-14 21:56:37,079 - INFO - Fold 3, Epoch 70: Val Acc: 0.67%
2025-08-14 21:56:40,881 - INFO - Fold 3, Epoch 80: Val Acc: 0.69%
2025-08-14 21:56:44,678 - INFO - Fold 3, Epoch 90: Val Acc: 0.71%
2025-08-14 21:56:48,471 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-14 21:56:52,251 - INFO - Fold 3, Epoch 110: Val Acc: 0.73%
2025-08-14 21:56:56,019 - INFO - Fold 3, Epoch 120: Val Acc: 0.60%
2025-08-14 21:56:59,795 - INFO - Fold 3, Epoch 130: Val Acc: 0.73%
2025-08-14 21:57:03,551 - INFO - Fold 3, Epoch 140: Val Acc: 0.73%
2025-08-14 21:57:07,371 - INFO - Fold 3, Epoch 150: Val Acc: 0.77%
2025-08-14 21:57:11,136 - INFO - Fold 3, Epoch 160: Val Acc: 0.77%
2025-08-14 21:57:13,190 - INFO - Early stopping at epoch 166
2025-08-14 21:57:14,297 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.2659463352627225), 'std': np.float64(0.3045399519875702)}, 'train_accuracy': {'mean': np.float64(0.7083333333333334), 'std': np.float64(0.07654655446197427)}, 'val_loss': {'mean': np.float64(3.9012825753953724), 'std': np.float64(0.3289171556591983)}, 'val_accuracy': {'mean': np.float64(0.8402777777777778), 'std': np.float64(0.04280843057617338)}, 'epoch': {'mean': np.float64(80.66666666666667), 'std': np.float64(61.829514706884844)}}
[I 2025-08-14 21:57:14,305] Trial 58 finished with value: -0.8402777777777778 and parameters: {'learning_rate': 0.000608131064348767, 'batch_size': 16, 'num_epochs': 686, 'temperature': 0.09744729032394533, 'embedding_dim': 128, 'hidden_dim': 128, 'dropout': 0.47021476095649456, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1549142782311392, 'crop_size': 0.534653599668642}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 58 finished with value: -0.8402777777777778 and parameters: {'learning_rate': 0.000608131064348767, 'batch_size': 16, 'num_epochs': 686, 'temperature': 0.09744729032394533, 'embedding_dim': 128, 'hidden_dim': 128, 'dropout': 0.47021476095649456, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1549142782311392, 'crop_size': 0.534653599668642}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:57:14,340 - INFO - Using device: cuda
2025-08-14 21:57:24,272 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:57:24,274 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:57:24,274 - WARNING - Fold 1 has insufficient pairs to form a batch. Skipping.
2025-08-14 21:57:24,274 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:57:24,275 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:57:24,275 - WARNING - Fold 2 has insufficient pairs to form a batch. Skipping.
2025-08-14 21:57:24,275 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:57:24,277 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:57:24,277 - WARNING - Fold 3 has insufficient pairs to form a batch. Skipping.
2025-08-14 21:57:24,277 - WARNING - No folds completed successfully to aggregate metrics.
[I 2025-08-14 21:57:24,279] Trial 59 finished with value: inf and parameters: {'learning_rate': 0.00033817102603473997, 'batch_size': 64, 'num_epochs': 847, 'temperature': 0.07017883737866265, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4491483603159302, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19067306725979905, 'crop_size': 0.5099052364263982}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 59 finished with value: inf and parameters: {'learning_rate': 0.00033817102603473997, 'batch_size': 64, 'num_epochs': 847, 'temperature': 0.07017883737866265, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4491483603159302, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19067306725979905, 'crop_size': 0.5099052364263982}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 21:57:24,313 - INFO - Using device: cuda
2025-08-14 21:57:34,126 - INFO - --- Starting Fold 1/3 ---
2025-08-14 21:57:34,128 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:57:34,128 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 21:57:40,833 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-14 21:57:44,048 - INFO - Fold 1, Epoch 20: Val Acc: 0.66%
2025-08-14 21:57:47,275 - INFO - Fold 1, Epoch 30: Val Acc: 0.59%
2025-08-14 21:57:49,085 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-14 21:57:50,882 - INFO - Fold 1, Epoch 50: Val Acc: 0.41%
2025-08-14 21:57:52,725 - INFO - Fold 1, Epoch 60: Val Acc: 0.62%
2025-08-14 21:57:55,531 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-14 21:57:57,318 - INFO - Fold 1, Epoch 80: Val Acc: 0.62%
2025-08-14 21:58:00,514 - INFO - Fold 1, Epoch 90: Val Acc: 0.56%
2025-08-14 21:58:02,291 - INFO - Fold 1, Epoch 100: Val Acc: 0.78%
2025-08-14 21:58:04,076 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-14 21:58:05,864 - INFO - Fold 1, Epoch 120: Val Acc: 0.66%
2025-08-14 21:58:07,646 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-14 21:58:09,435 - INFO - Fold 1, Epoch 140: Val Acc: 0.62%
2025-08-14 21:58:11,218 - INFO - Fold 1, Epoch 150: Val Acc: 0.62%
2025-08-14 21:58:13,007 - INFO - Fold 1, Epoch 160: Val Acc: 0.66%
2025-08-14 21:58:16,225 - INFO - Fold 1, Epoch 170: Val Acc: 0.91%
2025-08-14 21:58:18,085 - INFO - Fold 1, Epoch 180: Val Acc: 0.66%
2025-08-14 21:58:19,879 - INFO - Fold 1, Epoch 190: Val Acc: 0.62%
2025-08-14 21:58:21,666 - INFO - Fold 1, Epoch 200: Val Acc: 0.81%
2025-08-14 21:58:23,445 - INFO - Fold 1, Epoch 210: Val Acc: 0.75%
2025-08-14 21:58:25,228 - INFO - Fold 1, Epoch 220: Val Acc: 0.59%
2025-08-14 21:58:27,012 - INFO - Fold 1, Epoch 230: Val Acc: 0.78%
2025-08-14 21:58:28,796 - INFO - Fold 1, Epoch 240: Val Acc: 0.50%
2025-08-14 21:58:30,576 - INFO - Fold 1, Epoch 250: Val Acc: 0.75%
2025-08-14 21:58:32,362 - INFO - Fold 1, Epoch 260: Val Acc: 0.69%
2025-08-14 21:58:34,150 - INFO - Early stopping at epoch 270
2025-08-14 21:58:36,409 - INFO - --- Starting Fold 2/3 ---
2025-08-14 21:58:36,431 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:58:36,431 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 21:58:41,140 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-14 21:58:43,969 - INFO - Fold 2, Epoch 20: Val Acc: 0.47%
2025-08-14 21:58:45,759 - INFO - Fold 2, Epoch 30: Val Acc: 0.56%
2025-08-14 21:58:49,510 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-14 21:58:51,299 - INFO - Fold 2, Epoch 50: Val Acc: 0.62%
2025-08-14 21:58:53,091 - INFO - Fold 2, Epoch 60: Val Acc: 0.59%
2025-08-14 21:58:54,941 - INFO - Fold 2, Epoch 70: Val Acc: 0.59%
2025-08-14 21:58:56,795 - INFO - Fold 2, Epoch 80: Val Acc: 0.62%
2025-08-14 21:58:58,651 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-14 21:59:01,448 - INFO - Fold 2, Epoch 100: Val Acc: 0.81%
2025-08-14 21:59:03,308 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-14 21:59:04,907 - INFO - Fold 2, Epoch 120: Val Acc: 0.78%
2025-08-14 21:59:06,395 - INFO - Fold 2, Epoch 130: Val Acc: 0.62%
2025-08-14 21:59:07,923 - INFO - Fold 2, Epoch 140: Val Acc: 0.62%
2025-08-14 21:59:10,752 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-14 21:59:13,388 - INFO - Fold 2, Epoch 160: Val Acc: 0.59%
2025-08-14 21:59:14,891 - INFO - Fold 2, Epoch 170: Val Acc: 0.66%
2025-08-14 21:59:16,554 - INFO - Fold 2, Epoch 180: Val Acc: 0.78%
2025-08-14 21:59:18,438 - INFO - Fold 2, Epoch 190: Val Acc: 0.75%
2025-08-14 21:59:20,184 - INFO - Fold 2, Epoch 200: Val Acc: 0.62%
2025-08-14 21:59:21,676 - INFO - Fold 2, Epoch 210: Val Acc: 0.84%
2025-08-14 21:59:23,277 - INFO - Fold 2, Epoch 220: Val Acc: 0.78%
2025-08-14 21:59:24,837 - INFO - Fold 2, Epoch 230: Val Acc: 0.69%
2025-08-14 21:59:26,328 - INFO - Fold 2, Epoch 240: Val Acc: 0.72%
2025-08-14 21:59:28,128 - INFO - Fold 2, Epoch 250: Val Acc: 0.66%
2025-08-14 21:59:28,498 - INFO - Early stopping at epoch 252
2025-08-14 21:59:29,185 - INFO - --- Starting Fold 3/3 ---
2025-08-14 21:59:29,187 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 21:59:29,188 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 21:59:32,204 - INFO - Fold 3, Epoch 10: Val Acc: 0.47%
2025-08-14 21:59:35,161 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-14 21:59:37,702 - INFO - Fold 3, Epoch 30: Val Acc: 0.56%
2025-08-14 21:59:40,465 - INFO - Fold 3, Epoch 40: Val Acc: 0.72%
2025-08-14 21:59:41,854 - INFO - Fold 3, Epoch 50: Val Acc: 0.53%
2025-08-14 21:59:45,303 - INFO - Fold 3, Epoch 60: Val Acc: 0.69%
2025-08-14 21:59:46,818 - INFO - Fold 3, Epoch 70: Val Acc: 0.75%
2025-08-14 21:59:49,294 - INFO - Fold 3, Epoch 80: Val Acc: 0.56%
2025-08-14 21:59:51,960 - INFO - Fold 3, Epoch 90: Val Acc: 0.62%
2025-08-14 21:59:53,807 - INFO - Fold 3, Epoch 100: Val Acc: 0.62%
2025-08-14 21:59:55,613 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-14 21:59:57,409 - INFO - Fold 3, Epoch 120: Val Acc: 0.66%
2025-08-14 21:59:59,185 - INFO - Fold 3, Epoch 130: Val Acc: 0.62%
2025-08-14 22:00:01,046 - INFO - Fold 3, Epoch 140: Val Acc: 0.62%
2025-08-14 22:00:02,912 - INFO - Fold 3, Epoch 150: Val Acc: 0.84%
2025-08-14 22:00:04,749 - INFO - Fold 3, Epoch 160: Val Acc: 0.69%
2025-08-14 22:00:06,601 - INFO - Fold 3, Epoch 170: Val Acc: 0.59%
2025-08-14 22:00:08,211 - INFO - Fold 3, Epoch 180: Val Acc: 0.62%
2025-08-14 22:00:09,390 - INFO - Early stopping at epoch 187
2025-08-14 22:00:10,062 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.975465456644694), 'std': np.float64(0.07479347739260174)}, 'train_accuracy': {'mean': np.float64(0.7569444444444443), 'std': np.float64(0.04280843057617347)}, 'val_loss': {'mean': np.float64(4.423962434132894), 'std': np.float64(0.05769995958356393)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(135.33333333333334), 'std': np.float64(35.64952859280034)}}
[I 2025-08-14 22:00:10,068] Trial 60 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0003917893059768682, 'batch_size': 32, 'num_epochs': 997, 'temperature': 0.12775311137601408, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.39966514430789923, 'num_layers': 3, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1998998013854754, 'crop_size': 0.556949098195792}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 60 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0003917893059768682, 'batch_size': 32, 'num_epochs': 997, 'temperature': 0.12775311137601408, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.39966514430789923, 'num_layers': 3, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1998998013854754, 'crop_size': 0.556949098195792}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:00:10,099 - INFO - Using device: cuda
2025-08-14 22:00:19,851 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:00:19,852 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:00:19,853 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:00:28,837 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-14 22:00:31,068 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-14 22:00:33,295 - INFO - Fold 1, Epoch 30: Val Acc: 0.56%
2025-08-14 22:00:37,745 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-14 22:00:42,291 - INFO - Fold 1, Epoch 50: Val Acc: 0.69%
2025-08-14 22:00:44,617 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-14 22:00:46,940 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-14 22:00:49,271 - INFO - Fold 1, Epoch 80: Val Acc: 0.62%
2025-08-14 22:00:51,592 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-14 22:00:56,131 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-14 22:00:58,442 - INFO - Fold 1, Epoch 110: Val Acc: 0.78%
2025-08-14 22:01:00,764 - INFO - Fold 1, Epoch 120: Val Acc: 0.62%
2025-08-14 22:01:03,090 - INFO - Fold 1, Epoch 130: Val Acc: 0.72%
2025-08-14 22:01:05,413 - INFO - Fold 1, Epoch 140: Val Acc: 0.62%
2025-08-14 22:01:07,735 - INFO - Fold 1, Epoch 150: Val Acc: 0.56%
2025-08-14 22:01:10,001 - INFO - Fold 1, Epoch 160: Val Acc: 0.62%
2025-08-14 22:01:12,227 - INFO - Fold 1, Epoch 170: Val Acc: 0.72%
2025-08-14 22:01:14,456 - INFO - Fold 1, Epoch 180: Val Acc: 0.72%
2025-08-14 22:01:16,685 - INFO - Fold 1, Epoch 190: Val Acc: 0.72%
2025-08-14 22:01:17,569 - INFO - Early stopping at epoch 194
2025-08-14 22:01:21,366 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:01:21,369 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:01:21,370 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:01:28,242 - INFO - Fold 2, Epoch 10: Val Acc: 0.69%
2025-08-14 22:01:31,973 - INFO - Fold 2, Epoch 20: Val Acc: 0.69%
2025-08-14 22:01:34,191 - INFO - Fold 2, Epoch 30: Val Acc: 0.56%
2025-08-14 22:01:36,410 - INFO - Fold 2, Epoch 40: Val Acc: 0.62%
2025-08-14 22:01:38,645 - INFO - Fold 2, Epoch 50: Val Acc: 0.59%
2025-08-14 22:01:42,290 - INFO - Fold 2, Epoch 60: Val Acc: 0.59%
2025-08-14 22:01:44,506 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-14 22:01:46,723 - INFO - Fold 2, Epoch 80: Val Acc: 0.62%
2025-08-14 22:01:50,412 - INFO - Fold 2, Epoch 90: Val Acc: 0.66%
2025-08-14 22:01:52,623 - INFO - Fold 2, Epoch 100: Val Acc: 0.62%
2025-08-14 22:01:56,224 - INFO - Fold 2, Epoch 110: Val Acc: 0.88%
2025-08-14 22:01:58,526 - INFO - Fold 2, Epoch 120: Val Acc: 0.84%
2025-08-14 22:02:02,221 - INFO - Fold 2, Epoch 130: Val Acc: 0.81%
2025-08-14 22:02:04,450 - INFO - Fold 2, Epoch 140: Val Acc: 0.66%
2025-08-14 22:02:06,676 - INFO - Fold 2, Epoch 150: Val Acc: 0.66%
2025-08-14 22:02:08,908 - INFO - Fold 2, Epoch 160: Val Acc: 0.56%
2025-08-14 22:02:11,120 - INFO - Fold 2, Epoch 170: Val Acc: 0.81%
2025-08-14 22:02:12,984 - INFO - Fold 2, Epoch 180: Val Acc: 0.78%
2025-08-14 22:02:15,183 - INFO - Fold 2, Epoch 190: Val Acc: 0.84%
2025-08-14 22:02:17,412 - INFO - Fold 2, Epoch 200: Val Acc: 0.66%
2025-08-14 22:02:19,631 - INFO - Fold 2, Epoch 210: Val Acc: 0.75%
2025-08-14 22:02:21,851 - INFO - Fold 2, Epoch 220: Val Acc: 0.75%
2025-08-14 22:02:22,969 - INFO - Early stopping at epoch 225
2025-08-14 22:02:26,114 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:02:26,117 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:02:26,117 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:02:35,740 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-14 22:02:40,987 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-14 22:02:43,283 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-14 22:02:47,014 - INFO - Fold 3, Epoch 40: Val Acc: 0.53%
2025-08-14 22:02:49,235 - INFO - Fold 3, Epoch 50: Val Acc: 0.66%
2025-08-14 22:02:52,799 - INFO - Fold 3, Epoch 60: Val Acc: 0.59%
2025-08-14 22:02:54,587 - INFO - Fold 3, Epoch 70: Val Acc: 0.44%
2025-08-14 22:02:56,581 - INFO - Fold 3, Epoch 80: Val Acc: 0.66%
2025-08-14 22:02:58,802 - INFO - Fold 3, Epoch 90: Val Acc: 0.62%
2025-08-14 22:03:00,725 - INFO - Fold 3, Epoch 100: Val Acc: 0.53%
2025-08-14 22:03:02,752 - INFO - Fold 3, Epoch 110: Val Acc: 0.53%
2025-08-14 22:03:06,445 - INFO - Fold 3, Epoch 120: Val Acc: 0.69%
2025-08-14 22:03:08,655 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-14 22:03:10,863 - INFO - Fold 3, Epoch 140: Val Acc: 0.59%
2025-08-14 22:03:13,072 - INFO - Fold 3, Epoch 150: Val Acc: 0.75%
2025-08-14 22:03:15,278 - INFO - Fold 3, Epoch 160: Val Acc: 0.53%
2025-08-14 22:03:17,471 - INFO - Fold 3, Epoch 170: Val Acc: 0.84%
2025-08-14 22:03:19,668 - INFO - Fold 3, Epoch 180: Val Acc: 0.59%
2025-08-14 22:03:21,879 - INFO - Fold 3, Epoch 190: Val Acc: 0.78%
2025-08-14 22:03:24,084 - INFO - Fold 3, Epoch 200: Val Acc: 0.84%
2025-08-14 22:03:26,292 - INFO - Fold 3, Epoch 210: Val Acc: 0.62%
2025-08-14 22:03:26,512 - INFO - Early stopping at epoch 211
2025-08-14 22:03:27,692 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9562418990665016), 'std': np.float64(0.05981659090645379)}, 'train_accuracy': {'mean': np.float64(0.7395833333333334), 'std': np.float64(0.008505172717997117)}, 'val_loss': {'mean': np.float64(4.467652479807536), 'std': np.float64(0.05370459841795285)}, 'val_accuracy': {'mean': np.float64(0.875), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(109.0), 'std': np.float64(12.675435561221029)}}
[I 2025-08-14 22:03:27,699] Trial 61 finished with value: -0.875 and parameters: {'learning_rate': 0.0005310874652406345, 'batch_size': 32, 'num_epochs': 785, 'temperature': 0.0919135993428742, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4624062525403712, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.16835649587935236, 'crop_size': 0.5761694258558091}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 61 finished with value: -0.875 and parameters: {'learning_rate': 0.0005310874652406345, 'batch_size': 32, 'num_epochs': 785, 'temperature': 0.0919135993428742, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4624062525403712, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.16835649587935236, 'crop_size': 0.5761694258558091}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:03:27,731 - INFO - Using device: cuda
2025-08-14 22:03:37,491 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:03:37,493 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:03:37,493 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:03:46,819 - INFO - Fold 1, Epoch 10: Val Acc: 0.44%
2025-08-14 22:03:49,044 - INFO - Fold 1, Epoch 20: Val Acc: 0.69%
2025-08-14 22:03:51,151 - INFO - Fold 1, Epoch 30: Val Acc: 0.56%
2025-08-14 22:03:55,786 - INFO - Fold 1, Epoch 40: Val Acc: 0.62%
2025-08-14 22:04:00,341 - INFO - Fold 1, Epoch 50: Val Acc: 0.53%
2025-08-14 22:04:02,571 - INFO - Fold 1, Epoch 60: Val Acc: 0.56%
2025-08-14 22:04:04,794 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-14 22:04:07,018 - INFO - Fold 1, Epoch 80: Val Acc: 0.69%
2025-08-14 22:04:09,237 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-14 22:04:11,456 - INFO - Fold 1, Epoch 100: Val Acc: 0.84%
2025-08-14 22:04:13,270 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-14 22:04:15,493 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-14 22:04:17,798 - INFO - Fold 1, Epoch 130: Val Acc: 0.72%
2025-08-14 22:04:20,099 - INFO - Fold 1, Epoch 140: Val Acc: 0.72%
2025-08-14 22:04:21,023 - INFO - Early stopping at epoch 144
2025-08-14 22:04:24,731 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:04:24,734 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:04:24,735 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:04:29,624 - INFO - Fold 2, Epoch 10: Val Acc: 0.53%
2025-08-14 22:04:33,044 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-14 22:04:36,822 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-14 22:04:40,488 - INFO - Fold 2, Epoch 40: Val Acc: 0.62%
2025-08-14 22:04:42,806 - INFO - Fold 2, Epoch 50: Val Acc: 0.72%
2025-08-14 22:04:44,810 - INFO - Fold 2, Epoch 60: Val Acc: 0.62%
2025-08-14 22:04:47,119 - INFO - Fold 2, Epoch 70: Val Acc: 0.62%
2025-08-14 22:04:49,440 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-14 22:04:51,750 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-14 22:04:54,072 - INFO - Fold 2, Epoch 100: Val Acc: 0.56%
2025-08-14 22:04:57,769 - INFO - Fold 2, Epoch 110: Val Acc: 0.88%
2025-08-14 22:05:00,066 - INFO - Fold 2, Epoch 120: Val Acc: 0.62%
2025-08-14 22:05:02,280 - INFO - Fold 2, Epoch 130: Val Acc: 0.62%
2025-08-14 22:05:04,488 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-14 22:05:06,706 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-14 22:05:08,913 - INFO - Fold 2, Epoch 160: Val Acc: 0.72%
2025-08-14 22:05:11,131 - INFO - Fold 2, Epoch 170: Val Acc: 0.81%
2025-08-14 22:05:13,351 - INFO - Fold 2, Epoch 180: Val Acc: 0.75%
2025-08-14 22:05:15,580 - INFO - Fold 2, Epoch 190: Val Acc: 0.78%
2025-08-14 22:05:17,877 - INFO - Fold 2, Epoch 200: Val Acc: 0.75%
2025-08-14 22:05:20,137 - INFO - Early stopping at epoch 210
2025-08-14 22:05:24,507 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:05:24,511 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:05:24,511 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:05:32,568 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-14 22:05:34,849 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-14 22:05:38,566 - INFO - Fold 3, Epoch 30: Val Acc: 0.59%
2025-08-14 22:05:42,340 - INFO - Fold 3, Epoch 40: Val Acc: 0.59%
2025-08-14 22:05:46,138 - INFO - Fold 3, Epoch 50: Val Acc: 0.66%
2025-08-14 22:05:48,453 - INFO - Fold 3, Epoch 60: Val Acc: 0.69%
2025-08-14 22:05:52,107 - INFO - Fold 3, Epoch 70: Val Acc: 0.81%
2025-08-14 22:05:55,824 - INFO - Fold 3, Epoch 80: Val Acc: 0.56%
2025-08-14 22:05:58,071 - INFO - Fold 3, Epoch 90: Val Acc: 0.62%
2025-08-14 22:06:00,303 - INFO - Fold 3, Epoch 100: Val Acc: 0.62%
2025-08-14 22:06:02,531 - INFO - Fold 3, Epoch 110: Val Acc: 0.59%
2025-08-14 22:06:04,766 - INFO - Fold 3, Epoch 120: Val Acc: 0.69%
2025-08-14 22:06:06,995 - INFO - Fold 3, Epoch 130: Val Acc: 0.75%
2025-08-14 22:06:09,229 - INFO - Fold 3, Epoch 140: Val Acc: 0.66%
2025-08-14 22:06:11,461 - INFO - Fold 3, Epoch 150: Val Acc: 0.56%
2025-08-14 22:06:13,692 - INFO - Fold 3, Epoch 160: Val Acc: 0.56%
2025-08-14 22:06:15,927 - INFO - Fold 3, Epoch 170: Val Acc: 0.50%
2025-08-14 22:06:16,368 - INFO - Early stopping at epoch 172
2025-08-14 22:06:17,448 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.007871442370944), 'std': np.float64(0.08626210176608812)}, 'train_accuracy': {'mean': np.float64(0.6805555555555557), 'std': np.float64(0.024552318791199637)}, 'val_loss': {'mean': np.float64(4.299416542053223), 'std': np.float64(0.14798854758633787)}, 'val_accuracy': {'mean': np.float64(0.8645833333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(74.33333333333333), 'std': np.float64(27.047283700134393)}}
[I 2025-08-14 22:06:17,455] Trial 62 finished with value: -0.8645833333333334 and parameters: {'learning_rate': 0.0006189474651663565, 'batch_size': 32, 'num_epochs': 813, 'temperature': 0.12046845573980793, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.42745231748893353, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.17947927209099163, 'crop_size': 0.5335829120506683}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 62 finished with value: -0.8645833333333334 and parameters: {'learning_rate': 0.0006189474651663565, 'batch_size': 32, 'num_epochs': 813, 'temperature': 0.12046845573980793, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.42745231748893353, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.17947927209099163, 'crop_size': 0.5335829120506683}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:06:17,485 - INFO - Using device: cuda
2025-08-14 22:06:27,383 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:06:27,385 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:06:27,385 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:06:40,404 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-14 22:06:45,387 - INFO - Fold 1, Epoch 20: Val Acc: 0.69%
2025-08-14 22:06:50,328 - INFO - Fold 1, Epoch 30: Val Acc: 0.78%
2025-08-14 22:06:52,867 - INFO - Fold 1, Epoch 40: Val Acc: 0.56%
2025-08-14 22:06:55,238 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-14 22:06:57,688 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-14 22:07:00,135 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-14 22:07:02,598 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-14 22:07:05,157 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-14 22:07:10,540 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-14 22:07:12,839 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-14 22:07:15,204 - INFO - Fold 1, Epoch 120: Val Acc: 0.59%
2025-08-14 22:07:17,352 - INFO - Fold 1, Epoch 130: Val Acc: 0.72%
2025-08-14 22:07:19,702 - INFO - Fold 1, Epoch 140: Val Acc: 0.53%
2025-08-14 22:07:22,235 - INFO - Fold 1, Epoch 150: Val Acc: 0.75%
2025-08-14 22:07:24,674 - INFO - Fold 1, Epoch 160: Val Acc: 0.66%
2025-08-14 22:07:27,186 - INFO - Fold 1, Epoch 170: Val Acc: 0.72%
2025-08-14 22:07:32,217 - INFO - Fold 1, Epoch 180: Val Acc: 0.69%
2025-08-14 22:07:34,757 - INFO - Fold 1, Epoch 190: Val Acc: 0.72%
2025-08-14 22:07:37,308 - INFO - Fold 1, Epoch 200: Val Acc: 0.69%
2025-08-14 22:07:39,858 - INFO - Fold 1, Epoch 210: Val Acc: 0.75%
2025-08-14 22:07:42,342 - INFO - Fold 1, Epoch 220: Val Acc: 0.56%
2025-08-14 22:07:44,803 - INFO - Fold 1, Epoch 230: Val Acc: 0.59%
2025-08-14 22:07:47,259 - INFO - Fold 1, Epoch 240: Val Acc: 0.72%
2025-08-14 22:07:49,716 - INFO - Fold 1, Epoch 250: Val Acc: 0.69%
2025-08-14 22:07:52,180 - INFO - Fold 1, Epoch 260: Val Acc: 0.59%
2025-08-14 22:07:54,645 - INFO - Fold 1, Epoch 270: Val Acc: 0.66%
2025-08-14 22:07:56,613 - INFO - Early stopping at epoch 278
2025-08-14 22:08:00,505 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:08:00,508 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:08:00,508 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:08:08,041 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-14 22:08:12,295 - INFO - Fold 2, Epoch 20: Val Acc: 0.72%
2025-08-14 22:08:16,452 - INFO - Fold 2, Epoch 30: Val Acc: 0.66%
2025-08-14 22:08:20,721 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-14 22:08:22,623 - INFO - Fold 2, Epoch 50: Val Acc: 0.62%
2025-08-14 22:08:26,703 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-14 22:08:29,158 - INFO - Fold 2, Epoch 70: Val Acc: 0.62%
2025-08-14 22:08:31,578 - INFO - Fold 2, Epoch 80: Val Acc: 0.72%
2025-08-14 22:08:34,038 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-14 22:08:36,561 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-14 22:08:40,510 - INFO - Fold 2, Epoch 110: Val Acc: 0.88%
2025-08-14 22:08:43,036 - INFO - Fold 2, Epoch 120: Val Acc: 0.78%
2025-08-14 22:08:45,488 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-14 22:08:47,939 - INFO - Fold 2, Epoch 140: Val Acc: 0.84%
2025-08-14 22:08:50,387 - INFO - Fold 2, Epoch 150: Val Acc: 0.84%
2025-08-14 22:08:52,838 - INFO - Fold 2, Epoch 160: Val Acc: 0.81%
2025-08-14 22:08:55,292 - INFO - Fold 2, Epoch 170: Val Acc: 0.69%
2025-08-14 22:08:57,332 - INFO - Fold 2, Epoch 180: Val Acc: 0.72%
2025-08-14 22:09:00,878 - INFO - Fold 2, Epoch 190: Val Acc: 0.75%
2025-08-14 22:09:02,740 - INFO - Fold 2, Epoch 200: Val Acc: 0.72%
2025-08-14 22:09:05,123 - INFO - Fold 2, Epoch 210: Val Acc: 0.75%
2025-08-14 22:09:07,555 - INFO - Fold 2, Epoch 220: Val Acc: 0.72%
2025-08-14 22:09:09,983 - INFO - Fold 2, Epoch 230: Val Acc: 0.62%
2025-08-14 22:09:12,424 - INFO - Fold 2, Epoch 240: Val Acc: 0.72%
2025-08-14 22:09:14,878 - INFO - Fold 2, Epoch 250: Val Acc: 0.69%
2025-08-14 22:09:17,369 - INFO - Fold 2, Epoch 260: Val Acc: 0.72%
2025-08-14 22:09:19,483 - INFO - Fold 2, Epoch 270: Val Acc: 0.72%
2025-08-14 22:09:21,346 - INFO - Fold 2, Epoch 280: Val Acc: 0.81%
2025-08-14 22:09:22,463 - INFO - Early stopping at epoch 286
2025-08-14 22:09:25,666 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:09:25,670 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:09:25,670 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:09:32,951 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-14 22:09:42,464 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-14 22:09:44,961 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-14 22:09:47,498 - INFO - Fold 3, Epoch 40: Val Acc: 0.69%
2025-08-14 22:09:51,701 - INFO - Fold 3, Epoch 50: Val Acc: 0.56%
2025-08-14 22:09:54,223 - INFO - Fold 3, Epoch 60: Val Acc: 0.72%
2025-08-14 22:09:56,770 - INFO - Fold 3, Epoch 70: Val Acc: 0.75%
2025-08-14 22:10:00,906 - INFO - Fold 3, Epoch 80: Val Acc: 0.69%
2025-08-14 22:10:03,208 - INFO - Fold 3, Epoch 90: Val Acc: 0.59%
2025-08-14 22:10:05,138 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-14 22:10:07,634 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-14 22:10:11,862 - INFO - Fold 3, Epoch 120: Val Acc: 0.91%
2025-08-14 22:10:14,408 - INFO - Fold 3, Epoch 130: Val Acc: 0.62%
2025-08-14 22:10:16,868 - INFO - Fold 3, Epoch 140: Val Acc: 0.69%
2025-08-14 22:10:19,335 - INFO - Fold 3, Epoch 150: Val Acc: 0.66%
2025-08-14 22:10:21,692 - INFO - Fold 3, Epoch 160: Val Acc: 0.84%
2025-08-14 22:10:24,137 - INFO - Fold 3, Epoch 170: Val Acc: 0.66%
2025-08-14 22:10:26,589 - INFO - Fold 3, Epoch 180: Val Acc: 0.56%
2025-08-14 22:10:29,042 - INFO - Fold 3, Epoch 190: Val Acc: 0.62%
2025-08-14 22:10:31,501 - INFO - Fold 3, Epoch 200: Val Acc: 0.66%
2025-08-14 22:10:33,951 - INFO - Fold 3, Epoch 210: Val Acc: 0.66%
2025-08-14 22:10:36,404 - INFO - Early stopping at epoch 220
2025-08-14 22:10:37,677 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.730555560853746), 'std': np.float64(0.1539009066000799)}, 'train_accuracy': {'mean': np.float64(0.857638888888889), 'std': np.float64(0.04364515656241856)}, 'val_loss': {'mean': np.float64(4.285947799682617), 'std': np.float64(0.14357576611795414)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(160.33333333333334), 'std': np.float64(29.408993333483707)}}
[I 2025-08-14 22:10:37,684] Trial 63 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0007658234192045605, 'batch_size': 32, 'num_epochs': 744, 'temperature': 0.11034766695208342, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.2629535385066366, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.13955863780300204, 'crop_size': 0.6148734461513311}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 63 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0007658234192045605, 'batch_size': 32, 'num_epochs': 744, 'temperature': 0.11034766695208342, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.2629535385066366, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.13955863780300204, 'crop_size': 0.6148734461513311}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:10:37,716 - INFO - Using device: cuda
2025-08-14 22:10:47,079 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:10:47,080 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:10:47,081 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:10:58,275 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-14 22:11:02,625 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-14 22:11:04,643 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-14 22:11:11,451 - INFO - Fold 1, Epoch 40: Val Acc: 0.66%
2025-08-14 22:11:13,261 - INFO - Fold 1, Epoch 50: Val Acc: 0.59%
2025-08-14 22:11:15,068 - INFO - Fold 1, Epoch 60: Val Acc: 0.53%
2025-08-14 22:11:16,876 - INFO - Fold 1, Epoch 70: Val Acc: 0.78%
2025-08-14 22:11:18,685 - INFO - Fold 1, Epoch 80: Val Acc: 0.69%
2025-08-14 22:11:20,617 - INFO - Fold 1, Epoch 90: Val Acc: 0.59%
2025-08-14 22:11:22,938 - INFO - Fold 1, Epoch 100: Val Acc: 0.78%
2025-08-14 22:11:25,251 - INFO - Fold 1, Epoch 110: Val Acc: 0.56%
2025-08-14 22:11:27,581 - INFO - Fold 1, Epoch 120: Val Acc: 0.78%
2025-08-14 22:11:29,896 - INFO - Fold 1, Epoch 130: Val Acc: 0.59%
2025-08-14 22:11:31,275 - INFO - Early stopping at epoch 136
2025-08-14 22:11:34,880 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:11:34,883 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:11:34,883 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:11:43,117 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-14 22:11:46,865 - INFO - Fold 2, Epoch 20: Val Acc: 0.56%
2025-08-14 22:11:50,432 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-14 22:11:52,660 - INFO - Fold 2, Epoch 40: Val Acc: 0.59%
2025-08-14 22:11:54,899 - INFO - Fold 2, Epoch 50: Val Acc: 0.72%
2025-08-14 22:11:57,128 - INFO - Fold 2, Epoch 60: Val Acc: 0.56%
2025-08-14 22:12:00,950 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-14 22:12:03,185 - INFO - Fold 2, Epoch 80: Val Acc: 0.81%
2025-08-14 22:12:05,131 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-14 22:12:08,798 - INFO - Fold 2, Epoch 100: Val Acc: 0.69%
2025-08-14 22:12:11,024 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-14 22:12:13,241 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-14 22:12:15,452 - INFO - Fold 2, Epoch 130: Val Acc: 0.59%
2025-08-14 22:12:17,664 - INFO - Fold 2, Epoch 140: Val Acc: 0.66%
2025-08-14 22:12:21,318 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-14 22:12:23,026 - INFO - Fold 2, Epoch 160: Val Acc: 0.59%
2025-08-14 22:12:25,018 - INFO - Fold 2, Epoch 170: Val Acc: 0.66%
2025-08-14 22:12:28,660 - INFO - Fold 2, Epoch 180: Val Acc: 0.69%
2025-08-14 22:12:30,925 - INFO - Fold 2, Epoch 190: Val Acc: 0.75%
2025-08-14 22:12:33,140 - INFO - Fold 2, Epoch 200: Val Acc: 0.62%
2025-08-14 22:12:35,358 - INFO - Fold 2, Epoch 210: Val Acc: 0.81%
2025-08-14 22:12:37,574 - INFO - Fold 2, Epoch 220: Val Acc: 0.69%
2025-08-14 22:12:39,812 - INFO - Fold 2, Epoch 230: Val Acc: 0.81%
2025-08-14 22:12:42,114 - INFO - Fold 2, Epoch 240: Val Acc: 0.75%
2025-08-14 22:12:44,410 - INFO - Fold 2, Epoch 250: Val Acc: 0.69%
2025-08-14 22:12:46,714 - INFO - Fold 2, Epoch 260: Val Acc: 0.69%
2025-08-14 22:12:49,028 - INFO - Fold 2, Epoch 270: Val Acc: 0.88%
2025-08-14 22:12:49,953 - INFO - Early stopping at epoch 274
2025-08-14 22:12:52,898 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:12:52,901 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:12:52,902 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:12:58,157 - INFO - Fold 3, Epoch 10: Val Acc: 0.41%
2025-08-14 22:13:00,371 - INFO - Fold 3, Epoch 20: Val Acc: 0.56%
2025-08-14 22:13:02,599 - INFO - Fold 3, Epoch 30: Val Acc: 0.69%
2025-08-14 22:13:04,824 - INFO - Fold 3, Epoch 40: Val Acc: 0.72%
2025-08-14 22:13:07,052 - INFO - Fold 3, Epoch 50: Val Acc: 0.81%
2025-08-14 22:13:09,162 - INFO - Fold 3, Epoch 60: Val Acc: 0.59%
2025-08-14 22:13:10,888 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-14 22:13:12,597 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-14 22:13:14,312 - INFO - Fold 3, Epoch 90: Val Acc: 0.59%
2025-08-14 22:13:16,020 - INFO - Fold 3, Epoch 100: Val Acc: 0.78%
2025-08-14 22:13:16,365 - INFO - Early stopping at epoch 102
2025-08-14 22:13:17,441 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.152785142262776), 'std': np.float64(0.3675959060459009)}, 'train_accuracy': {'mean': np.float64(0.7083333333333334), 'std': np.float64(0.11154429447367366)}, 'val_loss': {'mean': np.float64(4.459640026092529), 'std': np.float64(0.15668420001347097)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(69.66666666666667), 'std': np.float64(74.37442810237638)}}
[I 2025-08-14 22:13:17,447] Trial 64 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0004641778899128381, 'batch_size': 32, 'num_epochs': 962, 'temperature': 0.16924048936212296, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.45065041481192886, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.17248043213914643, 'crop_size': 0.5876852568489724}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 64 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0004641778899128381, 'batch_size': 32, 'num_epochs': 962, 'temperature': 0.16924048936212296, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.45065041481192886, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.17248043213914643, 'crop_size': 0.5876852568489724}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:13:17,478 - INFO - Using device: cuda
2025-08-14 22:13:27,292 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:13:27,293 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:13:27,294 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:13:34,856 - INFO - Fold 1, Epoch 10: Val Acc: 0.66%
2025-08-14 22:13:36,919 - INFO - Fold 1, Epoch 20: Val Acc: 0.44%
2025-08-14 22:13:38,567 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 22:13:40,113 - INFO - Fold 1, Epoch 40: Val Acc: 0.56%
2025-08-14 22:13:43,656 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-14 22:13:45,201 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-14 22:13:47,211 - INFO - Fold 1, Epoch 70: Val Acc: 0.69%
2025-08-14 22:13:49,213 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-14 22:13:51,198 - INFO - Fold 1, Epoch 90: Val Acc: 0.66%
2025-08-14 22:13:55,212 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-14 22:13:57,222 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-14 22:13:59,228 - INFO - Fold 1, Epoch 120: Val Acc: 0.78%
2025-08-14 22:14:01,239 - INFO - Fold 1, Epoch 130: Val Acc: 0.56%
2025-08-14 22:14:03,136 - INFO - Fold 1, Epoch 140: Val Acc: 0.69%
2025-08-14 22:14:04,687 - INFO - Fold 1, Epoch 150: Val Acc: 0.81%
2025-08-14 22:14:06,229 - INFO - Fold 1, Epoch 160: Val Acc: 0.59%
2025-08-14 22:14:08,113 - INFO - Fold 1, Epoch 170: Val Acc: 0.66%
2025-08-14 22:14:10,116 - INFO - Fold 1, Epoch 180: Val Acc: 0.72%
2025-08-14 22:14:12,104 - INFO - Fold 1, Epoch 190: Val Acc: 0.66%
2025-08-14 22:14:12,310 - INFO - Early stopping at epoch 191
2025-08-14 22:14:15,216 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:14:15,219 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:14:15,220 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:14:21,105 - INFO - Fold 2, Epoch 10: Val Acc: 0.47%
2025-08-14 22:14:25,484 - INFO - Fold 2, Epoch 20: Val Acc: 0.62%
2025-08-14 22:14:28,636 - INFO - Fold 2, Epoch 30: Val Acc: 0.78%
2025-08-14 22:14:30,648 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-14 22:14:33,817 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-14 22:14:35,681 - INFO - Fold 2, Epoch 60: Val Acc: 0.78%
2025-08-14 22:14:37,239 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-14 22:14:38,967 - INFO - Fold 2, Epoch 80: Val Acc: 0.78%
2025-08-14 22:14:40,979 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-14 22:14:44,288 - INFO - Fold 2, Epoch 100: Val Acc: 0.84%
2025-08-14 22:14:46,307 - INFO - Fold 2, Epoch 110: Val Acc: 0.81%
2025-08-14 22:14:48,317 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-14 22:14:51,298 - INFO - Fold 2, Epoch 130: Val Acc: 0.72%
2025-08-14 22:14:52,987 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-14 22:14:54,543 - INFO - Fold 2, Epoch 150: Val Acc: 0.66%
2025-08-14 22:14:56,103 - INFO - Fold 2, Epoch 160: Val Acc: 0.78%
2025-08-14 22:14:57,658 - INFO - Fold 2, Epoch 170: Val Acc: 0.66%
2025-08-14 22:14:59,214 - INFO - Fold 2, Epoch 180: Val Acc: 0.72%
2025-08-14 22:15:00,779 - INFO - Fold 2, Epoch 190: Val Acc: 0.72%
2025-08-14 22:15:02,334 - INFO - Fold 2, Epoch 200: Val Acc: 0.78%
2025-08-14 22:15:03,893 - INFO - Fold 2, Epoch 210: Val Acc: 0.88%
2025-08-14 22:15:05,450 - INFO - Fold 2, Epoch 220: Val Acc: 0.75%
2025-08-14 22:15:05,761 - INFO - Early stopping at epoch 222
2025-08-14 22:15:08,278 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:15:08,284 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:15:08,284 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:15:14,039 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-14 22:15:19,419 - INFO - Fold 3, Epoch 20: Val Acc: 0.84%
2025-08-14 22:15:21,512 - INFO - Fold 3, Epoch 30: Val Acc: 0.72%
2025-08-14 22:15:24,494 - INFO - Fold 3, Epoch 40: Val Acc: 0.59%
2025-08-14 22:15:26,349 - INFO - Fold 3, Epoch 50: Val Acc: 0.66%
2025-08-14 22:15:28,373 - INFO - Fold 3, Epoch 60: Val Acc: 0.81%
2025-08-14 22:15:30,444 - INFO - Fold 3, Epoch 70: Val Acc: 0.78%
2025-08-14 22:15:32,494 - INFO - Fold 3, Epoch 80: Val Acc: 0.81%
2025-08-14 22:15:34,565 - INFO - Fold 3, Epoch 90: Val Acc: 0.56%
2025-08-14 22:15:36,597 - INFO - Fold 3, Epoch 100: Val Acc: 0.59%
2025-08-14 22:15:38,584 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-14 22:15:40,566 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-14 22:15:42,498 - INFO - Fold 3, Epoch 130: Val Acc: 0.75%
2025-08-14 22:15:43,269 - INFO - Early stopping at epoch 135
2025-08-14 22:15:44,156 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.8997945520612927), 'std': np.float64(0.07359547923202589)}, 'train_accuracy': {'mean': np.float64(0.7569444444444445), 'std': np.float64(0.021404215288086698)}, 'val_loss': {'mean': np.float64(4.345572789510091), 'std': np.float64(0.11686916701690288)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(81.66666666666667), 'std': np.float64(36.003086287459055)}}
[I 2025-08-14 22:15:44,162] Trial 65 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.000990384890066292, 'batch_size': 32, 'num_epochs': 896, 'temperature': 0.11905660009927235, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4788142406304534, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1944721644423184, 'crop_size': 0.5517129829158075}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 65 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.000990384890066292, 'batch_size': 32, 'num_epochs': 896, 'temperature': 0.11905660009927235, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4788142406304534, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1944721644423184, 'crop_size': 0.5517129829158075}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:15:44,195 - INFO - Using device: cuda
2025-08-14 22:15:53,989 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:15:53,991 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:15:53,991 - INFO - Starting training for fold 1/3
2025-08-14 22:15:58,734 - INFO - Fold 1, Epoch 10: Val Acc: 0.62%
2025-08-14 22:16:05,590 - INFO - Fold 1, Epoch 20: Val Acc: 0.66%
2025-08-14 22:16:07,820 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-14 22:16:14,555 - INFO - Fold 1, Epoch 40: Val Acc: 0.66%
2025-08-14 22:16:16,814 - INFO - Fold 1, Epoch 50: Val Acc: 0.72%
2025-08-14 22:16:18,943 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-14 22:16:23,396 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-14 22:16:25,629 - INFO - Fold 1, Epoch 80: Val Acc: 0.78%
2025-08-14 22:16:27,865 - INFO - Fold 1, Epoch 90: Val Acc: 0.78%
2025-08-14 22:16:29,911 - INFO - Fold 1, Epoch 100: Val Acc: 0.78%
2025-08-14 22:16:32,146 - INFO - Fold 1, Epoch 110: Val Acc: 0.78%
2025-08-14 22:16:34,104 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-14 22:16:36,342 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-14 22:16:38,568 - INFO - Fold 1, Epoch 140: Val Acc: 0.72%
2025-08-14 22:16:40,786 - INFO - Fold 1, Epoch 150: Val Acc: 0.78%
2025-08-14 22:16:43,005 - INFO - Fold 1, Epoch 160: Val Acc: 0.84%
2025-08-14 22:16:44,779 - INFO - Early stopping at epoch 168
2025-08-14 22:16:48,859 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:16:48,874 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:16:48,875 - INFO - Starting training for fold 2/3
2025-08-14 22:16:53,941 - INFO - Fold 2, Epoch 10: Val Acc: 0.59%
2025-08-14 22:16:57,364 - INFO - Fold 2, Epoch 20: Val Acc: 0.47%
2025-08-14 22:17:04,075 - INFO - Fold 2, Epoch 30: Val Acc: 0.53%
2025-08-14 22:17:07,679 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-14 22:17:12,767 - INFO - Fold 2, Epoch 50: Val Acc: 0.91%
2025-08-14 22:17:15,076 - INFO - Fold 2, Epoch 60: Val Acc: 0.78%
2025-08-14 22:17:17,311 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-14 22:17:19,546 - INFO - Fold 2, Epoch 80: Val Acc: 0.78%
2025-08-14 22:17:21,770 - INFO - Fold 2, Epoch 90: Val Acc: 0.75%
2025-08-14 22:17:23,985 - INFO - Fold 2, Epoch 100: Val Acc: 0.81%
2025-08-14 22:17:26,205 - INFO - Fold 2, Epoch 110: Val Acc: 0.66%
2025-08-14 22:17:28,422 - INFO - Fold 2, Epoch 120: Val Acc: 0.78%
2025-08-14 22:17:30,641 - INFO - Fold 2, Epoch 130: Val Acc: 0.47%
2025-08-14 22:17:32,871 - INFO - Fold 2, Epoch 140: Val Acc: 0.69%
2025-08-14 22:17:35,109 - INFO - Early stopping at epoch 150
2025-08-14 22:17:38,060 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:17:38,062 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:17:38,063 - INFO - Starting training for fold 3/3
2025-08-14 22:17:47,798 - INFO - Fold 3, Epoch 10: Val Acc: 0.47%
2025-08-14 22:17:50,032 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-14 22:17:52,325 - INFO - Fold 3, Epoch 30: Val Acc: 0.56%
2025-08-14 22:17:56,090 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-14 22:17:58,404 - INFO - Fold 3, Epoch 50: Val Acc: 0.75%
2025-08-14 22:18:02,036 - INFO - Fold 3, Epoch 60: Val Acc: 0.84%
2025-08-14 22:18:04,431 - INFO - Fold 3, Epoch 70: Val Acc: 0.62%
2025-08-14 22:18:06,744 - INFO - Fold 3, Epoch 80: Val Acc: 0.62%
2025-08-14 22:18:08,956 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-14 22:18:11,181 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-14 22:18:14,836 - INFO - Fold 3, Epoch 110: Val Acc: 0.72%
2025-08-14 22:18:17,135 - INFO - Fold 3, Epoch 120: Val Acc: 0.84%
2025-08-14 22:18:19,440 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-14 22:18:23,691 - INFO - Fold 3, Epoch 140: Val Acc: 0.84%
2025-08-14 22:18:25,908 - INFO - Fold 3, Epoch 150: Val Acc: 0.75%
2025-08-14 22:18:28,129 - INFO - Fold 3, Epoch 160: Val Acc: 0.75%
2025-08-14 22:18:30,362 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-14 22:18:32,593 - INFO - Fold 3, Epoch 180: Val Acc: 0.81%
2025-08-14 22:18:34,814 - INFO - Fold 3, Epoch 190: Val Acc: 0.75%
2025-08-14 22:18:37,039 - INFO - Fold 3, Epoch 200: Val Acc: 0.88%
2025-08-14 22:18:39,279 - INFO - Fold 3, Epoch 210: Val Acc: 0.62%
2025-08-14 22:18:41,586 - INFO - Fold 3, Epoch 220: Val Acc: 0.59%
2025-08-14 22:18:43,827 - INFO - Fold 3, Epoch 230: Val Acc: 0.78%
2025-08-14 22:18:45,614 - INFO - Early stopping at epoch 238
2025-08-14 22:18:48,535 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.944811529583401), 'std': np.float64(0.022921657315934988)}, 'train_accuracy': {'mean': np.float64(0.7673611111111112), 'std': np.float64(0.04280843057617347)}, 'val_loss': {'mean': np.float64(4.363551616668701), 'std': np.float64(0.02239130737715644)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(84.33333333333333), 'std': np.float64(37.959042254631356)}}
[I 2025-08-14 22:18:48,544] Trial 66 finished with value: -0.90625 and parameters: {'learning_rate': 0.00025186556532252934, 'batch_size': 32, 'num_epochs': 878, 'temperature': 0.147146554042903, 'embedding_dim': 512, 'hidden_dim': 256, 'dropout': 0.43263415082827933, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1601288040219481, 'crop_size': 0.5175024140267394}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 66 finished with value: -0.90625 and parameters: {'learning_rate': 0.00025186556532252934, 'batch_size': 32, 'num_epochs': 878, 'temperature': 0.147146554042903, 'embedding_dim': 512, 'hidden_dim': 256, 'dropout': 0.43263415082827933, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1601288040219481, 'crop_size': 0.5175024140267394}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:18:48,617 - INFO - Using device: cuda
2025-08-14 22:18:58,477 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:18:58,480 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:18:58,480 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:19:09,640 - INFO - Fold 1, Epoch 10: Val Acc: 0.66%
2025-08-14 22:19:11,761 - INFO - Fold 1, Epoch 20: Val Acc: 0.62%
2025-08-14 22:19:16,042 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-14 22:19:18,128 - INFO - Fold 1, Epoch 40: Val Acc: 0.50%
2025-08-14 22:19:20,290 - INFO - Fold 1, Epoch 50: Val Acc: 0.62%
2025-08-14 22:19:24,739 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-14 22:19:26,953 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-14 22:19:29,171 - INFO - Fold 1, Epoch 80: Val Acc: 0.56%
2025-08-14 22:19:31,376 - INFO - Fold 1, Epoch 90: Val Acc: 0.53%
2025-08-14 22:19:33,584 - INFO - Fold 1, Epoch 100: Val Acc: 0.47%
2025-08-14 22:19:35,494 - INFO - Fold 1, Epoch 110: Val Acc: 0.56%
2025-08-14 22:19:37,713 - INFO - Fold 1, Epoch 120: Val Acc: 0.78%
2025-08-14 22:19:39,932 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-14 22:19:42,160 - INFO - Fold 1, Epoch 140: Val Acc: 0.72%
2025-08-14 22:19:46,636 - INFO - Fold 1, Epoch 150: Val Acc: 0.72%
2025-08-14 22:19:48,860 - INFO - Fold 1, Epoch 160: Val Acc: 0.69%
2025-08-14 22:19:51,082 - INFO - Fold 1, Epoch 170: Val Acc: 0.62%
2025-08-14 22:19:53,252 - INFO - Fold 1, Epoch 180: Val Acc: 0.56%
2025-08-14 22:19:55,381 - INFO - Fold 1, Epoch 190: Val Acc: 0.59%
2025-08-14 22:19:57,504 - INFO - Fold 1, Epoch 200: Val Acc: 0.66%
2025-08-14 22:19:59,594 - INFO - Fold 1, Epoch 210: Val Acc: 0.62%
2025-08-14 22:20:01,386 - INFO - Fold 1, Epoch 220: Val Acc: 0.53%
2025-08-14 22:20:02,990 - INFO - Fold 1, Epoch 230: Val Acc: 0.66%
2025-08-14 22:20:04,832 - INFO - Fold 1, Epoch 240: Val Acc: 0.66%
2025-08-14 22:20:05,049 - INFO - Early stopping at epoch 241
2025-08-14 22:20:08,549 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:20:08,552 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:20:08,553 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:20:14,965 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-14 22:20:17,154 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-14 22:20:20,732 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-14 22:20:22,940 - INFO - Fold 2, Epoch 40: Val Acc: 0.66%
2025-08-14 22:20:26,479 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-14 22:20:28,701 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-14 22:20:30,819 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-14 22:20:34,231 - INFO - Fold 2, Epoch 80: Val Acc: 0.84%
2025-08-14 22:20:37,752 - INFO - Fold 2, Epoch 90: Val Acc: 0.91%
2025-08-14 22:20:39,977 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-14 22:20:43,592 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-14 22:20:45,793 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-14 22:20:47,985 - INFO - Fold 2, Epoch 130: Val Acc: 0.59%
2025-08-14 22:20:50,177 - INFO - Fold 2, Epoch 140: Val Acc: 0.66%
2025-08-14 22:20:52,378 - INFO - Fold 2, Epoch 150: Val Acc: 0.66%
2025-08-14 22:20:54,179 - INFO - Fold 2, Epoch 160: Val Acc: 0.72%
2025-08-14 22:20:55,786 - INFO - Fold 2, Epoch 170: Val Acc: 0.72%
2025-08-14 22:20:57,390 - INFO - Fold 2, Epoch 180: Val Acc: 0.66%
2025-08-14 22:20:59,086 - INFO - Fold 2, Epoch 190: Val Acc: 0.72%
2025-08-14 22:21:01,273 - INFO - Fold 2, Epoch 200: Val Acc: 0.75%
2025-08-14 22:21:02,584 - INFO - Early stopping at epoch 206
2025-08-14 22:21:03,669 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:21:03,671 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:21:03,671 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:21:12,044 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-14 22:21:15,596 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-14 22:21:19,234 - INFO - Fold 3, Epoch 30: Val Acc: 0.62%
2025-08-14 22:21:21,361 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-14 22:21:23,478 - INFO - Fold 3, Epoch 50: Val Acc: 0.75%
2025-08-14 22:21:25,604 - INFO - Fold 3, Epoch 60: Val Acc: 0.62%
2025-08-14 22:21:27,724 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-14 22:21:31,264 - INFO - Fold 3, Epoch 80: Val Acc: 0.66%
2025-08-14 22:21:33,389 - INFO - Fold 3, Epoch 90: Val Acc: 0.56%
2025-08-14 22:21:35,498 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-14 22:21:37,613 - INFO - Fold 3, Epoch 110: Val Acc: 0.81%
2025-08-14 22:21:39,730 - INFO - Fold 3, Epoch 120: Val Acc: 0.62%
2025-08-14 22:21:41,850 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-14 22:21:43,969 - INFO - Fold 3, Epoch 140: Val Acc: 0.75%
2025-08-14 22:21:46,080 - INFO - Fold 3, Epoch 150: Val Acc: 0.78%
2025-08-14 22:21:48,199 - INFO - Fold 3, Epoch 160: Val Acc: 0.59%
2025-08-14 22:21:50,333 - INFO - Fold 3, Epoch 170: Val Acc: 0.78%
2025-08-14 22:21:51,383 - INFO - Early stopping at epoch 175
2025-08-14 22:21:52,455 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.854935089747111), 'std': np.float64(0.10125378161062808)}, 'train_accuracy': {'mean': np.float64(0.7916666666666666), 'std': np.float64(0.05577214723683687)}, 'val_loss': {'mean': np.float64(4.498048305511475), 'std': np.float64(0.27926233930350997)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(106.33333333333333), 'std': np.float64(26.96087700518826)}}
[I 2025-08-14 22:21:52,461] Trial 67 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0007368154500387393, 'batch_size': 32, 'num_epochs': 771, 'temperature': 0.08501158156011264, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.35910151830235615, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.6495615347017443}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 67 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0007368154500387393, 'batch_size': 32, 'num_epochs': 771, 'temperature': 0.08501158156011264, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.35910151830235615, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.6495615347017443}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:21:52,490 - INFO - Using device: cuda
2025-08-14 22:22:02,087 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:22:02,089 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:22:02,089 - INFO - Starting training for fold 1/3
2025-08-14 22:22:11,686 - INFO - Fold 1, Epoch 10: Val Acc: 0.41%
2025-08-14 22:22:13,681 - INFO - Fold 1, Epoch 20: Val Acc: 0.53%
2025-08-14 22:22:15,690 - INFO - Fold 1, Epoch 30: Val Acc: 0.53%
2025-08-14 22:22:17,454 - INFO - Fold 1, Epoch 40: Val Acc: 0.50%
2025-08-14 22:22:19,022 - INFO - Fold 1, Epoch 50: Val Acc: 0.69%
2025-08-14 22:22:20,923 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-14 22:22:22,955 - INFO - Fold 1, Epoch 70: Val Acc: 0.53%
2025-08-14 22:22:24,975 - INFO - Fold 1, Epoch 80: Val Acc: 0.44%
2025-08-14 22:22:27,010 - INFO - Fold 1, Epoch 90: Val Acc: 0.50%
2025-08-14 22:22:29,049 - INFO - Fold 1, Epoch 100: Val Acc: 0.47%
2025-08-14 22:22:30,260 - INFO - Early stopping at epoch 106
2025-08-14 22:22:33,387 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:22:33,390 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:22:33,391 - INFO - Starting training for fold 2/3
2025-08-14 22:22:36,853 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-14 22:22:38,953 - INFO - Fold 2, Epoch 20: Val Acc: 0.44%
2025-08-14 22:22:40,960 - INFO - Fold 2, Epoch 30: Val Acc: 0.38%
2025-08-14 22:22:43,081 - INFO - Fold 2, Epoch 40: Val Acc: 0.59%
2025-08-14 22:22:45,190 - INFO - Fold 2, Epoch 50: Val Acc: 0.53%
2025-08-14 22:22:47,306 - INFO - Fold 2, Epoch 60: Val Acc: 0.53%
2025-08-14 22:22:49,420 - INFO - Fold 2, Epoch 70: Val Acc: 0.47%
2025-08-14 22:22:51,519 - INFO - Fold 2, Epoch 80: Val Acc: 0.34%
2025-08-14 22:22:53,549 - INFO - Fold 2, Epoch 90: Val Acc: 0.53%
2025-08-14 22:22:56,781 - INFO - Fold 2, Epoch 100: Val Acc: 0.53%
2025-08-14 22:22:59,922 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-14 22:23:02,050 - INFO - Fold 2, Epoch 120: Val Acc: 0.56%
2025-08-14 22:23:04,084 - INFO - Fold 2, Epoch 130: Val Acc: 0.47%
2025-08-14 22:23:06,125 - INFO - Fold 2, Epoch 140: Val Acc: 0.34%
2025-08-14 22:23:08,160 - INFO - Fold 2, Epoch 150: Val Acc: 0.47%
2025-08-14 22:23:10,201 - INFO - Fold 2, Epoch 160: Val Acc: 0.62%
2025-08-14 22:23:12,235 - INFO - Fold 2, Epoch 170: Val Acc: 0.56%
2025-08-14 22:23:14,274 - INFO - Fold 2, Epoch 180: Val Acc: 0.50%
2025-08-14 22:23:16,319 - INFO - Fold 2, Epoch 190: Val Acc: 0.50%
2025-08-14 22:23:18,356 - INFO - Fold 2, Epoch 200: Val Acc: 0.44%
2025-08-14 22:23:21,592 - INFO - Fold 2, Epoch 210: Val Acc: 0.56%
2025-08-14 22:23:23,624 - INFO - Fold 2, Epoch 220: Val Acc: 0.66%
2025-08-14 22:23:25,648 - INFO - Fold 2, Epoch 230: Val Acc: 0.38%
2025-08-14 22:23:27,679 - INFO - Fold 2, Epoch 240: Val Acc: 0.47%
2025-08-14 22:23:29,714 - INFO - Fold 2, Epoch 250: Val Acc: 0.44%
2025-08-14 22:23:31,746 - INFO - Fold 2, Epoch 260: Val Acc: 0.56%
2025-08-14 22:23:33,773 - INFO - Fold 2, Epoch 270: Val Acc: 0.47%
2025-08-14 22:23:35,801 - INFO - Fold 2, Epoch 280: Val Acc: 0.53%
2025-08-14 22:23:37,844 - INFO - Fold 2, Epoch 290: Val Acc: 0.47%
2025-08-14 22:23:39,873 - INFO - Fold 2, Epoch 300: Val Acc: 0.47%
2025-08-14 22:23:41,500 - INFO - Early stopping at epoch 308
2025-08-14 22:23:44,054 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:23:44,057 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:23:44,057 - INFO - Starting training for fold 3/3
2025-08-14 22:23:50,925 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-14 22:23:53,055 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-14 22:23:55,101 - INFO - Fold 3, Epoch 30: Val Acc: 0.47%
2025-08-14 22:23:57,148 - INFO - Fold 3, Epoch 40: Val Acc: 0.47%
2025-08-14 22:23:59,172 - INFO - Fold 3, Epoch 50: Val Acc: 0.50%
2025-08-14 22:24:02,354 - INFO - Fold 3, Epoch 60: Val Acc: 0.47%
2025-08-14 22:24:04,459 - INFO - Fold 3, Epoch 70: Val Acc: 0.47%
2025-08-14 22:24:06,248 - INFO - Fold 3, Epoch 80: Val Acc: 0.41%
2025-08-14 22:24:07,942 - INFO - Fold 3, Epoch 90: Val Acc: 0.44%
2025-08-14 22:24:09,792 - INFO - Fold 3, Epoch 100: Val Acc: 0.62%
2025-08-14 22:24:11,646 - INFO - Fold 3, Epoch 110: Val Acc: 0.50%
2025-08-14 22:24:13,757 - INFO - Fold 3, Epoch 120: Val Acc: 0.53%
2025-08-14 22:24:15,870 - INFO - Fold 3, Epoch 130: Val Acc: 0.44%
2025-08-14 22:24:17,916 - INFO - Fold 3, Epoch 140: Val Acc: 0.47%
2025-08-14 22:24:19,958 - INFO - Fold 3, Epoch 150: Val Acc: 0.47%
2025-08-14 22:24:20,774 - INFO - Early stopping at epoch 154
2025-08-14 22:24:21,617 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.12899112701416), 'std': np.float64(0.007876044839332345)}, 'train_accuracy': {'mean': np.float64(0.5902777777777778), 'std': np.float64(0.02598373185259682)}, 'val_loss': {'mean': np.float64(4.137072245279948), 'std': np.float64(0.06279504432411154)}, 'val_accuracy': {'mean': np.float64(0.71875), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(88.33333333333333), 'std': np.float64(86.1677949635993)}}
[I 2025-08-14 22:24:21,623] Trial 68 finished with value: -0.71875 and parameters: {'learning_rate': 0.0005377179361968633, 'batch_size': 32, 'num_epochs': 826, 'temperature': 0.410304951613541, 'embedding_dim': 128, 'hidden_dim': 128, 'dropout': 0.42085075690066864, 'num_layers': 4, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.18413996793728596}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 68 finished with value: -0.71875 and parameters: {'learning_rate': 0.0005377179361968633, 'batch_size': 32, 'num_epochs': 826, 'temperature': 0.410304951613541, 'embedding_dim': 128, 'hidden_dim': 128, 'dropout': 0.42085075690066864, 'num_layers': 4, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.18413996793728596}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:24:21,655 - INFO - Using device: cuda
2025-08-14 22:24:31,468 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:24:31,470 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:24:31,470 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:24:38,777 - INFO - Fold 1, Epoch 10: Val Acc: 0.52%
2025-08-14 22:24:42,114 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-14 22:24:45,498 - INFO - Fold 1, Epoch 30: Val Acc: 0.52%
2025-08-14 22:24:48,866 - INFO - Fold 1, Epoch 40: Val Acc: 0.54%
2025-08-14 22:24:53,723 - INFO - Fold 1, Epoch 50: Val Acc: 0.58%
2025-08-14 22:24:57,073 - INFO - Fold 1, Epoch 60: Val Acc: 0.52%
2025-08-14 22:25:00,432 - INFO - Fold 1, Epoch 70: Val Acc: 0.52%
2025-08-14 22:25:03,944 - INFO - Fold 1, Epoch 80: Val Acc: 0.56%
2025-08-14 22:25:07,419 - INFO - Fold 1, Epoch 90: Val Acc: 0.58%
2025-08-14 22:25:10,894 - INFO - Fold 1, Epoch 100: Val Acc: 0.52%
2025-08-14 22:25:14,428 - INFO - Fold 1, Epoch 110: Val Acc: 0.48%
2025-08-14 22:25:17,928 - INFO - Fold 1, Epoch 120: Val Acc: 0.56%
2025-08-14 22:25:21,416 - INFO - Fold 1, Epoch 130: Val Acc: 0.52%
2025-08-14 22:25:26,866 - INFO - Fold 1, Epoch 140: Val Acc: 0.52%
2025-08-14 22:25:30,303 - INFO - Fold 1, Epoch 150: Val Acc: 0.54%
2025-08-14 22:25:33,841 - INFO - Fold 1, Epoch 160: Val Acc: 0.60%
2025-08-14 22:25:37,316 - INFO - Fold 1, Epoch 170: Val Acc: 0.62%
2025-08-14 22:25:42,228 - INFO - Fold 1, Epoch 180: Val Acc: 0.62%
2025-08-14 22:25:45,261 - INFO - Fold 1, Epoch 190: Val Acc: 0.54%
2025-08-14 22:25:48,623 - INFO - Fold 1, Epoch 200: Val Acc: 0.50%
2025-08-14 22:25:51,976 - INFO - Fold 1, Epoch 210: Val Acc: 0.52%
2025-08-14 22:25:55,357 - INFO - Fold 1, Epoch 220: Val Acc: 0.52%
2025-08-14 22:25:58,739 - INFO - Fold 1, Epoch 230: Val Acc: 0.62%
2025-08-14 22:26:02,118 - INFO - Fold 1, Epoch 240: Val Acc: 0.58%
2025-08-14 22:26:05,499 - INFO - Fold 1, Epoch 250: Val Acc: 0.52%
2025-08-14 22:26:08,869 - INFO - Fold 1, Epoch 260: Val Acc: 0.54%
2025-08-14 22:26:12,246 - INFO - Fold 1, Epoch 270: Val Acc: 0.62%
2025-08-14 22:26:13,934 - INFO - Early stopping at epoch 275
2025-08-14 22:26:16,974 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:26:16,977 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:26:16,977 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:26:21,650 - INFO - Fold 2, Epoch 10: Val Acc: 0.44%
2025-08-14 22:26:26,182 - INFO - Fold 2, Epoch 20: Val Acc: 0.52%
2025-08-14 22:26:28,676 - INFO - Fold 2, Epoch 30: Val Acc: 0.54%
2025-08-14 22:26:33,194 - INFO - Fold 2, Epoch 40: Val Acc: 0.52%
2025-08-14 22:26:37,536 - INFO - Fold 2, Epoch 50: Val Acc: 0.56%
2025-08-14 22:26:41,459 - INFO - Fold 2, Epoch 60: Val Acc: 0.58%
2025-08-14 22:26:44,810 - INFO - Fold 2, Epoch 70: Val Acc: 0.48%
2025-08-14 22:26:47,684 - INFO - Fold 2, Epoch 80: Val Acc: 0.54%
2025-08-14 22:26:50,104 - INFO - Fold 2, Epoch 90: Val Acc: 0.52%
2025-08-14 22:26:53,173 - INFO - Fold 2, Epoch 100: Val Acc: 0.50%
2025-08-14 22:26:56,538 - INFO - Fold 2, Epoch 110: Val Acc: 0.58%
2025-08-14 22:26:59,887 - INFO - Fold 2, Epoch 120: Val Acc: 0.52%
2025-08-14 22:27:03,245 - INFO - Fold 2, Epoch 130: Val Acc: 0.62%
2025-08-14 22:27:06,091 - INFO - Fold 2, Epoch 140: Val Acc: 0.67%
2025-08-14 22:27:09,451 - INFO - Fold 2, Epoch 150: Val Acc: 0.50%
2025-08-14 22:27:11,813 - INFO - Early stopping at epoch 157
2025-08-14 22:27:12,673 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:27:12,675 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:27:12,676 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:27:20,972 - INFO - Fold 3, Epoch 10: Val Acc: 0.52%
2025-08-14 22:27:24,347 - INFO - Fold 3, Epoch 20: Val Acc: 0.46%
2025-08-14 22:27:27,723 - INFO - Fold 3, Epoch 30: Val Acc: 0.54%
2025-08-14 22:27:31,089 - INFO - Fold 3, Epoch 40: Val Acc: 0.50%
2025-08-14 22:27:34,452 - INFO - Fold 3, Epoch 50: Val Acc: 0.50%
2025-08-14 22:27:37,836 - INFO - Fold 3, Epoch 60: Val Acc: 0.50%
2025-08-14 22:27:41,189 - INFO - Fold 3, Epoch 70: Val Acc: 0.50%
2025-08-14 22:27:44,527 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-14 22:27:48,445 - INFO - Fold 3, Epoch 90: Val Acc: 0.62%
2025-08-14 22:27:51,055 - INFO - Fold 3, Epoch 100: Val Acc: 0.50%
2025-08-14 22:27:55,122 - INFO - Fold 3, Epoch 110: Val Acc: 0.56%
2025-08-14 22:27:58,496 - INFO - Fold 3, Epoch 120: Val Acc: 0.56%
2025-08-14 22:28:03,103 - INFO - Fold 3, Epoch 130: Val Acc: 0.52%
2025-08-14 22:28:06,453 - INFO - Fold 3, Epoch 140: Val Acc: 0.54%
2025-08-14 22:28:09,825 - INFO - Fold 3, Epoch 150: Val Acc: 0.48%
2025-08-14 22:28:13,207 - INFO - Fold 3, Epoch 160: Val Acc: 0.50%
2025-08-14 22:28:16,599 - INFO - Fold 3, Epoch 170: Val Acc: 0.52%
2025-08-14 22:28:19,973 - INFO - Fold 3, Epoch 180: Val Acc: 0.48%
2025-08-14 22:28:23,320 - INFO - Fold 3, Epoch 190: Val Acc: 0.62%
2025-08-14 22:28:25,761 - INFO - Fold 3, Epoch 200: Val Acc: 0.56%
2025-08-14 22:28:28,206 - INFO - Fold 3, Epoch 210: Val Acc: 0.62%
2025-08-14 22:28:30,648 - INFO - Fold 3, Epoch 220: Val Acc: 0.65%
2025-08-14 22:28:31,623 - INFO - Early stopping at epoch 224
2025-08-14 22:28:34,133 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.3163332409328885), 'std': np.float64(0.10329827553300489)}, 'train_accuracy': {'mean': np.float64(0.6840277777777778), 'std': np.float64(0.021404215288086736)}, 'val_loss': {'mean': np.float64(3.8182916111416287), 'std': np.float64(0.08847395056009892)}, 'val_accuracy': {'mean': np.float64(0.75), 'std': np.float64(0.0450051437389435)}, 'epoch': {'mean': np.float64(117.66666666666667), 'std': np.float64(48.32068800098865)}}
[I 2025-08-14 22:28:34,143] Trial 69 finished with value: -0.75 and parameters: {'learning_rate': 0.0004187617290208881, 'batch_size': 16, 'num_epochs': 619, 'temperature': 0.10486913462926657, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.20239318739302165, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.17891066962097202, 'crop_size': 0.5564794133755552}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 69 finished with value: -0.75 and parameters: {'learning_rate': 0.0004187617290208881, 'batch_size': 16, 'num_epochs': 619, 'temperature': 0.10486913462926657, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.20239318739302165, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.17891066962097202, 'crop_size': 0.5564794133755552}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:28:34,221 - INFO - Using device: cuda
2025-08-14 22:28:43,914 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:28:43,916 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:28:43,916 - WARNING - Fold 1 has insufficient pairs to form a batch. Skipping.
2025-08-14 22:28:43,916 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:28:43,917 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:28:43,917 - WARNING - Fold 2 has insufficient pairs to form a batch. Skipping.
2025-08-14 22:28:43,918 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:28:43,919 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:28:43,919 - WARNING - Fold 3 has insufficient pairs to form a batch. Skipping.
2025-08-14 22:28:43,919 - WARNING - No folds completed successfully to aggregate metrics.
[I 2025-08-14 22:28:43,921] Trial 70 finished with value: inf and parameters: {'learning_rate': 0.0006131079733928903, 'batch_size': 64, 'num_epochs': 940, 'temperature': 0.12860560801831478, 'embedding_dim': 128, 'hidden_dim': 512, 'dropout': 0.4884001950242516, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19310985069665842, 'crop_size': 0.5809832213691353}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 70 finished with value: inf and parameters: {'learning_rate': 0.0006131079733928903, 'batch_size': 64, 'num_epochs': 940, 'temperature': 0.12860560801831478, 'embedding_dim': 128, 'hidden_dim': 512, 'dropout': 0.4884001950242516, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19310985069665842, 'crop_size': 0.5809832213691353}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:28:43,953 - INFO - Using device: cuda
2025-08-14 22:28:53,864 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:28:53,867 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:28:53,867 - INFO - Starting training for fold 1/3
2025-08-14 22:29:02,782 - INFO - Fold 1, Epoch 10: Val Acc: 0.72%
2025-08-14 22:29:07,204 - INFO - Fold 1, Epoch 20: Val Acc: 0.75%
2025-08-14 22:29:09,510 - INFO - Fold 1, Epoch 30: Val Acc: 0.69%
2025-08-14 22:29:13,850 - INFO - Fold 1, Epoch 40: Val Acc: 0.62%
2025-08-14 22:29:20,441 - INFO - Fold 1, Epoch 50: Val Acc: 0.84%
2025-08-14 22:29:22,743 - INFO - Fold 1, Epoch 60: Val Acc: 0.84%
2025-08-14 22:29:24,965 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-14 22:29:29,391 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-14 22:29:31,610 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-14 22:29:33,892 - INFO - Fold 1, Epoch 100: Val Acc: 0.91%
2025-08-14 22:29:36,185 - INFO - Fold 1, Epoch 110: Val Acc: 0.75%
2025-08-14 22:29:38,501 - INFO - Fold 1, Epoch 120: Val Acc: 0.66%
2025-08-14 22:29:40,817 - INFO - Fold 1, Epoch 130: Val Acc: 0.72%
2025-08-14 22:29:43,108 - INFO - Fold 1, Epoch 140: Val Acc: 0.75%
2025-08-14 22:29:45,338 - INFO - Fold 1, Epoch 150: Val Acc: 0.72%
2025-08-14 22:29:47,137 - INFO - Fold 1, Epoch 160: Val Acc: 0.72%
2025-08-14 22:29:48,846 - INFO - Fold 1, Epoch 170: Val Acc: 0.81%
2025-08-14 22:29:50,216 - INFO - Early stopping at epoch 178
2025-08-14 22:29:53,941 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:29:53,944 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:29:53,945 - INFO - Starting training for fold 2/3
2025-08-14 22:29:57,866 - INFO - Fold 2, Epoch 10: Val Acc: 0.53%
2025-08-14 22:30:04,403 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-14 22:30:08,568 - INFO - Fold 2, Epoch 30: Val Acc: 0.75%
2025-08-14 22:30:10,951 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-14 22:30:16,377 - INFO - Fold 2, Epoch 50: Val Acc: 0.72%
2025-08-14 22:30:21,570 - INFO - Fold 2, Epoch 60: Val Acc: 0.81%
2025-08-14 22:30:23,802 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-14 22:30:26,028 - INFO - Fold 2, Epoch 80: Val Acc: 0.78%
2025-08-14 22:30:28,266 - INFO - Fold 2, Epoch 90: Val Acc: 0.75%
2025-08-14 22:30:30,581 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-14 22:30:32,902 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-14 22:30:35,221 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-14 22:30:37,544 - INFO - Fold 2, Epoch 130: Val Acc: 0.81%
2025-08-14 22:30:39,863 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-14 22:30:42,109 - INFO - Fold 2, Epoch 150: Val Acc: 0.81%
2025-08-14 22:30:42,549 - INFO - Early stopping at epoch 152
2025-08-14 22:30:45,652 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:30:45,655 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:30:45,656 - INFO - Starting training for fold 3/3
2025-08-14 22:30:52,411 - INFO - Fold 3, Epoch 10: Val Acc: 0.72%
2025-08-14 22:30:56,139 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-14 22:30:58,367 - INFO - Fold 3, Epoch 30: Val Acc: 0.69%
2025-08-14 22:31:00,591 - INFO - Fold 3, Epoch 40: Val Acc: 0.72%
2025-08-14 22:31:02,814 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-14 22:31:05,041 - INFO - Fold 3, Epoch 60: Val Acc: 0.78%
2025-08-14 22:31:08,814 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-14 22:31:12,552 - INFO - Fold 3, Epoch 80: Val Acc: 0.88%
2025-08-14 22:31:14,854 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-14 22:31:17,168 - INFO - Fold 3, Epoch 100: Val Acc: 0.62%
2025-08-14 22:31:19,488 - INFO - Fold 3, Epoch 110: Val Acc: 0.72%
2025-08-14 22:31:21,777 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-14 22:31:23,883 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-14 22:31:25,926 - INFO - Fold 3, Epoch 140: Val Acc: 0.66%
2025-08-14 22:31:28,247 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-14 22:31:30,559 - INFO - Fold 3, Epoch 160: Val Acc: 0.75%
2025-08-14 22:31:32,798 - INFO - Fold 3, Epoch 170: Val Acc: 0.66%
2025-08-14 22:31:33,239 - INFO - Early stopping at epoch 172
2025-08-14 22:31:34,357 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.0169728597005205), 'std': np.float64(0.04210995510121482)}, 'train_accuracy': {'mean': np.float64(0.7465277777777778), 'std': np.float64(0.017704928866641653)}, 'val_loss': {'mean': np.float64(4.208071231842041), 'std': np.float64(0.009341417769835254)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(66.33333333333333), 'std': np.float64(11.115554667022044)}}
[I 2025-08-14 22:31:34,364] Trial 71 finished with value: -0.90625 and parameters: {'learning_rate': 0.00047971967069391163, 'batch_size': 32, 'num_epochs': 916, 'temperature': 0.42810627626189174, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.466312629227044, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18376841027077226, 'crop_size': 0.5466487892939503}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 71 finished with value: -0.90625 and parameters: {'learning_rate': 0.00047971967069391163, 'batch_size': 32, 'num_epochs': 916, 'temperature': 0.42810627626189174, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.466312629227044, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18376841027077226, 'crop_size': 0.5466487892939503}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:31:34,404 - INFO - Using device: cuda
2025-08-14 22:31:44,612 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:31:44,623 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:31:44,624 - INFO - Starting training for fold 1/3
2025-08-14 22:31:52,957 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-14 22:31:54,931 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-14 22:32:02,536 - INFO - Fold 1, Epoch 30: Val Acc: 0.81%
2025-08-14 22:32:04,985 - INFO - Fold 1, Epoch 40: Val Acc: 0.62%
2025-08-14 22:32:07,426 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-14 22:32:12,860 - INFO - Fold 1, Epoch 60: Val Acc: 0.56%
2025-08-14 22:32:17,991 - INFO - Fold 1, Epoch 70: Val Acc: 0.62%
2025-08-14 22:32:20,459 - INFO - Fold 1, Epoch 80: Val Acc: 0.69%
2025-08-14 22:32:22,906 - INFO - Fold 1, Epoch 90: Val Acc: 0.78%
2025-08-14 22:32:25,428 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-14 22:32:27,926 - INFO - Fold 1, Epoch 110: Val Acc: 0.59%
2025-08-14 22:32:30,177 - INFO - Fold 1, Epoch 120: Val Acc: 0.62%
2025-08-14 22:32:32,245 - INFO - Fold 1, Epoch 130: Val Acc: 0.56%
2025-08-14 22:32:34,406 - INFO - Fold 1, Epoch 140: Val Acc: 0.72%
2025-08-14 22:32:36,694 - INFO - Fold 1, Epoch 150: Val Acc: 0.62%
2025-08-14 22:32:39,151 - INFO - Fold 1, Epoch 160: Val Acc: 0.78%
2025-08-14 22:32:39,394 - INFO - Early stopping at epoch 161
2025-08-14 22:32:42,969 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:32:42,979 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:32:42,981 - INFO - Starting training for fold 2/3
2025-08-14 22:32:49,310 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-14 22:32:53,674 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-14 22:32:57,840 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-14 22:33:02,208 - INFO - Fold 2, Epoch 40: Val Acc: 0.66%
2025-08-14 22:33:04,826 - INFO - Fold 2, Epoch 50: Val Acc: 0.72%
2025-08-14 22:33:07,434 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-14 22:33:09,678 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-14 22:33:11,852 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-14 22:33:14,210 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-14 22:33:16,763 - INFO - Fold 2, Epoch 100: Val Acc: 0.81%
2025-08-14 22:33:21,031 - INFO - Fold 2, Epoch 110: Val Acc: 0.66%
2025-08-14 22:33:23,575 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-14 22:33:26,135 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-14 22:33:28,696 - INFO - Fold 2, Epoch 140: Val Acc: 0.88%
2025-08-14 22:33:31,249 - INFO - Fold 2, Epoch 150: Val Acc: 0.78%
2025-08-14 22:33:33,802 - INFO - Fold 2, Epoch 160: Val Acc: 0.84%
2025-08-14 22:33:36,229 - INFO - Fold 2, Epoch 170: Val Acc: 0.91%
2025-08-14 22:33:38,761 - INFO - Fold 2, Epoch 180: Val Acc: 0.75%
2025-08-14 22:33:41,326 - INFO - Fold 2, Epoch 190: Val Acc: 0.84%
2025-08-14 22:33:43,886 - INFO - Fold 2, Epoch 200: Val Acc: 0.81%
2025-08-14 22:33:46,189 - INFO - Early stopping at epoch 209
2025-08-14 22:33:49,704 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:33:49,707 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:33:49,707 - INFO - Starting training for fold 3/3
2025-08-14 22:33:55,708 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-14 22:34:00,681 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-14 22:34:03,158 - INFO - Fold 3, Epoch 30: Val Acc: 0.59%
2025-08-14 22:34:07,323 - INFO - Fold 3, Epoch 40: Val Acc: 0.59%
2025-08-14 22:34:11,504 - INFO - Fold 3, Epoch 50: Val Acc: 0.53%
2025-08-14 22:34:14,059 - INFO - Fold 3, Epoch 60: Val Acc: 0.72%
2025-08-14 22:34:16,455 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-14 22:34:18,994 - INFO - Fold 3, Epoch 80: Val Acc: 0.66%
2025-08-14 22:34:23,163 - INFO - Fold 3, Epoch 90: Val Acc: 0.59%
2025-08-14 22:34:25,707 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-14 22:34:28,265 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-14 22:34:30,823 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-14 22:34:33,380 - INFO - Fold 3, Epoch 130: Val Acc: 0.56%
2025-08-14 22:34:37,438 - INFO - Fold 3, Epoch 140: Val Acc: 0.78%
2025-08-14 22:34:39,873 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-14 22:34:42,341 - INFO - Fold 3, Epoch 160: Val Acc: 0.62%
2025-08-14 22:34:44,806 - INFO - Fold 3, Epoch 170: Val Acc: 0.78%
2025-08-14 22:34:47,258 - INFO - Fold 3, Epoch 180: Val Acc: 0.66%
2025-08-14 22:34:49,701 - INFO - Fold 3, Epoch 190: Val Acc: 0.75%
2025-08-14 22:34:52,146 - INFO - Fold 3, Epoch 200: Val Acc: 0.72%
2025-08-14 22:34:54,596 - INFO - Fold 3, Epoch 210: Val Acc: 0.84%
2025-08-14 22:34:57,063 - INFO - Fold 3, Epoch 220: Val Acc: 0.75%
2025-08-14 22:34:59,532 - INFO - Fold 3, Epoch 230: Val Acc: 0.75%
2025-08-14 22:35:00,271 - INFO - Early stopping at epoch 233
2025-08-14 22:35:01,547 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.970381736755371), 'std': np.float64(0.06549134864517775)}, 'train_accuracy': {'mean': np.float64(0.75), 'std': np.float64(0.008505172717997162)}, 'val_loss': {'mean': np.float64(4.2007724444071455), 'std': np.float64(0.0567927013009145)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(100.0), 'std': np.float64(29.93325909419153)}}
[I 2025-08-14 22:35:01,558] Trial 72 finished with value: -0.90625 and parameters: {'learning_rate': 0.000527213952644417, 'batch_size': 32, 'num_epochs': 977, 'temperature': 0.37043744131178785, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.47253850387048935, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18523717700488662, 'crop_size': 0.5390189706242334}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 72 finished with value: -0.90625 and parameters: {'learning_rate': 0.000527213952644417, 'batch_size': 32, 'num_epochs': 977, 'temperature': 0.37043744131178785, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.47253850387048935, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18523717700488662, 'crop_size': 0.5390189706242334}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:35:01,591 - INFO - Using device: cuda
2025-08-14 22:35:11,688 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:35:11,689 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:35:11,690 - INFO - Starting training for fold 1/3
2025-08-14 22:35:20,949 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-14 22:35:27,530 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-14 22:35:31,848 - INFO - Fold 1, Epoch 30: Val Acc: 0.69%
2025-08-14 22:35:36,301 - INFO - Fold 1, Epoch 40: Val Acc: 0.75%
2025-08-14 22:35:38,102 - INFO - Fold 1, Epoch 50: Val Acc: 0.72%
2025-08-14 22:35:42,279 - INFO - Fold 1, Epoch 60: Val Acc: 0.81%
2025-08-14 22:35:44,503 - INFO - Fold 1, Epoch 70: Val Acc: 0.75%
2025-08-14 22:35:48,875 - INFO - Fold 1, Epoch 80: Val Acc: 0.75%
2025-08-14 22:35:51,099 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-14 22:35:53,352 - INFO - Fold 1, Epoch 100: Val Acc: 0.81%
2025-08-14 22:35:55,669 - INFO - Fold 1, Epoch 110: Val Acc: 0.78%
2025-08-14 22:35:57,978 - INFO - Fold 1, Epoch 120: Val Acc: 0.78%
2025-08-14 22:36:00,278 - INFO - Fold 1, Epoch 130: Val Acc: 0.75%
2025-08-14 22:36:02,497 - INFO - Fold 1, Epoch 140: Val Acc: 0.62%
2025-08-14 22:36:04,713 - INFO - Fold 1, Epoch 150: Val Acc: 0.69%
2025-08-14 22:36:07,019 - INFO - Fold 1, Epoch 160: Val Acc: 0.69%
2025-08-14 22:36:08,990 - INFO - Fold 1, Epoch 170: Val Acc: 0.75%
2025-08-14 22:36:10,526 - INFO - Early stopping at epoch 179
2025-08-14 22:36:14,138 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:36:14,141 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:36:14,141 - INFO - Starting training for fold 2/3
2025-08-14 22:36:22,111 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-14 22:36:25,890 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-14 22:36:30,816 - INFO - Fold 2, Epoch 30: Val Acc: 0.62%
2025-08-14 22:36:35,900 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-14 22:36:39,569 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-14 22:36:41,794 - INFO - Fold 2, Epoch 60: Val Acc: 0.84%
2025-08-14 22:36:44,028 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-14 22:36:46,253 - INFO - Fold 2, Epoch 80: Val Acc: 0.81%
2025-08-14 22:36:49,913 - INFO - Fold 2, Epoch 90: Val Acc: 0.66%
2025-08-14 22:36:52,143 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-14 22:36:54,374 - INFO - Fold 2, Epoch 110: Val Acc: 0.78%
2025-08-14 22:36:56,295 - INFO - Fold 2, Epoch 120: Val Acc: 0.59%
2025-08-14 22:36:58,535 - INFO - Fold 2, Epoch 130: Val Acc: 0.84%
2025-08-14 22:37:00,767 - INFO - Fold 2, Epoch 140: Val Acc: 0.66%
2025-08-14 22:37:02,998 - INFO - Fold 2, Epoch 150: Val Acc: 0.72%
2025-08-14 22:37:04,830 - INFO - Fold 2, Epoch 160: Val Acc: 0.88%
2025-08-14 22:37:07,036 - INFO - Fold 2, Epoch 170: Val Acc: 0.59%
2025-08-14 22:37:09,271 - INFO - Fold 2, Epoch 180: Val Acc: 0.59%
2025-08-14 22:37:11,072 - INFO - Early stopping at epoch 188
2025-08-14 22:37:14,276 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:37:14,279 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:37:14,280 - INFO - Starting training for fold 3/3
2025-08-14 22:37:22,537 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-14 22:37:26,146 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-14 22:37:31,277 - INFO - Fold 3, Epoch 30: Val Acc: 0.72%
2025-08-14 22:37:33,553 - INFO - Fold 3, Epoch 40: Val Acc: 0.78%
2025-08-14 22:37:35,679 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-14 22:37:37,391 - INFO - Fold 3, Epoch 60: Val Acc: 0.72%
2025-08-14 22:37:40,881 - INFO - Fold 3, Epoch 70: Val Acc: 0.81%
2025-08-14 22:37:44,616 - INFO - Fold 3, Epoch 80: Val Acc: 0.66%
2025-08-14 22:37:46,858 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-14 22:37:49,080 - INFO - Fold 3, Epoch 100: Val Acc: 0.78%
2025-08-14 22:37:51,298 - INFO - Fold 3, Epoch 110: Val Acc: 0.84%
2025-08-14 22:37:53,524 - INFO - Fold 3, Epoch 120: Val Acc: 0.84%
2025-08-14 22:37:55,750 - INFO - Fold 3, Epoch 130: Val Acc: 0.78%
2025-08-14 22:37:57,975 - INFO - Fold 3, Epoch 140: Val Acc: 0.69%
2025-08-14 22:38:00,155 - INFO - Fold 3, Epoch 150: Val Acc: 0.78%
2025-08-14 22:38:01,886 - INFO - Fold 3, Epoch 160: Val Acc: 0.72%
2025-08-14 22:38:04,108 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-14 22:38:05,893 - INFO - Early stopping at epoch 178
2025-08-14 22:38:06,928 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9754988617367215), 'std': np.float64(0.01960676927474452)}, 'train_accuracy': {'mean': np.float64(0.8090277777777777), 'std': np.float64(0.025983731852596822)}, 'val_loss': {'mean': np.float64(4.210616270701091), 'std': np.float64(0.027490018237762506)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(80.66666666666667), 'std': np.float64(4.496912521077347)}}
[I 2025-08-14 22:38:06,935] Trial 73 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0008339016354833911, 'batch_size': 32, 'num_epochs': 856, 'temperature': 0.48564791752947584, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.45654018888889236, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.16995727157261312, 'crop_size': 0.5100129491584046}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 73 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0008339016354833911, 'batch_size': 32, 'num_epochs': 856, 'temperature': 0.48564791752947584, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.45654018888889236, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.16995727157261312, 'crop_size': 0.5100129491584046}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:38:06,969 - INFO - Using device: cuda
2025-08-14 22:38:16,701 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:38:16,703 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:38:16,703 - INFO - Starting training for fold 1/3
2025-08-14 22:38:28,916 - INFO - Fold 1, Epoch 10: Val Acc: 0.44%
2025-08-14 22:38:33,263 - INFO - Fold 1, Epoch 20: Val Acc: 0.53%
2025-08-14 22:38:35,490 - INFO - Fold 1, Epoch 30: Val Acc: 0.56%
2025-08-14 22:38:40,080 - INFO - Fold 1, Epoch 40: Val Acc: 0.38%
2025-08-14 22:38:42,325 - INFO - Fold 1, Epoch 50: Val Acc: 0.53%
2025-08-14 22:38:44,574 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-14 22:38:46,807 - INFO - Fold 1, Epoch 70: Val Acc: 0.59%
2025-08-14 22:38:49,047 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-14 22:38:51,275 - INFO - Fold 1, Epoch 90: Val Acc: 0.59%
2025-08-14 22:38:53,499 - INFO - Fold 1, Epoch 100: Val Acc: 0.50%
2025-08-14 22:38:55,725 - INFO - Fold 1, Epoch 110: Val Acc: 0.59%
2025-08-14 22:38:57,971 - INFO - Fold 1, Epoch 120: Val Acc: 0.66%
2025-08-14 22:39:00,198 - INFO - Fold 1, Epoch 130: Val Acc: 0.78%
2025-08-14 22:39:00,649 - INFO - Early stopping at epoch 132
2025-08-14 22:39:04,162 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:39:04,165 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:39:04,166 - INFO - Starting training for fold 2/3
2025-08-14 22:39:10,770 - INFO - Fold 2, Epoch 10: Val Acc: 0.53%
2025-08-14 22:39:12,994 - INFO - Fold 2, Epoch 20: Val Acc: 0.62%
2025-08-14 22:39:15,218 - INFO - Fold 2, Epoch 30: Val Acc: 0.41%
2025-08-14 22:39:17,452 - INFO - Fold 2, Epoch 40: Val Acc: 0.56%
2025-08-14 22:39:19,664 - INFO - Fold 2, Epoch 50: Val Acc: 0.44%
2025-08-14 22:39:21,901 - INFO - Fold 2, Epoch 60: Val Acc: 0.69%
2025-08-14 22:39:24,129 - INFO - Fold 2, Epoch 70: Val Acc: 0.59%
2025-08-14 22:39:27,739 - INFO - Fold 2, Epoch 80: Val Acc: 0.53%
2025-08-14 22:39:29,975 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-14 22:39:32,208 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-14 22:39:34,443 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-14 22:39:37,955 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-14 22:39:40,036 - INFO - Fold 2, Epoch 130: Val Acc: 0.62%
2025-08-14 22:39:42,260 - INFO - Fold 2, Epoch 140: Val Acc: 0.69%
2025-08-14 22:39:45,882 - INFO - Fold 2, Epoch 150: Val Acc: 0.69%
2025-08-14 22:39:48,112 - INFO - Fold 2, Epoch 160: Val Acc: 0.59%
2025-08-14 22:39:50,345 - INFO - Fold 2, Epoch 170: Val Acc: 0.75%
2025-08-14 22:39:52,570 - INFO - Fold 2, Epoch 180: Val Acc: 0.75%
2025-08-14 22:39:54,806 - INFO - Fold 2, Epoch 190: Val Acc: 0.72%
2025-08-14 22:39:57,037 - INFO - Fold 2, Epoch 200: Val Acc: 0.69%
2025-08-14 22:39:59,256 - INFO - Fold 2, Epoch 210: Val Acc: 0.62%
2025-08-14 22:40:01,131 - INFO - Fold 2, Epoch 220: Val Acc: 0.66%
2025-08-14 22:40:04,679 - INFO - Fold 2, Epoch 230: Val Acc: 0.91%
2025-08-14 22:40:07,022 - INFO - Fold 2, Epoch 240: Val Acc: 0.72%
2025-08-14 22:40:09,254 - INFO - Fold 2, Epoch 250: Val Acc: 0.72%
2025-08-14 22:40:11,483 - INFO - Fold 2, Epoch 260: Val Acc: 0.78%
2025-08-14 22:40:13,711 - INFO - Fold 2, Epoch 270: Val Acc: 0.81%
2025-08-14 22:40:15,953 - INFO - Fold 2, Epoch 280: Val Acc: 0.81%
2025-08-14 22:40:18,190 - INFO - Fold 2, Epoch 290: Val Acc: 0.59%
2025-08-14 22:40:20,437 - INFO - Fold 2, Epoch 300: Val Acc: 0.53%
2025-08-14 22:40:22,677 - INFO - Fold 2, Epoch 310: Val Acc: 0.72%
2025-08-14 22:40:24,922 - INFO - Fold 2, Epoch 320: Val Acc: 0.88%
2025-08-14 22:40:27,164 - INFO - Early stopping at epoch 330
2025-08-14 22:40:30,079 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:40:30,081 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:40:30,082 - INFO - Starting training for fold 3/3
2025-08-14 22:40:34,885 - INFO - Fold 3, Epoch 10: Val Acc: 0.41%
2025-08-14 22:40:38,653 - INFO - Fold 3, Epoch 20: Val Acc: 0.47%
2025-08-14 22:40:42,314 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-14 22:40:45,992 - INFO - Fold 3, Epoch 40: Val Acc: 0.62%
2025-08-14 22:40:48,318 - INFO - Fold 3, Epoch 50: Val Acc: 0.47%
2025-08-14 22:40:50,557 - INFO - Fold 3, Epoch 60: Val Acc: 0.62%
2025-08-14 22:40:55,771 - INFO - Fold 3, Epoch 70: Val Acc: 0.59%
2025-08-14 22:40:57,997 - INFO - Fold 3, Epoch 80: Val Acc: 0.66%
2025-08-14 22:41:00,216 - INFO - Fold 3, Epoch 90: Val Acc: 0.66%
2025-08-14 22:41:02,430 - INFO - Fold 3, Epoch 100: Val Acc: 0.62%
2025-08-14 22:41:04,634 - INFO - Fold 3, Epoch 110: Val Acc: 0.59%
2025-08-14 22:41:06,866 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-14 22:41:09,062 - INFO - Fold 3, Epoch 130: Val Acc: 0.66%
2025-08-14 22:41:11,360 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-14 22:41:15,083 - INFO - Fold 3, Epoch 150: Val Acc: 0.84%
2025-08-14 22:41:17,462 - INFO - Fold 3, Epoch 160: Val Acc: 0.59%
2025-08-14 22:41:19,789 - INFO - Fold 3, Epoch 170: Val Acc: 0.62%
2025-08-14 22:41:22,093 - INFO - Fold 3, Epoch 180: Val Acc: 0.81%
2025-08-14 22:41:24,359 - INFO - Fold 3, Epoch 190: Val Acc: 0.75%
2025-08-14 22:41:26,603 - INFO - Fold 3, Epoch 200: Val Acc: 0.69%
2025-08-14 22:41:28,841 - INFO - Fold 3, Epoch 210: Val Acc: 0.59%
2025-08-14 22:41:30,739 - INFO - Fold 3, Epoch 220: Val Acc: 0.72%
2025-08-14 22:41:34,359 - INFO - Fold 3, Epoch 230: Val Acc: 0.75%
2025-08-14 22:41:36,594 - INFO - Fold 3, Epoch 240: Val Acc: 0.81%
2025-08-14 22:41:38,776 - INFO - Fold 3, Epoch 250: Val Acc: 0.72%
2025-08-14 22:41:41,017 - INFO - Fold 3, Epoch 260: Val Acc: 0.69%
2025-08-14 22:41:42,721 - INFO - Fold 3, Epoch 270: Val Acc: 0.81%
2025-08-14 22:41:44,779 - INFO - Fold 3, Epoch 280: Val Acc: 0.75%
2025-08-14 22:41:46,975 - INFO - Fold 3, Epoch 290: Val Acc: 0.72%
2025-08-14 22:41:48,937 - INFO - Fold 3, Epoch 300: Val Acc: 0.81%
2025-08-14 22:41:51,092 - INFO - Fold 3, Epoch 310: Val Acc: 0.72%
2025-08-14 22:41:53,320 - INFO - Fold 3, Epoch 320: Val Acc: 0.69%
2025-08-14 22:41:53,542 - INFO - Early stopping at epoch 321
2025-08-14 22:41:54,614 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.054616424772475), 'std': np.float64(0.05778840771226603)}, 'train_accuracy': {'mean': np.float64(0.6979166666666666), 'std': np.float64(0.0517349459227477)}, 'val_loss': {'mean': np.float64(4.157290140787761), 'std': np.float64(0.055400485621669326)}, 'val_accuracy': {'mean': np.float64(0.8645833333333334), 'std': np.float64(0.05892556509887896)}, 'epoch': {'mean': np.float64(160.0), 'std': np.float64(91.29074432821763)}}
[I 2025-08-14 22:41:54,620] Trial 74 finished with value: -0.8645833333333334 and parameters: {'learning_rate': 0.00011952366665055053, 'batch_size': 32, 'num_epochs': 904, 'temperature': 0.4596968892673704, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.43816454214243966, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19095005874710871, 'crop_size': 0.5003663084414757}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 74 finished with value: -0.8645833333333334 and parameters: {'learning_rate': 0.00011952366665055053, 'batch_size': 32, 'num_epochs': 904, 'temperature': 0.4596968892673704, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.43816454214243966, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19095005874710871, 'crop_size': 0.5003663084414757}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:41:54,653 - INFO - Using device: cuda
2025-08-14 22:42:04,630 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:42:04,632 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:42:04,632 - INFO - Starting training for fold 1/3
2025-08-14 22:42:15,559 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-14 22:42:19,618 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-14 22:42:23,905 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-14 22:42:25,888 - INFO - Fold 1, Epoch 40: Val Acc: 0.75%
2025-08-14 22:42:30,450 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-14 22:42:32,693 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-14 22:42:34,929 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-14 22:42:39,268 - INFO - Fold 1, Epoch 80: Val Acc: 0.59%
2025-08-14 22:42:41,513 - INFO - Fold 1, Epoch 90: Val Acc: 0.78%
2025-08-14 22:42:43,320 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-14 22:42:45,498 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-14 22:42:47,622 - INFO - Fold 1, Epoch 120: Val Acc: 0.62%
2025-08-14 22:42:49,853 - INFO - Fold 1, Epoch 130: Val Acc: 0.72%
2025-08-14 22:42:52,091 - INFO - Fold 1, Epoch 140: Val Acc: 0.66%
2025-08-14 22:42:54,318 - INFO - Fold 1, Epoch 150: Val Acc: 0.59%
2025-08-14 22:42:56,536 - INFO - Fold 1, Epoch 160: Val Acc: 0.69%
2025-08-14 22:42:58,750 - INFO - Fold 1, Epoch 170: Val Acc: 0.66%
2025-08-14 22:42:59,418 - INFO - Early stopping at epoch 173
2025-08-14 22:43:03,018 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:43:03,020 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:43:03,021 - INFO - Starting training for fold 2/3
2025-08-14 22:43:12,797 - INFO - Fold 2, Epoch 10: Val Acc: 0.62%
2025-08-14 22:43:16,467 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-14 22:43:21,610 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-14 22:43:26,764 - INFO - Fold 2, Epoch 40: Val Acc: 0.66%
2025-08-14 22:43:28,978 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-14 22:43:31,206 - INFO - Fold 2, Epoch 60: Val Acc: 0.69%
2025-08-14 22:43:33,511 - INFO - Fold 2, Epoch 70: Val Acc: 0.62%
2025-08-14 22:43:35,828 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-14 22:43:38,139 - INFO - Fold 2, Epoch 90: Val Acc: 0.84%
2025-08-14 22:43:40,368 - INFO - Fold 2, Epoch 100: Val Acc: 0.62%
2025-08-14 22:43:43,921 - INFO - Fold 2, Epoch 110: Val Acc: 0.91%
2025-08-14 22:43:46,217 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-14 22:43:48,438 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-14 22:43:50,665 - INFO - Fold 2, Epoch 140: Val Acc: 0.81%
2025-08-14 22:43:54,246 - INFO - Fold 2, Epoch 150: Val Acc: 0.94%
2025-08-14 22:43:56,574 - INFO - Fold 2, Epoch 160: Val Acc: 0.88%
2025-08-14 22:43:58,795 - INFO - Fold 2, Epoch 170: Val Acc: 0.84%
2025-08-14 22:44:01,054 - INFO - Fold 2, Epoch 180: Val Acc: 0.78%
2025-08-14 22:44:03,343 - INFO - Fold 2, Epoch 190: Val Acc: 0.91%
2025-08-14 22:44:05,644 - INFO - Fold 2, Epoch 200: Val Acc: 0.59%
2025-08-14 22:44:07,950 - INFO - Fold 2, Epoch 210: Val Acc: 0.72%
2025-08-14 22:44:10,248 - INFO - Fold 2, Epoch 220: Val Acc: 0.84%
2025-08-14 22:44:12,534 - INFO - Fold 2, Epoch 230: Val Acc: 0.78%
2025-08-14 22:44:14,834 - INFO - Fold 2, Epoch 240: Val Acc: 0.81%
2025-08-14 22:44:17,086 - INFO - Early stopping at epoch 250
2025-08-14 22:44:20,236 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:44:20,239 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:44:20,240 - INFO - Starting training for fold 3/3
2025-08-14 22:44:26,990 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-14 22:44:30,679 - INFO - Fold 3, Epoch 20: Val Acc: 0.75%
2025-08-14 22:44:34,329 - INFO - Fold 3, Epoch 30: Val Acc: 0.69%
2025-08-14 22:44:37,981 - INFO - Fold 3, Epoch 40: Val Acc: 0.81%
2025-08-14 22:44:40,202 - INFO - Fold 3, Epoch 50: Val Acc: 0.75%
2025-08-14 22:44:42,425 - INFO - Fold 3, Epoch 60: Val Acc: 0.72%
2025-08-14 22:44:44,736 - INFO - Fold 3, Epoch 70: Val Acc: 0.75%
2025-08-14 22:44:48,552 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-14 22:44:50,832 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-14 22:44:53,073 - INFO - Fold 3, Epoch 100: Val Acc: 0.81%
2025-08-14 22:44:55,296 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-14 22:44:57,517 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-14 22:44:59,746 - INFO - Fold 3, Epoch 130: Val Acc: 0.69%
2025-08-14 22:45:01,982 - INFO - Fold 3, Epoch 140: Val Acc: 0.69%
2025-08-14 22:45:04,209 - INFO - Fold 3, Epoch 150: Val Acc: 0.81%
2025-08-14 22:45:06,444 - INFO - Fold 3, Epoch 160: Val Acc: 0.84%
2025-08-14 22:45:08,746 - INFO - Fold 3, Epoch 170: Val Acc: 0.75%
2025-08-14 22:45:10,359 - INFO - Early stopping at epoch 177
2025-08-14 22:45:11,494 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.8759356869591612), 'std': np.float64(0.035107146853108034)}, 'train_accuracy': {'mean': np.float64(0.7881944444444445), 'std': np.float64(0.04280843057617344)}, 'val_loss': {'mean': np.float64(4.2300651868184405), 'std': np.float64(0.040751896402868346)}, 'val_accuracy': {'mean': np.float64(0.9270833333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(99.0), 'std': np.float64(35.393031329156685)}}
[I 2025-08-14 22:45:11,502] Trial 75 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0006880881159388922, 'batch_size': 32, 'num_epochs': 936, 'temperature': 0.3224014075969774, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4424470373449749, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18052511264555268, 'crop_size': 0.5614352128113032}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 75 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0006880881159388922, 'batch_size': 32, 'num_epochs': 936, 'temperature': 0.3224014075969774, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4424470373449749, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18052511264555268, 'crop_size': 0.5614352128113032}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:45:11,538 - INFO - Using device: cuda
2025-08-14 22:45:21,464 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:45:21,466 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:45:21,466 - INFO - Starting training for fold 1/3
2025-08-14 22:45:27,676 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-14 22:45:37,028 - INFO - Fold 1, Epoch 20: Val Acc: 0.69%
2025-08-14 22:45:40,928 - INFO - Fold 1, Epoch 30: Val Acc: 0.56%
2025-08-14 22:45:42,950 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-14 22:45:44,948 - INFO - Fold 1, Epoch 50: Val Acc: 0.84%
2025-08-14 22:45:46,953 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-14 22:45:48,965 - INFO - Fold 1, Epoch 70: Val Acc: 0.81%
2025-08-14 22:45:50,968 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-14 22:45:52,980 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-14 22:45:55,041 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-14 22:45:57,090 - INFO - Fold 1, Epoch 110: Val Acc: 0.75%
2025-08-14 22:45:59,154 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-14 22:45:59,654 - INFO - Early stopping at epoch 123
2025-08-14 22:46:02,354 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:46:02,357 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:46:02,357 - INFO - Starting training for fold 2/3
2025-08-14 22:46:11,216 - INFO - Fold 2, Epoch 10: Val Acc: 0.69%
2025-08-14 22:46:14,688 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-14 22:46:16,780 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-14 22:46:21,207 - INFO - Fold 2, Epoch 40: Val Acc: 0.84%
2025-08-14 22:46:24,563 - INFO - Fold 2, Epoch 50: Val Acc: 0.88%
2025-08-14 22:46:26,582 - INFO - Fold 2, Epoch 60: Val Acc: 0.81%
2025-08-14 22:46:28,594 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-14 22:46:30,616 - INFO - Fold 2, Epoch 80: Val Acc: 0.84%
2025-08-14 22:46:32,638 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-14 22:46:34,658 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-14 22:46:37,918 - INFO - Fold 2, Epoch 110: Val Acc: 0.81%
2025-08-14 22:46:39,927 - INFO - Fold 2, Epoch 120: Val Acc: 0.78%
2025-08-14 22:46:41,930 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-14 22:46:43,941 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-14 22:46:45,949 - INFO - Fold 2, Epoch 150: Val Acc: 0.91%
2025-08-14 22:46:47,948 - INFO - Fold 2, Epoch 160: Val Acc: 0.81%
2025-08-14 22:46:49,953 - INFO - Fold 2, Epoch 170: Val Acc: 0.81%
2025-08-14 22:46:51,961 - INFO - Fold 2, Epoch 180: Val Acc: 0.84%
2025-08-14 22:46:53,970 - INFO - Fold 2, Epoch 190: Val Acc: 0.72%
2025-08-14 22:46:55,979 - INFO - Fold 2, Epoch 200: Val Acc: 0.72%
2025-08-14 22:46:57,380 - INFO - Early stopping at epoch 207
2025-08-14 22:47:00,023 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:47:00,026 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:47:00,027 - INFO - Starting training for fold 3/3
2025-08-14 22:47:04,858 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-14 22:47:09,281 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-14 22:47:12,547 - INFO - Fold 3, Epoch 30: Val Acc: 0.53%
2025-08-14 22:47:14,329 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-14 22:47:16,410 - INFO - Fold 3, Epoch 50: Val Acc: 0.66%
2025-08-14 22:47:18,489 - INFO - Fold 3, Epoch 60: Val Acc: 0.69%
2025-08-14 22:47:20,522 - INFO - Fold 3, Epoch 70: Val Acc: 0.84%
2025-08-14 22:47:22,520 - INFO - Fold 3, Epoch 80: Val Acc: 0.78%
2025-08-14 22:47:25,723 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-14 22:47:27,727 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-14 22:47:29,724 - INFO - Fold 3, Epoch 110: Val Acc: 0.59%
2025-08-14 22:47:31,726 - INFO - Fold 3, Epoch 120: Val Acc: 0.66%
2025-08-14 22:47:33,764 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-14 22:47:35,854 - INFO - Fold 3, Epoch 140: Val Acc: 0.62%
2025-08-14 22:47:37,949 - INFO - Fold 3, Epoch 150: Val Acc: 0.84%
2025-08-14 22:47:40,031 - INFO - Fold 3, Epoch 160: Val Acc: 0.78%
2025-08-14 22:47:42,118 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-14 22:47:44,219 - INFO - Fold 3, Epoch 180: Val Acc: 0.66%
2025-08-14 22:47:45,673 - INFO - Early stopping at epoch 187
2025-08-14 22:47:46,544 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.895449770821465), 'std': np.float64(0.11535817057815993)}, 'train_accuracy': {'mean': np.float64(0.7847222222222223), 'std': np.float64(0.06927061577520836)}, 'val_loss': {'mean': np.float64(4.1996235847473145), 'std': np.float64(0.058818060960039914)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(71.33333333333333), 'std': np.float64(35.82674358011841)}}
[I 2025-08-14 22:47:46,552] Trial 76 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0006992327333023838, 'batch_size': 32, 'num_epochs': 947, 'temperature': 0.29746037451018087, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.1121397104381468, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.16378097648944928, 'crop_size': 0.5612668055025476}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 76 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0006992327333023838, 'batch_size': 32, 'num_epochs': 947, 'temperature': 0.29746037451018087, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.1121397104381468, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.16378097648944928, 'crop_size': 0.5612668055025476}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:47:46,587 - INFO - Using device: cuda
2025-08-14 22:47:56,336 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:47:56,338 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:47:56,338 - INFO - Starting training for fold 1/3
2025-08-14 22:48:04,207 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-14 22:48:08,157 - INFO - Fold 1, Epoch 20: Val Acc: 0.47%
2025-08-14 22:48:10,169 - INFO - Fold 1, Epoch 30: Val Acc: 0.59%
2025-08-14 22:48:12,176 - INFO - Fold 1, Epoch 40: Val Acc: 0.66%
2025-08-14 22:48:17,059 - INFO - Fold 1, Epoch 50: Val Acc: 0.56%
2025-08-14 22:48:20,961 - INFO - Fold 1, Epoch 60: Val Acc: 0.62%
2025-08-14 22:48:22,964 - INFO - Fold 1, Epoch 70: Val Acc: 0.81%
2025-08-14 22:48:24,969 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-14 22:48:26,974 - INFO - Fold 1, Epoch 90: Val Acc: 0.44%
2025-08-14 22:48:28,962 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-14 22:48:30,955 - INFO - Fold 1, Epoch 110: Val Acc: 0.59%
2025-08-14 22:48:32,964 - INFO - Fold 1, Epoch 120: Val Acc: 0.62%
2025-08-14 22:48:34,982 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-14 22:48:36,992 - INFO - Fold 1, Epoch 140: Val Acc: 0.78%
2025-08-14 22:48:39,003 - INFO - Fold 1, Epoch 150: Val Acc: 0.75%
2025-08-14 22:48:43,000 - INFO - Fold 1, Epoch 160: Val Acc: 0.75%
2025-08-14 22:48:45,006 - INFO - Fold 1, Epoch 170: Val Acc: 0.66%
2025-08-14 22:48:47,022 - INFO - Fold 1, Epoch 180: Val Acc: 0.66%
2025-08-14 22:48:49,028 - INFO - Fold 1, Epoch 190: Val Acc: 0.69%
2025-08-14 22:48:51,024 - INFO - Fold 1, Epoch 200: Val Acc: 0.62%
2025-08-14 22:48:53,026 - INFO - Fold 1, Epoch 210: Val Acc: 0.78%
2025-08-14 22:48:55,032 - INFO - Fold 1, Epoch 220: Val Acc: 0.72%
2025-08-14 22:48:57,051 - INFO - Fold 1, Epoch 230: Val Acc: 0.66%
2025-08-14 22:48:59,116 - INFO - Fold 1, Epoch 240: Val Acc: 0.62%
2025-08-14 22:49:01,110 - INFO - Fold 1, Epoch 250: Val Acc: 0.53%
2025-08-14 22:49:01,906 - INFO - Early stopping at epoch 254
2025-08-14 22:49:04,698 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:49:04,710 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:49:04,711 - INFO - Starting training for fold 2/3
2025-08-14 22:49:11,488 - INFO - Fold 2, Epoch 10: Val Acc: 0.59%
2025-08-14 22:49:14,538 - INFO - Fold 2, Epoch 20: Val Acc: 0.62%
2025-08-14 22:49:16,582 - INFO - Fold 2, Epoch 30: Val Acc: 0.56%
2025-08-14 22:49:20,748 - INFO - Fold 2, Epoch 40: Val Acc: 0.78%
2025-08-14 22:49:22,828 - INFO - Fold 2, Epoch 50: Val Acc: 0.62%
2025-08-14 22:49:24,844 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-14 22:49:28,019 - INFO - Fold 2, Epoch 70: Val Acc: 0.56%
2025-08-14 22:49:29,850 - INFO - Fold 2, Epoch 80: Val Acc: 0.72%
2025-08-14 22:49:31,864 - INFO - Fold 2, Epoch 90: Val Acc: 0.62%
2025-08-14 22:49:33,872 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-14 22:49:35,870 - INFO - Fold 2, Epoch 110: Val Acc: 0.59%
2025-08-14 22:49:37,855 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-14 22:49:39,853 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-14 22:49:41,860 - INFO - Fold 2, Epoch 140: Val Acc: 0.69%
2025-08-14 22:49:43,872 - INFO - Fold 2, Epoch 150: Val Acc: 0.78%
2025-08-14 22:49:45,886 - INFO - Fold 2, Epoch 160: Val Acc: 0.75%
2025-08-14 22:49:49,026 - INFO - Fold 2, Epoch 170: Val Acc: 0.81%
2025-08-14 22:49:51,041 - INFO - Fold 2, Epoch 180: Val Acc: 0.75%
2025-08-14 22:49:52,938 - INFO - Fold 2, Epoch 190: Val Acc: 0.81%
2025-08-14 22:49:54,946 - INFO - Fold 2, Epoch 200: Val Acc: 0.62%
2025-08-14 22:49:56,978 - INFO - Fold 2, Epoch 210: Val Acc: 0.78%
2025-08-14 22:49:58,996 - INFO - Fold 2, Epoch 220: Val Acc: 0.81%
2025-08-14 22:50:01,003 - INFO - Fold 2, Epoch 230: Val Acc: 0.72%
2025-08-14 22:50:03,004 - INFO - Fold 2, Epoch 240: Val Acc: 0.69%
2025-08-14 22:50:05,007 - INFO - Fold 2, Epoch 250: Val Acc: 0.84%
2025-08-14 22:50:07,023 - INFO - Fold 2, Epoch 260: Val Acc: 0.59%
2025-08-14 22:50:08,356 - INFO - Early stopping at epoch 267
2025-08-14 22:50:09,183 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:50:09,185 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:50:09,185 - INFO - Starting training for fold 3/3
2025-08-14 22:50:14,964 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-14 22:50:18,119 - INFO - Fold 3, Epoch 20: Val Acc: 0.44%
2025-08-14 22:50:21,300 - INFO - Fold 3, Epoch 30: Val Acc: 0.47%
2025-08-14 22:50:23,318 - INFO - Fold 3, Epoch 40: Val Acc: 0.59%
2025-08-14 22:50:26,474 - INFO - Fold 3, Epoch 50: Val Acc: 0.56%
2025-08-14 22:50:28,402 - INFO - Fold 3, Epoch 60: Val Acc: 0.62%
2025-08-14 22:50:30,421 - INFO - Fold 3, Epoch 70: Val Acc: 0.59%
2025-08-14 22:50:33,586 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-14 22:50:36,922 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-14 22:50:38,912 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-14 22:50:40,690 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-14 22:50:43,994 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-14 22:50:46,074 - INFO - Fold 3, Epoch 130: Val Acc: 0.66%
2025-08-14 22:50:48,142 - INFO - Fold 3, Epoch 140: Val Acc: 0.66%
2025-08-14 22:50:50,236 - INFO - Fold 3, Epoch 150: Val Acc: 0.66%
2025-08-14 22:50:52,248 - INFO - Fold 3, Epoch 160: Val Acc: 0.78%
2025-08-14 22:50:54,270 - INFO - Fold 3, Epoch 170: Val Acc: 0.75%
2025-08-14 22:50:56,291 - INFO - Fold 3, Epoch 180: Val Acc: 0.88%
2025-08-14 22:50:58,321 - INFO - Fold 3, Epoch 190: Val Acc: 0.75%
2025-08-14 22:51:00,425 - INFO - Fold 3, Epoch 200: Val Acc: 0.56%
2025-08-14 22:51:02,436 - INFO - Fold 3, Epoch 210: Val Acc: 0.78%
2025-08-14 22:51:03,435 - INFO - Early stopping at epoch 215
2025-08-14 22:51:05,835 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.035165945688884), 'std': np.float64(0.023236829333406425)}, 'train_accuracy': {'mean': np.float64(0.7222222222222222), 'std': np.float64(0.035409857733283256)}, 'val_loss': {'mean': np.float64(4.179284890492757), 'std': np.float64(0.04254504430321643)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(144.33333333333334), 'std': np.float64(22.095751225568733)}}
[I 2025-08-14 22:51:05,844] Trial 77 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0001813586138449173, 'batch_size': 32, 'num_epochs': 836, 'temperature': 0.3226526373980575, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.40216528003296154, 'num_layers': 4, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19613300288392876, 'crop_size': 0.6005912272220708}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 77 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0001813586138449173, 'batch_size': 32, 'num_epochs': 836, 'temperature': 0.3226526373980575, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.40216528003296154, 'num_layers': 4, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19613300288392876, 'crop_size': 0.6005912272220708}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:51:05,915 - INFO - Using device: cuda
2025-08-14 22:51:15,941 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:51:15,942 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:51:15,943 - INFO - Starting training for fold 1/3
2025-08-14 22:51:24,946 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-14 22:51:29,265 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-14 22:51:33,621 - INFO - Fold 1, Epoch 30: Val Acc: 0.66%
2025-08-14 22:51:38,038 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-14 22:51:42,324 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-14 22:51:44,451 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-14 22:51:46,579 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-14 22:51:48,702 - INFO - Fold 1, Epoch 80: Val Acc: 0.75%
2025-08-14 22:51:50,826 - INFO - Fold 1, Epoch 90: Val Acc: 0.66%
2025-08-14 22:51:52,954 - INFO - Fold 1, Epoch 100: Val Acc: 0.66%
2025-08-14 22:51:55,073 - INFO - Fold 1, Epoch 110: Val Acc: 0.72%
2025-08-14 22:51:56,909 - INFO - Fold 1, Epoch 120: Val Acc: 0.78%
2025-08-14 22:51:58,627 - INFO - Fold 1, Epoch 130: Val Acc: 0.56%
2025-08-14 22:52:00,227 - INFO - Fold 1, Epoch 140: Val Acc: 0.75%
2025-08-14 22:52:00,386 - INFO - Early stopping at epoch 141
2025-08-14 22:52:04,894 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:52:04,897 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:52:04,897 - INFO - Starting training for fold 2/3
2025-08-14 22:52:11,501 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-14 22:52:14,975 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-14 22:52:20,186 - INFO - Fold 2, Epoch 30: Val Acc: 0.66%
2025-08-14 22:52:22,031 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-14 22:52:24,230 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-14 22:52:28,022 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-14 22:52:31,719 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-14 22:52:33,838 - INFO - Fold 2, Epoch 80: Val Acc: 0.78%
2025-08-14 22:52:35,960 - INFO - Fold 2, Epoch 90: Val Acc: 0.75%
2025-08-14 22:52:38,079 - INFO - Fold 2, Epoch 100: Val Acc: 0.84%
2025-08-14 22:52:40,197 - INFO - Fold 2, Epoch 110: Val Acc: 0.66%
2025-08-14 22:52:42,310 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-14 22:52:44,418 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-14 22:52:46,527 - INFO - Fold 2, Epoch 140: Val Acc: 0.66%
2025-08-14 22:52:48,647 - INFO - Fold 2, Epoch 150: Val Acc: 0.81%
2025-08-14 22:52:50,770 - INFO - Fold 2, Epoch 160: Val Acc: 0.47%
2025-08-14 22:52:54,305 - INFO - Fold 2, Epoch 170: Val Acc: 0.69%
2025-08-14 22:52:56,421 - INFO - Fold 2, Epoch 180: Val Acc: 0.81%
2025-08-14 22:52:59,932 - INFO - Fold 2, Epoch 190: Val Acc: 0.78%
2025-08-14 22:53:02,049 - INFO - Fold 2, Epoch 200: Val Acc: 0.75%
2025-08-14 22:53:04,147 - INFO - Fold 2, Epoch 210: Val Acc: 0.84%
2025-08-14 22:53:06,253 - INFO - Fold 2, Epoch 220: Val Acc: 0.84%
2025-08-14 22:53:08,361 - INFO - Fold 2, Epoch 230: Val Acc: 0.75%
2025-08-14 22:53:10,463 - INFO - Fold 2, Epoch 240: Val Acc: 0.88%
2025-08-14 22:53:12,562 - INFO - Fold 2, Epoch 250: Val Acc: 0.88%
2025-08-14 22:53:14,663 - INFO - Fold 2, Epoch 260: Val Acc: 0.72%
2025-08-14 22:53:16,758 - INFO - Fold 2, Epoch 270: Val Acc: 0.91%
2025-08-14 22:53:18,847 - INFO - Fold 2, Epoch 280: Val Acc: 0.78%
2025-08-14 22:53:20,740 - INFO - Early stopping at epoch 289
2025-08-14 22:53:23,654 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:53:23,673 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:53:23,673 - INFO - Starting training for fold 3/3
2025-08-14 22:53:34,058 - INFO - Fold 3, Epoch 10: Val Acc: 0.78%
2025-08-14 22:53:37,624 - INFO - Fold 3, Epoch 20: Val Acc: 0.78%
2025-08-14 22:53:39,518 - INFO - Fold 3, Epoch 30: Val Acc: 0.72%
2025-08-14 22:53:43,285 - INFO - Fold 3, Epoch 40: Val Acc: 0.72%
2025-08-14 22:53:45,542 - INFO - Fold 3, Epoch 50: Val Acc: 0.81%
2025-08-14 22:53:49,117 - INFO - Fold 3, Epoch 60: Val Acc: 0.72%
2025-08-14 22:53:51,107 - INFO - Fold 3, Epoch 70: Val Acc: 0.84%
2025-08-14 22:53:53,372 - INFO - Fold 3, Epoch 80: Val Acc: 0.81%
2025-08-14 22:53:55,539 - INFO - Fold 3, Epoch 90: Val Acc: 0.59%
2025-08-14 22:53:57,650 - INFO - Fold 3, Epoch 100: Val Acc: 0.78%
2025-08-14 22:53:59,885 - INFO - Fold 3, Epoch 110: Val Acc: 0.81%
2025-08-14 22:54:02,155 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-14 22:54:04,435 - INFO - Fold 3, Epoch 130: Val Acc: 0.66%
2025-08-14 22:54:06,706 - INFO - Fold 3, Epoch 140: Val Acc: 0.66%
2025-08-14 22:54:08,969 - INFO - Fold 3, Epoch 150: Val Acc: 0.81%
2025-08-14 22:54:10,095 - INFO - Early stopping at epoch 155
2025-08-14 22:54:11,162 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.8267393906911216), 'std': np.float64(0.09700884749484429)}, 'train_accuracy': {'mean': np.float64(0.7534722222222223), 'std': np.float64(0.0597383699100183)}, 'val_loss': {'mean': np.float64(4.250280062357585), 'std': np.float64(0.06749461236618201)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.04419417382415922)}, 'epoch': {'mean': np.float64(94.0), 'std': np.float64(66.71331701142334)}}
[I 2025-08-14 22:54:11,169] Trial 78 finished with value: -0.90625 and parameters: {'learning_rate': 0.00032129243597457473, 'batch_size': 32, 'num_epochs': 875, 'temperature': 0.21676602436430473, 'embedding_dim': 512, 'hidden_dim': 256, 'dropout': 0.2893574604223457, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.5788702386051747}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 78 finished with value: -0.90625 and parameters: {'learning_rate': 0.00032129243597457473, 'batch_size': 32, 'num_epochs': 875, 'temperature': 0.21676602436430473, 'embedding_dim': 512, 'hidden_dim': 256, 'dropout': 0.2893574604223457, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.5788702386051747}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:54:11,207 - INFO - Using device: cuda
2025-08-14 22:54:23,933 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:54:23,935 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:54:23,935 - INFO - Starting training for fold 1/3
2025-08-14 22:54:31,702 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-14 22:54:34,237 - INFO - Fold 1, Epoch 20: Val Acc: 0.38%
2025-08-14 22:54:36,790 - INFO - Fold 1, Epoch 30: Val Acc: 0.47%
2025-08-14 22:54:39,336 - INFO - Fold 1, Epoch 40: Val Acc: 0.56%
2025-08-14 22:54:41,878 - INFO - Fold 1, Epoch 50: Val Acc: 0.41%
2025-08-14 22:54:44,426 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-14 22:54:46,975 - INFO - Fold 1, Epoch 70: Val Acc: 0.53%
2025-08-14 22:54:49,495 - INFO - Fold 1, Epoch 80: Val Acc: 0.56%
2025-08-14 22:54:52,029 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-14 22:54:54,614 - INFO - Fold 1, Epoch 100: Val Acc: 0.53%
2025-08-14 22:54:55,121 - INFO - Early stopping at epoch 102
2025-08-14 22:54:58,706 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:54:58,709 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:54:58,709 - INFO - Starting training for fold 2/3
2025-08-14 22:55:04,905 - INFO - Fold 2, Epoch 10: Val Acc: 0.59%
2025-08-14 22:55:09,245 - INFO - Fold 2, Epoch 20: Val Acc: 0.41%
2025-08-14 22:55:11,839 - INFO - Fold 2, Epoch 30: Val Acc: 0.53%
2025-08-14 22:55:14,472 - INFO - Fold 2, Epoch 40: Val Acc: 0.44%
2025-08-14 22:55:16,825 - INFO - Fold 2, Epoch 50: Val Acc: 0.34%
2025-08-14 22:55:19,172 - INFO - Fold 2, Epoch 60: Val Acc: 0.44%
2025-08-14 22:55:23,295 - INFO - Fold 2, Epoch 70: Val Acc: 0.50%
2025-08-14 22:55:25,507 - INFO - Fold 2, Epoch 80: Val Acc: 0.50%
2025-08-14 22:55:28,126 - INFO - Fold 2, Epoch 90: Val Acc: 0.44%
2025-08-14 22:55:30,652 - INFO - Fold 2, Epoch 100: Val Acc: 0.53%
2025-08-14 22:55:33,182 - INFO - Fold 2, Epoch 110: Val Acc: 0.56%
2025-08-14 22:55:35,727 - INFO - Fold 2, Epoch 120: Val Acc: 0.56%
2025-08-14 22:55:38,285 - INFO - Fold 2, Epoch 130: Val Acc: 0.44%
2025-08-14 22:55:40,830 - INFO - Fold 2, Epoch 140: Val Acc: 0.38%
2025-08-14 22:55:43,377 - INFO - Fold 2, Epoch 150: Val Acc: 0.47%
2025-08-14 22:55:45,902 - INFO - Fold 2, Epoch 160: Val Acc: 0.50%
2025-08-14 22:55:47,414 - INFO - Early stopping at epoch 166
2025-08-14 22:55:48,698 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:55:48,700 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:55:48,700 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:55:52,761 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-14 22:55:54,719 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-14 22:55:58,684 - INFO - Fold 3, Epoch 30: Val Acc: 0.41%
2025-08-14 22:56:01,231 - INFO - Fold 3, Epoch 40: Val Acc: 0.50%
2025-08-14 22:56:03,764 - INFO - Fold 3, Epoch 50: Val Acc: 0.38%
2025-08-14 22:56:06,299 - INFO - Fold 3, Epoch 60: Val Acc: 0.59%
2025-08-14 22:56:08,837 - INFO - Fold 3, Epoch 70: Val Acc: 0.56%
2025-08-14 22:56:11,371 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-14 22:56:13,912 - INFO - Fold 3, Epoch 90: Val Acc: 0.53%
2025-08-14 22:56:16,456 - INFO - Fold 3, Epoch 100: Val Acc: 0.56%
2025-08-14 22:56:18,985 - INFO - Fold 3, Epoch 110: Val Acc: 0.44%
2025-08-14 22:56:21,525 - INFO - Fold 3, Epoch 120: Val Acc: 0.56%
2025-08-14 22:56:22,284 - INFO - Early stopping at epoch 123
2025-08-14 22:56:23,542 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.622765329149035), 'std': np.float64(0.1326702062724672)}, 'train_accuracy': {'mean': np.float64(0.5763888888888888), 'std': np.float64(0.025983731852596822)}, 'val_loss': {'mean': np.float64(4.541309038798015), 'std': np.float64(0.12914907041089407)}, 'val_accuracy': {'mean': np.float64(0.6770833333333334), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(29.333333333333332), 'std': np.float64(26.637484032009397)}}
[I 2025-08-14 22:56:23,549] Trial 79 finished with value: -0.6770833333333334 and parameters: {'learning_rate': 0.0003843375965162803, 'batch_size': 32, 'num_epochs': 980, 'temperature': 0.07917576380401477, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4410934405263818, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.012603420520817962, 'crop_size': 0.6299935682772629}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 79 finished with value: -0.6770833333333334 and parameters: {'learning_rate': 0.0003843375965162803, 'batch_size': 32, 'num_epochs': 980, 'temperature': 0.07917576380401477, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4410934405263818, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.012603420520817962, 'crop_size': 0.6299935682772629}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:56:23,579 - INFO - Using device: cuda
2025-08-14 22:56:33,349 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:56:33,351 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:56:33,351 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:56:44,674 - INFO - Fold 1, Epoch 10: Val Acc: 0.62%
2025-08-14 22:56:46,929 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-14 22:56:49,184 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 22:56:51,429 - INFO - Fold 1, Epoch 40: Val Acc: 0.56%
2025-08-14 22:56:53,652 - INFO - Fold 1, Epoch 50: Val Acc: 0.56%
2025-08-14 22:56:55,886 - INFO - Fold 1, Epoch 60: Val Acc: 0.53%
2025-08-14 22:56:58,129 - INFO - Fold 1, Epoch 70: Val Acc: 0.56%
2025-08-14 22:57:00,373 - INFO - Fold 1, Epoch 80: Val Acc: 0.53%
2025-08-14 22:57:02,597 - INFO - Fold 1, Epoch 90: Val Acc: 0.53%
2025-08-14 22:57:04,765 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-14 22:57:05,880 - INFO - Early stopping at epoch 105
2025-08-14 22:57:09,661 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:57:09,664 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:57:09,664 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:57:16,364 - INFO - Fold 2, Epoch 10: Val Acc: 0.69%
2025-08-14 22:57:18,516 - INFO - Fold 2, Epoch 20: Val Acc: 0.69%
2025-08-14 22:57:20,687 - INFO - Fold 2, Epoch 30: Val Acc: 0.62%
2025-08-14 22:57:24,210 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-14 22:57:27,771 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-14 22:57:29,924 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-14 22:57:31,956 - INFO - Fold 2, Epoch 70: Val Acc: 0.69%
2025-08-14 22:57:34,107 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-14 22:57:36,264 - INFO - Fold 2, Epoch 90: Val Acc: 0.66%
2025-08-14 22:57:38,059 - INFO - Fold 2, Epoch 100: Val Acc: 0.62%
2025-08-14 22:57:39,785 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-14 22:57:41,588 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-14 22:57:43,467 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-14 22:57:45,348 - INFO - Fold 2, Epoch 140: Val Acc: 0.59%
2025-08-14 22:57:46,061 - INFO - Early stopping at epoch 144
2025-08-14 22:57:49,122 - INFO - --- Starting Fold 3/3 ---
2025-08-14 22:57:49,125 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:57:49,125 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 22:57:56,886 - INFO - Fold 3, Epoch 10: Val Acc: 0.72%
2025-08-14 22:57:58,845 - INFO - Fold 3, Epoch 20: Val Acc: 0.88%
2025-08-14 22:58:00,897 - INFO - Fold 3, Epoch 30: Val Acc: 0.62%
2025-08-14 22:58:03,068 - INFO - Fold 3, Epoch 40: Val Acc: 0.59%
2025-08-14 22:58:05,224 - INFO - Fold 3, Epoch 50: Val Acc: 0.59%
2025-08-14 22:58:07,351 - INFO - Fold 3, Epoch 60: Val Acc: 0.62%
2025-08-14 22:58:09,078 - INFO - Fold 3, Epoch 70: Val Acc: 0.53%
2025-08-14 22:58:10,725 - INFO - Fold 3, Epoch 80: Val Acc: 0.62%
2025-08-14 22:58:12,851 - INFO - Fold 3, Epoch 90: Val Acc: 0.59%
2025-08-14 22:58:15,014 - INFO - Fold 3, Epoch 100: Val Acc: 0.47%
2025-08-14 22:58:16,325 - INFO - Early stopping at epoch 106
2025-08-14 22:58:20,850 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.719583670298259), 'std': np.float64(0.8112933484835131)}, 'train_accuracy': {'mean': np.float64(0.8680555555555555), 'std': np.float64(0.07233564811110996)}, 'val_loss': {'mean': np.float64(5.832117557525635), 'std': np.float64(0.5084844887783986)}, 'val_accuracy': {'mean': np.float64(0.8229166666666666), 'std': np.float64(0.05311478659992484)}, 'epoch': {'mean': np.float64(17.333333333333332), 'std': np.float64(18.153665072253467)}}
[I 2025-08-14 22:58:20,870] Trial 80 finished with value: -0.8229166666666666 and parameters: {'learning_rate': 0.0006488643784224167, 'batch_size': 32, 'num_epochs': 934, 'temperature': 0.09475150118428446, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4172868979046141, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1222982135958599}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 80 finished with value: -0.8229166666666666 and parameters: {'learning_rate': 0.0006488643784224167, 'batch_size': 32, 'num_epochs': 934, 'temperature': 0.09475150118428446, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4172868979046141, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1222982135958599}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 22:58:20,952 - INFO - Using device: cuda
2025-08-14 22:58:30,991 - INFO - --- Starting Fold 1/3 ---
2025-08-14 22:58:30,993 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:58:30,993 - INFO - Starting training for fold 1/3
2025-08-14 22:58:38,039 - INFO - Fold 1, Epoch 10: Val Acc: 0.44%
2025-08-14 22:58:42,180 - INFO - Fold 1, Epoch 20: Val Acc: 0.53%
2025-08-14 22:58:51,187 - INFO - Fold 1, Epoch 30: Val Acc: 0.41%
2025-08-14 22:58:53,407 - INFO - Fold 1, Epoch 40: Val Acc: 0.66%
2025-08-14 22:58:55,638 - INFO - Fold 1, Epoch 50: Val Acc: 0.59%
2025-08-14 22:58:57,867 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-14 22:59:02,265 - INFO - Fold 1, Epoch 70: Val Acc: 0.62%
2025-08-14 22:59:04,482 - INFO - Fold 1, Epoch 80: Val Acc: 0.78%
2025-08-14 22:59:06,703 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-14 22:59:08,918 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-14 22:59:13,336 - INFO - Fold 1, Epoch 110: Val Acc: 0.72%
2025-08-14 22:59:15,577 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-14 22:59:17,810 - INFO - Fold 1, Epoch 130: Val Acc: 0.78%
2025-08-14 22:59:20,041 - INFO - Fold 1, Epoch 140: Val Acc: 0.53%
2025-08-14 22:59:22,282 - INFO - Fold 1, Epoch 150: Val Acc: 0.72%
2025-08-14 22:59:24,517 - INFO - Fold 1, Epoch 160: Val Acc: 0.66%
2025-08-14 22:59:26,739 - INFO - Fold 1, Epoch 170: Val Acc: 0.62%
2025-08-14 22:59:29,009 - INFO - Fold 1, Epoch 180: Val Acc: 0.78%
2025-08-14 22:59:31,326 - INFO - Fold 1, Epoch 190: Val Acc: 0.72%
2025-08-14 22:59:33,617 - INFO - Fold 1, Epoch 200: Val Acc: 0.72%
2025-08-14 22:59:34,073 - INFO - Early stopping at epoch 202
2025-08-14 22:59:37,764 - INFO - --- Starting Fold 2/3 ---
2025-08-14 22:59:37,767 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 22:59:37,768 - INFO - Starting training for fold 2/3
2025-08-14 22:59:46,150 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-14 22:59:51,261 - INFO - Fold 2, Epoch 20: Val Acc: 0.69%
2025-08-14 22:59:53,495 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-14 22:59:57,160 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-14 22:59:59,394 - INFO - Fold 2, Epoch 50: Val Acc: 0.72%
2025-08-14 23:00:03,314 - INFO - Fold 2, Epoch 60: Val Acc: 0.69%
2025-08-14 23:00:05,565 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-14 23:00:09,296 - INFO - Fold 2, Epoch 80: Val Acc: 0.78%
2025-08-14 23:00:11,531 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-14 23:00:13,748 - INFO - Fold 2, Epoch 100: Val Acc: 0.81%
2025-08-14 23:00:15,979 - INFO - Fold 2, Epoch 110: Val Acc: 0.88%
2025-08-14 23:00:19,692 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-14 23:00:21,931 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-14 23:00:24,154 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-14 23:00:26,399 - INFO - Fold 2, Epoch 150: Val Acc: 0.72%
2025-08-14 23:00:28,716 - INFO - Fold 2, Epoch 160: Val Acc: 0.84%
2025-08-14 23:00:31,017 - INFO - Fold 2, Epoch 170: Val Acc: 0.72%
2025-08-14 23:00:33,278 - INFO - Fold 2, Epoch 180: Val Acc: 0.78%
2025-08-14 23:00:35,580 - INFO - Fold 2, Epoch 190: Val Acc: 0.78%
2025-08-14 23:00:37,830 - INFO - Fold 2, Epoch 200: Val Acc: 0.81%
2025-08-14 23:00:40,051 - INFO - Fold 2, Epoch 210: Val Acc: 0.81%
2025-08-14 23:00:40,271 - INFO - Early stopping at epoch 211
2025-08-14 23:00:43,688 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:00:43,692 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:00:43,693 - INFO - Starting training for fold 3/3
2025-08-14 23:00:50,275 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-14 23:00:57,078 - INFO - Fold 3, Epoch 20: Val Acc: 0.56%
2025-08-14 23:01:00,771 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-14 23:01:03,017 - INFO - Fold 3, Epoch 40: Val Acc: 0.59%
2025-08-14 23:01:05,228 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-14 23:01:08,860 - INFO - Fold 3, Epoch 60: Val Acc: 0.62%
2025-08-14 23:01:11,101 - INFO - Fold 3, Epoch 70: Val Acc: 0.88%
2025-08-14 23:01:13,324 - INFO - Fold 3, Epoch 80: Val Acc: 0.78%
2025-08-14 23:01:16,984 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-14 23:01:19,199 - INFO - Fold 3, Epoch 100: Val Acc: 0.59%
2025-08-14 23:01:21,501 - INFO - Fold 3, Epoch 110: Val Acc: 0.84%
2025-08-14 23:01:23,802 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-14 23:01:26,101 - INFO - Fold 3, Epoch 130: Val Acc: 0.88%
2025-08-14 23:01:28,401 - INFO - Fold 3, Epoch 140: Val Acc: 0.75%
2025-08-14 23:01:30,691 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-14 23:01:32,985 - INFO - Fold 3, Epoch 160: Val Acc: 0.78%
2025-08-14 23:01:34,850 - INFO - Fold 3, Epoch 170: Val Acc: 0.62%
2025-08-14 23:01:37,066 - INFO - Fold 3, Epoch 180: Val Acc: 0.84%
2025-08-14 23:01:38,174 - INFO - Early stopping at epoch 185
2025-08-14 23:01:39,242 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9847587214575877), 'std': np.float64(0.03747032699408707)}, 'train_accuracy': {'mean': np.float64(0.78125), 'std': np.float64(0.008505172717997162)}, 'val_loss': {'mean': np.float64(4.233977476755778), 'std': np.float64(0.06284254986707029)}, 'val_accuracy': {'mean': np.float64(0.9270833333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(98.33333333333333), 'std': np.float64(10.780641085864152)}}
[I 2025-08-14 23:01:39,256] Trial 81 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0005235736400071786, 'batch_size': 32, 'num_epochs': 891, 'temperature': 0.41574188966359393, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.453828591694691, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.17895053079937617, 'crop_size': 0.5433986486176675}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 81 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0005235736400071786, 'batch_size': 32, 'num_epochs': 891, 'temperature': 0.41574188966359393, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.453828591694691, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.17895053079937617, 'crop_size': 0.5433986486176675}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 23:01:39,304 - INFO - Using device: cuda
2025-08-14 23:01:48,805 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:01:48,807 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:01:48,807 - INFO - Starting training for fold 1/3
2025-08-14 23:01:58,084 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-14 23:02:04,771 - INFO - Fold 1, Epoch 20: Val Acc: 0.72%
2025-08-14 23:02:09,406 - INFO - Fold 1, Epoch 30: Val Acc: 0.84%
2025-08-14 23:02:11,724 - INFO - Fold 1, Epoch 40: Val Acc: 0.81%
2025-08-14 23:02:14,050 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-14 23:02:16,372 - INFO - Fold 1, Epoch 60: Val Acc: 0.75%
2025-08-14 23:02:18,689 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-14 23:02:21,015 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-14 23:02:23,321 - INFO - Fold 1, Epoch 90: Val Acc: 0.78%
2025-08-14 23:02:25,629 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-14 23:02:27,954 - INFO - Fold 1, Epoch 110: Val Acc: 0.72%
2025-08-14 23:02:32,485 - INFO - Fold 1, Epoch 120: Val Acc: 0.59%
2025-08-14 23:02:34,821 - INFO - Fold 1, Epoch 130: Val Acc: 0.72%
2025-08-14 23:02:37,052 - INFO - Fold 1, Epoch 140: Val Acc: 0.84%
2025-08-14 23:02:39,269 - INFO - Fold 1, Epoch 150: Val Acc: 0.66%
2025-08-14 23:02:41,498 - INFO - Fold 1, Epoch 160: Val Acc: 0.50%
2025-08-14 23:02:43,716 - INFO - Fold 1, Epoch 170: Val Acc: 0.59%
2025-08-14 23:02:45,934 - INFO - Fold 1, Epoch 180: Val Acc: 0.69%
2025-08-14 23:02:48,156 - INFO - Fold 1, Epoch 190: Val Acc: 0.72%
2025-08-14 23:02:50,384 - INFO - Fold 1, Epoch 200: Val Acc: 0.78%
2025-08-14 23:02:52,615 - INFO - Fold 1, Epoch 210: Val Acc: 0.62%
2025-08-14 23:02:53,287 - INFO - Early stopping at epoch 213
2025-08-14 23:02:57,013 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:02:57,016 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:02:57,017 - INFO - Starting training for fold 2/3
2025-08-14 23:03:06,820 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-14 23:03:09,058 - INFO - Fold 2, Epoch 20: Val Acc: 0.69%
2025-08-14 23:03:12,771 - INFO - Fold 2, Epoch 30: Val Acc: 0.81%
2025-08-14 23:03:16,311 - INFO - Fold 2, Epoch 40: Val Acc: 0.84%
2025-08-14 23:03:19,915 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-14 23:03:22,138 - INFO - Fold 2, Epoch 60: Val Acc: 0.81%
2025-08-14 23:03:24,361 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-14 23:03:26,577 - INFO - Fold 2, Epoch 80: Val Acc: 0.66%
2025-08-14 23:03:28,797 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-14 23:03:31,028 - INFO - Fold 2, Epoch 100: Val Acc: 0.72%
2025-08-14 23:03:34,659 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-14 23:03:36,699 - INFO - Fold 2, Epoch 120: Val Acc: 0.88%
2025-08-14 23:03:38,919 - INFO - Fold 2, Epoch 130: Val Acc: 0.84%
2025-08-14 23:03:41,140 - INFO - Fold 2, Epoch 140: Val Acc: 0.81%
2025-08-14 23:03:43,361 - INFO - Fold 2, Epoch 150: Val Acc: 0.78%
2025-08-14 23:03:45,583 - INFO - Fold 2, Epoch 160: Val Acc: 0.78%
2025-08-14 23:03:47,806 - INFO - Fold 2, Epoch 170: Val Acc: 0.84%
2025-08-14 23:03:49,970 - INFO - Fold 2, Epoch 180: Val Acc: 0.84%
2025-08-14 23:03:52,123 - INFO - Fold 2, Epoch 190: Val Acc: 0.84%
2025-08-14 23:03:54,302 - INFO - Fold 2, Epoch 200: Val Acc: 0.78%
2025-08-14 23:03:54,974 - INFO - Early stopping at epoch 203
2025-08-14 23:03:56,052 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:03:56,054 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:03:56,055 - INFO - Starting training for fold 3/3
2025-08-14 23:04:01,348 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-14 23:04:05,071 - INFO - Fold 3, Epoch 20: Val Acc: 0.66%
2025-08-14 23:04:07,304 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-14 23:04:09,537 - INFO - Fold 3, Epoch 40: Val Acc: 0.62%
2025-08-14 23:04:11,767 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-14 23:04:13,998 - INFO - Fold 3, Epoch 60: Val Acc: 0.66%
2025-08-14 23:04:17,325 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-14 23:04:20,766 - INFO - Fold 3, Epoch 80: Val Acc: 0.66%
2025-08-14 23:04:22,987 - INFO - Fold 3, Epoch 90: Val Acc: 0.78%
2025-08-14 23:04:25,204 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-14 23:04:27,436 - INFO - Fold 3, Epoch 110: Val Acc: 0.62%
2025-08-14 23:04:31,015 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-14 23:04:33,233 - INFO - Fold 3, Epoch 130: Val Acc: 0.69%
2025-08-14 23:04:35,453 - INFO - Fold 3, Epoch 140: Val Acc: 0.69%
2025-08-14 23:04:37,675 - INFO - Fold 3, Epoch 150: Val Acc: 0.66%
2025-08-14 23:04:39,897 - INFO - Fold 3, Epoch 160: Val Acc: 0.66%
2025-08-14 23:04:41,780 - INFO - Fold 3, Epoch 170: Val Acc: 0.66%
2025-08-14 23:04:44,030 - INFO - Fold 3, Epoch 180: Val Acc: 0.72%
2025-08-14 23:04:46,261 - INFO - Fold 3, Epoch 190: Val Acc: 0.59%
2025-08-14 23:04:48,543 - INFO - Fold 3, Epoch 200: Val Acc: 0.69%
2025-08-14 23:04:50,796 - INFO - Fold 3, Epoch 210: Val Acc: 0.75%
2025-08-14 23:04:51,239 - INFO - Early stopping at epoch 212
2025-08-14 23:04:52,319 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.894057591756185), 'std': np.float64(0.03253400429892906)}, 'train_accuracy': {'mean': np.float64(0.8020833333333334), 'std': np.float64(0.02250257186947169)}, 'val_loss': {'mean': np.float64(4.26180362701416), 'std': np.float64(0.031159951071745157)}, 'val_accuracy': {'mean': np.float64(0.9270833333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(108.33333333333333), 'std': np.float64(4.496912521077347)}}
[I 2025-08-14 23:04:52,328] Trial 82 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0007702059893529439, 'batch_size': 32, 'num_epochs': 886, 'temperature': 0.378830937580882, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4527800562694821, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07507555348252201, 'crop_size': 0.5349863974609144}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 82 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0007702059893529439, 'batch_size': 32, 'num_epochs': 886, 'temperature': 0.378830937580882, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4527800562694821, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07507555348252201, 'crop_size': 0.5349863974609144}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 23:04:52,377 - INFO - Using device: cuda
2025-08-14 23:05:02,225 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:05:02,227 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:05:02,227 - INFO - Starting training for fold 1/3
2025-08-14 23:05:13,550 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-14 23:05:21,080 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-14 23:05:25,062 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-14 23:05:33,619 - INFO - Fold 1, Epoch 40: Val Acc: 0.84%
2025-08-14 23:05:35,962 - INFO - Fold 1, Epoch 50: Val Acc: 0.81%
2025-08-14 23:05:38,195 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-14 23:05:42,737 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-14 23:05:44,966 - INFO - Fold 1, Epoch 80: Val Acc: 0.81%
2025-08-14 23:05:47,202 - INFO - Fold 1, Epoch 90: Val Acc: 0.66%
2025-08-14 23:05:49,424 - INFO - Fold 1, Epoch 100: Val Acc: 0.84%
2025-08-14 23:05:51,665 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-14 23:05:53,905 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-14 23:05:56,140 - INFO - Fold 1, Epoch 130: Val Acc: 0.75%
2025-08-14 23:06:00,500 - INFO - Fold 1, Epoch 140: Val Acc: 0.78%
2025-08-14 23:06:02,737 - INFO - Fold 1, Epoch 150: Val Acc: 0.72%
2025-08-14 23:06:04,967 - INFO - Fold 1, Epoch 160: Val Acc: 0.59%
2025-08-14 23:06:07,197 - INFO - Fold 1, Epoch 170: Val Acc: 0.84%
2025-08-14 23:06:09,420 - INFO - Fold 1, Epoch 180: Val Acc: 0.56%
2025-08-14 23:06:11,645 - INFO - Fold 1, Epoch 190: Val Acc: 0.62%
2025-08-14 23:06:13,863 - INFO - Fold 1, Epoch 200: Val Acc: 0.59%
2025-08-14 23:06:16,087 - INFO - Fold 1, Epoch 210: Val Acc: 0.72%
2025-08-14 23:06:18,315 - INFO - Fold 1, Epoch 220: Val Acc: 0.78%
2025-08-14 23:06:20,559 - INFO - Fold 1, Epoch 230: Val Acc: 0.78%
2025-08-14 23:06:22,108 - INFO - Early stopping at epoch 237
2025-08-14 23:06:25,694 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:06:25,696 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:06:25,697 - INFO - Starting training for fold 2/3
2025-08-14 23:06:32,411 - INFO - Fold 2, Epoch 10: Val Acc: 0.59%
2025-08-14 23:06:37,283 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-14 23:06:40,661 - INFO - Fold 2, Epoch 30: Val Acc: 0.56%
2025-08-14 23:06:43,811 - INFO - Fold 2, Epoch 40: Val Acc: 0.81%
2025-08-14 23:06:47,436 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-14 23:06:49,343 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-14 23:06:52,661 - INFO - Fold 2, Epoch 70: Val Acc: 0.81%
2025-08-14 23:06:55,851 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-14 23:06:59,492 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-14 23:07:01,729 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-14 23:07:03,983 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-14 23:07:06,275 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-14 23:07:08,550 - INFO - Fold 2, Epoch 130: Val Acc: 0.81%
2025-08-14 23:07:10,810 - INFO - Fold 2, Epoch 140: Val Acc: 0.81%
2025-08-14 23:07:12,910 - INFO - Fold 2, Epoch 150: Val Acc: 0.69%
2025-08-14 23:07:14,619 - INFO - Fold 2, Epoch 160: Val Acc: 0.62%
2025-08-14 23:07:16,497 - INFO - Fold 2, Epoch 170: Val Acc: 0.81%
2025-08-14 23:07:18,730 - INFO - Fold 2, Epoch 180: Val Acc: 0.81%
2025-08-14 23:07:19,612 - INFO - Early stopping at epoch 184
2025-08-14 23:07:20,699 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:07:20,702 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:07:20,703 - INFO - Starting training for fold 3/3
2025-08-14 23:07:30,323 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-14 23:07:33,909 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-14 23:07:38,784 - INFO - Fold 3, Epoch 30: Val Acc: 0.72%
2025-08-14 23:07:44,052 - INFO - Fold 3, Epoch 40: Val Acc: 0.81%
2025-08-14 23:07:47,901 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-14 23:07:51,536 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-14 23:07:53,869 - INFO - Fold 3, Epoch 70: Val Acc: 0.78%
2025-08-14 23:07:55,842 - INFO - Fold 3, Epoch 80: Val Acc: 0.78%
2025-08-14 23:07:57,752 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-14 23:07:59,872 - INFO - Fold 3, Epoch 100: Val Acc: 0.78%
2025-08-14 23:08:01,906 - INFO - Fold 3, Epoch 110: Val Acc: 0.59%
2025-08-14 23:08:03,637 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-14 23:08:05,431 - INFO - Fold 3, Epoch 130: Val Acc: 0.62%
2025-08-14 23:08:07,204 - INFO - Fold 3, Epoch 140: Val Acc: 0.78%
2025-08-14 23:08:10,972 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-14 23:08:13,209 - INFO - Fold 3, Epoch 160: Val Acc: 0.72%
2025-08-14 23:08:15,455 - INFO - Fold 3, Epoch 170: Val Acc: 0.59%
2025-08-14 23:08:17,705 - INFO - Fold 3, Epoch 180: Val Acc: 0.81%
2025-08-14 23:08:19,953 - INFO - Fold 3, Epoch 190: Val Acc: 0.62%
2025-08-14 23:08:22,200 - INFO - Fold 3, Epoch 200: Val Acc: 0.66%
2025-08-14 23:08:24,436 - INFO - Fold 3, Epoch 210: Val Acc: 0.88%
2025-08-14 23:08:26,676 - INFO - Fold 3, Epoch 220: Val Acc: 0.78%
2025-08-14 23:08:28,877 - INFO - Fold 3, Epoch 230: Val Acc: 0.75%
2025-08-14 23:08:31,003 - INFO - Fold 3, Epoch 240: Val Acc: 0.50%
2025-08-14 23:08:31,811 - INFO - Early stopping at epoch 244
2025-08-14 23:08:32,880 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.8374694188435874), 'std': np.float64(0.09563317877845734)}, 'train_accuracy': {'mean': np.float64(0.8055555555555557), 'std': np.float64(0.03220006422047115)}, 'val_loss': {'mean': np.float64(4.248658816019694), 'std': np.float64(0.05092559471536373)}, 'val_accuracy': {'mean': np.float64(0.9270833333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(120.66666666666667), 'std': np.float64(26.78722747048592)}}
[I 2025-08-14 23:08:32,886] Trial 83 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0008105175983317972, 'batch_size': 32, 'num_epochs': 891, 'temperature': 0.32582879330725417, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4447421907613134, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0388647093370367, 'crop_size': 0.5297065357916201}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 83 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0008105175983317972, 'batch_size': 32, 'num_epochs': 891, 'temperature': 0.32582879330725417, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4447421907613134, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0388647093370367, 'crop_size': 0.5297065357916201}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 23:08:32,919 - INFO - Using device: cuda
2025-08-14 23:08:42,793 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:08:42,795 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:08:42,795 - INFO - Starting training for fold 1/3
2025-08-14 23:08:54,062 - INFO - Fold 1, Epoch 10: Val Acc: 0.69%
2025-08-14 23:08:56,291 - INFO - Fold 1, Epoch 20: Val Acc: 0.66%
2025-08-14 23:09:00,621 - INFO - Fold 1, Epoch 30: Val Acc: 0.66%
2025-08-14 23:09:07,292 - INFO - Fold 1, Epoch 40: Val Acc: 0.88%
2025-08-14 23:09:09,566 - INFO - Fold 1, Epoch 50: Val Acc: 0.78%
2025-08-14 23:09:11,927 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-14 23:09:14,343 - INFO - Fold 1, Epoch 70: Val Acc: 0.69%
2025-08-14 23:09:16,730 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-14 23:09:18,665 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-14 23:09:21,089 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-14 23:09:23,107 - INFO - Fold 1, Epoch 110: Val Acc: 0.81%
2025-08-14 23:09:25,131 - INFO - Fold 1, Epoch 120: Val Acc: 0.81%
2025-08-14 23:09:27,550 - INFO - Fold 1, Epoch 130: Val Acc: 0.78%
2025-08-14 23:09:29,809 - INFO - Early stopping at epoch 140
2025-08-14 23:09:33,364 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:09:33,376 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:09:33,381 - INFO - Starting training for fold 2/3
2025-08-14 23:09:40,117 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-14 23:09:44,156 - INFO - Fold 2, Epoch 20: Val Acc: 0.69%
2025-08-14 23:09:49,504 - INFO - Fold 2, Epoch 30: Val Acc: 0.81%
2025-08-14 23:09:51,907 - INFO - Fold 2, Epoch 40: Val Acc: 0.62%
2025-08-14 23:09:53,842 - INFO - Fold 2, Epoch 50: Val Acc: 0.72%
2025-08-14 23:09:55,823 - INFO - Fold 2, Epoch 60: Val Acc: 0.81%
2025-08-14 23:09:59,464 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-14 23:10:01,786 - INFO - Fold 2, Epoch 80: Val Acc: 0.88%
2025-08-14 23:10:04,102 - INFO - Fold 2, Epoch 90: Val Acc: 0.66%
2025-08-14 23:10:06,407 - INFO - Fold 2, Epoch 100: Val Acc: 0.69%
2025-08-14 23:10:08,804 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-14 23:10:11,202 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-14 23:10:13,546 - INFO - Fold 2, Epoch 130: Val Acc: 0.72%
2025-08-14 23:10:15,788 - INFO - Fold 2, Epoch 140: Val Acc: 0.84%
2025-08-14 23:10:18,007 - INFO - Fold 2, Epoch 150: Val Acc: 0.78%
2025-08-14 23:10:20,314 - INFO - Fold 2, Epoch 160: Val Acc: 0.66%
2025-08-14 23:10:21,230 - INFO - Early stopping at epoch 164
2025-08-14 23:10:24,146 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:10:24,148 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:10:24,148 - INFO - Starting training for fold 3/3
2025-08-14 23:10:30,992 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-14 23:10:34,623 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-14 23:10:39,959 - INFO - Fold 3, Epoch 30: Val Acc: 0.62%
2025-08-14 23:10:43,589 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-14 23:10:45,809 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-14 23:10:48,040 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-14 23:10:50,222 - INFO - Fold 3, Epoch 70: Val Acc: 0.81%
2025-08-14 23:10:52,449 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-14 23:10:56,187 - INFO - Fold 3, Epoch 90: Val Acc: 0.66%
2025-08-14 23:10:58,409 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-14 23:11:00,614 - INFO - Fold 3, Epoch 110: Val Acc: 0.72%
2025-08-14 23:11:02,851 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-14 23:11:05,079 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-14 23:11:07,322 - INFO - Fold 3, Epoch 140: Val Acc: 0.75%
2025-08-14 23:11:09,577 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-14 23:11:11,812 - INFO - Fold 3, Epoch 160: Val Acc: 0.81%
2025-08-14 23:11:14,021 - INFO - Fold 3, Epoch 170: Val Acc: 0.56%
2025-08-14 23:11:16,241 - INFO - Fold 3, Epoch 180: Val Acc: 0.75%
2025-08-14 23:11:18,011 - INFO - Early stopping at epoch 188
2025-08-14 23:11:21,017 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.945670869615343), 'std': np.float64(0.019393318188007116)}, 'train_accuracy': {'mean': np.float64(0.7569444444444443), 'std': np.float64(0.019641855032959583)}, 'val_loss': {'mean': np.float64(4.21728499730428), 'std': np.float64(0.006058088296927387)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(63.0), 'std': np.float64(19.595917942265423)}}
[I 2025-08-14 23:11:21,040] Trial 84 finished with value: -0.90625 and parameters: {'learning_rate': 0.0008812795600231797, 'batch_size': 32, 'num_epochs': 892, 'temperature': 0.37269003347770774, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.44936492815695617, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0787611233096378, 'crop_size': 0.5286362031455586}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 84 finished with value: -0.90625 and parameters: {'learning_rate': 0.0008812795600231797, 'batch_size': 32, 'num_epochs': 892, 'temperature': 0.37269003347770774, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.44936492815695617, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0787611233096378, 'crop_size': 0.5286362031455586}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 23:11:21,120 - INFO - Using device: cuda
2025-08-14 23:11:31,109 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:11:31,111 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:11:31,111 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-14 23:11:38,067 - INFO - Fold 1, Epoch 10: Val Acc: 0.41%
2025-08-14 23:11:42,723 - INFO - Fold 1, Epoch 20: Val Acc: 0.53%
2025-08-14 23:11:49,577 - INFO - Fold 1, Epoch 30: Val Acc: 0.75%
2025-08-14 23:11:54,227 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-14 23:11:58,806 - INFO - Fold 1, Epoch 50: Val Acc: 0.72%
2025-08-14 23:12:05,721 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-14 23:12:08,041 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-14 23:12:10,356 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-14 23:12:12,669 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-14 23:12:14,998 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-14 23:12:17,290 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-14 23:12:19,582 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-14 23:12:21,882 - INFO - Fold 1, Epoch 130: Val Acc: 0.75%
2025-08-14 23:12:24,192 - INFO - Fold 1, Epoch 140: Val Acc: 0.66%
2025-08-14 23:12:26,500 - INFO - Fold 1, Epoch 150: Val Acc: 0.69%
2025-08-14 23:12:28,106 - INFO - Early stopping at epoch 157
2025-08-14 23:12:31,683 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:12:31,686 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:12:31,686 - INFO - Starting training for fold 2/3
2025-08-14 23:12:39,735 - INFO - Fold 2, Epoch 10: Val Acc: 0.62%
2025-08-14 23:12:45,025 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-14 23:12:49,798 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-14 23:12:53,444 - INFO - Fold 2, Epoch 40: Val Acc: 0.81%
2025-08-14 23:12:55,682 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-14 23:12:59,320 - INFO - Fold 2, Epoch 60: Val Acc: 0.69%
2025-08-14 23:13:01,539 - INFO - Fold 2, Epoch 70: Val Acc: 0.81%
2025-08-14 23:13:03,757 - INFO - Fold 2, Epoch 80: Val Acc: 0.62%
2025-08-14 23:13:05,976 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-14 23:13:08,198 - INFO - Fold 2, Epoch 100: Val Acc: 0.62%
2025-08-14 23:13:10,502 - INFO - Fold 2, Epoch 110: Val Acc: 0.78%
2025-08-14 23:13:12,754 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-14 23:13:14,987 - INFO - Fold 2, Epoch 130: Val Acc: 0.59%
2025-08-14 23:13:17,201 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-14 23:13:19,430 - INFO - Fold 2, Epoch 150: Val Acc: 0.81%
2025-08-14 23:13:21,197 - INFO - Early stopping at epoch 158
2025-08-14 23:13:22,275 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:13:22,277 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:13:22,277 - INFO - Starting training for fold 3/3
2025-08-14 23:13:29,091 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-14 23:13:32,810 - INFO - Fold 3, Epoch 20: Val Acc: 0.66%
2025-08-14 23:13:37,863 - INFO - Fold 3, Epoch 30: Val Acc: 0.62%
2025-08-14 23:13:41,564 - INFO - Fold 3, Epoch 40: Val Acc: 0.84%
2025-08-14 23:13:43,863 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-14 23:13:46,098 - INFO - Fold 3, Epoch 60: Val Acc: 0.72%
2025-08-14 23:13:48,334 - INFO - Fold 3, Epoch 70: Val Acc: 0.84%
2025-08-14 23:13:50,576 - INFO - Fold 3, Epoch 80: Val Acc: 0.66%
2025-08-14 23:13:54,250 - INFO - Fold 3, Epoch 90: Val Acc: 0.56%
2025-08-14 23:13:57,760 - INFO - Fold 3, Epoch 100: Val Acc: 0.78%
2025-08-14 23:13:59,824 - INFO - Fold 3, Epoch 110: Val Acc: 0.81%
2025-08-14 23:14:01,814 - INFO - Fold 3, Epoch 120: Val Acc: 0.84%
2025-08-14 23:14:04,051 - INFO - Fold 3, Epoch 130: Val Acc: 0.66%
2025-08-14 23:14:06,366 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-14 23:14:08,689 - INFO - Fold 3, Epoch 150: Val Acc: 0.56%
2025-08-14 23:14:10,912 - INFO - Fold 3, Epoch 160: Val Acc: 0.78%
2025-08-14 23:14:13,160 - INFO - Fold 3, Epoch 170: Val Acc: 0.66%
2025-08-14 23:14:15,445 - INFO - Fold 3, Epoch 180: Val Acc: 0.78%
2025-08-14 23:14:17,701 - INFO - Fold 3, Epoch 190: Val Acc: 0.75%
2025-08-14 23:14:19,111 - INFO - Early stopping at epoch 197
2025-08-14 23:14:20,145 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9387081993950734), 'std': np.float64(0.041283321162313404)}, 'train_accuracy': {'mean': np.float64(0.7708333333333334), 'std': np.float64(0.030665836341416113)}, 'val_loss': {'mean': np.float64(4.257309118906657), 'std': np.float64(0.010204222360329387)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(69.66666666666667), 'std': np.float64(18.624953392931992)}}
[I 2025-08-14 23:14:20,152] Trial 85 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0009964930569107075, 'batch_size': 32, 'num_epochs': 925, 'temperature': 0.32944146140942887, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4253012126771004, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.05023971740661305, 'crop_size': 0.5140783535148626}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 85 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0009964930569107075, 'batch_size': 32, 'num_epochs': 925, 'temperature': 0.32944146140942887, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4253012126771004, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.05023971740661305, 'crop_size': 0.5140783535148626}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 23:14:20,185 - INFO - Using device: cuda
2025-08-14 23:14:30,557 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:14:30,568 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:14:30,568 - INFO - Starting training for fold 1/3
2025-08-14 23:14:40,829 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-14 23:14:48,204 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-14 23:14:50,662 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 23:14:55,742 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-14 23:14:58,183 - INFO - Fold 1, Epoch 50: Val Acc: 0.78%
2025-08-14 23:15:03,395 - INFO - Fold 1, Epoch 60: Val Acc: 0.59%
2025-08-14 23:15:05,848 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-14 23:15:08,221 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-14 23:15:10,088 - INFO - Fold 1, Epoch 90: Val Acc: 0.66%
2025-08-14 23:15:12,341 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-14 23:15:14,782 - INFO - Fold 1, Epoch 110: Val Acc: 0.72%
2025-08-14 23:15:17,226 - INFO - Fold 1, Epoch 120: Val Acc: 0.72%
2025-08-14 23:15:19,684 - INFO - Fold 1, Epoch 130: Val Acc: 0.66%
2025-08-14 23:15:22,137 - INFO - Fold 1, Epoch 140: Val Acc: 0.62%
2025-08-14 23:15:24,590 - INFO - Fold 1, Epoch 150: Val Acc: 0.72%
2025-08-14 23:15:26,303 - INFO - Early stopping at epoch 157
2025-08-14 23:15:30,018 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:15:30,030 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:15:30,031 - INFO - Starting training for fold 2/3
2025-08-14 23:15:37,471 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-14 23:15:45,116 - INFO - Fold 2, Epoch 20: Val Acc: 0.62%
2025-08-14 23:15:47,633 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-14 23:15:51,764 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-14 23:15:54,215 - INFO - Fold 2, Epoch 50: Val Acc: 0.84%
2025-08-14 23:15:56,652 - INFO - Fold 2, Epoch 60: Val Acc: 0.69%
2025-08-14 23:15:59,083 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-14 23:16:03,143 - INFO - Fold 2, Epoch 80: Val Acc: 0.72%
2025-08-14 23:16:05,006 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-14 23:16:06,870 - INFO - Fold 2, Epoch 100: Val Acc: 0.59%
2025-08-14 23:16:08,802 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-14 23:16:10,661 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-14 23:16:12,797 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-14 23:16:14,828 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-14 23:16:17,316 - INFO - Fold 2, Epoch 150: Val Acc: 0.91%
2025-08-14 23:16:19,785 - INFO - Fold 2, Epoch 160: Val Acc: 0.75%
2025-08-14 23:16:22,233 - INFO - Fold 2, Epoch 170: Val Acc: 0.81%
2025-08-14 23:16:23,246 - INFO - Early stopping at epoch 174
2025-08-14 23:16:26,378 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:16:26,381 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:16:26,381 - INFO - Starting training for fold 3/3
2025-08-14 23:16:34,081 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-14 23:16:36,641 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-14 23:16:39,165 - INFO - Fold 3, Epoch 30: Val Acc: 0.78%
2025-08-14 23:16:41,687 - INFO - Fold 3, Epoch 40: Val Acc: 0.72%
2025-08-14 23:16:45,833 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-14 23:16:49,869 - INFO - Fold 3, Epoch 60: Val Acc: 0.88%
2025-08-14 23:16:52,481 - INFO - Fold 3, Epoch 70: Val Acc: 0.84%
2025-08-14 23:16:54,990 - INFO - Fold 3, Epoch 80: Val Acc: 0.69%
2025-08-14 23:16:57,433 - INFO - Fold 3, Epoch 90: Val Acc: 0.84%
2025-08-14 23:16:59,874 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-14 23:17:02,328 - INFO - Fold 3, Epoch 110: Val Acc: 0.81%
2025-08-14 23:17:04,787 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-14 23:17:07,261 - INFO - Fold 3, Epoch 130: Val Acc: 0.59%
2025-08-14 23:17:09,825 - INFO - Fold 3, Epoch 140: Val Acc: 0.66%
2025-08-14 23:17:12,395 - INFO - Fold 3, Epoch 150: Val Acc: 0.75%
2025-08-14 23:17:15,025 - INFO - Early stopping at epoch 160
2025-08-14 23:17:16,298 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9206065866682263), 'std': np.float64(0.018406263711943895)}, 'train_accuracy': {'mean': np.float64(0.7152777777777778), 'std': np.float64(0.024552318791199557)}, 'val_loss': {'mean': np.float64(4.213697115580241), 'std': np.float64(0.08035891436724407)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(62.666666666666664), 'std': np.float64(7.408703590297622)}}
[I 2025-08-14 23:17:16,305] Trial 86 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0008021744569060321, 'batch_size': 32, 'num_epochs': 964, 'temperature': 0.27368630873958677, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3092371122351169, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06295819085040885, 'crop_size': 0.5477361605591952}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 86 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0008021744569060321, 'batch_size': 32, 'num_epochs': 964, 'temperature': 0.27368630873958677, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3092371122351169, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06295819085040885, 'crop_size': 0.5477361605591952}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 23:17:16,339 - INFO - Using device: cuda
2025-08-14 23:17:26,144 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:17:26,145 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:17:26,145 - INFO - Starting training for fold 1/3
2025-08-14 23:17:31,683 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-14 23:17:33,834 - INFO - Fold 1, Epoch 20: Val Acc: 0.47%
2025-08-14 23:17:35,878 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 23:17:39,693 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-14 23:17:41,811 - INFO - Fold 1, Epoch 50: Val Acc: 0.56%
2025-08-14 23:17:45,591 - INFO - Fold 1, Epoch 60: Val Acc: 0.47%
2025-08-14 23:17:47,636 - INFO - Fold 1, Epoch 70: Val Acc: 0.44%
2025-08-14 23:17:49,639 - INFO - Fold 1, Epoch 80: Val Acc: 0.47%
2025-08-14 23:17:51,679 - INFO - Fold 1, Epoch 90: Val Acc: 0.50%
2025-08-14 23:17:53,715 - INFO - Fold 1, Epoch 100: Val Acc: 0.41%
2025-08-14 23:17:55,640 - INFO - Fold 1, Epoch 110: Val Acc: 0.50%
2025-08-14 23:17:57,552 - INFO - Fold 1, Epoch 120: Val Acc: 0.53%
2025-08-14 23:17:59,251 - INFO - Fold 1, Epoch 130: Val Acc: 0.41%
2025-08-14 23:18:01,298 - INFO - Fold 1, Epoch 140: Val Acc: 0.53%
2025-08-14 23:18:03,337 - INFO - Fold 1, Epoch 150: Val Acc: 0.44%
2025-08-14 23:18:04,153 - INFO - Early stopping at epoch 154
2025-08-14 23:18:06,939 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:18:06,941 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:18:06,941 - INFO - Starting training for fold 2/3
2025-08-14 23:18:11,607 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-14 23:18:13,736 - INFO - Fold 2, Epoch 20: Val Acc: 0.41%
2025-08-14 23:18:17,036 - INFO - Fold 2, Epoch 30: Val Acc: 0.50%
2025-08-14 23:18:19,095 - INFO - Fold 2, Epoch 40: Val Acc: 0.44%
2025-08-14 23:18:21,151 - INFO - Fold 2, Epoch 50: Val Acc: 0.56%
2025-08-14 23:18:23,217 - INFO - Fold 2, Epoch 60: Val Acc: 0.44%
2025-08-14 23:18:25,281 - INFO - Fold 2, Epoch 70: Val Acc: 0.53%
2025-08-14 23:18:27,328 - INFO - Fold 2, Epoch 80: Val Acc: 0.47%
2025-08-14 23:18:29,394 - INFO - Fold 2, Epoch 90: Val Acc: 0.41%
2025-08-14 23:18:31,445 - INFO - Fold 2, Epoch 100: Val Acc: 0.53%
2025-08-14 23:18:33,548 - INFO - Fold 2, Epoch 110: Val Acc: 0.47%
2025-08-14 23:18:35,660 - INFO - Fold 2, Epoch 120: Val Acc: 0.50%
2025-08-14 23:18:37,121 - INFO - Early stopping at epoch 127
2025-08-14 23:18:37,985 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:18:37,987 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:18:37,987 - INFO - Starting training for fold 3/3
2025-08-14 23:18:42,668 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-14 23:18:44,719 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-14 23:18:46,757 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-14 23:18:48,522 - INFO - Fold 3, Epoch 40: Val Acc: 0.56%
2025-08-14 23:18:50,382 - INFO - Fold 3, Epoch 50: Val Acc: 0.38%
2025-08-14 23:18:53,646 - INFO - Fold 3, Epoch 60: Val Acc: 0.50%
2025-08-14 23:18:55,679 - INFO - Fold 3, Epoch 70: Val Acc: 0.47%
2025-08-14 23:18:57,710 - INFO - Fold 3, Epoch 80: Val Acc: 0.56%
2025-08-14 23:18:59,747 - INFO - Fold 3, Epoch 90: Val Acc: 0.53%
2025-08-14 23:19:01,792 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-14 23:19:03,837 - INFO - Fold 3, Epoch 110: Val Acc: 0.47%
2025-08-14 23:19:05,893 - INFO - Fold 3, Epoch 120: Val Acc: 0.53%
2025-08-14 23:19:07,952 - INFO - Fold 3, Epoch 130: Val Acc: 0.41%
2025-08-14 23:19:10,024 - INFO - Fold 3, Epoch 140: Val Acc: 0.53%
2025-08-14 23:19:12,049 - INFO - Fold 3, Epoch 150: Val Acc: 0.47%
2025-08-14 23:19:13,322 - INFO - Early stopping at epoch 156
2025-08-14 23:19:15,770 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.156563440958659), 'std': np.float64(0.021090523749672394)}, 'train_accuracy': {'mean': np.float64(0.5833333333333334), 'std': np.float64(0.030665836341416113)}, 'val_loss': {'mean': np.float64(4.167566140492757), 'std': np.float64(0.018464452820016578)}, 'val_accuracy': {'mean': np.float64(0.6666666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(44.666666666666664), 'std': np.float64(13.224556283251582)}}
[I 2025-08-14 23:19:15,779] Trial 87 finished with value: -0.6666666666666666 and parameters: {'learning_rate': 0.000752580003236727, 'batch_size': 32, 'num_epochs': 864, 'temperature': 0.4151053768498774, 'embedding_dim': 128, 'hidden_dim': 128, 'dropout': 0.4383642676219941, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.029630570681475003, 'crop_size': 0.8853160642245878}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 87 finished with value: -0.6666666666666666 and parameters: {'learning_rate': 0.000752580003236727, 'batch_size': 32, 'num_epochs': 864, 'temperature': 0.4151053768498774, 'embedding_dim': 128, 'hidden_dim': 128, 'dropout': 0.4383642676219941, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.029630570681475003, 'crop_size': 0.8853160642245878}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 23:19:15,859 - INFO - Using device: cuda
2025-08-14 23:19:26,015 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:19:26,016 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:19:26,016 - WARNING - Fold 1 has insufficient pairs to form a batch. Skipping.
2025-08-14 23:19:26,017 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:19:26,018 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:19:26,018 - WARNING - Fold 2 has insufficient pairs to form a batch. Skipping.
2025-08-14 23:19:26,018 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:19:26,019 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:19:26,019 - WARNING - Fold 3 has insufficient pairs to form a batch. Skipping.
2025-08-14 23:19:26,019 - WARNING - No folds completed successfully to aggregate metrics.
[I 2025-08-14 23:19:26,022] Trial 88 finished with value: inf and parameters: {'learning_rate': 0.0004949224720321423, 'batch_size': 64, 'num_epochs': 891, 'temperature': 0.39325813523736053, 'embedding_dim': 128, 'hidden_dim': 512, 'dropout': 0.39180082275016925, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08311682857580138, 'crop_size': 0.5264666793810785}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 88 finished with value: inf and parameters: {'learning_rate': 0.0004949224720321423, 'batch_size': 64, 'num_epochs': 891, 'temperature': 0.39325813523736053, 'embedding_dim': 128, 'hidden_dim': 512, 'dropout': 0.39180082275016925, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08311682857580138, 'crop_size': 0.5264666793810785}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 23:19:26,056 - INFO - Using device: cuda
2025-08-14 23:19:35,846 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:19:35,848 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:19:35,848 - INFO - Starting training for fold 1/3
2025-08-14 23:19:45,095 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-14 23:19:49,860 - INFO - Fold 1, Epoch 20: Val Acc: 0.69%
2025-08-14 23:19:54,351 - INFO - Fold 1, Epoch 30: Val Acc: 0.58%
2025-08-14 23:19:59,092 - INFO - Fold 1, Epoch 40: Val Acc: 0.73%
2025-08-14 23:20:06,201 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-14 23:20:08,778 - INFO - Fold 1, Epoch 60: Val Acc: 0.71%
2025-08-14 23:20:11,476 - INFO - Fold 1, Epoch 70: Val Acc: 0.81%
2025-08-14 23:20:14,447 - INFO - Fold 1, Epoch 80: Val Acc: 0.71%
2025-08-14 23:20:19,515 - INFO - Fold 1, Epoch 90: Val Acc: 0.73%
2025-08-14 23:20:23,027 - INFO - Fold 1, Epoch 100: Val Acc: 0.67%
2025-08-14 23:20:26,505 - INFO - Fold 1, Epoch 110: Val Acc: 0.73%
2025-08-14 23:20:29,817 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-14 23:20:32,744 - INFO - Fold 1, Epoch 130: Val Acc: 0.71%
2025-08-14 23:20:36,117 - INFO - Fold 1, Epoch 140: Val Acc: 0.60%
2025-08-14 23:20:39,444 - INFO - Fold 1, Epoch 150: Val Acc: 0.83%
2025-08-14 23:20:42,822 - INFO - Fold 1, Epoch 160: Val Acc: 0.60%
2025-08-14 23:20:45,983 - INFO - Fold 1, Epoch 170: Val Acc: 0.67%
2025-08-14 23:20:49,231 - INFO - Fold 1, Epoch 180: Val Acc: 0.77%
2025-08-14 23:20:50,920 - INFO - Early stopping at epoch 185
2025-08-14 23:20:53,834 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:20:53,837 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:20:53,838 - INFO - Starting training for fold 2/3
2025-08-14 23:20:59,998 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-14 23:21:07,095 - INFO - Fold 2, Epoch 20: Val Acc: 0.62%
2025-08-14 23:21:14,757 - INFO - Fold 2, Epoch 30: Val Acc: 0.71%
2025-08-14 23:21:18,401 - INFO - Fold 2, Epoch 40: Val Acc: 0.73%
2025-08-14 23:21:22,773 - INFO - Fold 2, Epoch 50: Val Acc: 0.71%
2025-08-14 23:21:26,777 - INFO - Fold 2, Epoch 60: Val Acc: 0.81%
2025-08-14 23:21:30,179 - INFO - Fold 2, Epoch 70: Val Acc: 0.81%
2025-08-14 23:21:33,534 - INFO - Fold 2, Epoch 80: Val Acc: 0.67%
2025-08-14 23:21:36,957 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-14 23:21:40,406 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-14 23:21:43,404 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-14 23:21:46,665 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-14 23:21:50,146 - INFO - Fold 2, Epoch 130: Val Acc: 0.85%
2025-08-14 23:21:53,336 - INFO - Fold 2, Epoch 140: Val Acc: 0.69%
2025-08-14 23:21:56,547 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-14 23:21:59,047 - INFO - Early stopping at epoch 159
2025-08-14 23:22:01,723 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:22:01,726 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:22:01,726 - INFO - Starting training for fold 3/3
2025-08-14 23:22:07,967 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-14 23:22:13,945 - INFO - Fold 3, Epoch 20: Val Acc: 0.58%
2025-08-14 23:22:19,833 - INFO - Fold 3, Epoch 30: Val Acc: 0.71%
2025-08-14 23:22:22,918 - INFO - Fold 3, Epoch 40: Val Acc: 0.67%
2025-08-14 23:22:26,014 - INFO - Fold 3, Epoch 50: Val Acc: 0.62%
2025-08-14 23:22:28,446 - INFO - Fold 3, Epoch 60: Val Acc: 0.69%
2025-08-14 23:22:30,880 - INFO - Fold 3, Epoch 70: Val Acc: 0.71%
2025-08-14 23:22:33,315 - INFO - Fold 3, Epoch 80: Val Acc: 0.71%
2025-08-14 23:22:36,761 - INFO - Fold 3, Epoch 90: Val Acc: 0.88%
2025-08-14 23:22:39,782 - INFO - Fold 3, Epoch 100: Val Acc: 0.77%
2025-08-14 23:22:43,147 - INFO - Fold 3, Epoch 110: Val Acc: 0.79%
2025-08-14 23:22:46,510 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-14 23:22:50,027 - INFO - Fold 3, Epoch 130: Val Acc: 0.77%
2025-08-14 23:22:53,526 - INFO - Fold 3, Epoch 140: Val Acc: 0.69%
2025-08-14 23:22:56,962 - INFO - Fold 3, Epoch 150: Val Acc: 0.71%
2025-08-14 23:23:00,466 - INFO - Fold 3, Epoch 160: Val Acc: 0.62%
2025-08-14 23:23:03,864 - INFO - Fold 3, Epoch 170: Val Acc: 0.75%
2025-08-14 23:23:07,240 - INFO - Fold 3, Epoch 180: Val Acc: 0.69%
2025-08-14 23:23:10,702 - INFO - Early stopping at epoch 190
2025-08-14 23:23:11,549 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.2438840733634096), 'std': np.float64(0.014812346316840768)}, 'train_accuracy': {'mean': np.float64(0.7951388888888888), 'std': np.float64(0.009820927516479817)}, 'val_loss': {'mean': np.float64(3.5507686403062606), 'std': np.float64(0.032864321678333135)}, 'val_accuracy': {'mean': np.float64(0.888888888888889), 'std': np.float64(0.01964185503295969)}, 'epoch': {'mean': np.float64(77.0), 'std': np.float64(13.589211407093005)}}
[I 2025-08-14 23:23:11,556] Trial 89 finished with value: -0.888888888888889 and parameters: {'learning_rate': 0.0006799445715016386, 'batch_size': 16, 'num_epochs': 988, 'temperature': 0.45945348345172105, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4080721975996448, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.045447304168501276, 'crop_size': 0.5693263019199052}. Best is trial 9 with value: -0.9270833333333334.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 89 finished with value: -0.888888888888889 and parameters: {'learning_rate': 0.0006799445715016386, 'batch_size': 16, 'num_epochs': 988, 'temperature': 0.45945348345172105, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4080721975996448, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.045447304168501276, 'crop_size': 0.5693263019199052}. Best is trial 9 with value: -0.9270833333333334.
2025-08-14 23:23:11,589 - INFO - Using device: cuda
2025-08-14 23:23:21,550 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:23:21,551 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:23:21,551 - INFO - Starting training for fold 1/3
2025-08-14 23:23:33,081 - INFO - Fold 1, Epoch 10: Val Acc: 0.72%
2025-08-14 23:23:39,746 - INFO - Fold 1, Epoch 20: Val Acc: 0.81%
2025-08-14 23:23:42,147 - INFO - Fold 1, Epoch 30: Val Acc: 0.75%
2025-08-14 23:23:46,494 - INFO - Fold 1, Epoch 40: Val Acc: 0.81%
2025-08-14 23:23:48,777 - INFO - Fold 1, Epoch 50: Val Acc: 0.72%
2025-08-14 23:23:53,368 - INFO - Fold 1, Epoch 60: Val Acc: 0.75%
2025-08-14 23:23:55,639 - INFO - Fold 1, Epoch 70: Val Acc: 0.75%
2025-08-14 23:23:57,867 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-14 23:24:00,088 - INFO - Fold 1, Epoch 90: Val Acc: 0.81%
2025-08-14 23:24:02,308 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-14 23:24:04,523 - INFO - Fold 1, Epoch 110: Val Acc: 0.88%
2025-08-14 23:24:06,772 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-14 23:24:09,075 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-14 23:24:11,386 - INFO - Fold 1, Epoch 140: Val Acc: 0.69%
2025-08-14 23:24:13,569 - INFO - Fold 1, Epoch 150: Val Acc: 0.75%
2025-08-14 23:24:15,189 - INFO - Early stopping at epoch 157
2025-08-14 23:24:18,757 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:24:18,760 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:24:18,761 - INFO - Starting training for fold 2/3
2025-08-14 23:24:22,702 - INFO - Fold 2, Epoch 10: Val Acc: 0.47%
2025-08-14 23:24:29,127 - INFO - Fold 2, Epoch 20: Val Acc: 0.81%
2025-08-14 23:24:31,435 - INFO - Fold 2, Epoch 30: Val Acc: 0.81%
2025-08-14 23:24:35,207 - INFO - Fold 2, Epoch 40: Val Acc: 0.62%
2025-08-14 23:24:37,446 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-14 23:24:41,162 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-14 23:24:43,385 - INFO - Fold 2, Epoch 70: Val Acc: 0.88%
2025-08-14 23:24:45,608 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-14 23:24:47,841 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-14 23:24:50,072 - INFO - Fold 2, Epoch 100: Val Acc: 0.72%
2025-08-14 23:24:52,281 - INFO - Fold 2, Epoch 110: Val Acc: 0.66%
2025-08-14 23:24:54,498 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-14 23:24:56,710 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-14 23:24:58,924 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-14 23:25:01,138 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-14 23:25:01,358 - INFO - Early stopping at epoch 151
2025-08-14 23:25:02,423 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:25:02,425 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:25:02,425 - INFO - Starting training for fold 3/3
2025-08-14 23:25:07,733 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-14 23:25:14,394 - INFO - Fold 3, Epoch 20: Val Acc: 0.66%
2025-08-14 23:25:16,611 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-14 23:25:18,837 - INFO - Fold 3, Epoch 40: Val Acc: 0.78%
2025-08-14 23:25:21,064 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-14 23:25:23,283 - INFO - Fold 3, Epoch 60: Val Acc: 0.78%
2025-08-14 23:25:25,603 - INFO - Fold 3, Epoch 70: Val Acc: 0.75%
2025-08-14 23:25:27,915 - INFO - Fold 3, Epoch 80: Val Acc: 0.66%
2025-08-14 23:25:31,742 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-14 23:25:34,130 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-14 23:25:36,362 - INFO - Fold 3, Epoch 110: Val Acc: 0.69%
2025-08-14 23:25:38,623 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-14 23:25:42,087 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-14 23:25:44,185 - INFO - Fold 3, Epoch 140: Val Acc: 0.62%
2025-08-14 23:25:45,985 - INFO - Fold 3, Epoch 150: Val Acc: 0.78%
2025-08-14 23:25:47,781 - INFO - Fold 3, Epoch 160: Val Acc: 0.88%
2025-08-14 23:25:49,577 - INFO - Fold 3, Epoch 170: Val Acc: 0.75%
2025-08-14 23:25:51,375 - INFO - Fold 3, Epoch 180: Val Acc: 0.66%
2025-08-14 23:25:53,605 - INFO - Fold 3, Epoch 190: Val Acc: 0.59%
2025-08-14 23:25:55,899 - INFO - Fold 3, Epoch 200: Val Acc: 0.78%
2025-08-14 23:25:57,605 - INFO - Fold 3, Epoch 210: Val Acc: 0.78%
2025-08-14 23:25:59,566 - INFO - Fold 3, Epoch 220: Val Acc: 0.66%
2025-08-14 23:26:00,007 - INFO - Early stopping at epoch 222
2025-08-14 23:26:01,066 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9318211608462863), 'std': np.float64(0.02871549192640392)}, 'train_accuracy': {'mean': np.float64(0.7604166666666666), 'std': np.float64(0.017010345435994324)}, 'val_loss': {'mean': np.float64(4.2997260093688965), 'std': np.float64(0.06822858622594909)}, 'val_accuracy': {'mean': np.float64(0.9375), 'std': np.float64(0.0)}, 'epoch': {'mean': np.float64(75.66666666666667), 'std': np.float64(32.14895885647863)}}
[I 2025-08-14 23:26:01,072] Trial 90 finished with value: -0.9375 and parameters: {'learning_rate': 0.0005651198764447992, 'batch_size': 32, 'num_epochs': 392, 'temperature': 0.36350117996633236, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4830043619829427, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.10106895320384918, 'crop_size': 0.5410111325780634}. Best is trial 90 with value: -0.9375.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 90 finished with value: -0.9375 and parameters: {'learning_rate': 0.0005651198764447992, 'batch_size': 32, 'num_epochs': 392, 'temperature': 0.36350117996633236, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4830043619829427, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.10106895320384918, 'crop_size': 0.5410111325780634}. Best is trial 90 with value: -0.9375.
2025-08-14 23:26:01,106 - INFO - Using device: cuda
2025-08-14 23:26:11,123 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:26:11,125 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:26:11,125 - INFO - Starting training for fold 1/3
2025-08-14 23:26:20,169 - INFO - Fold 1, Epoch 10: Val Acc: 0.66%
2025-08-14 23:26:24,446 - INFO - Fold 1, Epoch 20: Val Acc: 0.72%
2025-08-14 23:26:28,313 - INFO - Fold 1, Epoch 30: Val Acc: 0.66%
2025-08-14 23:26:30,016 - INFO - Fold 1, Epoch 40: Val Acc: 0.75%
2025-08-14 23:26:34,131 - INFO - Fold 1, Epoch 50: Val Acc: 0.72%
2025-08-14 23:26:38,201 - INFO - Fold 1, Epoch 60: Val Acc: 0.75%
2025-08-14 23:26:39,909 - INFO - Fold 1, Epoch 70: Val Acc: 0.62%
2025-08-14 23:26:41,851 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-14 23:26:44,081 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-14 23:26:46,308 - INFO - Fold 1, Epoch 100: Val Acc: 0.66%
2025-08-14 23:26:48,538 - INFO - Fold 1, Epoch 110: Val Acc: 0.72%
2025-08-14 23:26:50,769 - INFO - Fold 1, Epoch 120: Val Acc: 0.81%
2025-08-14 23:26:53,082 - INFO - Fold 1, Epoch 130: Val Acc: 0.66%
2025-08-14 23:26:55,378 - INFO - Fold 1, Epoch 140: Val Acc: 0.81%
2025-08-14 23:26:57,686 - INFO - Fold 1, Epoch 150: Val Acc: 0.72%
2025-08-14 23:26:58,835 - INFO - Early stopping at epoch 155
2025-08-14 23:27:02,613 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:27:02,616 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:27:02,616 - INFO - Starting training for fold 2/3
2025-08-14 23:27:09,601 - INFO - Fold 2, Epoch 10: Val Acc: 0.59%
2025-08-14 23:27:13,272 - INFO - Fold 2, Epoch 20: Val Acc: 0.62%
2025-08-14 23:27:18,467 - INFO - Fold 2, Epoch 30: Val Acc: 0.78%
2025-08-14 23:27:22,239 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-14 23:27:24,454 - INFO - Fold 2, Epoch 50: Val Acc: 0.66%
2025-08-14 23:27:26,671 - INFO - Fold 2, Epoch 60: Val Acc: 0.62%
2025-08-14 23:27:28,888 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-14 23:27:31,098 - INFO - Fold 2, Epoch 80: Val Acc: 0.72%
2025-08-14 23:27:34,625 - INFO - Fold 2, Epoch 90: Val Acc: 0.88%
2025-08-14 23:27:36,904 - INFO - Fold 2, Epoch 100: Val Acc: 0.81%
2025-08-14 23:27:39,098 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-14 23:27:41,025 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-14 23:27:43,198 - INFO - Fold 2, Epoch 130: Val Acc: 0.81%
2025-08-14 23:27:45,388 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-14 23:27:47,549 - INFO - Fold 2, Epoch 150: Val Acc: 0.81%
2025-08-14 23:27:49,768 - INFO - Fold 2, Epoch 160: Val Acc: 0.72%
2025-08-14 23:27:51,995 - INFO - Fold 2, Epoch 170: Val Acc: 0.84%
2025-08-14 23:27:54,221 - INFO - Fold 2, Epoch 180: Val Acc: 0.72%
2025-08-14 23:27:57,842 - INFO - Fold 2, Epoch 190: Val Acc: 0.88%
2025-08-14 23:28:00,082 - INFO - Fold 2, Epoch 200: Val Acc: 0.78%
2025-08-14 23:28:03,616 - INFO - Fold 2, Epoch 210: Val Acc: 0.72%
2025-08-14 23:28:05,708 - INFO - Fold 2, Epoch 220: Val Acc: 0.88%
2025-08-14 23:28:07,858 - INFO - Fold 2, Epoch 230: Val Acc: 0.81%
2025-08-14 23:28:10,077 - INFO - Fold 2, Epoch 240: Val Acc: 0.78%
2025-08-14 23:28:12,291 - INFO - Fold 2, Epoch 250: Val Acc: 0.81%
2025-08-14 23:28:14,517 - INFO - Fold 2, Epoch 260: Val Acc: 0.75%
2025-08-14 23:28:16,811 - INFO - Fold 2, Epoch 270: Val Acc: 0.66%
2025-08-14 23:28:19,108 - INFO - Fold 2, Epoch 280: Val Acc: 0.75%
2025-08-14 23:28:21,339 - INFO - Fold 2, Epoch 290: Val Acc: 0.75%
2025-08-14 23:28:23,577 - INFO - Fold 2, Epoch 300: Val Acc: 0.75%
2025-08-14 23:28:25,377 - INFO - Early stopping at epoch 308
2025-08-14 23:28:26,456 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:28:26,458 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:28:26,459 - INFO - Starting training for fold 3/3
2025-08-14 23:28:33,255 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-14 23:28:39,802 - INFO - Fold 3, Epoch 20: Val Acc: 0.72%
2025-08-14 23:28:43,303 - INFO - Fold 3, Epoch 30: Val Acc: 0.81%
2025-08-14 23:28:45,615 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-14 23:28:47,894 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-14 23:28:51,659 - INFO - Fold 3, Epoch 60: Val Acc: 0.69%
2025-08-14 23:28:53,953 - INFO - Fold 3, Epoch 70: Val Acc: 0.66%
2025-08-14 23:28:56,253 - INFO - Fold 3, Epoch 80: Val Acc: 0.81%
2025-08-14 23:28:58,550 - INFO - Fold 3, Epoch 90: Val Acc: 0.59%
2025-08-14 23:29:00,846 - INFO - Fold 3, Epoch 100: Val Acc: 0.78%
2025-08-14 23:29:03,145 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-14 23:29:06,754 - INFO - Fold 3, Epoch 120: Val Acc: 0.94%
2025-08-14 23:29:09,055 - INFO - Fold 3, Epoch 130: Val Acc: 0.62%
2025-08-14 23:29:11,266 - INFO - Fold 3, Epoch 140: Val Acc: 0.75%
2025-08-14 23:29:13,480 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-14 23:29:15,689 - INFO - Fold 3, Epoch 160: Val Acc: 0.81%
2025-08-14 23:29:17,902 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-14 23:29:20,105 - INFO - Fold 3, Epoch 180: Val Acc: 0.84%
2025-08-14 23:29:22,316 - INFO - Fold 3, Epoch 190: Val Acc: 0.78%
2025-08-14 23:29:24,514 - INFO - Fold 3, Epoch 200: Val Acc: 0.66%
2025-08-14 23:29:26,727 - INFO - Fold 3, Epoch 210: Val Acc: 0.72%
2025-08-14 23:29:28,944 - INFO - Early stopping at epoch 220
2025-08-14 23:29:30,040 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.837152984407213), 'std': np.float64(0.09985700189464064)}, 'train_accuracy': {'mean': np.float64(0.8229166666666666), 'std': np.float64(0.03897559777889522)}, 'val_loss': {'mean': np.float64(4.175854206085205), 'std': np.float64(0.10111607396709908)}, 'val_accuracy': {'mean': np.float64(0.9375), 'std': np.float64(0.0)}, 'epoch': {'mean': np.float64(126.66666666666667), 'std': np.float64(62.69680126520721)}}
[I 2025-08-14 23:29:30,047] Trial 91 finished with value: -0.9375 and parameters: {'learning_rate': 0.000583145059609407, 'batch_size': 32, 'num_epochs': 387, 'temperature': 0.36450667433915757, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4810290475482115, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06868372993579419, 'crop_size': 0.5409646865963132}. Best is trial 90 with value: -0.9375.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 91 finished with value: -0.9375 and parameters: {'learning_rate': 0.000583145059609407, 'batch_size': 32, 'num_epochs': 387, 'temperature': 0.36450667433915757, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4810290475482115, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06868372993579419, 'crop_size': 0.5409646865963132}. Best is trial 90 with value: -0.9375.
2025-08-14 23:29:30,083 - INFO - Using device: cuda
2025-08-14 23:29:39,820 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:29:39,821 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:29:39,821 - INFO - Starting training for fold 1/3
2025-08-14 23:29:46,740 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-14 23:29:51,184 - INFO - Fold 1, Epoch 20: Val Acc: 0.81%
2025-08-14 23:29:53,405 - INFO - Fold 1, Epoch 30: Val Acc: 0.59%
2025-08-14 23:29:55,625 - INFO - Fold 1, Epoch 40: Val Acc: 0.66%
2025-08-14 23:30:00,078 - INFO - Fold 1, Epoch 50: Val Acc: 0.91%
2025-08-14 23:30:02,303 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-14 23:30:04,503 - INFO - Fold 1, Epoch 70: Val Acc: 0.62%
2025-08-14 23:30:06,684 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-14 23:30:08,384 - INFO - Fold 1, Epoch 90: Val Acc: 0.81%
2025-08-14 23:30:10,077 - INFO - Fold 1, Epoch 100: Val Acc: 0.66%
2025-08-14 23:30:11,772 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-14 23:30:13,466 - INFO - Fold 1, Epoch 120: Val Acc: 0.66%
2025-08-14 23:30:15,162 - INFO - Fold 1, Epoch 130: Val Acc: 0.81%
2025-08-14 23:30:16,856 - INFO - Fold 1, Epoch 140: Val Acc: 0.62%
2025-08-14 23:30:17,026 - INFO - Early stopping at epoch 141
2025-08-14 23:30:20,950 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:30:20,953 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:30:20,953 - INFO - Starting training for fold 2/3
2025-08-14 23:30:27,674 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-14 23:30:31,224 - INFO - Fold 2, Epoch 20: Val Acc: 0.75%
2025-08-14 23:30:34,924 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-14 23:30:38,497 - INFO - Fold 2, Epoch 40: Val Acc: 0.88%
2025-08-14 23:30:40,789 - INFO - Fold 2, Epoch 50: Val Acc: 0.66%
2025-08-14 23:30:42,925 - INFO - Fold 2, Epoch 60: Val Acc: 0.78%
2025-08-14 23:30:45,136 - INFO - Fold 2, Epoch 70: Val Acc: 0.66%
2025-08-14 23:30:47,349 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-14 23:30:49,512 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-14 23:30:51,675 - INFO - Fold 2, Epoch 100: Val Acc: 0.59%
2025-08-14 23:30:53,867 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-14 23:30:56,063 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-14 23:30:58,268 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-14 23:31:02,011 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-14 23:31:04,215 - INFO - Fold 2, Epoch 150: Val Acc: 0.66%
2025-08-14 23:31:06,407 - INFO - Fold 2, Epoch 160: Val Acc: 0.84%
2025-08-14 23:31:08,620 - INFO - Fold 2, Epoch 170: Val Acc: 0.84%
2025-08-14 23:31:10,840 - INFO - Fold 2, Epoch 180: Val Acc: 0.72%
2025-08-14 23:31:13,053 - INFO - Fold 2, Epoch 190: Val Acc: 0.72%
2025-08-14 23:31:15,277 - INFO - Fold 2, Epoch 200: Val Acc: 0.62%
2025-08-14 23:31:17,495 - INFO - Fold 2, Epoch 210: Val Acc: 0.94%
2025-08-14 23:31:19,719 - INFO - Fold 2, Epoch 220: Val Acc: 0.78%
2025-08-14 23:31:22,013 - INFO - Fold 2, Epoch 230: Val Acc: 0.72%
2025-08-14 23:31:22,241 - INFO - Early stopping at epoch 231
2025-08-14 23:31:25,481 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:31:25,484 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:31:25,484 - INFO - Starting training for fold 3/3
2025-08-14 23:31:33,694 - INFO - Fold 3, Epoch 10: Val Acc: 0.72%
2025-08-14 23:31:37,464 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-14 23:31:39,757 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-14 23:31:42,032 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-14 23:31:44,318 - INFO - Fold 3, Epoch 50: Val Acc: 0.66%
2025-08-14 23:31:46,137 - INFO - Fold 3, Epoch 60: Val Acc: 0.62%
2025-08-14 23:31:47,934 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-14 23:31:51,322 - INFO - Fold 3, Epoch 80: Val Acc: 0.84%
2025-08-14 23:31:55,124 - INFO - Fold 3, Epoch 90: Val Acc: 0.78%
2025-08-14 23:31:57,346 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-14 23:31:59,595 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-14 23:32:01,890 - INFO - Fold 3, Epoch 120: Val Acc: 0.69%
2025-08-14 23:32:04,191 - INFO - Fold 3, Epoch 130: Val Acc: 0.69%
2025-08-14 23:32:06,405 - INFO - Fold 3, Epoch 140: Val Acc: 0.88%
2025-08-14 23:32:08,603 - INFO - Fold 3, Epoch 150: Val Acc: 0.59%
2025-08-14 23:32:10,808 - INFO - Fold 3, Epoch 160: Val Acc: 0.69%
2025-08-14 23:32:14,432 - INFO - Fold 3, Epoch 170: Val Acc: 0.66%
2025-08-14 23:32:16,645 - INFO - Fold 3, Epoch 180: Val Acc: 0.75%
2025-08-14 23:32:18,855 - INFO - Fold 3, Epoch 190: Val Acc: 0.62%
2025-08-14 23:32:21,069 - INFO - Fold 3, Epoch 200: Val Acc: 0.75%
2025-08-14 23:32:23,286 - INFO - Fold 3, Epoch 210: Val Acc: 0.62%
2025-08-14 23:32:25,496 - INFO - Fold 3, Epoch 220: Val Acc: 0.66%
2025-08-14 23:32:27,714 - INFO - Fold 3, Epoch 230: Val Acc: 0.78%
2025-08-14 23:32:29,938 - INFO - Fold 3, Epoch 240: Val Acc: 0.72%
2025-08-14 23:32:32,140 - INFO - Fold 3, Epoch 250: Val Acc: 0.62%
2025-08-14 23:32:34,344 - INFO - Fold 3, Epoch 260: Val Acc: 0.75%
2025-08-14 23:32:35,448 - INFO - Early stopping at epoch 265
2025-08-14 23:32:38,161 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.85190118683709), 'std': np.float64(0.09037780566143006)}, 'train_accuracy': {'mean': np.float64(0.8020833333333334), 'std': np.float64(0.07795119555779044)}, 'val_loss': {'mean': np.float64(4.199009259541829), 'std': np.float64(0.02589670500586246)}, 'val_accuracy': {'mean': np.float64(0.9479166666666666), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(111.33333333333333), 'std': np.float64(52.315283511502535)}}
[I 2025-08-14 23:32:38,171] Trial 92 finished with value: -0.9479166666666666 and parameters: {'learning_rate': 0.0005679322945498316, 'batch_size': 32, 'num_epochs': 375, 'temperature': 0.29063452579262367, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.48991175948539684, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0984100262799093, 'crop_size': 0.537691257614809}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 92 finished with value: -0.9479166666666666 and parameters: {'learning_rate': 0.0005679322945498316, 'batch_size': 32, 'num_epochs': 375, 'temperature': 0.29063452579262367, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.48991175948539684, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0984100262799093, 'crop_size': 0.537691257614809}. Best is trial 92 with value: -0.9479166666666666.
2025-08-14 23:32:38,257 - INFO - Using device: cuda
2025-08-14 23:32:48,110 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:32:48,111 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:32:48,111 - INFO - Starting training for fold 1/3
2025-08-14 23:32:59,509 - INFO - Fold 1, Epoch 10: Val Acc: 0.72%
2025-08-14 23:33:03,448 - INFO - Fold 1, Epoch 20: Val Acc: 0.75%
2025-08-14 23:33:05,839 - INFO - Fold 1, Epoch 30: Val Acc: 0.69%
2025-08-14 23:33:09,950 - INFO - Fold 1, Epoch 40: Val Acc: 0.78%
2025-08-14 23:33:16,892 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-14 23:33:19,109 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-14 23:33:21,324 - INFO - Fold 1, Epoch 70: Val Acc: 0.50%
2025-08-14 23:33:23,546 - INFO - Fold 1, Epoch 80: Val Acc: 0.62%
2025-08-14 23:33:25,757 - INFO - Fold 1, Epoch 90: Val Acc: 0.59%
2025-08-14 23:33:27,967 - INFO - Fold 1, Epoch 100: Val Acc: 0.78%
2025-08-14 23:33:30,183 - INFO - Fold 1, Epoch 110: Val Acc: 0.81%
2025-08-14 23:33:32,405 - INFO - Fold 1, Epoch 120: Val Acc: 0.72%
2025-08-14 23:33:34,622 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-14 23:33:36,837 - INFO - Fold 1, Epoch 140: Val Acc: 0.84%
2025-08-14 23:33:38,611 - INFO - Early stopping at epoch 148
2025-08-14 23:33:42,149 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:33:42,161 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:33:42,162 - INFO - Starting training for fold 2/3
2025-08-14 23:33:47,429 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-14 23:33:51,029 - INFO - Fold 2, Epoch 20: Val Acc: 0.53%
2025-08-14 23:33:53,238 - INFO - Fold 2, Epoch 30: Val Acc: 0.75%
2025-08-14 23:33:58,374 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-14 23:34:00,586 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-14 23:34:02,807 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-14 23:34:07,879 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-14 23:34:10,137 - INFO - Fold 2, Epoch 80: Val Acc: 0.78%
2025-08-14 23:34:12,451 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-14 23:34:14,757 - INFO - Fold 2, Epoch 100: Val Acc: 0.56%
2025-08-14 23:34:17,060 - INFO - Fold 2, Epoch 110: Val Acc: 0.78%
2025-08-14 23:34:19,369 - INFO - Fold 2, Epoch 120: Val Acc: 0.84%
2025-08-14 23:34:21,672 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-14 23:34:23,977 - INFO - Fold 2, Epoch 140: Val Acc: 0.84%
2025-08-14 23:34:26,278 - INFO - Fold 2, Epoch 150: Val Acc: 0.66%
2025-08-14 23:34:28,576 - INFO - Fold 2, Epoch 160: Val Acc: 0.88%
2025-08-14 23:34:29,780 - INFO - Early stopping at epoch 166
2025-08-14 23:34:30,858 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:34:30,860 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:34:30,860 - INFO - Starting training for fold 3/3
2025-08-14 23:34:39,022 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-14 23:34:42,795 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-14 23:34:47,908 - INFO - Fold 3, Epoch 30: Val Acc: 0.59%
2025-08-14 23:34:50,116 - INFO - Fold 3, Epoch 40: Val Acc: 0.72%
2025-08-14 23:34:53,586 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-14 23:34:55,643 - INFO - Fold 3, Epoch 60: Val Acc: 0.78%
2025-08-14 23:34:57,378 - INFO - Fold 3, Epoch 70: Val Acc: 0.66%
2025-08-14 23:34:59,566 - INFO - Fold 3, Epoch 80: Val Acc: 0.88%
2025-08-14 23:35:01,772 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-14 23:35:03,976 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-14 23:35:06,180 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-14 23:35:08,391 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-14 23:35:11,936 - INFO - Fold 3, Epoch 130: Val Acc: 0.75%
2025-08-14 23:35:14,158 - INFO - Fold 3, Epoch 140: Val Acc: 0.84%
2025-08-14 23:35:16,054 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-14 23:35:17,749 - INFO - Fold 3, Epoch 160: Val Acc: 0.69%
2025-08-14 23:35:19,952 - INFO - Fold 3, Epoch 170: Val Acc: 0.66%
2025-08-14 23:35:22,135 - INFO - Fold 3, Epoch 180: Val Acc: 0.84%
2025-08-14 23:35:24,343 - INFO - Fold 3, Epoch 190: Val Acc: 0.75%
2025-08-14 23:35:26,562 - INFO - Fold 3, Epoch 200: Val Acc: 0.53%
2025-08-14 23:35:28,785 - INFO - Fold 3, Epoch 210: Val Acc: 0.84%
2025-08-14 23:35:31,008 - INFO - Fold 3, Epoch 220: Val Acc: 0.78%
2025-08-14 23:35:32,558 - INFO - Early stopping at epoch 227
2025-08-14 23:35:33,632 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9158018430074057), 'std': np.float64(0.027960464997216092)}, 'train_accuracy': {'mean': np.float64(0.8020833333333334), 'std': np.float64(0.008505172717997117)}, 'val_loss': {'mean': np.float64(4.295488039652507), 'std': np.float64(0.08740602759714305)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.0)}, 'epoch': {'mean': np.float64(79.33333333333333), 'std': np.float64(33.8066397160216)}}
[I 2025-08-14 23:35:33,639] Trial 93 finished with value: -0.90625 and parameters: {'learning_rate': 0.0005583579921194509, 'batch_size': 32, 'num_epochs': 278, 'temperature': 0.28690976754814324, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.48910997278030083, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.09887362650256662, 'crop_size': 0.5371507036742992}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 93 finished with value: -0.90625 and parameters: {'learning_rate': 0.0005583579921194509, 'batch_size': 32, 'num_epochs': 278, 'temperature': 0.28690976754814324, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.48910997278030083, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.09887362650256662, 'crop_size': 0.5371507036742992}. Best is trial 92 with value: -0.9479166666666666.
2025-08-14 23:35:33,674 - INFO - Using device: cuda
2025-08-14 23:35:43,664 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:35:43,665 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:35:43,666 - INFO - Starting training for fold 1/3
2025-08-14 23:35:57,200 - INFO - Fold 1, Epoch 10: Val Acc: 0.66%
2025-08-14 23:36:01,574 - INFO - Fold 1, Epoch 20: Val Acc: 0.75%
2025-08-14 23:36:08,397 - INFO - Fold 1, Epoch 30: Val Acc: 0.78%
2025-08-14 23:36:10,498 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-14 23:36:12,199 - INFO - Fold 1, Epoch 50: Val Acc: 0.62%
2025-08-14 23:36:13,903 - INFO - Fold 1, Epoch 60: Val Acc: 0.84%
2025-08-14 23:36:15,722 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-14 23:36:17,936 - INFO - Fold 1, Epoch 80: Val Acc: 0.69%
2025-08-14 23:36:20,148 - INFO - Fold 1, Epoch 90: Val Acc: 0.62%
2025-08-14 23:36:22,359 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-14 23:36:24,574 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-14 23:36:26,786 - INFO - Fold 1, Epoch 120: Val Acc: 0.72%
2025-08-14 23:36:28,338 - INFO - Early stopping at epoch 127
2025-08-14 23:36:32,043 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:36:32,046 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:36:32,046 - INFO - Starting training for fold 2/3
2025-08-14 23:36:38,707 - INFO - Fold 2, Epoch 10: Val Acc: 0.69%
2025-08-14 23:36:42,463 - INFO - Fold 2, Epoch 20: Val Acc: 0.69%
2025-08-14 23:36:44,771 - INFO - Fold 2, Epoch 30: Val Acc: 0.66%
2025-08-14 23:36:47,090 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-14 23:36:50,921 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-14 23:36:53,194 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-14 23:36:55,410 - INFO - Fold 2, Epoch 70: Val Acc: 0.84%
2025-08-14 23:36:57,632 - INFO - Fold 2, Epoch 80: Val Acc: 0.81%
2025-08-14 23:36:59,846 - INFO - Fold 2, Epoch 90: Val Acc: 0.59%
2025-08-14 23:37:02,070 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-14 23:37:04,287 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-14 23:37:06,516 - INFO - Fold 2, Epoch 120: Val Acc: 0.88%
2025-08-14 23:37:08,734 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-14 23:37:10,944 - INFO - Fold 2, Epoch 140: Val Acc: 0.66%
2025-08-14 23:37:11,833 - INFO - Early stopping at epoch 144
2025-08-14 23:37:14,825 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:37:14,828 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:37:14,828 - INFO - Starting training for fold 3/3
2025-08-14 23:37:22,834 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-14 23:37:29,505 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-14 23:37:32,703 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-14 23:37:36,510 - INFO - Fold 3, Epoch 40: Val Acc: 0.84%
2025-08-14 23:37:38,807 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-14 23:37:41,116 - INFO - Fold 3, Epoch 60: Val Acc: 0.69%
2025-08-14 23:37:43,425 - INFO - Fold 3, Epoch 70: Val Acc: 0.66%
2025-08-14 23:37:45,733 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-14 23:37:48,033 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-14 23:37:50,337 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-14 23:37:54,131 - INFO - Fold 3, Epoch 110: Val Acc: 0.62%
2025-08-14 23:37:56,074 - INFO - Fold 3, Epoch 120: Val Acc: 0.69%
2025-08-14 23:37:58,358 - INFO - Fold 3, Epoch 130: Val Acc: 0.69%
2025-08-14 23:38:00,365 - INFO - Fold 3, Epoch 140: Val Acc: 0.59%
2025-08-14 23:38:02,157 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-14 23:38:03,950 - INFO - Fold 3, Epoch 160: Val Acc: 0.78%
2025-08-14 23:38:05,749 - INFO - Fold 3, Epoch 170: Val Acc: 0.66%
2025-08-14 23:38:07,528 - INFO - Fold 3, Epoch 180: Val Acc: 0.75%
2025-08-14 23:38:09,321 - INFO - Fold 3, Epoch 190: Val Acc: 0.78%
2025-08-14 23:38:11,112 - INFO - Fold 3, Epoch 200: Val Acc: 0.72%
2025-08-14 23:38:12,867 - INFO - Early stopping at epoch 209
2025-08-14 23:38:16,004 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9243317974938283), 'std': np.float64(0.07546020992874265)}, 'train_accuracy': {'mean': np.float64(0.7847222222222223), 'std': np.float64(0.05126674673692153)}, 'val_loss': {'mean': np.float64(4.234500567118327), 'std': np.float64(0.06496554516282209)}, 'val_accuracy': {'mean': np.float64(0.875), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(59.0), 'std': np.float64(35.33647784749729)}}
[I 2025-08-14 23:38:16,015] Trial 94 finished with value: -0.875 and parameters: {'learning_rate': 0.0008689767598528612, 'batch_size': 32, 'num_epochs': 438, 'temperature': 0.3130414530432175, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4798804540147145, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.10774697104018768, 'crop_size': 0.5568647741085796}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 94 finished with value: -0.875 and parameters: {'learning_rate': 0.0008689767598528612, 'batch_size': 32, 'num_epochs': 438, 'temperature': 0.3130414530432175, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4798804540147145, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.10774697104018768, 'crop_size': 0.5568647741085796}. Best is trial 92 with value: -0.9479166666666666.
2025-08-14 23:38:16,096 - INFO - Using device: cuda
2025-08-14 23:38:25,689 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:38:25,690 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:38:25,690 - INFO - Starting training for fold 1/3
2025-08-14 23:38:32,613 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-14 23:38:39,265 - INFO - Fold 1, Epoch 20: Val Acc: 0.72%
2025-08-14 23:38:41,301 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-14 23:38:48,017 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-14 23:38:50,230 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-14 23:38:54,602 - INFO - Fold 1, Epoch 60: Val Acc: 0.81%
2025-08-14 23:38:59,122 - INFO - Fold 1, Epoch 70: Val Acc: 0.69%
2025-08-14 23:39:01,261 - INFO - Fold 1, Epoch 80: Val Acc: 0.81%
2025-08-14 23:39:03,475 - INFO - Fold 1, Epoch 90: Val Acc: 0.81%
2025-08-14 23:39:05,694 - INFO - Fold 1, Epoch 100: Val Acc: 0.84%
2025-08-14 23:39:07,914 - INFO - Fold 1, Epoch 110: Val Acc: 0.75%
2025-08-14 23:39:10,125 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-14 23:39:12,336 - INFO - Fold 1, Epoch 130: Val Acc: 0.72%
2025-08-14 23:39:14,557 - INFO - Fold 1, Epoch 140: Val Acc: 0.72%
2025-08-14 23:39:16,778 - INFO - Fold 1, Epoch 150: Val Acc: 0.62%
2025-08-14 23:39:21,365 - INFO - Fold 1, Epoch 160: Val Acc: 0.59%
2025-08-14 23:39:23,573 - INFO - Fold 1, Epoch 170: Val Acc: 0.78%
2025-08-14 23:39:25,785 - INFO - Fold 1, Epoch 180: Val Acc: 0.75%
2025-08-14 23:39:28,004 - INFO - Fold 1, Epoch 190: Val Acc: 0.66%
2025-08-14 23:39:29,828 - INFO - Fold 1, Epoch 200: Val Acc: 0.72%
2025-08-14 23:39:31,522 - INFO - Fold 1, Epoch 210: Val Acc: 0.59%
2025-08-14 23:39:33,219 - INFO - Fold 1, Epoch 220: Val Acc: 0.69%
2025-08-14 23:39:34,915 - INFO - Fold 1, Epoch 230: Val Acc: 0.66%
2025-08-14 23:39:36,610 - INFO - Fold 1, Epoch 240: Val Acc: 0.59%
2025-08-14 23:39:38,304 - INFO - Fold 1, Epoch 250: Val Acc: 0.72%
2025-08-14 23:39:38,813 - INFO - Early stopping at epoch 253
2025-08-14 23:39:42,536 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:39:42,538 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:39:42,539 - INFO - Starting training for fold 2/3
2025-08-14 23:39:50,784 - INFO - Fold 2, Epoch 10: Val Acc: 0.47%
2025-08-14 23:39:54,421 - INFO - Fold 2, Epoch 20: Val Acc: 0.69%
2025-08-14 23:40:01,032 - INFO - Fold 2, Epoch 30: Val Acc: 0.59%
2025-08-14 23:40:03,229 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-14 23:40:07,008 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-14 23:40:09,225 - INFO - Fold 2, Epoch 60: Val Acc: 0.78%
2025-08-14 23:40:12,920 - INFO - Fold 2, Epoch 70: Val Acc: 0.88%
2025-08-14 23:40:15,128 - INFO - Fold 2, Epoch 80: Val Acc: 0.88%
2025-08-14 23:40:17,348 - INFO - Fold 2, Epoch 90: Val Acc: 0.88%
2025-08-14 23:40:19,555 - INFO - Fold 2, Epoch 100: Val Acc: 0.88%
2025-08-14 23:40:23,196 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-14 23:40:25,413 - INFO - Fold 2, Epoch 120: Val Acc: 0.78%
2025-08-14 23:40:27,629 - INFO - Fold 2, Epoch 130: Val Acc: 0.88%
2025-08-14 23:40:29,846 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-14 23:40:32,063 - INFO - Fold 2, Epoch 150: Val Acc: 0.72%
2025-08-14 23:40:34,274 - INFO - Fold 2, Epoch 160: Val Acc: 0.59%
2025-08-14 23:40:36,482 - INFO - Fold 2, Epoch 170: Val Acc: 0.72%
2025-08-14 23:40:38,697 - INFO - Fold 2, Epoch 180: Val Acc: 0.69%
2025-08-14 23:40:40,902 - INFO - Fold 2, Epoch 190: Val Acc: 0.66%
2025-08-14 23:40:43,098 - INFO - Fold 2, Epoch 200: Val Acc: 0.78%
2025-08-14 23:40:43,540 - INFO - Early stopping at epoch 202
2025-08-14 23:40:46,631 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:40:46,633 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:40:46,634 - INFO - Starting training for fold 3/3
2025-08-14 23:40:53,318 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-14 23:40:56,935 - INFO - Fold 3, Epoch 20: Val Acc: 0.78%
2025-08-14 23:40:59,255 - INFO - Fold 3, Epoch 30: Val Acc: 0.62%
2025-08-14 23:41:02,902 - INFO - Fold 3, Epoch 40: Val Acc: 0.81%
2025-08-14 23:41:05,149 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-14 23:41:07,419 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-14 23:41:10,656 - INFO - Fold 3, Epoch 70: Val Acc: 0.78%
2025-08-14 23:41:14,184 - INFO - Fold 3, Epoch 80: Val Acc: 0.84%
2025-08-14 23:41:17,679 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-14 23:41:19,403 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-14 23:41:21,546 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-14 23:41:23,765 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-14 23:41:25,997 - INFO - Fold 3, Epoch 130: Val Acc: 0.88%
2025-08-14 23:41:28,300 - INFO - Fold 3, Epoch 140: Val Acc: 0.53%
2025-08-14 23:41:30,172 - INFO - Fold 3, Epoch 150: Val Acc: 0.91%
2025-08-14 23:41:32,176 - INFO - Fold 3, Epoch 160: Val Acc: 0.62%
2025-08-14 23:41:34,155 - INFO - Fold 3, Epoch 170: Val Acc: 0.62%
2025-08-14 23:41:36,049 - INFO - Fold 3, Epoch 180: Val Acc: 0.75%
2025-08-14 23:41:37,226 - INFO - Early stopping at epoch 186
2025-08-14 23:41:38,291 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.900635533862644), 'std': np.float64(0.07193088944567834)}, 'train_accuracy': {'mean': np.float64(0.7916666666666666), 'std': np.float64(0.017010345435994324)}, 'val_loss': {'mean': np.float64(4.314878145853679), 'std': np.float64(0.020957904138148676)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(112.66666666666667), 'std': np.float64(28.56960311628816)}}
[I 2025-08-14 23:41:38,298] Trial 95 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0004235704694244595, 'batch_size': 32, 'num_epochs': 360, 'temperature': 0.35886541671063316, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.49372196465013285, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0687852399101597, 'crop_size': 0.5467518818594655}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 95 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0004235704694244595, 'batch_size': 32, 'num_epochs': 360, 'temperature': 0.35886541671063316, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.49372196465013285, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0687852399101597, 'crop_size': 0.5467518818594655}. Best is trial 92 with value: -0.9479166666666666.
2025-08-14 23:41:38,336 - INFO - Using device: cuda
2025-08-14 23:41:48,141 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:41:48,143 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:41:48,143 - INFO - Starting training for fold 1/3
2025-08-14 23:41:59,634 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-14 23:42:06,068 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-14 23:42:12,443 - INFO - Fold 1, Epoch 30: Val Acc: 0.75%
2025-08-14 23:42:14,647 - INFO - Fold 1, Epoch 40: Val Acc: 0.62%
2025-08-14 23:42:18,909 - INFO - Fold 1, Epoch 50: Val Acc: 0.62%
2025-08-14 23:42:20,612 - INFO - Fold 1, Epoch 60: Val Acc: 0.62%
2025-08-14 23:42:22,312 - INFO - Fold 1, Epoch 70: Val Acc: 0.78%
2025-08-14 23:42:24,010 - INFO - Fold 1, Epoch 80: Val Acc: 0.69%
2025-08-14 23:42:25,710 - INFO - Fold 1, Epoch 90: Val Acc: 0.62%
2025-08-14 23:42:27,409 - INFO - Fold 1, Epoch 100: Val Acc: 0.81%
2025-08-14 23:42:29,113 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-14 23:42:30,814 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-14 23:42:33,029 - INFO - Fold 1, Epoch 130: Val Acc: 0.78%
2025-08-14 23:42:35,324 - INFO - Fold 1, Epoch 140: Val Acc: 0.88%
2025-08-14 23:42:37,244 - INFO - Early stopping at epoch 149
2025-08-14 23:42:40,805 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:42:40,808 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:42:40,808 - INFO - Starting training for fold 2/3
2025-08-14 23:42:47,494 - INFO - Fold 2, Epoch 10: Val Acc: 0.41%
2025-08-14 23:42:51,281 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-14 23:42:53,501 - INFO - Fold 2, Epoch 30: Val Acc: 0.62%
2025-08-14 23:42:57,136 - INFO - Fold 2, Epoch 40: Val Acc: 0.66%
2025-08-14 23:42:59,347 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-14 23:43:01,563 - INFO - Fold 2, Epoch 60: Val Acc: 0.88%
2025-08-14 23:43:03,777 - INFO - Fold 2, Epoch 70: Val Acc: 0.88%
2025-08-14 23:43:05,976 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-14 23:43:07,670 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-14 23:43:09,370 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-14 23:43:11,584 - INFO - Fold 2, Epoch 110: Val Acc: 0.78%
2025-08-14 23:43:13,772 - INFO - Fold 2, Epoch 120: Val Acc: 0.84%
2025-08-14 23:43:15,994 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-14 23:43:17,305 - INFO - Early stopping at epoch 136
2025-08-14 23:43:18,413 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:43:18,415 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:43:18,415 - INFO - Starting training for fold 3/3
2025-08-14 23:43:25,162 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-14 23:43:29,000 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-14 23:43:31,273 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-14 23:43:33,566 - INFO - Fold 3, Epoch 40: Val Acc: 0.72%
2025-08-14 23:43:37,305 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-14 23:43:39,509 - INFO - Fold 3, Epoch 60: Val Acc: 0.78%
2025-08-14 23:43:41,721 - INFO - Fold 3, Epoch 70: Val Acc: 0.75%
2025-08-14 23:43:43,937 - INFO - Fold 3, Epoch 80: Val Acc: 0.84%
2025-08-14 23:43:46,153 - INFO - Fold 3, Epoch 90: Val Acc: 0.78%
2025-08-14 23:43:48,367 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-14 23:43:50,582 - INFO - Fold 3, Epoch 110: Val Acc: 0.84%
2025-08-14 23:43:52,805 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-14 23:43:54,803 - INFO - Fold 3, Epoch 130: Val Acc: 0.88%
2025-08-14 23:43:56,500 - INFO - Fold 3, Epoch 140: Val Acc: 0.62%
2025-08-14 23:43:57,858 - INFO - Early stopping at epoch 148
2025-08-14 23:43:58,909 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9569715658823648), 'std': np.float64(0.025625069605922295)}, 'train_accuracy': {'mean': np.float64(0.7430555555555555), 'std': np.float64(0.027340305118096573)}, 'val_loss': {'mean': np.float64(4.147192001342773), 'std': np.float64(0.06996593125670132)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(43.333333333333336), 'std': np.float64(5.90668171555645)}}
[I 2025-08-14 23:43:58,915] Trial 96 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0005824853692291223, 'batch_size': 32, 'num_epochs': 370, 'temperature': 0.3427829921675797, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4761449429413749, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.09041705500895818, 'crop_size': 0.5204807832092091}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 96 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0005824853692291223, 'batch_size': 32, 'num_epochs': 370, 'temperature': 0.3427829921675797, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4761449429413749, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.09041705500895818, 'crop_size': 0.5204807832092091}. Best is trial 92 with value: -0.9479166666666666.
2025-08-14 23:43:58,947 - INFO - Using device: cuda
2025-08-14 23:44:08,530 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:44:08,532 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:44:08,532 - INFO - Starting training for fold 1/3
2025-08-14 23:44:22,159 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-14 23:44:26,502 - INFO - Fold 1, Epoch 20: Val Acc: 0.66%
2025-08-14 23:44:28,598 - INFO - Fold 1, Epoch 30: Val Acc: 0.72%
2025-08-14 23:44:33,008 - INFO - Fold 1, Epoch 40: Val Acc: 0.75%
2025-08-14 23:44:37,286 - INFO - Fold 1, Epoch 50: Val Acc: 0.59%
2025-08-14 23:44:39,411 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-14 23:44:41,574 - INFO - Fold 1, Epoch 70: Val Acc: 0.53%
2025-08-14 23:44:43,706 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-14 23:44:45,807 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-14 23:44:47,909 - INFO - Fold 1, Epoch 100: Val Acc: 0.50%
2025-08-14 23:44:50,009 - INFO - Fold 1, Epoch 110: Val Acc: 0.72%
2025-08-14 23:44:51,861 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-14 23:44:53,448 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-14 23:44:55,033 - INFO - Fold 1, Epoch 140: Val Acc: 0.72%
2025-08-14 23:44:55,565 - INFO - Early stopping at epoch 143
2025-08-14 23:44:59,149 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:44:59,152 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:44:59,153 - INFO - Starting training for fold 2/3
2025-08-14 23:45:05,751 - INFO - Fold 2, Epoch 10: Val Acc: 0.41%
2025-08-14 23:45:12,499 - INFO - Fold 2, Epoch 20: Val Acc: 0.75%
2025-08-14 23:45:18,061 - INFO - Fold 2, Epoch 30: Val Acc: 0.66%
2025-08-14 23:45:20,164 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-14 23:45:23,732 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-14 23:45:27,296 - INFO - Fold 2, Epoch 60: Val Acc: 0.78%
2025-08-14 23:45:29,382 - INFO - Fold 2, Epoch 70: Val Acc: 0.59%
2025-08-14 23:45:31,481 - INFO - Fold 2, Epoch 80: Val Acc: 0.62%
2025-08-14 23:45:33,572 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-14 23:45:35,670 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-14 23:45:37,759 - INFO - Fold 2, Epoch 110: Val Acc: 0.81%
2025-08-14 23:45:39,851 - INFO - Fold 2, Epoch 120: Val Acc: 0.84%
2025-08-14 23:45:41,947 - INFO - Fold 2, Epoch 130: Val Acc: 0.81%
2025-08-14 23:45:44,041 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-14 23:45:46,135 - INFO - Fold 2, Epoch 150: Val Acc: 0.69%
2025-08-14 23:45:46,757 - INFO - Early stopping at epoch 153
2025-08-14 23:45:49,848 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:45:49,851 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:45:49,851 - INFO - Starting training for fold 3/3
2025-08-14 23:45:56,529 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-14 23:46:01,390 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-14 23:46:04,929 - INFO - Fold 3, Epoch 30: Val Acc: 0.56%
2025-08-14 23:46:07,111 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-14 23:46:10,728 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-14 23:46:12,917 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-14 23:46:16,455 - INFO - Fold 3, Epoch 70: Val Acc: 0.81%
2025-08-14 23:46:18,640 - INFO - Fold 3, Epoch 80: Val Acc: 0.69%
2025-08-14 23:46:20,818 - INFO - Fold 3, Epoch 90: Val Acc: 0.91%
2025-08-14 23:46:23,011 - INFO - Fold 3, Epoch 100: Val Acc: 0.78%
2025-08-14 23:46:25,196 - INFO - Fold 3, Epoch 110: Val Acc: 0.88%
2025-08-14 23:46:27,308 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-14 23:46:29,410 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-14 23:46:31,490 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-14 23:46:33,583 - INFO - Fold 3, Epoch 150: Val Acc: 0.66%
2025-08-14 23:46:35,683 - INFO - Fold 3, Epoch 160: Val Acc: 0.81%
2025-08-14 23:46:37,560 - INFO - Early stopping at epoch 169
2025-08-14 23:46:38,631 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9770728217230906), 'std': np.float64(0.023751024265311088)}, 'train_accuracy': {'mean': np.float64(0.7777777777777777), 'std': np.float64(0.03437324630767941)}, 'val_loss': {'mean': np.float64(4.186501979827881), 'std': np.float64(0.045971017223301956)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(54.0), 'std': np.float64(10.708252269472673)}}
[I 2025-08-14 23:46:38,638] Trial 97 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0006863252614772264, 'batch_size': 32, 'num_epochs': 324, 'temperature': 0.2594642833022991, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.45517961180238414, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.5311255771334632}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 97 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0006863252614772264, 'batch_size': 32, 'num_epochs': 324, 'temperature': 0.2594642833022991, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.45517961180238414, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.5311255771334632}. Best is trial 92 with value: -0.9479166666666666.
2025-08-14 23:46:38,673 - INFO - Using device: cuda
2025-08-14 23:46:48,438 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:46:48,439 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:46:48,439 - INFO - Starting training for fold 1/3
2025-08-14 23:46:59,792 - INFO - Fold 1, Epoch 10: Val Acc: 0.69%
2025-08-14 23:47:02,018 - INFO - Fold 1, Epoch 20: Val Acc: 0.62%
2025-08-14 23:47:04,243 - INFO - Fold 1, Epoch 30: Val Acc: 0.72%
2025-08-14 23:47:08,678 - INFO - Fold 1, Epoch 40: Val Acc: 0.84%
2025-08-14 23:47:13,151 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-14 23:47:15,330 - INFO - Fold 1, Epoch 60: Val Acc: 0.66%
2025-08-14 23:47:17,539 - INFO - Fold 1, Epoch 70: Val Acc: 0.62%
2025-08-14 23:47:19,760 - INFO - Fold 1, Epoch 80: Val Acc: 0.59%
2025-08-14 23:47:21,964 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-14 23:47:24,184 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-14 23:47:26,393 - INFO - Fold 1, Epoch 110: Val Acc: 0.88%
2025-08-14 23:47:28,601 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-14 23:47:30,838 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-14 23:47:33,037 - INFO - Fold 1, Epoch 140: Val Acc: 0.75%
2025-08-14 23:47:34,365 - INFO - Early stopping at epoch 146
2025-08-14 23:47:37,990 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:47:37,992 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:47:37,993 - INFO - Starting training for fold 2/3
2025-08-14 23:47:46,045 - INFO - Fold 2, Epoch 10: Val Acc: 0.72%
2025-08-14 23:47:49,780 - INFO - Fold 2, Epoch 20: Val Acc: 0.78%
2025-08-14 23:47:53,424 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-14 23:47:55,627 - INFO - Fold 2, Epoch 40: Val Acc: 0.88%
2025-08-14 23:47:57,812 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-14 23:47:59,877 - INFO - Fold 2, Epoch 60: Val Acc: 0.78%
2025-08-14 23:48:01,769 - INFO - Fold 2, Epoch 70: Val Acc: 0.62%
2025-08-14 23:48:03,560 - INFO - Fold 2, Epoch 80: Val Acc: 0.88%
2025-08-14 23:48:05,416 - INFO - Fold 2, Epoch 90: Val Acc: 0.66%
2025-08-14 23:48:07,711 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-14 23:48:10,012 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-14 23:48:12,304 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-14 23:48:12,532 - INFO - Early stopping at epoch 121
2025-08-14 23:48:16,935 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:48:16,938 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:48:16,938 - INFO - Starting training for fold 3/3
2025-08-14 23:48:24,014 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-14 23:48:27,279 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-14 23:48:32,305 - INFO - Fold 3, Epoch 30: Val Acc: 0.88%
2025-08-14 23:48:34,486 - INFO - Fold 3, Epoch 40: Val Acc: 0.81%
2025-08-14 23:48:36,329 - INFO - Fold 3, Epoch 50: Val Acc: 0.75%
2025-08-14 23:48:39,619 - INFO - Fold 3, Epoch 60: Val Acc: 0.78%
2025-08-14 23:48:41,374 - INFO - Fold 3, Epoch 70: Val Acc: 0.84%
2025-08-14 23:48:43,063 - INFO - Fold 3, Epoch 80: Val Acc: 0.88%
2025-08-14 23:48:44,780 - INFO - Fold 3, Epoch 90: Val Acc: 0.62%
2025-08-14 23:48:46,879 - INFO - Fold 3, Epoch 100: Val Acc: 0.81%
2025-08-14 23:48:49,091 - INFO - Fold 3, Epoch 110: Val Acc: 0.81%
2025-08-14 23:48:51,322 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-14 23:48:53,513 - INFO - Fold 3, Epoch 130: Val Acc: 0.66%
2025-08-14 23:48:55,708 - INFO - Fold 3, Epoch 140: Val Acc: 0.69%
2025-08-14 23:48:57,402 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-14 23:48:58,910 - INFO - Early stopping at epoch 158
2025-08-14 23:49:01,694 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.947901116477119), 'std': np.float64(0.024138081803552685)}, 'train_accuracy': {'mean': np.float64(0.78125), 'std': np.float64(0.014731391274719766)}, 'val_loss': {'mean': np.float64(4.2339145342508955), 'std': np.float64(0.07466016802338163)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(40.666666666666664), 'std': np.float64(15.412837362262522)}}
[I 2025-08-14 23:49:01,704] Trial 98 finished with value: -0.90625 and parameters: {'learning_rate': 0.0007784946728515513, 'batch_size': 32, 'num_epochs': 456, 'temperature': 0.37708326029063916, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4620916916945069, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.10362053443912297, 'crop_size': 0.5706235358179798}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 98 finished with value: -0.90625 and parameters: {'learning_rate': 0.0007784946728515513, 'batch_size': 32, 'num_epochs': 456, 'temperature': 0.37708326029063916, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4620916916945069, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.10362053443912297, 'crop_size': 0.5706235358179798}. Best is trial 92 with value: -0.9479166666666666.
2025-08-14 23:49:01,787 - INFO - Using device: cuda
2025-08-14 23:49:11,636 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:49:11,638 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:49:11,638 - INFO - Starting training for fold 1/3
2025-08-14 23:49:22,997 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-14 23:49:31,910 - INFO - Fold 1, Epoch 20: Val Acc: 0.72%
2025-08-14 23:49:36,364 - INFO - Fold 1, Epoch 30: Val Acc: 0.66%
2025-08-14 23:49:38,597 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-14 23:49:40,836 - INFO - Fold 1, Epoch 50: Val Acc: 0.84%
2025-08-14 23:49:43,086 - INFO - Fold 1, Epoch 60: Val Acc: 0.75%
2025-08-14 23:49:45,324 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-14 23:49:47,550 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-14 23:49:49,775 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-14 23:49:52,005 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-14 23:49:56,392 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-14 23:49:58,593 - INFO - Fold 1, Epoch 120: Val Acc: 0.72%
2025-08-14 23:50:00,803 - INFO - Fold 1, Epoch 130: Val Acc: 0.72%
2025-08-14 23:50:03,020 - INFO - Fold 1, Epoch 140: Val Acc: 0.72%
2025-08-14 23:50:05,236 - INFO - Fold 1, Epoch 150: Val Acc: 0.72%
2025-08-14 23:50:07,457 - INFO - Fold 1, Epoch 160: Val Acc: 0.59%
2025-08-14 23:50:09,681 - INFO - Fold 1, Epoch 170: Val Acc: 0.81%
2025-08-14 23:50:11,910 - INFO - Fold 1, Epoch 180: Val Acc: 0.78%
2025-08-14 23:50:16,367 - INFO - Fold 1, Epoch 190: Val Acc: 0.69%
2025-08-14 23:50:18,577 - INFO - Fold 1, Epoch 200: Val Acc: 0.78%
2025-08-14 23:50:20,784 - INFO - Fold 1, Epoch 210: Val Acc: 0.69%
2025-08-14 23:50:23,000 - INFO - Fold 1, Epoch 220: Val Acc: 0.72%
2025-08-14 23:50:25,229 - INFO - Fold 1, Epoch 230: Val Acc: 0.75%
2025-08-14 23:50:27,442 - INFO - Fold 1, Epoch 240: Val Acc: 0.75%
2025-08-14 23:50:29,659 - INFO - Fold 1, Epoch 250: Val Acc: 0.72%
2025-08-14 23:50:31,873 - INFO - Fold 1, Epoch 260: Val Acc: 0.66%
2025-08-14 23:50:34,066 - INFO - Fold 1, Epoch 270: Val Acc: 0.69%
2025-08-14 23:50:36,353 - INFO - Fold 1, Epoch 280: Val Acc: 0.59%
2025-08-14 23:50:37,743 - INFO - Early stopping at epoch 286
2025-08-14 23:50:41,168 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:50:41,171 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:50:41,171 - INFO - Starting training for fold 2/3
2025-08-14 23:50:46,394 - INFO - Fold 2, Epoch 10: Val Acc: 0.72%
2025-08-14 23:50:50,259 - INFO - Fold 2, Epoch 20: Val Acc: 0.62%
2025-08-14 23:50:53,942 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-14 23:50:56,145 - INFO - Fold 2, Epoch 40: Val Acc: 0.78%
2025-08-14 23:51:01,155 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-14 23:51:03,357 - INFO - Fold 2, Epoch 60: Val Acc: 0.88%
2025-08-14 23:51:05,564 - INFO - Fold 2, Epoch 70: Val Acc: 0.91%
2025-08-14 23:51:07,563 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-14 23:51:09,252 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-14 23:51:10,941 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-14 23:51:12,668 - INFO - Fold 2, Epoch 110: Val Acc: 0.88%
2025-08-14 23:51:14,355 - INFO - Fold 2, Epoch 120: Val Acc: 0.78%
2025-08-14 23:51:16,040 - INFO - Fold 2, Epoch 130: Val Acc: 0.94%
2025-08-14 23:51:17,727 - INFO - Fold 2, Epoch 140: Val Acc: 0.84%
2025-08-14 23:51:19,061 - INFO - Early stopping at epoch 148
2025-08-14 23:51:21,983 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:51:21,986 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:51:21,986 - INFO - Starting training for fold 3/3
2025-08-14 23:51:31,184 - INFO - Fold 3, Epoch 10: Val Acc: 0.69%
2025-08-14 23:51:37,765 - INFO - Fold 3, Epoch 20: Val Acc: 0.81%
2025-08-14 23:51:40,071 - INFO - Fold 3, Epoch 30: Val Acc: 0.72%
2025-08-14 23:51:44,336 - INFO - Fold 3, Epoch 40: Val Acc: 0.81%
2025-08-14 23:51:46,550 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-14 23:51:48,775 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-14 23:51:50,986 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-14 23:51:53,205 - INFO - Fold 3, Epoch 80: Val Acc: 0.69%
2025-08-14 23:51:56,955 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-14 23:51:59,158 - INFO - Fold 3, Epoch 100: Val Acc: 0.66%
2025-08-14 23:52:01,370 - INFO - Fold 3, Epoch 110: Val Acc: 0.81%
2025-08-14 23:52:03,366 - INFO - Fold 3, Epoch 120: Val Acc: 0.62%
2025-08-14 23:52:05,111 - INFO - Fold 3, Epoch 130: Val Acc: 0.75%
2025-08-14 23:52:06,854 - INFO - Fold 3, Epoch 140: Val Acc: 0.69%
2025-08-14 23:52:08,552 - INFO - Fold 3, Epoch 150: Val Acc: 0.62%
2025-08-14 23:52:10,242 - INFO - Fold 3, Epoch 160: Val Acc: 0.84%
2025-08-14 23:52:13,579 - INFO - Fold 3, Epoch 170: Val Acc: 0.75%
2025-08-14 23:52:15,778 - INFO - Fold 3, Epoch 180: Val Acc: 0.69%
2025-08-14 23:52:17,934 - INFO - Fold 3, Epoch 190: Val Acc: 0.66%
2025-08-14 23:52:20,144 - INFO - Fold 3, Epoch 200: Val Acc: 0.66%
2025-08-14 23:52:22,326 - INFO - Fold 3, Epoch 210: Val Acc: 0.53%
2025-08-14 23:52:24,441 - INFO - Fold 3, Epoch 220: Val Acc: 0.72%
2025-08-14 23:52:26,653 - INFO - Fold 3, Epoch 230: Val Acc: 0.78%
2025-08-14 23:52:28,862 - INFO - Fold 3, Epoch 240: Val Acc: 0.69%
2025-08-14 23:52:31,070 - INFO - Fold 3, Epoch 250: Val Acc: 0.56%
2025-08-14 23:52:33,284 - INFO - Fold 3, Epoch 260: Val Acc: 0.78%
2025-08-14 23:52:34,387 - INFO - Early stopping at epoch 265
2025-08-14 23:52:35,448 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.6673924658033585), 'std': np.float64(0.175996517852317)}, 'train_accuracy': {'mean': np.float64(0.8472222222222223), 'std': np.float64(0.06821834272357112)}, 'val_loss': {'mean': np.float64(4.252886136372884), 'std': np.float64(0.02808714405112783)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(132.0), 'std': np.float64(60.71243694664216)}}
[I 2025-08-14 23:52:35,455] Trial 99 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0009069595881342901, 'batch_size': 32, 'num_epochs': 388, 'temperature': 0.2911148504641923, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4813798960703371, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07314227434770403, 'crop_size': 0.5453611934661641}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 99 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0009069595881342901, 'batch_size': 32, 'num_epochs': 388, 'temperature': 0.2911148504641923, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4813798960703371, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07314227434770403, 'crop_size': 0.5453611934661641}. Best is trial 92 with value: -0.9479166666666666.
2025-08-14 23:52:35,487 - INFO - Using device: cuda
2025-08-14 23:52:45,169 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:52:45,171 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:52:45,171 - INFO - Starting training for fold 1/3
2025-08-14 23:52:55,713 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-14 23:52:58,060 - INFO - Fold 1, Epoch 20: Val Acc: 0.44%
2025-08-14 23:53:00,521 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-14 23:53:03,002 - INFO - Fold 1, Epoch 40: Val Acc: 0.50%
2025-08-14 23:53:05,471 - INFO - Fold 1, Epoch 50: Val Acc: 0.50%
2025-08-14 23:53:07,945 - INFO - Fold 1, Epoch 60: Val Acc: 0.53%
2025-08-14 23:53:10,419 - INFO - Fold 1, Epoch 70: Val Acc: 0.44%
2025-08-14 23:53:12,892 - INFO - Fold 1, Epoch 80: Val Acc: 0.50%
2025-08-14 23:53:15,364 - INFO - Fold 1, Epoch 90: Val Acc: 0.50%
2025-08-14 23:53:17,848 - INFO - Fold 1, Epoch 100: Val Acc: 0.50%
2025-08-14 23:53:18,583 - INFO - Early stopping at epoch 103
2025-08-14 23:53:22,481 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:53:22,483 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:53:22,484 - INFO - Starting training for fold 2/3
2025-08-14 23:53:26,896 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-14 23:53:31,157 - INFO - Fold 2, Epoch 20: Val Acc: 0.41%
2025-08-14 23:53:35,432 - INFO - Fold 2, Epoch 30: Val Acc: 0.56%
2025-08-14 23:53:37,898 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-14 23:53:40,360 - INFO - Fold 2, Epoch 50: Val Acc: 0.47%
2025-08-14 23:53:42,834 - INFO - Fold 2, Epoch 60: Val Acc: 0.44%
2025-08-14 23:53:45,167 - INFO - Fold 2, Epoch 70: Val Acc: 0.44%
2025-08-14 23:53:47,651 - INFO - Fold 2, Epoch 80: Val Acc: 0.56%
2025-08-14 23:53:51,920 - INFO - Fold 2, Epoch 90: Val Acc: 0.41%
2025-08-14 23:53:54,382 - INFO - Fold 2, Epoch 100: Val Acc: 0.50%
2025-08-14 23:53:56,850 - INFO - Fold 2, Epoch 110: Val Acc: 0.31%
2025-08-14 23:53:59,322 - INFO - Fold 2, Epoch 120: Val Acc: 0.47%
2025-08-14 23:54:01,779 - INFO - Fold 2, Epoch 130: Val Acc: 0.47%
2025-08-14 23:54:04,233 - INFO - Fold 2, Epoch 140: Val Acc: 0.38%
2025-08-14 23:54:06,574 - INFO - Fold 2, Epoch 150: Val Acc: 0.50%
2025-08-14 23:54:10,721 - INFO - Fold 2, Epoch 160: Val Acc: 0.53%
2025-08-14 23:54:13,196 - INFO - Fold 2, Epoch 170: Val Acc: 0.34%
2025-08-14 23:54:15,676 - INFO - Fold 2, Epoch 180: Val Acc: 0.50%
2025-08-14 23:54:17,624 - INFO - Fold 2, Epoch 190: Val Acc: 0.53%
2025-08-14 23:54:19,511 - INFO - Fold 2, Epoch 200: Val Acc: 0.50%
2025-08-14 23:54:21,397 - INFO - Fold 2, Epoch 210: Val Acc: 0.66%
2025-08-14 23:54:23,439 - INFO - Fold 2, Epoch 220: Val Acc: 0.41%
2025-08-14 23:54:25,896 - INFO - Fold 2, Epoch 230: Val Acc: 0.50%
2025-08-14 23:54:28,362 - INFO - Fold 2, Epoch 240: Val Acc: 0.59%
2025-08-14 23:54:30,826 - INFO - Fold 2, Epoch 250: Val Acc: 0.72%
2025-08-14 23:54:32,064 - INFO - Early stopping at epoch 255
2025-08-14 23:54:35,250 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:54:35,254 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:54:35,254 - INFO - Starting training for fold 3/3
2025-08-14 23:54:42,933 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-14 23:54:45,404 - INFO - Fold 3, Epoch 20: Val Acc: 0.56%
2025-08-14 23:54:47,872 - INFO - Fold 3, Epoch 30: Val Acc: 0.44%
2025-08-14 23:54:50,329 - INFO - Fold 3, Epoch 40: Val Acc: 0.41%
2025-08-14 23:54:54,486 - INFO - Fold 3, Epoch 50: Val Acc: 0.47%
2025-08-14 23:54:56,948 - INFO - Fold 3, Epoch 60: Val Acc: 0.59%
2025-08-14 23:54:59,293 - INFO - Fold 3, Epoch 70: Val Acc: 0.53%
2025-08-14 23:55:02,869 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-14 23:55:05,433 - INFO - Fold 3, Epoch 90: Val Acc: 0.53%
2025-08-14 23:55:08,007 - INFO - Fold 3, Epoch 100: Val Acc: 0.47%
2025-08-14 23:55:10,584 - INFO - Fold 3, Epoch 110: Val Acc: 0.56%
2025-08-14 23:55:13,161 - INFO - Fold 3, Epoch 120: Val Acc: 0.59%
2025-08-14 23:55:15,606 - INFO - Fold 3, Epoch 130: Val Acc: 0.44%
2025-08-14 23:55:18,193 - INFO - Fold 3, Epoch 140: Val Acc: 0.44%
2025-08-14 23:55:20,684 - INFO - Fold 3, Epoch 150: Val Acc: 0.47%
2025-08-14 23:55:23,256 - INFO - Fold 3, Epoch 160: Val Acc: 0.44%
2025-08-14 23:55:25,541 - INFO - Fold 3, Epoch 170: Val Acc: 0.53%
2025-08-14 23:55:29,718 - INFO - Fold 3, Epoch 180: Val Acc: 0.53%
2025-08-14 23:55:31,920 - INFO - Fold 3, Epoch 190: Val Acc: 0.62%
2025-08-14 23:55:34,105 - INFO - Fold 3, Epoch 200: Val Acc: 0.47%
2025-08-14 23:55:36,576 - INFO - Fold 3, Epoch 210: Val Acc: 0.47%
2025-08-14 23:55:39,039 - INFO - Fold 3, Epoch 220: Val Acc: 0.56%
2025-08-14 23:55:41,506 - INFO - Fold 3, Epoch 230: Val Acc: 0.53%
2025-08-14 23:55:43,973 - INFO - Fold 3, Epoch 240: Val Acc: 0.53%
2025-08-14 23:55:46,440 - INFO - Fold 3, Epoch 250: Val Acc: 0.47%
2025-08-14 23:55:48,910 - INFO - Fold 3, Epoch 260: Val Acc: 0.50%
2025-08-14 23:55:51,375 - INFO - Fold 3, Epoch 270: Val Acc: 0.53%
2025-08-14 23:55:52,614 - INFO - Early stopping at epoch 275
2025-08-14 23:55:53,926 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.13676659266154), 'std': np.float64(0.01860591108450205)}, 'train_accuracy': {'mean': np.float64(0.5451388888888888), 'std': np.float64(0.017704928866641587)}, 'val_loss': {'mean': np.float64(4.147727171579997), 'std': np.float64(0.03705368968286349)}, 'val_accuracy': {'mean': np.float64(0.6979166666666666), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(110.0), 'std': np.float64(76.8027777275449)}}
[I 2025-08-14 23:55:53,933] Trial 100 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 0.00045047548803899635, 'batch_size': 32, 'num_epochs': 528, 'temperature': 0.3320655151276991, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4996335643769641, 'num_layers': 6, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.0849584141291882}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 100 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 0.00045047548803899635, 'batch_size': 32, 'num_epochs': 528, 'temperature': 0.3320655151276991, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4996335643769641, 'num_layers': 6, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.0849584141291882}. Best is trial 92 with value: -0.9479166666666666.
2025-08-14 23:55:53,972 - INFO - Using device: cuda
2025-08-14 23:56:04,150 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:56:04,152 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:56:04,152 - INFO - Starting training for fold 1/3
2025-08-14 23:56:20,029 - INFO - Fold 1, Epoch 10: Val Acc: 0.66%
2025-08-14 23:56:24,717 - INFO - Fold 1, Epoch 20: Val Acc: 0.66%
2025-08-14 23:56:26,929 - INFO - Fold 1, Epoch 30: Val Acc: 0.72%
2025-08-14 23:56:29,140 - INFO - Fold 1, Epoch 40: Val Acc: 0.62%
2025-08-14 23:56:33,704 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-14 23:56:35,906 - INFO - Fold 1, Epoch 60: Val Acc: 0.66%
2025-08-14 23:56:40,392 - INFO - Fold 1, Epoch 70: Val Acc: 0.69%
2025-08-14 23:56:42,332 - INFO - Fold 1, Epoch 80: Val Acc: 0.75%
2025-08-14 23:56:44,115 - INFO - Fold 1, Epoch 90: Val Acc: 0.56%
2025-08-14 23:56:46,318 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-14 23:56:48,528 - INFO - Fold 1, Epoch 110: Val Acc: 0.72%
2025-08-14 23:56:50,744 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-14 23:56:52,948 - INFO - Fold 1, Epoch 130: Val Acc: 0.56%
2025-08-14 23:56:55,098 - INFO - Fold 1, Epoch 140: Val Acc: 0.69%
2025-08-14 23:56:57,096 - INFO - Fold 1, Epoch 150: Val Acc: 0.81%
2025-08-14 23:56:59,104 - INFO - Fold 1, Epoch 160: Val Acc: 0.59%
2025-08-14 23:56:59,274 - INFO - Early stopping at epoch 161
2025-08-14 23:57:03,025 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:57:03,028 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:57:03,028 - INFO - Starting training for fold 2/3
2025-08-14 23:57:11,242 - INFO - Fold 2, Epoch 10: Val Acc: 0.47%
2025-08-14 23:57:14,950 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-14 23:57:18,640 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-14 23:57:20,858 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-14 23:57:23,073 - INFO - Fold 2, Epoch 50: Val Acc: 0.72%
2025-08-14 23:57:25,280 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-14 23:57:27,492 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-14 23:57:29,710 - INFO - Fold 2, Epoch 80: Val Acc: 0.78%
2025-08-14 23:57:31,927 - INFO - Fold 2, Epoch 90: Val Acc: 0.84%
2025-08-14 23:57:34,148 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-14 23:57:37,866 - INFO - Fold 2, Epoch 110: Val Acc: 0.78%
2025-08-14 23:57:40,074 - INFO - Fold 2, Epoch 120: Val Acc: 0.84%
2025-08-14 23:57:42,334 - INFO - Fold 2, Epoch 130: Val Acc: 0.88%
2025-08-14 23:57:44,600 - INFO - Fold 2, Epoch 140: Val Acc: 0.69%
2025-08-14 23:57:46,837 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-14 23:57:49,038 - INFO - Fold 2, Epoch 160: Val Acc: 0.62%
2025-08-14 23:57:51,255 - INFO - Fold 2, Epoch 170: Val Acc: 0.75%
2025-08-14 23:57:53,470 - INFO - Fold 2, Epoch 180: Val Acc: 0.88%
2025-08-14 23:57:55,156 - INFO - Fold 2, Epoch 190: Val Acc: 0.69%
2025-08-14 23:57:56,843 - INFO - Fold 2, Epoch 200: Val Acc: 0.69%
2025-08-14 23:57:57,180 - INFO - Early stopping at epoch 202
2025-08-14 23:58:00,294 - INFO - --- Starting Fold 3/3 ---
2025-08-14 23:58:00,297 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:58:00,298 - INFO - Starting training for fold 3/3
2025-08-14 23:58:08,441 - INFO - Fold 3, Epoch 10: Val Acc: 0.41%
2025-08-14 23:58:14,183 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-14 23:58:18,022 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-14 23:58:21,785 - INFO - Fold 3, Epoch 40: Val Acc: 0.62%
2025-08-14 23:58:24,000 - INFO - Fold 3, Epoch 50: Val Acc: 0.75%
2025-08-14 23:58:27,611 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-14 23:58:29,829 - INFO - Fold 3, Epoch 70: Val Acc: 0.81%
2025-08-14 23:58:32,042 - INFO - Fold 3, Epoch 80: Val Acc: 0.62%
2025-08-14 23:58:34,255 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-14 23:58:36,461 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-14 23:58:38,671 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-14 23:58:40,877 - INFO - Fold 3, Epoch 120: Val Acc: 0.66%
2025-08-14 23:58:43,083 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-14 23:58:45,194 - INFO - Fold 3, Epoch 140: Val Acc: 0.84%
2025-08-14 23:58:47,336 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-14 23:58:47,791 - INFO - Early stopping at epoch 152
2025-08-14 23:58:48,887 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.941029283735487), 'std': np.float64(0.04459291075876088)}, 'train_accuracy': {'mean': np.float64(0.7604166666666666), 'std': np.float64(0.0450051437389435)}, 'val_loss': {'mean': np.float64(4.173643430074056), 'std': np.float64(0.05026884223628929)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(70.66666666666667), 'std': np.float64(21.761331658599286)}}
[I 2025-08-14 23:58:48,896] Trial 101 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0005816551214589487, 'batch_size': 32, 'num_epochs': 429, 'temperature': 0.40093219806181746, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.44547843651541186, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.11202750689866492, 'crop_size': 0.5113401680863593}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 101 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0005816551214589487, 'batch_size': 32, 'num_epochs': 429, 'temperature': 0.40093219806181746, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.44547843651541186, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.11202750689866492, 'crop_size': 0.5113401680863593}. Best is trial 92 with value: -0.9479166666666666.
2025-08-14 23:58:48,947 - INFO - Using device: cuda
2025-08-14 23:58:58,608 - INFO - --- Starting Fold 1/3 ---
2025-08-14 23:58:58,610 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:58:58,610 - INFO - Starting training for fold 1/3
2025-08-14 23:59:03,102 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-14 23:59:07,600 - INFO - Fold 1, Epoch 20: Val Acc: 0.69%
2025-08-14 23:59:11,947 - INFO - Fold 1, Epoch 30: Val Acc: 0.69%
2025-08-14 23:59:14,252 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-14 23:59:18,780 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-14 23:59:23,102 - INFO - Fold 1, Epoch 60: Val Acc: 0.75%
2025-08-14 23:59:25,406 - INFO - Fold 1, Epoch 70: Val Acc: 0.78%
2025-08-14 23:59:29,892 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-14 23:59:32,182 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-14 23:59:34,058 - INFO - Fold 1, Epoch 100: Val Acc: 0.84%
2025-08-14 23:59:36,005 - INFO - Fold 1, Epoch 110: Val Acc: 0.78%
2025-08-14 23:59:38,306 - INFO - Fold 1, Epoch 120: Val Acc: 0.72%
2025-08-14 23:59:40,601 - INFO - Fold 1, Epoch 130: Val Acc: 0.66%
2025-08-14 23:59:42,896 - INFO - Fold 1, Epoch 140: Val Acc: 0.78%
2025-08-14 23:59:45,161 - INFO - Fold 1, Epoch 150: Val Acc: 0.69%
2025-08-14 23:59:47,281 - INFO - Fold 1, Epoch 160: Val Acc: 0.66%
2025-08-14 23:59:49,110 - INFO - Fold 1, Epoch 170: Val Acc: 0.66%
2025-08-14 23:59:50,363 - INFO - Early stopping at epoch 177
2025-08-14 23:59:53,929 - INFO - --- Starting Fold 2/3 ---
2025-08-14 23:59:53,932 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-14 23:59:53,932 - INFO - Starting training for fold 2/3
2025-08-14 23:59:59,097 - INFO - Fold 2, Epoch 10: Val Acc: 0.62%
2025-08-15 00:00:04,692 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-15 00:00:06,896 - INFO - Fold 2, Epoch 30: Val Acc: 0.62%
2025-08-15 00:00:11,102 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-15 00:00:13,314 - INFO - Fold 2, Epoch 50: Val Acc: 0.62%
2025-08-15 00:00:15,520 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-15 00:00:17,724 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-15 00:00:21,390 - INFO - Fold 2, Epoch 80: Val Acc: 0.72%
2025-08-15 00:00:23,482 - INFO - Fold 2, Epoch 90: Val Acc: 0.75%
2025-08-15 00:00:25,382 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-15 00:00:27,085 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-15 00:00:28,783 - INFO - Fold 2, Epoch 120: Val Acc: 0.62%
2025-08-15 00:00:30,482 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-15 00:00:32,182 - INFO - Fold 2, Epoch 140: Val Acc: 0.62%
2025-08-15 00:00:33,878 - INFO - Fold 2, Epoch 150: Val Acc: 0.72%
2025-08-15 00:00:35,575 - INFO - Fold 2, Epoch 160: Val Acc: 0.75%
2025-08-15 00:00:37,278 - INFO - Fold 2, Epoch 170: Val Acc: 0.84%
2025-08-15 00:00:38,299 - INFO - Early stopping at epoch 176
2025-08-15 00:00:39,385 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:00:39,387 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:00:39,387 - INFO - Starting training for fold 3/3
2025-08-15 00:00:47,821 - INFO - Fold 3, Epoch 10: Val Acc: 0.41%
2025-08-15 00:00:54,397 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-15 00:00:56,638 - INFO - Fold 3, Epoch 30: Val Acc: 0.75%
2025-08-15 00:01:02,009 - INFO - Fold 3, Epoch 40: Val Acc: 0.81%
2025-08-15 00:01:03,969 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-15 00:01:05,766 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-15 00:01:07,666 - INFO - Fold 3, Epoch 70: Val Acc: 0.78%
2025-08-15 00:01:09,575 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-15 00:01:11,879 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-15 00:01:14,185 - INFO - Fold 3, Epoch 100: Val Acc: 0.81%
2025-08-15 00:01:16,488 - INFO - Fold 3, Epoch 110: Val Acc: 0.88%
2025-08-15 00:01:18,643 - INFO - Fold 3, Epoch 120: Val Acc: 0.66%
2025-08-15 00:01:22,780 - INFO - Fold 3, Epoch 130: Val Acc: 0.78%
2025-08-15 00:01:24,605 - INFO - Fold 3, Epoch 140: Val Acc: 0.69%
2025-08-15 00:01:26,413 - INFO - Fold 3, Epoch 150: Val Acc: 0.78%
2025-08-15 00:01:28,215 - INFO - Fold 3, Epoch 160: Val Acc: 0.62%
2025-08-15 00:01:30,003 - INFO - Fold 3, Epoch 170: Val Acc: 0.66%
2025-08-15 00:01:31,796 - INFO - Fold 3, Epoch 180: Val Acc: 0.72%
2025-08-15 00:01:33,588 - INFO - Fold 3, Epoch 190: Val Acc: 0.75%
2025-08-15 00:01:35,507 - INFO - Fold 3, Epoch 200: Val Acc: 0.72%
2025-08-15 00:01:37,809 - INFO - Fold 3, Epoch 210: Val Acc: 0.75%
2025-08-15 00:01:43,750 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9394065009223085), 'std': np.float64(0.004000522313095583)}, 'train_accuracy': {'mean': np.float64(0.7916666666666666), 'std': np.float64(0.01473139127471974)}, 'val_loss': {'mean': np.float64(4.216904640197754), 'std': np.float64(0.06672559159713708)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(92.0), 'std': np.float64(23.338094752285727)}}
[I 2025-08-15 00:01:43,777] Trial 102 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0005014541906274236, 'batch_size': 32, 'num_epochs': 219, 'temperature': 0.4367924873726151, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4690386348173431, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.054860425094056815, 'crop_size': 0.5273258016433588}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 102 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0005014541906274236, 'batch_size': 32, 'num_epochs': 219, 'temperature': 0.4367924873726151, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4690386348173431, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.054860425094056815, 'crop_size': 0.5273258016433588}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:01:43,861 - INFO - Using device: cuda
2025-08-15 00:01:53,624 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:01:53,625 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:01:53,626 - INFO - Starting training for fold 1/3
2025-08-15 00:02:07,580 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-15 00:02:09,786 - INFO - Fold 1, Epoch 20: Val Acc: 0.62%
2025-08-15 00:02:14,966 - INFO - Fold 1, Epoch 30: Val Acc: 0.78%
2025-08-15 00:02:19,988 - INFO - Fold 1, Epoch 40: Val Acc: 0.78%
2025-08-15 00:02:21,905 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-15 00:02:23,606 - INFO - Fold 1, Epoch 60: Val Acc: 0.75%
2025-08-15 00:02:25,302 - INFO - Fold 1, Epoch 70: Val Acc: 0.81%
2025-08-15 00:02:27,004 - INFO - Fold 1, Epoch 80: Val Acc: 0.75%
2025-08-15 00:02:28,698 - INFO - Fold 1, Epoch 90: Val Acc: 0.81%
2025-08-15 00:02:30,851 - INFO - Fold 1, Epoch 100: Val Acc: 0.62%
2025-08-15 00:02:32,567 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-15 00:02:34,266 - INFO - Fold 1, Epoch 120: Val Acc: 0.62%
2025-08-15 00:02:36,359 - INFO - Fold 1, Epoch 130: Val Acc: 0.66%
2025-08-15 00:02:37,965 - INFO - Early stopping at epoch 137
2025-08-15 00:02:42,565 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:02:42,568 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:02:42,568 - INFO - Starting training for fold 2/3
2025-08-15 00:02:50,260 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 00:02:56,066 - INFO - Fold 2, Epoch 20: Val Acc: 0.56%
2025-08-15 00:02:58,286 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-15 00:03:02,086 - INFO - Fold 2, Epoch 40: Val Acc: 0.81%
2025-08-15 00:03:07,860 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-15 00:03:09,985 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-15 00:03:12,205 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-15 00:03:14,430 - INFO - Fold 2, Epoch 80: Val Acc: 0.84%
2025-08-15 00:03:16,648 - INFO - Fold 2, Epoch 90: Val Acc: 0.59%
2025-08-15 00:03:18,618 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-15 00:03:20,693 - INFO - Fold 2, Epoch 110: Val Acc: 0.59%
2025-08-15 00:03:22,911 - INFO - Fold 2, Epoch 120: Val Acc: 0.84%
2025-08-15 00:03:25,117 - INFO - Fold 2, Epoch 130: Val Acc: 0.72%
2025-08-15 00:03:27,317 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-15 00:03:28,683 - INFO - Early stopping at epoch 148
2025-08-15 00:03:31,749 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:03:31,752 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:03:31,753 - INFO - Starting training for fold 3/3
2025-08-15 00:03:38,546 - INFO - Fold 3, Epoch 10: Val Acc: 0.69%
2025-08-15 00:03:42,276 - INFO - Fold 3, Epoch 20: Val Acc: 0.66%
2025-08-15 00:03:46,087 - INFO - Fold 3, Epoch 30: Val Acc: 0.75%
2025-08-15 00:03:51,234 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-15 00:03:53,443 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-15 00:03:55,504 - INFO - Fold 3, Epoch 60: Val Acc: 0.78%
2025-08-15 00:03:57,205 - INFO - Fold 3, Epoch 70: Val Acc: 0.88%
2025-08-15 00:03:58,907 - INFO - Fold 3, Epoch 80: Val Acc: 0.81%
2025-08-15 00:04:00,921 - INFO - Fold 3, Epoch 90: Val Acc: 0.78%
2025-08-15 00:04:03,135 - INFO - Fold 3, Epoch 100: Val Acc: 0.81%
2025-08-15 00:04:05,341 - INFO - Fold 3, Epoch 110: Val Acc: 0.72%
2025-08-15 00:04:07,529 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-15 00:04:09,749 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-15 00:04:11,748 - INFO - Early stopping at epoch 139
2025-08-15 00:04:12,834 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.98441219329834), 'std': np.float64(0.010074042823783129)}, 'train_accuracy': {'mean': np.float64(0.7881944444444445), 'std': np.float64(0.02598373185259682)}, 'val_loss': {'mean': np.float64(4.161401112874349), 'std': np.float64(0.0478480733253454)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(40.333333333333336), 'std': np.float64(4.784233364802441)}}
[I 2025-08-15 00:04:12,841] Trial 103 finished with value: -0.90625 and parameters: {'learning_rate': 0.0006524530249655876, 'batch_size': 32, 'num_epochs': 419, 'temperature': 0.49682974482858805, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4322144119939963, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.09760413910244412, 'crop_size': 0.558223114575588}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 103 finished with value: -0.90625 and parameters: {'learning_rate': 0.0006524530249655876, 'batch_size': 32, 'num_epochs': 419, 'temperature': 0.49682974482858805, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4322144119939963, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.09760413910244412, 'crop_size': 0.558223114575588}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:04:12,883 - INFO - Using device: cuda
2025-08-15 00:04:22,677 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:04:22,678 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:04:22,679 - INFO - Starting training for fold 1/3
2025-08-15 00:04:36,376 - INFO - Fold 1, Epoch 10: Val Acc: 0.66%
2025-08-15 00:04:42,948 - INFO - Fold 1, Epoch 20: Val Acc: 0.69%
2025-08-15 00:04:45,167 - INFO - Fold 1, Epoch 30: Val Acc: 0.66%
2025-08-15 00:04:47,399 - INFO - Fold 1, Epoch 40: Val Acc: 0.62%
2025-08-15 00:04:49,367 - INFO - Fold 1, Epoch 50: Val Acc: 0.69%
2025-08-15 00:04:53,745 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-15 00:04:55,892 - INFO - Fold 1, Epoch 70: Val Acc: 0.50%
2025-08-15 00:04:57,898 - INFO - Fold 1, Epoch 80: Val Acc: 0.78%
2025-08-15 00:05:00,117 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-15 00:05:02,345 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-15 00:05:04,646 - INFO - Fold 1, Epoch 110: Val Acc: 0.59%
2025-08-15 00:05:06,951 - INFO - Fold 1, Epoch 120: Val Acc: 0.66%
2025-08-15 00:05:09,251 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-15 00:05:11,494 - INFO - Fold 1, Epoch 140: Val Acc: 0.59%
2025-08-15 00:05:13,717 - INFO - Fold 1, Epoch 150: Val Acc: 0.66%
2025-08-15 00:05:14,156 - INFO - Early stopping at epoch 152
2025-08-15 00:05:17,790 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:05:17,792 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:05:17,793 - INFO - Starting training for fold 2/3
2025-08-15 00:05:30,830 - INFO - Fold 2, Epoch 10: Val Acc: 0.75%
2025-08-15 00:05:35,981 - INFO - Fold 2, Epoch 20: Val Acc: 0.91%
2025-08-15 00:05:38,279 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-15 00:05:41,572 - INFO - Fold 2, Epoch 40: Val Acc: 0.81%
2025-08-15 00:05:43,470 - INFO - Fold 2, Epoch 50: Val Acc: 0.72%
2025-08-15 00:05:45,695 - INFO - Fold 2, Epoch 60: Val Acc: 0.78%
2025-08-15 00:05:47,912 - INFO - Fold 2, Epoch 70: Val Acc: 0.81%
2025-08-15 00:05:49,710 - INFO - Fold 2, Epoch 80: Val Acc: 0.84%
2025-08-15 00:05:51,743 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-15 00:05:53,964 - INFO - Fold 2, Epoch 100: Val Acc: 0.72%
2025-08-15 00:05:55,768 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-15 00:05:57,475 - INFO - Fold 2, Epoch 120: Val Acc: 0.78%
2025-08-15 00:05:59,171 - INFO - Fold 2, Epoch 130: Val Acc: 0.72%
2025-08-15 00:06:00,038 - INFO - Early stopping at epoch 134
2025-08-15 00:06:03,268 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:06:03,271 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:06:03,271 - INFO - Starting training for fold 3/3
2025-08-15 00:06:13,246 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-15 00:06:16,962 - INFO - Fold 3, Epoch 20: Val Acc: 0.75%
2025-08-15 00:06:19,034 - INFO - Fold 3, Epoch 30: Val Acc: 0.84%
2025-08-15 00:06:21,238 - INFO - Fold 3, Epoch 40: Val Acc: 0.78%
2025-08-15 00:06:23,436 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-15 00:06:25,647 - INFO - Fold 3, Epoch 60: Val Acc: 0.78%
2025-08-15 00:06:27,905 - INFO - Fold 3, Epoch 70: Val Acc: 0.59%
2025-08-15 00:06:30,107 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-15 00:06:33,669 - INFO - Fold 3, Epoch 90: Val Acc: 0.78%
2025-08-15 00:06:35,881 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-15 00:06:38,148 - INFO - Fold 3, Epoch 110: Val Acc: 0.69%
2025-08-15 00:06:40,440 - INFO - Fold 3, Epoch 120: Val Acc: 0.66%
2025-08-15 00:06:42,735 - INFO - Fold 3, Epoch 130: Val Acc: 0.75%
2025-08-15 00:06:44,998 - INFO - Fold 3, Epoch 140: Val Acc: 0.56%
2025-08-15 00:06:46,931 - INFO - Fold 3, Epoch 150: Val Acc: 0.62%
2025-08-15 00:06:48,626 - INFO - Fold 3, Epoch 160: Val Acc: 0.72%
2025-08-15 00:06:50,497 - INFO - Fold 3, Epoch 170: Val Acc: 0.66%
2025-08-15 00:06:52,716 - INFO - Fold 3, Epoch 180: Val Acc: 0.72%
2025-08-15 00:06:52,920 - INFO - Early stopping at epoch 181
2025-08-15 00:06:54,015 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.77300837304857), 'std': np.float64(0.08017706266311973)}, 'train_accuracy': {'mean': np.float64(0.84375), 'std': np.float64(0.04500514373894348)}, 'val_loss': {'mean': np.float64(4.187516848246257), 'std': np.float64(0.04647116676030397)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.06421264586426018)}, 'epoch': {'mean': np.float64(54.666666666666664), 'std': np.float64(19.362047641943477)}}
[I 2025-08-15 00:06:54,022] Trial 104 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0007952696369353558, 'batch_size': 32, 'num_epochs': 403, 'temperature': 0.3543256395369494, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4866349514202222, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.04107047662309709, 'crop_size': 0.7794427340164821}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 104 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0007952696369353558, 'batch_size': 32, 'num_epochs': 403, 'temperature': 0.3543256395369494, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4866349514202222, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.04107047662309709, 'crop_size': 0.7794427340164821}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:06:54,059 - INFO - Using device: cuda
2025-08-15 00:07:03,686 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:07:03,690 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:07:03,690 - INFO - Starting training for fold 1/3
2025-08-15 00:07:16,055 - INFO - Fold 1, Epoch 10: Val Acc: 0.62%
2025-08-15 00:07:18,275 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-15 00:07:20,489 - INFO - Fold 1, Epoch 30: Val Acc: 0.53%
2025-08-15 00:07:25,016 - INFO - Fold 1, Epoch 40: Val Acc: 0.75%
2025-08-15 00:07:27,225 - INFO - Fold 1, Epoch 50: Val Acc: 0.72%
2025-08-15 00:07:28,924 - INFO - Fold 1, Epoch 60: Val Acc: 0.81%
2025-08-15 00:07:30,622 - INFO - Fold 1, Epoch 70: Val Acc: 0.62%
2025-08-15 00:07:32,318 - INFO - Fold 1, Epoch 80: Val Acc: 0.69%
2025-08-15 00:07:34,015 - INFO - Fold 1, Epoch 90: Val Acc: 0.62%
2025-08-15 00:07:38,048 - INFO - Fold 1, Epoch 100: Val Acc: 0.81%
2025-08-15 00:07:39,753 - INFO - Fold 1, Epoch 110: Val Acc: 0.59%
2025-08-15 00:07:41,846 - INFO - Fold 1, Epoch 120: Val Acc: 0.72%
2025-08-15 00:07:43,866 - INFO - Fold 1, Epoch 130: Val Acc: 0.66%
2025-08-15 00:07:45,559 - INFO - Fold 1, Epoch 140: Val Acc: 0.66%
2025-08-15 00:07:47,252 - INFO - Fold 1, Epoch 150: Val Acc: 0.62%
2025-08-15 00:07:48,943 - INFO - Fold 1, Epoch 160: Val Acc: 0.72%
2025-08-15 00:07:50,637 - INFO - Fold 1, Epoch 170: Val Acc: 0.72%
2025-08-15 00:07:52,328 - INFO - Fold 1, Epoch 180: Val Acc: 0.69%
2025-08-15 00:07:54,038 - INFO - Fold 1, Epoch 190: Val Acc: 0.50%
2025-08-15 00:07:54,702 - INFO - Early stopping at epoch 193
2025-08-15 00:07:58,455 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:07:58,457 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:07:58,458 - INFO - Starting training for fold 2/3
2025-08-15 00:08:05,718 - INFO - Fold 2, Epoch 10: Val Acc: 0.59%
2025-08-15 00:08:10,996 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-15 00:08:14,446 - INFO - Fold 2, Epoch 30: Val Acc: 0.56%
2025-08-15 00:08:16,148 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-15 00:08:17,848 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-15 00:08:22,051 - INFO - Fold 2, Epoch 60: Val Acc: 0.84%
2025-08-15 00:08:23,748 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-15 00:08:25,451 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-15 00:08:28,759 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-15 00:08:30,844 - INFO - Fold 2, Epoch 100: Val Acc: 0.62%
2025-08-15 00:08:32,790 - INFO - Fold 2, Epoch 110: Val Acc: 0.78%
2025-08-15 00:08:34,999 - INFO - Fold 2, Epoch 120: Val Acc: 0.66%
2025-08-15 00:08:37,211 - INFO - Fold 2, Epoch 130: Val Acc: 0.66%
2025-08-15 00:08:39,421 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-15 00:08:41,627 - INFO - Fold 2, Epoch 150: Val Acc: 0.78%
2025-08-15 00:08:43,832 - INFO - Fold 2, Epoch 160: Val Acc: 0.75%
2025-08-15 00:08:46,044 - INFO - Fold 2, Epoch 170: Val Acc: 0.75%
2025-08-15 00:08:48,254 - INFO - Fold 2, Epoch 180: Val Acc: 0.81%
2025-08-15 00:08:49,582 - INFO - Early stopping at epoch 186
2025-08-15 00:08:50,674 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:08:50,678 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:08:50,678 - INFO - Starting training for fold 3/3
2025-08-15 00:08:57,689 - INFO - Fold 3, Epoch 10: Val Acc: 0.69%
2025-08-15 00:09:01,478 - INFO - Fold 3, Epoch 20: Val Acc: 0.47%
2025-08-15 00:09:03,709 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-15 00:09:05,517 - INFO - Fold 3, Epoch 40: Val Acc: 0.69%
2025-08-15 00:09:08,673 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-15 00:09:10,505 - INFO - Fold 3, Epoch 60: Val Acc: 0.66%
2025-08-15 00:09:13,741 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-15 00:09:16,032 - INFO - Fold 3, Epoch 80: Val Acc: 0.62%
2025-08-15 00:09:19,807 - INFO - Fold 3, Epoch 90: Val Acc: 0.66%
2025-08-15 00:09:22,100 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-15 00:09:24,398 - INFO - Fold 3, Epoch 110: Val Acc: 0.69%
2025-08-15 00:09:26,678 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-15 00:09:28,940 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-15 00:09:30,632 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-15 00:09:32,621 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-15 00:09:34,516 - INFO - Fold 3, Epoch 160: Val Acc: 0.69%
2025-08-15 00:09:36,810 - INFO - Fold 3, Epoch 170: Val Acc: 0.75%
2025-08-15 00:09:38,817 - INFO - Fold 3, Epoch 180: Val Acc: 0.78%
2025-08-15 00:09:40,594 - INFO - Early stopping at epoch 188
2025-08-15 00:09:41,666 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9572774834103055), 'std': np.float64(0.022649033237215246)}, 'train_accuracy': {'mean': np.float64(0.732638888888889), 'std': np.float64(0.04019387813468828)}, 'val_loss': {'mean': np.float64(4.157341003417969), 'std': np.float64(0.061356173320404744)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.0)}, 'epoch': {'mean': np.float64(88.0), 'std': np.float64(2.943920288775949)}}
[I 2025-08-15 00:09:41,673] Trial 105 finished with value: -0.90625 and parameters: {'learning_rate': 0.0002798113038779284, 'batch_size': 32, 'num_epochs': 315, 'temperature': 0.3132119859985611, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4571587134025844, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06501572399077714, 'crop_size': 0.5378232339634017}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 105 finished with value: -0.90625 and parameters: {'learning_rate': 0.0002798113038779284, 'batch_size': 32, 'num_epochs': 315, 'temperature': 0.3132119859985611, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4571587134025844, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06501572399077714, 'crop_size': 0.5378232339634017}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:09:41,710 - INFO - Using device: cuda
2025-08-15 00:09:51,728 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:09:51,730 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:09:51,730 - INFO - Starting training for fold 1/3
2025-08-15 00:10:05,674 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-15 00:10:07,930 - INFO - Fold 1, Epoch 20: Val Acc: 0.41%
2025-08-15 00:10:10,182 - INFO - Fold 1, Epoch 30: Val Acc: 0.44%
2025-08-15 00:10:12,431 - INFO - Fold 1, Epoch 40: Val Acc: 0.41%
2025-08-15 00:10:14,687 - INFO - Fold 1, Epoch 50: Val Acc: 0.41%
2025-08-15 00:10:16,944 - INFO - Fold 1, Epoch 60: Val Acc: 0.44%
2025-08-15 00:10:19,182 - INFO - Fold 1, Epoch 70: Val Acc: 0.41%
2025-08-15 00:10:21,430 - INFO - Fold 1, Epoch 80: Val Acc: 0.41%
2025-08-15 00:10:23,673 - INFO - Fold 1, Epoch 90: Val Acc: 0.41%
2025-08-15 00:10:25,605 - INFO - Fold 1, Epoch 100: Val Acc: 0.38%
2025-08-15 00:10:27,175 - INFO - Early stopping at epoch 109
2025-08-15 00:10:30,943 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:10:30,946 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:10:30,946 - INFO - Starting training for fold 2/3
2025-08-15 00:10:36,440 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-15 00:10:38,685 - INFO - Fold 2, Epoch 20: Val Acc: 0.47%
2025-08-15 00:10:40,929 - INFO - Fold 2, Epoch 30: Val Acc: 0.44%
2025-08-15 00:10:43,185 - INFO - Fold 2, Epoch 40: Val Acc: 0.59%
2025-08-15 00:10:45,441 - INFO - Fold 2, Epoch 50: Val Acc: 0.41%
2025-08-15 00:10:47,722 - INFO - Fold 2, Epoch 60: Val Acc: 0.59%
2025-08-15 00:10:49,963 - INFO - Fold 2, Epoch 70: Val Acc: 0.41%
2025-08-15 00:10:52,034 - INFO - Fold 2, Epoch 80: Val Acc: 0.50%
2025-08-15 00:10:53,766 - INFO - Fold 2, Epoch 90: Val Acc: 0.50%
2025-08-15 00:10:57,458 - INFO - Fold 2, Epoch 100: Val Acc: 0.44%
2025-08-15 00:10:59,535 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-15 00:11:01,791 - INFO - Fold 2, Epoch 120: Val Acc: 0.53%
2025-08-15 00:11:04,043 - INFO - Fold 2, Epoch 130: Val Acc: 0.66%
2025-08-15 00:11:06,056 - INFO - Fold 2, Epoch 140: Val Acc: 0.50%
2025-08-15 00:11:08,008 - INFO - Fold 2, Epoch 150: Val Acc: 0.47%
2025-08-15 00:11:09,749 - INFO - Fold 2, Epoch 160: Val Acc: 0.50%
2025-08-15 00:11:11,908 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:11:11,911 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:11:11,912 - INFO - Starting training for fold 3/3
2025-08-15 00:11:17,078 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-15 00:11:18,921 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-15 00:11:21,039 - INFO - Fold 3, Epoch 30: Val Acc: 0.59%
2025-08-15 00:11:25,062 - INFO - Fold 3, Epoch 40: Val Acc: 0.44%
2025-08-15 00:11:26,990 - INFO - Fold 3, Epoch 50: Val Acc: 0.59%
2025-08-15 00:11:28,843 - INFO - Fold 3, Epoch 60: Val Acc: 0.44%
2025-08-15 00:11:31,175 - INFO - Fold 3, Epoch 70: Val Acc: 0.50%
2025-08-15 00:11:33,520 - INFO - Fold 3, Epoch 80: Val Acc: 0.53%
2025-08-15 00:11:35,870 - INFO - Fold 3, Epoch 90: Val Acc: 0.50%
2025-08-15 00:11:38,216 - INFO - Fold 3, Epoch 100: Val Acc: 0.47%
2025-08-15 00:11:40,563 - INFO - Fold 3, Epoch 110: Val Acc: 0.53%
2025-08-15 00:11:44,520 - INFO - Fold 3, Epoch 120: Val Acc: 0.47%
2025-08-15 00:11:46,860 - INFO - Fold 3, Epoch 130: Val Acc: 0.44%
2025-08-15 00:11:49,005 - INFO - Fold 3, Epoch 140: Val Acc: 0.47%
2025-08-15 00:11:50,849 - INFO - Fold 3, Epoch 150: Val Acc: 0.44%
2025-08-15 00:11:52,839 - INFO - Fold 3, Epoch 160: Val Acc: 0.62%
2025-08-15 00:11:57,268 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.142039881812202), 'std': np.float64(0.01687943484295715)}, 'train_accuracy': {'mean': np.float64(0.5590277777777778), 'std': np.float64(0.03220006422047123)}, 'val_loss': {'mean': np.float64(4.159301122029622), 'std': np.float64(0.01405104037120803)}, 'val_accuracy': {'mean': np.float64(0.6979166666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(72.33333333333333), 'std': np.float64(45.900859348043674)}}
[I 2025-08-15 00:11:57,281] Trial 106 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 0.0007112774138597203, 'batch_size': 32, 'num_epochs': 166, 'temperature': 0.4693282067342264, 'embedding_dim': 512, 'hidden_dim': 256, 'dropout': 0.46518390276223265, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.12471192318102309, 'crop_size': 0.518323777184678}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 106 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 0.0007112774138597203, 'batch_size': 32, 'num_epochs': 166, 'temperature': 0.4693282067342264, 'embedding_dim': 512, 'hidden_dim': 256, 'dropout': 0.46518390276223265, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.12471192318102309, 'crop_size': 0.518323777184678}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:11:57,366 - INFO - Using device: cuda
2025-08-15 00:12:07,100 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:12:07,102 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:12:07,102 - INFO - Starting training for fold 1/3
2025-08-15 00:12:17,706 - INFO - Fold 1, Epoch 10: Val Acc: 0.69%
2025-08-15 00:12:20,271 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-15 00:12:22,706 - INFO - Fold 1, Epoch 30: Val Acc: 0.47%
2025-08-15 00:12:27,978 - INFO - Fold 1, Epoch 40: Val Acc: 0.53%
2025-08-15 00:12:30,427 - INFO - Fold 1, Epoch 50: Val Acc: 0.56%
2025-08-15 00:12:32,873 - INFO - Fold 1, Epoch 60: Val Acc: 0.44%
2025-08-15 00:12:37,752 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-15 00:12:39,715 - INFO - Fold 1, Epoch 80: Val Acc: 0.59%
2025-08-15 00:12:41,671 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-15 00:12:43,625 - INFO - Fold 1, Epoch 100: Val Acc: 0.62%
2025-08-15 00:12:45,739 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-15 00:12:48,260 - INFO - Fold 1, Epoch 120: Val Acc: 0.72%
2025-08-15 00:12:50,754 - INFO - Fold 1, Epoch 130: Val Acc: 0.66%
2025-08-15 00:12:53,275 - INFO - Fold 1, Epoch 140: Val Acc: 0.69%
2025-08-15 00:12:58,851 - INFO - Fold 1, Epoch 150: Val Acc: 0.78%
2025-08-15 00:13:06,748 - INFO - Fold 1, Epoch 160: Val Acc: 0.59%
2025-08-15 00:13:09,018 - INFO - Fold 1, Epoch 170: Val Acc: 0.78%
2025-08-15 00:13:11,159 - INFO - Fold 1, Epoch 180: Val Acc: 0.75%
2025-08-15 00:13:13,410 - INFO - Fold 1, Epoch 190: Val Acc: 0.59%
2025-08-15 00:13:15,832 - INFO - Fold 1, Epoch 200: Val Acc: 0.72%
2025-08-15 00:13:18,263 - INFO - Fold 1, Epoch 210: Val Acc: 0.72%
2025-08-15 00:13:20,692 - INFO - Fold 1, Epoch 220: Val Acc: 0.62%
2025-08-15 00:13:22,999 - INFO - Fold 1, Epoch 230: Val Acc: 0.62%
2025-08-15 00:13:24,850 - INFO - Fold 1, Epoch 240: Val Acc: 0.72%
2025-08-15 00:13:27,155 - INFO - Fold 1, Epoch 250: Val Acc: 0.75%
2025-08-15 00:13:27,889 - INFO - Early stopping at epoch 253
2025-08-15 00:13:32,528 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:13:32,530 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:13:32,531 - INFO - Starting training for fold 2/3
2025-08-15 00:13:40,214 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-15 00:13:42,666 - INFO - Fold 2, Epoch 20: Val Acc: 0.62%
2025-08-15 00:13:45,100 - INFO - Fold 2, Epoch 30: Val Acc: 0.56%
2025-08-15 00:13:47,518 - INFO - Fold 2, Epoch 40: Val Acc: 0.53%
2025-08-15 00:13:49,954 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-15 00:13:52,098 - INFO - Fold 2, Epoch 60: Val Acc: 0.59%
2025-08-15 00:13:54,460 - INFO - Fold 2, Epoch 70: Val Acc: 0.62%
2025-08-15 00:13:58,468 - INFO - Fold 2, Epoch 80: Val Acc: 0.50%
2025-08-15 00:14:00,900 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-15 00:14:03,330 - INFO - Fold 2, Epoch 100: Val Acc: 0.62%
2025-08-15 00:14:07,309 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-15 00:14:11,353 - INFO - Fold 2, Epoch 120: Val Acc: 0.56%
2025-08-15 00:14:13,778 - INFO - Fold 2, Epoch 130: Val Acc: 0.66%
2025-08-15 00:14:17,872 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-15 00:14:20,284 - INFO - Fold 2, Epoch 150: Val Acc: 0.62%
2025-08-15 00:14:22,706 - INFO - Fold 2, Epoch 160: Val Acc: 0.72%
2025-08-15 00:14:25,121 - INFO - Fold 2, Epoch 170: Val Acc: 0.66%
2025-08-15 00:14:27,120 - INFO - Fold 2, Epoch 180: Val Acc: 0.69%
2025-08-15 00:14:28,978 - INFO - Fold 2, Epoch 190: Val Acc: 0.78%
2025-08-15 00:14:31,102 - INFO - Fold 2, Epoch 200: Val Acc: 0.78%
2025-08-15 00:14:33,517 - INFO - Fold 2, Epoch 210: Val Acc: 0.72%
2025-08-15 00:14:35,941 - INFO - Fold 2, Epoch 220: Val Acc: 0.69%
2025-08-15 00:14:38,360 - INFO - Fold 2, Epoch 230: Val Acc: 0.69%
2025-08-15 00:14:39,337 - INFO - Early stopping at epoch 234
2025-08-15 00:14:40,611 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:14:40,612 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:14:40,613 - INFO - Starting training for fold 3/3
2025-08-15 00:14:48,040 - INFO - Fold 3, Epoch 10: Val Acc: 0.44%
2025-08-15 00:14:50,561 - INFO - Fold 3, Epoch 20: Val Acc: 0.50%
2025-08-15 00:14:54,712 - INFO - Fold 3, Epoch 30: Val Acc: 0.47%
2025-08-15 00:14:58,525 - INFO - Fold 3, Epoch 40: Val Acc: 0.53%
2025-08-15 00:15:00,374 - INFO - Fold 3, Epoch 50: Val Acc: 0.53%
2025-08-15 00:15:02,429 - INFO - Fold 3, Epoch 60: Val Acc: 0.62%
2025-08-15 00:15:04,443 - INFO - Fold 3, Epoch 70: Val Acc: 0.53%
2025-08-15 00:15:08,719 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-15 00:15:12,792 - INFO - Fold 3, Epoch 90: Val Acc: 0.56%
2025-08-15 00:15:14,754 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-15 00:15:17,241 - INFO - Fold 3, Epoch 110: Val Acc: 0.72%
2025-08-15 00:15:19,693 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-15 00:15:22,203 - INFO - Fold 3, Epoch 130: Val Acc: 0.59%
2025-08-15 00:15:26,457 - INFO - Fold 3, Epoch 140: Val Acc: 0.62%
2025-08-15 00:15:28,978 - INFO - Fold 3, Epoch 150: Val Acc: 0.78%
2025-08-15 00:15:31,415 - INFO - Fold 3, Epoch 160: Val Acc: 0.66%
2025-08-15 00:15:33,267 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-15 00:15:35,117 - INFO - Fold 3, Epoch 180: Val Acc: 0.78%
2025-08-15 00:15:37,316 - INFO - Fold 3, Epoch 190: Val Acc: 0.75%
2025-08-15 00:15:39,661 - INFO - Fold 3, Epoch 200: Val Acc: 0.69%
2025-08-15 00:15:41,521 - INFO - Fold 3, Epoch 210: Val Acc: 0.72%
2025-08-15 00:15:43,408 - INFO - Fold 3, Epoch 220: Val Acc: 0.81%
2025-08-15 00:15:45,888 - INFO - Fold 3, Epoch 230: Val Acc: 0.81%
2025-08-15 00:15:46,140 - INFO - Early stopping at epoch 231
2025-08-15 00:15:49,498 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.059463156594171), 'std': np.float64(0.030023360033584138)}, 'train_accuracy': {'mean': np.float64(0.6388888888888888), 'std': np.float64(0.02734030511809652)}, 'val_loss': {'mean': np.float64(4.144166310628255), 'std': np.float64(0.0420547085366189)}, 'val_accuracy': {'mean': np.float64(0.8541666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(138.33333333333334), 'std': np.float64(9.741092797468305)}}
[I 2025-08-15 00:15:49,511] Trial 107 finished with value: -0.8541666666666666 and parameters: {'learning_rate': 7.266844484566745e-05, 'batch_size': 32, 'num_epochs': 529, 'temperature': 0.3833086360646086, 'embedding_dim': 256, 'hidden_dim': 128, 'dropout': 0.44611938169188603, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1305170917740858, 'crop_size': 0.5625442866671909}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 107 finished with value: -0.8541666666666666 and parameters: {'learning_rate': 7.266844484566745e-05, 'batch_size': 32, 'num_epochs': 529, 'temperature': 0.3833086360646086, 'embedding_dim': 256, 'hidden_dim': 128, 'dropout': 0.44611938169188603, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1305170917740858, 'crop_size': 0.5625442866671909}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:15:49,595 - INFO - Using device: cuda
2025-08-15 00:15:59,516 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:15:59,517 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:15:59,518 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 00:16:15,617 - INFO - Fold 1, Epoch 10: Val Acc: 0.54%
2025-08-15 00:16:23,862 - INFO - Fold 1, Epoch 20: Val Acc: 0.69%
2025-08-15 00:16:29,929 - INFO - Fold 1, Epoch 30: Val Acc: 0.52%
2025-08-15 00:16:35,867 - INFO - Fold 1, Epoch 40: Val Acc: 0.71%
2025-08-15 00:16:41,867 - INFO - Fold 1, Epoch 50: Val Acc: 0.73%
2025-08-15 00:16:47,966 - INFO - Fold 1, Epoch 60: Val Acc: 0.60%
2025-08-15 00:16:56,297 - INFO - Fold 1, Epoch 70: Val Acc: 0.67%
2025-08-15 00:17:00,102 - INFO - Fold 1, Epoch 80: Val Acc: 0.62%
2025-08-15 00:17:03,914 - INFO - Fold 1, Epoch 90: Val Acc: 0.77%
2025-08-15 00:17:07,710 - INFO - Fold 1, Epoch 100: Val Acc: 0.77%
2025-08-15 00:17:11,517 - INFO - Fold 1, Epoch 110: Val Acc: 0.71%
2025-08-15 00:17:15,324 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-15 00:17:19,121 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-15 00:17:21,954 - INFO - Fold 1, Epoch 140: Val Acc: 0.67%
2025-08-15 00:17:25,429 - INFO - Fold 1, Epoch 150: Val Acc: 0.73%
2025-08-15 00:17:28,167 - INFO - Fold 1, Epoch 160: Val Acc: 0.75%
2025-08-15 00:17:30,181 - INFO - Early stopping at epoch 167
2025-08-15 00:17:33,737 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:17:33,739 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:17:33,740 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 00:17:43,522 - INFO - Fold 2, Epoch 10: Val Acc: 0.65%
2025-08-15 00:17:50,259 - INFO - Fold 2, Epoch 20: Val Acc: 0.58%
2025-08-15 00:17:58,681 - INFO - Fold 2, Epoch 30: Val Acc: 0.73%
2025-08-15 00:18:05,449 - INFO - Fold 2, Epoch 40: Val Acc: 0.65%
2025-08-15 00:18:10,881 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-15 00:18:14,688 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-15 00:18:18,482 - INFO - Fold 2, Epoch 70: Val Acc: 0.69%
2025-08-15 00:18:22,283 - INFO - Fold 2, Epoch 80: Val Acc: 0.71%
2025-08-15 00:18:26,109 - INFO - Fold 2, Epoch 90: Val Acc: 0.71%
2025-08-15 00:18:29,511 - INFO - Fold 2, Epoch 100: Val Acc: 0.85%
2025-08-15 00:18:32,860 - INFO - Fold 2, Epoch 110: Val Acc: 0.88%
2025-08-15 00:18:36,396 - INFO - Fold 2, Epoch 120: Val Acc: 0.79%
2025-08-15 00:18:40,200 - INFO - Fold 2, Epoch 130: Val Acc: 0.67%
2025-08-15 00:18:44,022 - INFO - Fold 2, Epoch 140: Val Acc: 0.71%
2025-08-15 00:18:44,795 - INFO - Early stopping at epoch 142
2025-08-15 00:18:47,773 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:18:47,776 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:18:47,777 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 00:18:59,252 - INFO - Fold 3, Epoch 10: Val Acc: 0.58%
2025-08-15 00:19:03,180 - INFO - Fold 3, Epoch 20: Val Acc: 0.56%
2025-08-15 00:19:09,413 - INFO - Fold 3, Epoch 30: Val Acc: 0.71%
2025-08-15 00:19:13,047 - INFO - Fold 3, Epoch 40: Val Acc: 0.65%
2025-08-15 00:19:16,837 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-15 00:19:20,652 - INFO - Fold 3, Epoch 60: Val Acc: 0.71%
2025-08-15 00:19:24,456 - INFO - Fold 3, Epoch 70: Val Acc: 0.79%
2025-08-15 00:19:29,645 - INFO - Fold 3, Epoch 80: Val Acc: 0.85%
2025-08-15 00:19:33,523 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-15 00:19:37,139 - INFO - Fold 3, Epoch 100: Val Acc: 0.67%
2025-08-15 00:19:40,957 - INFO - Fold 3, Epoch 110: Val Acc: 0.60%
2025-08-15 00:19:44,772 - INFO - Fold 3, Epoch 120: Val Acc: 0.77%
2025-08-15 00:19:48,590 - INFO - Fold 3, Epoch 130: Val Acc: 0.71%
2025-08-15 00:19:52,222 - INFO - Fold 3, Epoch 140: Val Acc: 0.85%
2025-08-15 00:19:55,968 - INFO - Fold 3, Epoch 150: Val Acc: 0.81%
2025-08-15 00:19:59,779 - INFO - Fold 3, Epoch 160: Val Acc: 0.67%
2025-08-15 00:20:03,591 - INFO - Fold 3, Epoch 170: Val Acc: 0.71%
2025-08-15 00:20:06,665 - INFO - Early stopping at epoch 180
2025-08-15 00:20:07,911 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.138586031066047), 'std': np.float64(0.072346993736755)}, 'train_accuracy': {'mean': np.float64(0.7430555555555557), 'std': np.float64(0.04280843057617347)}, 'val_loss': {'mean': np.float64(3.436596949895223), 'std': np.float64(0.05018807224979063)}, 'val_accuracy': {'mean': np.float64(0.8472222222222222), 'std': np.float64(0.025983731852596812)}, 'epoch': {'mean': np.float64(62.0), 'std': np.float64(15.769168230019828)}}
[I 2025-08-15 00:20:07,924] Trial 108 finished with value: -0.8472222222222222 and parameters: {'learning_rate': 0.00036852155317736884, 'batch_size': 16, 'num_epochs': 498, 'temperature': 0.24285075447711132, 'embedding_dim': 128, 'hidden_dim': 512, 'dropout': 0.47429207842192506, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.11905692360935324, 'crop_size': 0.7191800178265981}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 108 finished with value: -0.8472222222222222 and parameters: {'learning_rate': 0.00036852155317736884, 'batch_size': 16, 'num_epochs': 498, 'temperature': 0.24285075447711132, 'embedding_dim': 128, 'hidden_dim': 512, 'dropout': 0.47429207842192506, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.11905692360935324, 'crop_size': 0.7191800178265981}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:20:07,961 - INFO - Using device: cuda
2025-08-15 00:20:17,271 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:20:17,272 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:20:17,272 - WARNING - Fold 1 has insufficient pairs to form a batch. Skipping.
2025-08-15 00:20:17,272 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:20:17,274 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:20:17,274 - WARNING - Fold 2 has insufficient pairs to form a batch. Skipping.
2025-08-15 00:20:17,274 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:20:17,275 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:20:17,275 - WARNING - Fold 3 has insufficient pairs to form a batch. Skipping.
2025-08-15 00:20:17,275 - WARNING - No folds completed successfully to aggregate metrics.
[I 2025-08-15 00:20:17,276] Trial 109 finished with value: inf and parameters: {'learning_rate': 0.0005568893604655663, 'batch_size': 64, 'num_epochs': 393, 'temperature': 0.42101351728714853, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.45334340927686917, 'num_layers': 2, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08989670188279061, 'crop_size': 0.5094822660948236}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 109 finished with value: inf and parameters: {'learning_rate': 0.0005568893604655663, 'batch_size': 64, 'num_epochs': 393, 'temperature': 0.42101351728714853, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.45334340927686917, 'num_layers': 2, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08989670188279061, 'crop_size': 0.5094822660948236}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:20:17,312 - INFO - Using device: cuda
2025-08-15 00:20:26,974 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:20:26,975 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:20:26,975 - INFO - Starting training for fold 1/3
2025-08-15 00:20:31,221 - INFO - Fold 1, Epoch 10: Val Acc: 0.69%
2025-08-15 00:20:32,922 - INFO - Fold 1, Epoch 20: Val Acc: 0.72%
2025-08-15 00:20:34,622 - INFO - Fold 1, Epoch 30: Val Acc: 0.59%
2025-08-15 00:20:36,322 - INFO - Fold 1, Epoch 40: Val Acc: 0.75%
2025-08-15 00:20:40,881 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-15 00:20:43,195 - INFO - Fold 1, Epoch 60: Val Acc: 0.75%
2025-08-15 00:20:47,629 - INFO - Fold 1, Epoch 70: Val Acc: 0.84%
2025-08-15 00:20:49,729 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-15 00:20:51,964 - INFO - Fold 1, Epoch 90: Val Acc: 0.78%
2025-08-15 00:20:54,189 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-15 00:20:56,417 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-15 00:20:58,643 - INFO - Fold 1, Epoch 120: Val Acc: 0.72%
2025-08-15 00:21:02,939 - INFO - Fold 1, Epoch 130: Val Acc: 0.59%
2025-08-15 00:21:04,942 - INFO - Fold 1, Epoch 140: Val Acc: 0.75%
2025-08-15 00:21:07,170 - INFO - Fold 1, Epoch 150: Val Acc: 0.62%
2025-08-15 00:21:09,395 - INFO - Fold 1, Epoch 160: Val Acc: 0.81%
2025-08-15 00:21:11,628 - INFO - Fold 1, Epoch 170: Val Acc: 0.78%
2025-08-15 00:21:13,855 - INFO - Fold 1, Epoch 180: Val Acc: 0.75%
2025-08-15 00:21:16,090 - INFO - Fold 1, Epoch 190: Val Acc: 0.78%
2025-08-15 00:21:18,317 - INFO - Fold 1, Epoch 200: Val Acc: 0.66%
2025-08-15 00:21:20,359 - INFO - Fold 1, Epoch 210: Val Acc: 0.78%
2025-08-15 00:21:22,526 - INFO - Fold 1, Epoch 220: Val Acc: 0.75%
2025-08-15 00:21:22,976 - INFO - Early stopping at epoch 222
2025-08-15 00:21:26,610 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:21:26,613 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:21:26,614 - INFO - Starting training for fold 2/3
2025-08-15 00:21:34,713 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 00:21:39,791 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-15 00:21:43,352 - INFO - Fold 2, Epoch 30: Val Acc: 0.62%
2025-08-15 00:21:46,756 - INFO - Fold 2, Epoch 40: Val Acc: 0.84%
2025-08-15 00:21:50,485 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-15 00:21:52,699 - INFO - Fold 2, Epoch 60: Val Acc: 0.78%
2025-08-15 00:21:54,911 - INFO - Fold 2, Epoch 70: Val Acc: 0.84%
2025-08-15 00:21:56,957 - INFO - Fold 2, Epoch 80: Val Acc: 0.88%
2025-08-15 00:21:58,662 - INFO - Fold 2, Epoch 90: Val Acc: 0.66%
2025-08-15 00:22:00,369 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-15 00:22:02,076 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-15 00:22:03,786 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-15 00:22:05,492 - INFO - Fold 2, Epoch 130: Val Acc: 0.72%
2025-08-15 00:22:08,611 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-15 00:22:10,324 - INFO - Fold 2, Epoch 150: Val Acc: 0.72%
2025-08-15 00:22:12,032 - INFO - Fold 2, Epoch 160: Val Acc: 0.84%
2025-08-15 00:22:13,742 - INFO - Fold 2, Epoch 170: Val Acc: 0.72%
2025-08-15 00:22:15,436 - INFO - Fold 2, Epoch 180: Val Acc: 0.75%
2025-08-15 00:22:17,146 - INFO - Fold 2, Epoch 190: Val Acc: 0.81%
2025-08-15 00:22:19,167 - INFO - Fold 2, Epoch 200: Val Acc: 0.88%
2025-08-15 00:22:21,397 - INFO - Fold 2, Epoch 210: Val Acc: 0.81%
2025-08-15 00:22:23,622 - INFO - Fold 2, Epoch 220: Val Acc: 0.69%
2025-08-15 00:22:25,851 - INFO - Fold 2, Epoch 230: Val Acc: 0.59%
2025-08-15 00:22:26,070 - INFO - Early stopping at epoch 231
2025-08-15 00:22:29,149 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:22:29,152 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:22:29,153 - INFO - Starting training for fold 3/3
2025-08-15 00:22:36,151 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-15 00:22:39,831 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-15 00:22:43,475 - INFO - Fold 3, Epoch 30: Val Acc: 0.69%
2025-08-15 00:22:47,236 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-15 00:22:49,479 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-15 00:22:51,678 - INFO - Fold 3, Epoch 60: Val Acc: 0.62%
2025-08-15 00:22:53,646 - INFO - Fold 3, Epoch 70: Val Acc: 0.78%
2025-08-15 00:22:57,153 - INFO - Fold 3, Epoch 80: Val Acc: 0.56%
2025-08-15 00:22:59,081 - INFO - Fold 3, Epoch 90: Val Acc: 0.66%
2025-08-15 00:23:00,785 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-15 00:23:02,485 - INFO - Fold 3, Epoch 110: Val Acc: 0.62%
2025-08-15 00:23:04,192 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-15 00:23:05,895 - INFO - Fold 3, Epoch 130: Val Acc: 0.66%
2025-08-15 00:23:07,597 - INFO - Fold 3, Epoch 140: Val Acc: 0.62%
2025-08-15 00:23:09,302 - INFO - Fold 3, Epoch 150: Val Acc: 0.62%
2025-08-15 00:23:11,006 - INFO - Fold 3, Epoch 160: Val Acc: 0.62%
2025-08-15 00:23:13,171 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-15 00:23:14,776 - INFO - Early stopping at epoch 177
2025-08-15 00:23:15,826 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.879020426008436), 'std': np.float64(0.0413752467620598)}, 'train_accuracy': {'mean': np.float64(0.8125), 'std': np.float64(0.03897559777889522)}, 'val_loss': {'mean': np.float64(4.323964277903239), 'std': np.float64(0.058873919704057066)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(109.0), 'std': np.float64(23.62202362203543)}}
[I 2025-08-15 00:23:15,834] Trial 110 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0009150988948425758, 'batch_size': 32, 'num_epochs': 341, 'temperature': 0.3408769438811844, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.41883080904555775, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0326713504436068, 'crop_size': 0.540773757185998}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 110 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0009150988948425758, 'batch_size': 32, 'num_epochs': 341, 'temperature': 0.3408769438811844, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.41883080904555775, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0326713504436068, 'crop_size': 0.540773757185998}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:23:15,885 - INFO - Using device: cuda
2025-08-15 00:23:25,768 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:23:25,770 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:23:25,770 - INFO - Starting training for fold 1/3
2025-08-15 00:23:31,529 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-15 00:23:35,473 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-15 00:23:37,563 - INFO - Fold 1, Epoch 30: Val Acc: 0.56%
2025-08-15 00:23:41,403 - INFO - Fold 1, Epoch 40: Val Acc: 0.66%
2025-08-15 00:23:45,154 - INFO - Fold 1, Epoch 50: Val Acc: 0.84%
2025-08-15 00:23:47,243 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-15 00:23:50,732 - INFO - Fold 1, Epoch 70: Val Acc: 0.75%
2025-08-15 00:23:52,727 - INFO - Fold 1, Epoch 80: Val Acc: 0.75%
2025-08-15 00:23:54,621 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-15 00:23:56,165 - INFO - Fold 1, Epoch 100: Val Acc: 0.62%
2025-08-15 00:23:57,720 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-15 00:23:59,280 - INFO - Fold 1, Epoch 120: Val Acc: 0.62%
2025-08-15 00:24:00,893 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-15 00:24:02,447 - INFO - Fold 1, Epoch 140: Val Acc: 0.59%
2025-08-15 00:24:04,001 - INFO - Fold 1, Epoch 150: Val Acc: 0.69%
2025-08-15 00:24:05,688 - INFO - Fold 1, Epoch 160: Val Acc: 0.62%
2025-08-15 00:24:06,621 - INFO - Early stopping at epoch 166
2025-08-15 00:24:09,467 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:24:09,469 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:24:09,470 - INFO - Starting training for fold 2/3
2025-08-15 00:24:17,447 - INFO - Fold 2, Epoch 10: Val Acc: 0.69%
2025-08-15 00:24:22,084 - INFO - Fold 2, Epoch 20: Val Acc: 0.75%
2025-08-15 00:24:24,099 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-15 00:24:27,296 - INFO - Fold 2, Epoch 40: Val Acc: 0.62%
2025-08-15 00:24:30,440 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-15 00:24:32,435 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-15 00:24:34,152 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-15 00:24:35,706 - INFO - Fold 2, Epoch 80: Val Acc: 0.81%
2025-08-15 00:24:37,288 - INFO - Fold 2, Epoch 90: Val Acc: 0.75%
2025-08-15 00:24:39,296 - INFO - Fold 2, Epoch 100: Val Acc: 0.72%
2025-08-15 00:24:40,844 - INFO - Fold 2, Epoch 110: Val Acc: 0.81%
2025-08-15 00:24:42,394 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-15 00:24:44,288 - INFO - Fold 2, Epoch 130: Val Acc: 0.56%
2025-08-15 00:24:46,295 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-15 00:24:47,099 - INFO - Early stopping at epoch 144
2025-08-15 00:24:49,511 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:24:49,513 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:24:49,514 - INFO - Starting training for fold 3/3
2025-08-15 00:24:55,319 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-15 00:24:58,457 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-15 00:25:01,777 - INFO - Fold 3, Epoch 30: Val Acc: 0.78%
2025-08-15 00:25:03,804 - INFO - Fold 3, Epoch 40: Val Acc: 0.53%
2025-08-15 00:25:06,888 - INFO - Fold 3, Epoch 50: Val Acc: 0.84%
2025-08-15 00:25:08,956 - INFO - Fold 3, Epoch 60: Val Acc: 0.78%
2025-08-15 00:25:10,964 - INFO - Fold 3, Epoch 70: Val Acc: 0.81%
2025-08-15 00:25:12,780 - INFO - Fold 3, Epoch 80: Val Acc: 0.81%
2025-08-15 00:25:16,413 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-15 00:25:18,442 - INFO - Fold 3, Epoch 100: Val Acc: 0.88%
2025-08-15 00:25:21,669 - INFO - Fold 3, Epoch 110: Val Acc: 0.69%
2025-08-15 00:25:23,754 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-15 00:25:25,821 - INFO - Fold 3, Epoch 130: Val Acc: 0.62%
2025-08-15 00:25:27,701 - INFO - Fold 3, Epoch 140: Val Acc: 0.75%
2025-08-15 00:25:29,351 - INFO - Fold 3, Epoch 150: Val Acc: 0.81%
2025-08-15 00:25:31,138 - INFO - Fold 3, Epoch 160: Val Acc: 0.75%
2025-08-15 00:25:33,175 - INFO - Fold 3, Epoch 170: Val Acc: 0.66%
2025-08-15 00:25:34,961 - INFO - Fold 3, Epoch 180: Val Acc: 0.69%
2025-08-15 00:25:37,010 - INFO - Fold 3, Epoch 190: Val Acc: 0.75%
2025-08-15 00:25:39,041 - INFO - Fold 3, Epoch 200: Val Acc: 0.69%
2025-08-15 00:25:40,507 - INFO - Early stopping at epoch 207
2025-08-15 00:25:41,359 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9477746751573353), 'std': np.float64(0.023874788307671476)}, 'train_accuracy': {'mean': np.float64(0.7361111111111112), 'std': np.float64(0.009820927516479793)}, 'val_loss': {'mean': np.float64(4.125205198923747), 'std': np.float64(0.0415571756629673)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(71.33333333333333), 'std': np.float64(26.10661899893503)}}
[I 2025-08-15 00:25:41,365] Trial 111 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0006073454960734368, 'batch_size': 32, 'num_epochs': 913, 'temperature': 0.4063378426654937, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.43566579424286783, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18657879211648928, 'crop_size': 0.5513081005183934}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 111 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0006073454960734368, 'batch_size': 32, 'num_epochs': 913, 'temperature': 0.4063378426654937, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.43566579424286783, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18657879211648928, 'crop_size': 0.5513081005183934}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:25:41,403 - INFO - Using device: cuda
2025-08-15 00:25:51,052 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:25:51,054 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:25:51,054 - INFO - Starting training for fold 1/3
2025-08-15 00:25:58,631 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-15 00:26:04,556 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-15 00:26:06,556 - INFO - Fold 1, Epoch 30: Val Acc: 0.72%
2025-08-15 00:26:10,437 - INFO - Fold 1, Epoch 40: Val Acc: 0.66%
2025-08-15 00:26:12,441 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-15 00:26:14,447 - INFO - Fold 1, Epoch 60: Val Acc: 0.66%
2025-08-15 00:26:16,437 - INFO - Fold 1, Epoch 70: Val Acc: 0.81%
2025-08-15 00:26:18,161 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-15 00:26:19,703 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-15 00:26:21,364 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-15 00:26:23,366 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-15 00:26:24,954 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-15 00:26:26,501 - INFO - Fold 1, Epoch 130: Val Acc: 0.81%
2025-08-15 00:26:26,707 - INFO - Early stopping at epoch 131
2025-08-15 00:26:29,718 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:26:29,722 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:26:29,723 - INFO - Starting training for fold 2/3
2025-08-15 00:26:34,131 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-15 00:26:36,142 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-15 00:26:40,542 - INFO - Fold 2, Epoch 30: Val Acc: 0.78%
2025-08-15 00:26:43,606 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-15 00:26:46,936 - INFO - Fold 2, Epoch 50: Val Acc: 0.66%
2025-08-15 00:26:49,033 - INFO - Fold 2, Epoch 60: Val Acc: 0.59%
2025-08-15 00:26:51,127 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-15 00:26:53,232 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-15 00:26:56,457 - INFO - Fold 2, Epoch 90: Val Acc: 0.75%
2025-08-15 00:26:58,182 - INFO - Fold 2, Epoch 100: Val Acc: 0.84%
2025-08-15 00:26:59,832 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-15 00:27:01,483 - INFO - Fold 2, Epoch 120: Val Acc: 0.66%
2025-08-15 00:27:03,132 - INFO - Fold 2, Epoch 130: Val Acc: 0.72%
2025-08-15 00:27:04,784 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-15 00:27:06,431 - INFO - Fold 2, Epoch 150: Val Acc: 0.69%
2025-08-15 00:27:08,399 - INFO - Fold 2, Epoch 160: Val Acc: 0.81%
2025-08-15 00:27:10,488 - INFO - Fold 2, Epoch 170: Val Acc: 0.56%
2025-08-15 00:27:12,519 - INFO - Fold 2, Epoch 180: Val Acc: 0.84%
2025-08-15 00:27:13,922 - INFO - Early stopping at epoch 187
2025-08-15 00:27:14,773 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:27:14,775 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:27:14,775 - INFO - Starting training for fold 3/3
2025-08-15 00:27:19,510 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-15 00:27:22,723 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-15 00:27:25,863 - INFO - Fold 3, Epoch 30: Val Acc: 0.72%
2025-08-15 00:27:29,043 - INFO - Fold 3, Epoch 40: Val Acc: 0.78%
2025-08-15 00:27:31,136 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-15 00:27:34,349 - INFO - Fold 3, Epoch 60: Val Acc: 0.69%
2025-08-15 00:27:36,354 - INFO - Fold 3, Epoch 70: Val Acc: 0.75%
2025-08-15 00:27:40,614 - INFO - Fold 3, Epoch 80: Val Acc: 0.91%
2025-08-15 00:27:42,557 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-15 00:27:44,113 - INFO - Fold 3, Epoch 100: Val Acc: 0.66%
2025-08-15 00:27:45,982 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-15 00:27:48,071 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-15 00:27:50,160 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-15 00:27:52,258 - INFO - Fold 3, Epoch 140: Val Acc: 0.88%
2025-08-15 00:27:54,354 - INFO - Fold 3, Epoch 150: Val Acc: 0.78%
2025-08-15 00:27:56,453 - INFO - Fold 3, Epoch 160: Val Acc: 0.69%
2025-08-15 00:27:58,550 - INFO - Fold 3, Epoch 170: Val Acc: 0.75%
2025-08-15 00:28:00,594 - INFO - Early stopping at epoch 180
2025-08-15 00:28:03,203 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.979196018642849), 'std': np.float64(0.05737014506414054)}, 'train_accuracy': {'mean': np.float64(0.7222222222222223), 'std': np.float64(0.024552318791199557)}, 'val_loss': {'mean': np.float64(4.145336945851644), 'std': np.float64(0.08894265517079392)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(65.0), 'std': np.float64(24.91318258807306)}}
[I 2025-08-15 00:28:03,213] Trial 112 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0004972874605381656, 'batch_size': 32, 'num_epochs': 844, 'temperature': 0.37242221570182243, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.46468027705287673, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19749583890690717, 'crop_size': 0.5904272079202576}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 112 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0004972874605381656, 'batch_size': 32, 'num_epochs': 844, 'temperature': 0.37242221570182243, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.46468027705287673, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19749583890690717, 'crop_size': 0.5904272079202576}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:28:03,296 - INFO - Using device: cuda
2025-08-15 00:28:13,204 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:28:13,205 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:28:13,205 - INFO - Starting training for fold 1/3
2025-08-15 00:28:23,395 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-15 00:28:27,828 - INFO - Fold 1, Epoch 20: Val Acc: 0.53%
2025-08-15 00:28:30,058 - INFO - Fold 1, Epoch 30: Val Acc: 0.59%
2025-08-15 00:28:34,590 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-15 00:28:38,837 - INFO - Fold 1, Epoch 50: Val Acc: 0.62%
2025-08-15 00:28:41,049 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-15 00:28:43,259 - INFO - Fold 1, Epoch 70: Val Acc: 0.81%
2025-08-15 00:28:47,758 - INFO - Fold 1, Epoch 80: Val Acc: 0.75%
2025-08-15 00:28:49,934 - INFO - Fold 1, Epoch 90: Val Acc: 0.62%
2025-08-15 00:28:52,157 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-15 00:28:56,645 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-15 00:28:58,871 - INFO - Fold 1, Epoch 120: Val Acc: 0.81%
2025-08-15 00:29:01,102 - INFO - Fold 1, Epoch 130: Val Acc: 0.84%
2025-08-15 00:29:03,332 - INFO - Fold 1, Epoch 140: Val Acc: 0.69%
2025-08-15 00:29:05,561 - INFO - Fold 1, Epoch 150: Val Acc: 0.84%
2025-08-15 00:29:07,789 - INFO - Fold 1, Epoch 160: Val Acc: 0.88%
2025-08-15 00:29:10,008 - INFO - Fold 1, Epoch 170: Val Acc: 0.69%
2025-08-15 00:29:14,472 - INFO - Fold 1, Epoch 180: Val Acc: 0.84%
2025-08-15 00:29:16,690 - INFO - Fold 1, Epoch 190: Val Acc: 0.66%
2025-08-15 00:29:18,909 - INFO - Fold 1, Epoch 200: Val Acc: 0.56%
2025-08-15 00:29:20,980 - INFO - Fold 1, Epoch 210: Val Acc: 0.69%
2025-08-15 00:29:23,039 - INFO - Fold 1, Epoch 220: Val Acc: 0.78%
2025-08-15 00:29:25,006 - INFO - Fold 1, Epoch 230: Val Acc: 0.72%
2025-08-15 00:29:27,218 - INFO - Fold 1, Epoch 240: Val Acc: 0.69%
2025-08-15 00:29:29,422 - INFO - Fold 1, Epoch 250: Val Acc: 0.72%
2025-08-15 00:29:31,469 - INFO - Fold 1, Epoch 260: Val Acc: 0.66%
2025-08-15 00:29:33,626 - INFO - Fold 1, Epoch 270: Val Acc: 0.78%
2025-08-15 00:29:35,629 - INFO - Early stopping at epoch 279
2025-08-15 00:29:39,249 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:29:39,252 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:29:39,252 - INFO - Starting training for fold 2/3
2025-08-15 00:29:44,253 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-15 00:29:45,958 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-15 00:29:52,387 - INFO - Fold 2, Epoch 30: Val Acc: 0.59%
2025-08-15 00:29:56,005 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-15 00:29:59,642 - INFO - Fold 2, Epoch 50: Val Acc: 0.66%
2025-08-15 00:30:03,264 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-15 00:30:06,990 - INFO - Fold 2, Epoch 70: Val Acc: 0.94%
2025-08-15 00:30:09,313 - INFO - Fold 2, Epoch 80: Val Acc: 0.78%
2025-08-15 00:30:11,477 - INFO - Fold 2, Epoch 90: Val Acc: 0.75%
2025-08-15 00:30:13,764 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-15 00:30:15,975 - INFO - Fold 2, Epoch 110: Val Acc: 0.81%
2025-08-15 00:30:18,187 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-15 00:30:20,387 - INFO - Fold 2, Epoch 130: Val Acc: 0.81%
2025-08-15 00:30:22,622 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-15 00:30:24,828 - INFO - Fold 2, Epoch 150: Val Acc: 0.84%
2025-08-15 00:30:27,041 - INFO - Fold 2, Epoch 160: Val Acc: 0.72%
2025-08-15 00:30:28,981 - INFO - Early stopping at epoch 170
2025-08-15 00:30:30,064 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:30:30,066 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:30:30,066 - INFO - Starting training for fold 3/3
2025-08-15 00:30:36,863 - INFO - Fold 3, Epoch 10: Val Acc: 0.69%
2025-08-15 00:30:40,472 - INFO - Fold 3, Epoch 20: Val Acc: 0.75%
2025-08-15 00:30:42,790 - INFO - Fold 3, Epoch 30: Val Acc: 0.59%
2025-08-15 00:30:46,356 - INFO - Fold 3, Epoch 40: Val Acc: 0.78%
2025-08-15 00:30:51,579 - INFO - Fold 3, Epoch 50: Val Acc: 0.94%
2025-08-15 00:30:53,891 - INFO - Fold 3, Epoch 60: Val Acc: 0.72%
2025-08-15 00:30:56,116 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-15 00:30:58,336 - INFO - Fold 3, Epoch 80: Val Acc: 0.88%
2025-08-15 00:31:00,558 - INFO - Fold 3, Epoch 90: Val Acc: 0.78%
2025-08-15 00:31:02,776 - INFO - Fold 3, Epoch 100: Val Acc: 0.88%
2025-08-15 00:31:05,004 - INFO - Fold 3, Epoch 110: Val Acc: 0.81%
2025-08-15 00:31:07,229 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-15 00:31:09,457 - INFO - Fold 3, Epoch 130: Val Acc: 0.84%
2025-08-15 00:31:11,665 - INFO - Fold 3, Epoch 140: Val Acc: 0.78%
2025-08-15 00:31:13,884 - INFO - Early stopping at epoch 150
2025-08-15 00:31:14,932 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9450378153059216), 'std': np.float64(0.048240260928501956)}, 'train_accuracy': {'mean': np.float64(0.7569444444444445), 'std': np.float64(0.025983731852596822)}, 'val_loss': {'mean': np.float64(4.21873410542806), 'std': np.float64(0.054827831914124756)}, 'val_accuracy': {'mean': np.float64(0.9375), 'std': np.float64(0.0)}, 'epoch': {'mean': np.float64(98.66666666666667), 'std': np.float64(56.68823119092318)}}
[I 2025-08-15 00:31:14,939] Trial 113 finished with value: -0.9375 and parameters: {'learning_rate': 0.00042864413019607815, 'batch_size': 32, 'num_epochs': 954, 'temperature': 0.4315309998418187, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.49053351973757864, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19492728399145917, 'crop_size': 0.5315667877747347}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 113 finished with value: -0.9375 and parameters: {'learning_rate': 0.00042864413019607815, 'batch_size': 32, 'num_epochs': 954, 'temperature': 0.4315309998418187, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.49053351973757864, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19492728399145917, 'crop_size': 0.5315667877747347}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:31:14,977 - INFO - Using device: cuda
2025-08-15 00:31:24,648 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:31:24,649 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:31:24,649 - INFO - Starting training for fold 1/3
2025-08-15 00:31:31,433 - INFO - Fold 1, Epoch 10: Val Acc: 0.34%
2025-08-15 00:31:42,524 - INFO - Fold 1, Epoch 20: Val Acc: 0.84%
2025-08-15 00:31:44,839 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-15 00:31:47,063 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-15 00:31:51,446 - INFO - Fold 1, Epoch 50: Val Acc: 0.88%
2025-08-15 00:31:53,562 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-15 00:31:55,727 - INFO - Fold 1, Epoch 70: Val Acc: 0.75%
2025-08-15 00:31:57,730 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-15 00:31:59,945 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-15 00:32:02,161 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-15 00:32:04,377 - INFO - Fold 1, Epoch 110: Val Acc: 0.78%
2025-08-15 00:32:06,599 - INFO - Fold 1, Epoch 120: Val Acc: 0.84%
2025-08-15 00:32:08,820 - INFO - Fold 1, Epoch 130: Val Acc: 0.78%
2025-08-15 00:32:11,040 - INFO - Fold 1, Epoch 140: Val Acc: 0.75%
2025-08-15 00:32:13,254 - INFO - Early stopping at epoch 150
2025-08-15 00:32:16,722 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:32:16,725 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:32:16,726 - INFO - Starting training for fold 2/3
2025-08-15 00:32:24,836 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 00:32:27,050 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-15 00:32:32,083 - INFO - Fold 2, Epoch 30: Val Acc: 0.84%
2025-08-15 00:32:34,387 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-15 00:32:36,093 - INFO - Fold 2, Epoch 50: Val Acc: 0.59%
2025-08-15 00:32:37,848 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-15 00:32:40,078 - INFO - Fold 2, Epoch 70: Val Acc: 0.69%
2025-08-15 00:32:42,302 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-15 00:32:44,008 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-15 00:32:47,263 - INFO - Fold 2, Epoch 100: Val Acc: 0.84%
2025-08-15 00:32:48,970 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-15 00:32:50,805 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-15 00:32:52,919 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-15 00:32:55,136 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-15 00:32:58,728 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-15 00:33:00,957 - INFO - Fold 2, Epoch 160: Val Acc: 0.72%
2025-08-15 00:33:03,162 - INFO - Fold 2, Epoch 170: Val Acc: 0.72%
2025-08-15 00:33:05,394 - INFO - Fold 2, Epoch 180: Val Acc: 0.78%
2025-08-15 00:33:07,656 - INFO - Fold 2, Epoch 190: Val Acc: 0.81%
2025-08-15 00:33:09,873 - INFO - Fold 2, Epoch 200: Val Acc: 0.66%
2025-08-15 00:33:12,090 - INFO - Fold 2, Epoch 210: Val Acc: 0.81%
2025-08-15 00:33:14,313 - INFO - Fold 2, Epoch 220: Val Acc: 0.84%
2025-08-15 00:33:16,326 - INFO - Fold 2, Epoch 230: Val Acc: 0.72%
2025-08-15 00:33:18,233 - INFO - Fold 2, Epoch 240: Val Acc: 0.72%
2025-08-15 00:33:19,561 - INFO - Early stopping at epoch 246
2025-08-15 00:33:22,465 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:33:22,467 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:33:22,468 - INFO - Starting training for fold 3/3
2025-08-15 00:33:33,440 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-15 00:33:37,031 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-15 00:33:40,669 - INFO - Fold 3, Epoch 30: Val Acc: 0.56%
2025-08-15 00:33:44,431 - INFO - Fold 3, Epoch 40: Val Acc: 0.72%
2025-08-15 00:33:46,663 - INFO - Fold 3, Epoch 50: Val Acc: 0.81%
2025-08-15 00:33:50,060 - INFO - Fold 3, Epoch 60: Val Acc: 0.84%
2025-08-15 00:33:51,871 - INFO - Fold 3, Epoch 70: Val Acc: 0.59%
2025-08-15 00:33:55,461 - INFO - Fold 3, Epoch 80: Val Acc: 0.62%
2025-08-15 00:33:57,749 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-15 00:34:00,055 - INFO - Fold 3, Epoch 100: Val Acc: 0.66%
2025-08-15 00:34:02,198 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-15 00:34:04,186 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-15 00:34:07,728 - INFO - Fold 3, Epoch 130: Val Acc: 0.88%
2025-08-15 00:34:09,952 - INFO - Fold 3, Epoch 140: Val Acc: 0.75%
2025-08-15 00:34:12,062 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-15 00:34:14,301 - INFO - Fold 3, Epoch 160: Val Acc: 0.72%
2025-08-15 00:34:16,530 - INFO - Fold 3, Epoch 170: Val Acc: 0.81%
2025-08-15 00:34:18,757 - INFO - Fold 3, Epoch 180: Val Acc: 0.75%
2025-08-15 00:34:21,005 - INFO - Fold 3, Epoch 190: Val Acc: 0.59%
2025-08-15 00:34:23,260 - INFO - Fold 3, Epoch 200: Val Acc: 0.69%
2025-08-15 00:34:25,481 - INFO - Fold 3, Epoch 210: Val Acc: 0.69%
2025-08-15 00:34:27,694 - INFO - Fold 3, Epoch 220: Val Acc: 0.78%
2025-08-15 00:34:28,135 - INFO - Early stopping at epoch 222
2025-08-15 00:34:29,198 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.952895402908325), 'std': np.float64(0.044131836797246776)}, 'train_accuracy': {'mean': np.float64(0.7708333333333334), 'std': np.float64(0.022502571869471796)}, 'val_loss': {'mean': np.float64(4.100129286448161), 'std': np.float64(0.010070751880738154)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(105.0), 'std': np.float64(40.792156108742276)}}
[I 2025-08-15 00:34:29,205] Trial 114 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.00042939033260609797, 'batch_size': 32, 'num_epochs': 947, 'temperature': 0.44538735893009285, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4915926344132548, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1943045087472735, 'crop_size': 0.5322728176322039}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 114 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.00042939033260609797, 'batch_size': 32, 'num_epochs': 947, 'temperature': 0.44538735893009285, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4915926344132548, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1943045087472735, 'crop_size': 0.5322728176322039}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:34:29,244 - INFO - Using device: cuda
2025-08-15 00:34:39,070 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:34:39,072 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:34:39,072 - INFO - Starting training for fold 1/3
2025-08-15 00:34:50,210 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-15 00:34:52,440 - INFO - Fold 1, Epoch 20: Val Acc: 0.41%
2025-08-15 00:34:59,047 - INFO - Fold 1, Epoch 30: Val Acc: 0.69%
2025-08-15 00:35:01,280 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-15 00:35:05,621 - INFO - Fold 1, Epoch 50: Val Acc: 0.59%
2025-08-15 00:35:07,837 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-15 00:35:10,061 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-15 00:35:12,284 - INFO - Fold 1, Epoch 80: Val Acc: 0.78%
2025-08-15 00:35:14,511 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-15 00:35:16,744 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-15 00:35:18,976 - INFO - Fold 1, Epoch 110: Val Acc: 0.75%
2025-08-15 00:35:21,210 - INFO - Fold 1, Epoch 120: Val Acc: 0.84%
2025-08-15 00:35:23,463 - INFO - Fold 1, Epoch 130: Val Acc: 0.78%
2025-08-15 00:35:25,756 - INFO - Fold 1, Epoch 140: Val Acc: 0.72%
2025-08-15 00:35:27,762 - INFO - Early stopping at epoch 149
2025-08-15 00:35:31,368 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:35:31,370 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:35:31,371 - INFO - Starting training for fold 2/3
2025-08-15 00:35:38,083 - INFO - Fold 2, Epoch 10: Val Acc: 0.62%
2025-08-15 00:35:41,577 - INFO - Fold 2, Epoch 20: Val Acc: 0.69%
2025-08-15 00:35:45,238 - INFO - Fold 2, Epoch 30: Val Acc: 0.56%
2025-08-15 00:35:48,886 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-15 00:35:52,603 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-15 00:35:56,243 - INFO - Fold 2, Epoch 60: Val Acc: 0.84%
2025-08-15 00:35:58,490 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-15 00:36:00,776 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-15 00:36:03,086 - INFO - Fold 2, Epoch 90: Val Acc: 0.75%
2025-08-15 00:36:06,812 - INFO - Fold 2, Epoch 100: Val Acc: 0.81%
2025-08-15 00:36:10,579 - INFO - Fold 2, Epoch 110: Val Acc: 0.62%
2025-08-15 00:36:12,890 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-15 00:36:15,208 - INFO - Fold 2, Epoch 130: Val Acc: 0.88%
2025-08-15 00:36:17,528 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-15 00:36:19,843 - INFO - Fold 2, Epoch 150: Val Acc: 0.72%
2025-08-15 00:36:22,153 - INFO - Fold 2, Epoch 160: Val Acc: 0.56%
2025-08-15 00:36:24,467 - INFO - Fold 2, Epoch 170: Val Acc: 0.69%
2025-08-15 00:36:26,744 - INFO - Fold 2, Epoch 180: Val Acc: 0.75%
2025-08-15 00:36:28,718 - INFO - Fold 2, Epoch 190: Val Acc: 0.69%
2025-08-15 00:36:30,684 - INFO - Fold 2, Epoch 200: Val Acc: 0.81%
2025-08-15 00:36:31,130 - INFO - Early stopping at epoch 202
2025-08-15 00:36:34,241 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:36:34,244 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:36:34,244 - INFO - Starting training for fold 3/3
2025-08-15 00:36:40,781 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-15 00:36:44,283 - INFO - Fold 3, Epoch 20: Val Acc: 0.50%
2025-08-15 00:36:47,864 - INFO - Fold 3, Epoch 30: Val Acc: 0.78%
2025-08-15 00:36:51,566 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-15 00:36:53,799 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-15 00:36:55,921 - INFO - Fold 3, Epoch 60: Val Acc: 0.81%
2025-08-15 00:36:59,483 - INFO - Fold 3, Epoch 70: Val Acc: 0.66%
2025-08-15 00:37:01,695 - INFO - Fold 3, Epoch 80: Val Acc: 0.84%
2025-08-15 00:37:05,136 - INFO - Fold 3, Epoch 90: Val Acc: 0.88%
2025-08-15 00:37:07,453 - INFO - Fold 3, Epoch 100: Val Acc: 0.56%
2025-08-15 00:37:09,671 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-15 00:37:11,888 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-15 00:37:14,107 - INFO - Fold 3, Epoch 130: Val Acc: 0.59%
2025-08-15 00:37:16,301 - INFO - Fold 3, Epoch 140: Val Acc: 0.78%
2025-08-15 00:37:18,600 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-15 00:37:22,266 - INFO - Fold 3, Epoch 160: Val Acc: 0.59%
2025-08-15 00:37:24,561 - INFO - Fold 3, Epoch 170: Val Acc: 0.69%
2025-08-15 00:37:26,870 - INFO - Fold 3, Epoch 180: Val Acc: 0.66%
2025-08-15 00:37:29,197 - INFO - Fold 3, Epoch 190: Val Acc: 0.72%
2025-08-15 00:37:31,447 - INFO - Fold 3, Epoch 200: Val Acc: 0.72%
2025-08-15 00:37:33,680 - INFO - Fold 3, Epoch 210: Val Acc: 0.62%
2025-08-15 00:37:35,907 - INFO - Fold 3, Epoch 220: Val Acc: 0.69%
2025-08-15 00:37:38,125 - INFO - Fold 3, Epoch 230: Val Acc: 0.72%
2025-08-15 00:37:40,310 - INFO - Fold 3, Epoch 240: Val Acc: 0.62%
2025-08-15 00:37:42,359 - INFO - Fold 3, Epoch 250: Val Acc: 0.91%
2025-08-15 00:37:43,708 - INFO - Early stopping at epoch 257
2025-08-15 00:37:44,782 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9059254858228893), 'std': np.float64(0.05328570885315432)}, 'train_accuracy': {'mean': np.float64(0.7881944444444443), 'std': np.float64(0.043645156562418456)}, 'val_loss': {'mean': np.float64(4.153213818868001), 'std': np.float64(0.08243280774555017)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(101.66666666666667), 'std': np.float64(44.0933353492591)}}
[I 2025-08-15 00:37:44,789] Trial 115 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0007299936041013703, 'batch_size': 32, 'num_epochs': 937, 'temperature': 0.46858250245215705, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.48237914302458496, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18014148182655865, 'crop_size': 0.5205235719375194}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 115 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0007299936041013703, 'batch_size': 32, 'num_epochs': 937, 'temperature': 0.46858250245215705, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.48237914302458496, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18014148182655865, 'crop_size': 0.5205235719375194}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:37:44,824 - INFO - Using device: cuda
2025-08-15 00:37:54,511 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:37:54,515 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:37:54,516 - INFO - Starting training for fold 1/3
2025-08-15 00:38:03,250 - INFO - Fold 1, Epoch 10: Val Acc: 0.44%
2025-08-15 00:38:09,381 - INFO - Fold 1, Epoch 20: Val Acc: 0.75%
2025-08-15 00:38:11,101 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-15 00:38:12,971 - INFO - Fold 1, Epoch 40: Val Acc: 0.66%
2025-08-15 00:38:14,774 - INFO - Fold 1, Epoch 50: Val Acc: 0.53%
2025-08-15 00:38:16,603 - INFO - Fold 1, Epoch 60: Val Acc: 0.59%
2025-08-15 00:38:18,352 - INFO - Fold 1, Epoch 70: Val Acc: 0.53%
2025-08-15 00:38:20,106 - INFO - Fold 1, Epoch 80: Val Acc: 0.50%
2025-08-15 00:38:21,973 - INFO - Fold 1, Epoch 90: Val Acc: 0.44%
2025-08-15 00:38:23,800 - INFO - Fold 1, Epoch 100: Val Acc: 0.41%
2025-08-15 00:38:25,826 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-15 00:38:27,881 - INFO - Early stopping at epoch 120
2025-08-15 00:38:31,419 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:38:31,421 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:38:31,422 - INFO - Starting training for fold 2/3
2025-08-15 00:38:37,944 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 00:38:40,058 - INFO - Fold 2, Epoch 20: Val Acc: 0.38%
2025-08-15 00:38:42,173 - INFO - Fold 2, Epoch 30: Val Acc: 0.53%
2025-08-15 00:38:44,290 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-15 00:38:47,803 - INFO - Fold 2, Epoch 50: Val Acc: 0.72%
2025-08-15 00:38:49,996 - INFO - Fold 2, Epoch 60: Val Acc: 0.53%
2025-08-15 00:38:52,111 - INFO - Fold 2, Epoch 70: Val Acc: 0.53%
2025-08-15 00:38:54,214 - INFO - Fold 2, Epoch 80: Val Acc: 0.53%
2025-08-15 00:38:56,095 - INFO - Fold 2, Epoch 90: Val Acc: 0.50%
2025-08-15 00:38:58,161 - INFO - Fold 2, Epoch 100: Val Acc: 0.59%
2025-08-15 00:39:00,279 - INFO - Fold 2, Epoch 110: Val Acc: 0.62%
2025-08-15 00:39:02,387 - INFO - Fold 2, Epoch 120: Val Acc: 0.59%
2025-08-15 00:39:04,490 - INFO - Fold 2, Epoch 130: Val Acc: 0.53%
2025-08-15 00:39:08,031 - INFO - Fold 2, Epoch 140: Val Acc: 0.62%
2025-08-15 00:39:10,143 - INFO - Fold 2, Epoch 150: Val Acc: 0.53%
2025-08-15 00:39:12,253 - INFO - Fold 2, Epoch 160: Val Acc: 0.66%
2025-08-15 00:39:14,045 - INFO - Fold 2, Epoch 170: Val Acc: 0.50%
2025-08-15 00:39:15,867 - INFO - Fold 2, Epoch 180: Val Acc: 0.47%
2025-08-15 00:39:17,725 - INFO - Fold 2, Epoch 190: Val Acc: 0.81%
2025-08-15 00:39:19,326 - INFO - Fold 2, Epoch 200: Val Acc: 0.53%
2025-08-15 00:39:21,120 - INFO - Fold 2, Epoch 210: Val Acc: 0.72%
2025-08-15 00:39:23,241 - INFO - Fold 2, Epoch 220: Val Acc: 0.56%
2025-08-15 00:39:25,368 - INFO - Fold 2, Epoch 230: Val Acc: 0.59%
2025-08-15 00:39:25,579 - INFO - Early stopping at epoch 231
2025-08-15 00:39:28,641 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:39:28,645 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:39:28,646 - INFO - Starting training for fold 3/3
2025-08-15 00:39:36,609 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-15 00:39:41,563 - INFO - Fold 3, Epoch 20: Val Acc: 0.56%
2025-08-15 00:39:45,013 - INFO - Fold 3, Epoch 30: Val Acc: 0.62%
2025-08-15 00:39:48,302 - INFO - Fold 3, Epoch 40: Val Acc: 0.38%
2025-08-15 00:39:50,368 - INFO - Fold 3, Epoch 50: Val Acc: 0.50%
2025-08-15 00:39:53,823 - INFO - Fold 3, Epoch 60: Val Acc: 0.81%
2025-08-15 00:39:55,964 - INFO - Fold 3, Epoch 70: Val Acc: 0.53%
2025-08-15 00:39:58,080 - INFO - Fold 3, Epoch 80: Val Acc: 0.53%
2025-08-15 00:40:00,203 - INFO - Fold 3, Epoch 90: Val Acc: 0.47%
2025-08-15 00:40:02,328 - INFO - Fold 3, Epoch 100: Val Acc: 0.62%
2025-08-15 00:40:04,437 - INFO - Fold 3, Epoch 110: Val Acc: 0.62%
2025-08-15 00:40:06,552 - INFO - Fold 3, Epoch 120: Val Acc: 0.59%
2025-08-15 00:40:08,667 - INFO - Fold 3, Epoch 130: Val Acc: 0.53%
2025-08-15 00:40:10,783 - INFO - Fold 3, Epoch 140: Val Acc: 0.56%
2025-08-15 00:40:12,902 - INFO - Fold 3, Epoch 150: Val Acc: 0.62%
2025-08-15 00:40:14,721 - INFO - Early stopping at epoch 160
2025-08-15 00:40:15,790 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.1943948533799915), 'std': np.float64(0.0358121363015275)}, 'train_accuracy': {'mean': np.float64(0.5972222222222222), 'std': np.float64(0.009820927516479843)}, 'val_loss': {'mean': np.float64(4.2441450754801435), 'std': np.float64(0.1006844299978486)}, 'val_accuracy': {'mean': np.float64(0.7916666666666666), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(69.33333333333333), 'std': np.float64(45.900859348043674)}}
[I 2025-08-15 00:40:15,796] Trial 116 finished with value: -0.7916666666666666 and parameters: {'learning_rate': 2.0802661081730697e-05, 'batch_size': 32, 'num_epochs': 955, 'temperature': 0.3597963405882436, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.44156724914075796, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.5005508701647717}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 116 finished with value: -0.7916666666666666 and parameters: {'learning_rate': 2.0802661081730697e-05, 'batch_size': 32, 'num_epochs': 955, 'temperature': 0.3597963405882436, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.44156724914075796, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.5005508701647717}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:40:15,834 - INFO - Using device: cuda
2025-08-15 00:40:25,721 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:40:25,723 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:40:25,723 - INFO - Starting training for fold 1/3
2025-08-15 00:40:41,233 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-15 00:40:50,239 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-15 00:40:52,461 - INFO - Fold 1, Epoch 30: Val Acc: 0.72%
2025-08-15 00:40:54,780 - INFO - Fold 1, Epoch 40: Val Acc: 0.66%
2025-08-15 00:40:59,112 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-15 00:41:03,535 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-15 00:41:08,551 - INFO - Fold 1, Epoch 70: Val Acc: 0.84%
2025-08-15 00:41:10,713 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-15 00:41:12,626 - INFO - Fold 1, Epoch 90: Val Acc: 0.88%
2025-08-15 00:41:14,852 - INFO - Fold 1, Epoch 100: Val Acc: 0.66%
2025-08-15 00:41:17,076 - INFO - Fold 1, Epoch 110: Val Acc: 0.56%
2025-08-15 00:41:19,302 - INFO - Fold 1, Epoch 120: Val Acc: 0.66%
2025-08-15 00:41:21,519 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-15 00:41:23,743 - INFO - Fold 1, Epoch 140: Val Acc: 0.72%
2025-08-15 00:41:25,963 - INFO - Fold 1, Epoch 150: Val Acc: 0.75%
2025-08-15 00:41:28,178 - INFO - Fold 1, Epoch 160: Val Acc: 0.62%
2025-08-15 00:41:30,171 - INFO - Early stopping at epoch 169
2025-08-15 00:41:33,876 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:41:33,878 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:41:33,879 - INFO - Starting training for fold 2/3
2025-08-15 00:41:40,076 - INFO - Fold 2, Epoch 10: Val Acc: 0.62%
2025-08-15 00:41:45,024 - INFO - Fold 2, Epoch 20: Val Acc: 0.72%
2025-08-15 00:41:48,701 - INFO - Fold 2, Epoch 30: Val Acc: 0.78%
2025-08-15 00:41:51,000 - INFO - Fold 2, Epoch 40: Val Acc: 0.47%
2025-08-15 00:41:53,308 - INFO - Fold 2, Epoch 50: Val Acc: 0.66%
2025-08-15 00:41:55,594 - INFO - Fold 2, Epoch 60: Val Acc: 0.84%
2025-08-15 00:41:59,298 - INFO - Fold 2, Epoch 70: Val Acc: 0.69%
2025-08-15 00:42:01,531 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-15 00:42:05,098 - INFO - Fold 2, Epoch 90: Val Acc: 0.88%
2025-08-15 00:42:07,369 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-15 00:42:09,684 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-15 00:42:11,992 - INFO - Fold 2, Epoch 120: Val Acc: 0.78%
2025-08-15 00:42:14,298 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-15 00:42:16,500 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-15 00:42:18,675 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-15 00:42:20,878 - INFO - Fold 2, Epoch 160: Val Acc: 0.78%
2025-08-15 00:42:23,004 - INFO - Fold 2, Epoch 170: Val Acc: 0.94%
2025-08-15 00:42:25,228 - INFO - Fold 2, Epoch 180: Val Acc: 0.78%
2025-08-15 00:42:26,105 - INFO - Early stopping at epoch 184
2025-08-15 00:42:29,124 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:42:29,127 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:42:29,127 - INFO - Starting training for fold 3/3
2025-08-15 00:42:35,707 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-15 00:42:39,464 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-15 00:42:44,631 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-15 00:42:48,176 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-15 00:42:50,226 - INFO - Fold 3, Epoch 50: Val Acc: 0.50%
2025-08-15 00:42:54,083 - INFO - Fold 3, Epoch 60: Val Acc: 0.66%
2025-08-15 00:42:56,381 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-15 00:42:58,687 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-15 00:43:00,926 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-15 00:43:04,531 - INFO - Fold 3, Epoch 100: Val Acc: 0.81%
2025-08-15 00:43:08,161 - INFO - Fold 3, Epoch 110: Val Acc: 0.72%
2025-08-15 00:43:10,412 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-15 00:43:12,389 - INFO - Fold 3, Epoch 130: Val Acc: 0.66%
2025-08-15 00:43:14,232 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-15 00:43:16,451 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-15 00:43:18,669 - INFO - Fold 3, Epoch 160: Val Acc: 0.66%
2025-08-15 00:43:20,889 - INFO - Fold 3, Epoch 170: Val Acc: 0.69%
2025-08-15 00:43:23,109 - INFO - Fold 3, Epoch 180: Val Acc: 0.72%
2025-08-15 00:43:25,335 - INFO - Fold 3, Epoch 190: Val Acc: 0.69%
2025-08-15 00:43:27,563 - INFO - Fold 3, Epoch 200: Val Acc: 0.62%
2025-08-15 00:43:29,562 - INFO - Early stopping at epoch 209
2025-08-15 00:43:30,663 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9203531477186417), 'std': np.float64(0.009781750081052898)}, 'train_accuracy': {'mean': np.float64(0.8020833333333334), 'std': np.float64(0.05892556509887896)}, 'val_loss': {'mean': np.float64(4.222835540771484), 'std': np.float64(0.05431209506048671)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(86.33333333333333), 'std': np.float64(16.49915822768611)}}
[I 2025-08-15 00:43:30,669] Trial 117 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.000630028677236892, 'batch_size': 32, 'num_epochs': 1000, 'temperature': 0.27109635289746087, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.47205125240618345, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18812535875567946, 'crop_size': 0.5509700380922102}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 117 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.000630028677236892, 'batch_size': 32, 'num_epochs': 1000, 'temperature': 0.27109635289746087, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.47205125240618345, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18812535875567946, 'crop_size': 0.5509700380922102}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:43:30,704 - INFO - Using device: cuda
2025-08-15 00:43:40,446 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:43:40,450 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:43:40,450 - INFO - Starting training for fold 1/3
2025-08-15 00:43:49,529 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-15 00:43:51,607 - INFO - Fold 1, Epoch 20: Val Acc: 0.53%
2025-08-15 00:43:55,914 - INFO - Fold 1, Epoch 30: Val Acc: 0.44%
2025-08-15 00:43:58,185 - INFO - Fold 1, Epoch 40: Val Acc: 0.50%
2025-08-15 00:44:00,452 - INFO - Fold 1, Epoch 50: Val Acc: 0.59%
2025-08-15 00:44:02,719 - INFO - Fold 1, Epoch 60: Val Acc: 0.44%
2025-08-15 00:44:04,991 - INFO - Fold 1, Epoch 70: Val Acc: 0.38%
2025-08-15 00:44:07,269 - INFO - Fold 1, Epoch 80: Val Acc: 0.50%
2025-08-15 00:44:09,546 - INFO - Fold 1, Epoch 90: Val Acc: 0.47%
2025-08-15 00:44:11,821 - INFO - Fold 1, Epoch 100: Val Acc: 0.47%
2025-08-15 00:44:16,523 - INFO - Fold 1, Epoch 110: Val Acc: 0.44%
2025-08-15 00:44:18,791 - INFO - Fold 1, Epoch 120: Val Acc: 0.47%
2025-08-15 00:44:21,102 - INFO - Fold 1, Epoch 130: Val Acc: 0.44%
2025-08-15 00:44:23,443 - INFO - Fold 1, Epoch 140: Val Acc: 0.41%
2025-08-15 00:44:25,433 - INFO - Fold 1, Epoch 150: Val Acc: 0.47%
2025-08-15 00:44:27,562 - INFO - Fold 1, Epoch 160: Val Acc: 0.41%
2025-08-15 00:44:29,834 - INFO - Fold 1, Epoch 170: Val Acc: 0.47%
2025-08-15 00:44:32,103 - INFO - Fold 1, Epoch 180: Val Acc: 0.50%
2025-08-15 00:44:34,374 - INFO - Fold 1, Epoch 190: Val Acc: 0.44%
2025-08-15 00:44:36,342 - INFO - Fold 1, Epoch 200: Val Acc: 0.50%
2025-08-15 00:44:36,532 - INFO - Early stopping at epoch 201
2025-08-15 00:44:40,032 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:44:40,035 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:44:40,035 - INFO - Starting training for fold 2/3
2025-08-15 00:44:46,523 - INFO - Fold 2, Epoch 10: Val Acc: 0.47%
2025-08-15 00:44:48,569 - INFO - Fold 2, Epoch 20: Val Acc: 0.56%
2025-08-15 00:44:52,203 - INFO - Fold 2, Epoch 30: Val Acc: 0.50%
2025-08-15 00:44:54,461 - INFO - Fold 2, Epoch 40: Val Acc: 0.47%
2025-08-15 00:44:56,709 - INFO - Fold 2, Epoch 50: Val Acc: 0.47%
2025-08-15 00:44:58,966 - INFO - Fold 2, Epoch 60: Val Acc: 0.53%
2025-08-15 00:45:01,191 - INFO - Fold 2, Epoch 70: Val Acc: 0.59%
2025-08-15 00:45:03,424 - INFO - Fold 2, Epoch 80: Val Acc: 0.38%
2025-08-15 00:45:05,669 - INFO - Fold 2, Epoch 90: Val Acc: 0.56%
2025-08-15 00:45:07,947 - INFO - Fold 2, Epoch 100: Val Acc: 0.59%
2025-08-15 00:45:09,980 - INFO - Fold 2, Epoch 110: Val Acc: 0.47%
2025-08-15 00:45:12,230 - INFO - Fold 2, Epoch 120: Val Acc: 0.50%
2025-08-15 00:45:13,993 - INFO - Early stopping at epoch 129
2025-08-15 00:45:15,067 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:45:15,068 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:45:15,069 - INFO - Starting training for fold 3/3
2025-08-15 00:45:20,318 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-15 00:45:23,937 - INFO - Fold 3, Epoch 20: Val Acc: 0.56%
2025-08-15 00:45:29,024 - INFO - Fold 3, Epoch 30: Val Acc: 0.53%
2025-08-15 00:45:32,859 - INFO - Fold 3, Epoch 40: Val Acc: 0.56%
2025-08-15 00:45:34,833 - INFO - Fold 3, Epoch 50: Val Acc: 0.47%
2025-08-15 00:45:36,582 - INFO - Fold 3, Epoch 60: Val Acc: 0.59%
2025-08-15 00:45:39,746 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-15 00:45:41,595 - INFO - Fold 3, Epoch 80: Val Acc: 0.53%
2025-08-15 00:45:43,350 - INFO - Fold 3, Epoch 90: Val Acc: 0.53%
2025-08-15 00:45:45,233 - INFO - Fold 3, Epoch 100: Val Acc: 0.56%
2025-08-15 00:45:47,593 - INFO - Fold 3, Epoch 110: Val Acc: 0.47%
2025-08-15 00:45:49,726 - INFO - Fold 3, Epoch 120: Val Acc: 0.53%
2025-08-15 00:45:52,010 - INFO - Fold 3, Epoch 130: Val Acc: 0.47%
2025-08-15 00:45:54,289 - INFO - Fold 3, Epoch 140: Val Acc: 0.50%
2025-08-15 00:45:56,567 - INFO - Fold 3, Epoch 150: Val Acc: 0.62%
2025-08-15 00:45:58,845 - INFO - Fold 3, Epoch 160: Val Acc: 0.47%
2025-08-15 00:46:01,110 - INFO - Early stopping at epoch 170
2025-08-15 00:46:02,182 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.142159197065566), 'std': np.float64(0.012626039238423755)}, 'train_accuracy': {'mean': np.float64(0.5555555555555556), 'std': np.float64(0.025983731852596812)}, 'val_loss': {'mean': np.float64(4.13437541325887), 'std': np.float64(0.027601492675739144)}, 'val_accuracy': {'mean': np.float64(0.6666666666666666), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(65.66666666666667), 'std': np.float64(29.48822740612863)}}
[I 2025-08-15 00:46:02,189] Trial 118 finished with value: -0.6666666666666666 and parameters: {'learning_rate': 0.0005462445258032414, 'batch_size': 32, 'num_epochs': 965, 'temperature': 0.4087585948974623, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.49997829745728267, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.1025022996405689}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 118 finished with value: -0.6666666666666666 and parameters: {'learning_rate': 0.0005462445258032414, 'batch_size': 32, 'num_epochs': 965, 'temperature': 0.4087585948974623, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.49997829745728267, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.1025022996405689}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:46:02,228 - INFO - Using device: cuda
2025-08-15 00:46:11,774 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:46:11,776 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:46:11,776 - INFO - Starting training for fold 1/3
2025-08-15 00:46:24,972 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-15 00:46:31,466 - INFO - Fold 1, Epoch 20: Val Acc: 0.62%
2025-08-15 00:46:33,697 - INFO - Fold 1, Epoch 30: Val Acc: 0.81%
2025-08-15 00:46:35,924 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-15 00:46:39,889 - INFO - Fold 1, Epoch 50: Val Acc: 0.72%
2025-08-15 00:46:41,963 - INFO - Fold 1, Epoch 60: Val Acc: 0.81%
2025-08-15 00:46:44,186 - INFO - Fold 1, Epoch 70: Val Acc: 0.75%
2025-08-15 00:46:46,411 - INFO - Fold 1, Epoch 80: Val Acc: 0.69%
2025-08-15 00:46:48,632 - INFO - Fold 1, Epoch 90: Val Acc: 0.81%
2025-08-15 00:46:53,163 - INFO - Fold 1, Epoch 100: Val Acc: 0.66%
2025-08-15 00:46:55,405 - INFO - Fold 1, Epoch 110: Val Acc: 0.75%
2025-08-15 00:46:57,644 - INFO - Fold 1, Epoch 120: Val Acc: 0.62%
2025-08-15 00:46:59,884 - INFO - Fold 1, Epoch 130: Val Acc: 0.59%
2025-08-15 00:47:02,126 - INFO - Fold 1, Epoch 140: Val Acc: 0.62%
2025-08-15 00:47:04,332 - INFO - Fold 1, Epoch 150: Val Acc: 0.62%
2025-08-15 00:47:06,545 - INFO - Fold 1, Epoch 160: Val Acc: 0.66%
2025-08-15 00:47:08,291 - INFO - Fold 1, Epoch 170: Val Acc: 0.69%
2025-08-15 00:47:10,000 - INFO - Fold 1, Epoch 180: Val Acc: 0.66%
2025-08-15 00:47:11,705 - INFO - Fold 1, Epoch 190: Val Acc: 0.47%
2025-08-15 00:47:11,876 - INFO - Early stopping at epoch 191
2025-08-15 00:47:15,545 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:47:15,563 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:47:15,565 - INFO - Starting training for fold 2/3
2025-08-15 00:47:22,321 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 00:47:29,051 - INFO - Fold 2, Epoch 20: Val Acc: 0.81%
2025-08-15 00:47:31,370 - INFO - Fold 2, Epoch 30: Val Acc: 0.81%
2025-08-15 00:47:35,055 - INFO - Fold 2, Epoch 40: Val Acc: 0.84%
2025-08-15 00:47:37,267 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-15 00:47:40,928 - INFO - Fold 2, Epoch 60: Val Acc: 0.88%
2025-08-15 00:47:43,132 - INFO - Fold 2, Epoch 70: Val Acc: 0.81%
2025-08-15 00:47:45,338 - INFO - Fold 2, Epoch 80: Val Acc: 0.84%
2025-08-15 00:47:47,562 - INFO - Fold 2, Epoch 90: Val Acc: 0.75%
2025-08-15 00:47:49,786 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-15 00:47:51,911 - INFO - Fold 2, Epoch 110: Val Acc: 0.78%
2025-08-15 00:47:53,940 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-15 00:47:56,142 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-15 00:47:58,360 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-15 00:48:00,583 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-15 00:48:01,910 - INFO - Early stopping at epoch 156
2025-08-15 00:48:02,978 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:48:02,980 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:48:02,980 - INFO - Starting training for fold 3/3
2025-08-15 00:48:08,081 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-15 00:48:14,177 - INFO - Fold 3, Epoch 20: Val Acc: 0.66%
2025-08-15 00:48:19,463 - INFO - Fold 3, Epoch 30: Val Acc: 0.72%
2025-08-15 00:48:22,858 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-15 00:48:24,562 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-15 00:48:26,271 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-15 00:48:27,977 - INFO - Fold 3, Epoch 70: Val Acc: 0.81%
2025-08-15 00:48:30,043 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-15 00:48:32,258 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-15 00:48:34,481 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-15 00:48:36,574 - INFO - Fold 3, Epoch 110: Val Acc: 0.62%
2025-08-15 00:48:40,184 - INFO - Fold 3, Epoch 120: Val Acc: 0.91%
2025-08-15 00:48:42,327 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-15 00:48:44,423 - INFO - Fold 3, Epoch 140: Val Acc: 0.75%
2025-08-15 00:48:46,648 - INFO - Fold 3, Epoch 150: Val Acc: 0.75%
2025-08-15 00:48:48,866 - INFO - Fold 3, Epoch 160: Val Acc: 0.72%
2025-08-15 00:48:51,035 - INFO - Fold 3, Epoch 170: Val Acc: 0.81%
2025-08-15 00:48:52,972 - INFO - Fold 3, Epoch 180: Val Acc: 0.62%
2025-08-15 00:48:54,892 - INFO - Fold 3, Epoch 190: Val Acc: 0.66%
2025-08-15 00:48:56,847 - INFO - Fold 3, Epoch 200: Val Acc: 0.62%
2025-08-15 00:48:58,760 - INFO - Fold 3, Epoch 210: Val Acc: 0.62%
2025-08-15 00:49:00,702 - INFO - Early stopping at epoch 220
2025-08-15 00:49:01,794 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9095727867550316), 'std': np.float64(0.006870592251336946)}, 'train_accuracy': {'mean': np.float64(0.78125), 'std': np.float64(0.008505172717997207)}, 'val_loss': {'mean': np.float64(4.230035781860352), 'std': np.float64(0.0758974473700749)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.0)}, 'epoch': {'mean': np.float64(88.0), 'std': np.float64(26.166135875720485)}}
[I 2025-08-15 00:49:01,801] Trial 119 finished with value: -0.90625 and parameters: {'learning_rate': 0.00039744043788387585, 'batch_size': 32, 'num_epochs': 878, 'temperature': 0.3904064333520803, 'embedding_dim': 512, 'hidden_dim': 256, 'dropout': 0.45435434968899396, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1821954752715212, 'crop_size': 0.5404614291355336}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 119 finished with value: -0.90625 and parameters: {'learning_rate': 0.00039744043788387585, 'batch_size': 32, 'num_epochs': 878, 'temperature': 0.3904064333520803, 'embedding_dim': 512, 'hidden_dim': 256, 'dropout': 0.45435434968899396, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1821954752715212, 'crop_size': 0.5404614291355336}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:49:01,840 - INFO - Using device: cuda
2025-08-15 00:49:11,547 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:49:11,549 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:49:11,549 - INFO - Starting training for fold 1/3
2025-08-15 00:49:18,282 - INFO - Fold 1, Epoch 10: Val Acc: 0.44%
2025-08-15 00:49:20,330 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-15 00:49:24,437 - INFO - Fold 1, Epoch 30: Val Acc: 0.56%
2025-08-15 00:49:26,479 - INFO - Fold 1, Epoch 40: Val Acc: 0.56%
2025-08-15 00:49:28,180 - INFO - Fold 1, Epoch 50: Val Acc: 0.47%
2025-08-15 00:49:29,879 - INFO - Fold 1, Epoch 60: Val Acc: 0.53%
2025-08-15 00:49:31,579 - INFO - Fold 1, Epoch 70: Val Acc: 0.62%
2025-08-15 00:49:33,278 - INFO - Fold 1, Epoch 80: Val Acc: 0.47%
2025-08-15 00:49:35,179 - INFO - Fold 1, Epoch 90: Val Acc: 0.50%
2025-08-15 00:49:36,880 - INFO - Fold 1, Epoch 100: Val Acc: 0.53%
2025-08-15 00:49:38,586 - INFO - Fold 1, Epoch 110: Val Acc: 0.56%
2025-08-15 00:49:42,550 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-15 00:49:44,430 - INFO - Fold 1, Epoch 130: Val Acc: 0.75%
2025-08-15 00:49:46,124 - INFO - Fold 1, Epoch 140: Val Acc: 0.50%
2025-08-15 00:49:47,826 - INFO - Fold 1, Epoch 150: Val Acc: 0.62%
2025-08-15 00:49:51,675 - INFO - Fold 1, Epoch 160: Val Acc: 0.62%
2025-08-15 00:49:53,724 - INFO - Fold 1, Epoch 170: Val Acc: 0.59%
2025-08-15 00:49:55,943 - INFO - Fold 1, Epoch 180: Val Acc: 0.62%
2025-08-15 00:49:58,178 - INFO - Fold 1, Epoch 190: Val Acc: 0.50%
2025-08-15 00:50:00,329 - INFO - Fold 1, Epoch 200: Val Acc: 0.75%
2025-08-15 00:50:04,702 - INFO - Fold 1, Epoch 210: Val Acc: 0.72%
2025-08-15 00:50:06,611 - INFO - Fold 1, Epoch 220: Val Acc: 0.69%
2025-08-15 00:50:08,599 - INFO - Fold 1, Epoch 230: Val Acc: 0.62%
2025-08-15 00:50:10,495 - INFO - Fold 1, Epoch 240: Val Acc: 0.50%
2025-08-15 00:50:12,525 - INFO - Fold 1, Epoch 250: Val Acc: 0.59%
2025-08-15 00:50:14,752 - INFO - Fold 1, Epoch 260: Val Acc: 0.50%
2025-08-15 00:50:16,972 - INFO - Fold 1, Epoch 270: Val Acc: 0.47%
2025-08-15 00:50:19,194 - INFO - Fold 1, Epoch 280: Val Acc: 0.50%
2025-08-15 00:50:21,388 - INFO - Fold 1, Epoch 290: Val Acc: 0.78%
2025-08-15 00:50:23,571 - INFO - Fold 1, Epoch 300: Val Acc: 0.84%
2025-08-15 00:50:25,127 - INFO - Early stopping at epoch 307
2025-08-15 00:50:28,664 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:50:28,666 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:50:28,667 - INFO - Starting training for fold 2/3
2025-08-15 00:50:35,338 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-15 00:50:37,414 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-15 00:50:40,942 - INFO - Fold 2, Epoch 30: Val Acc: 0.62%
2025-08-15 00:50:42,881 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-15 00:50:44,846 - INFO - Fold 2, Epoch 50: Val Acc: 0.59%
2025-08-15 00:50:48,345 - INFO - Fold 2, Epoch 60: Val Acc: 0.62%
2025-08-15 00:50:50,587 - INFO - Fold 2, Epoch 70: Val Acc: 0.50%
2025-08-15 00:50:52,812 - INFO - Fold 2, Epoch 80: Val Acc: 0.59%
2025-08-15 00:50:54,777 - INFO - Fold 2, Epoch 90: Val Acc: 0.47%
2025-08-15 00:50:56,775 - INFO - Fold 2, Epoch 100: Val Acc: 0.50%
2025-08-15 00:50:58,569 - INFO - Fold 2, Epoch 110: Val Acc: 0.56%
2025-08-15 00:51:00,478 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-15 00:51:02,710 - INFO - Fold 2, Epoch 130: Val Acc: 0.66%
2025-08-15 00:51:04,953 - INFO - Fold 2, Epoch 140: Val Acc: 0.62%
2025-08-15 00:51:07,195 - INFO - Fold 2, Epoch 150: Val Acc: 0.50%
2025-08-15 00:51:07,424 - INFO - Early stopping at epoch 151
2025-08-15 00:51:08,467 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:51:08,469 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:51:08,470 - INFO - Starting training for fold 3/3
2025-08-15 00:51:16,300 - INFO - Fold 3, Epoch 10: Val Acc: 0.69%
2025-08-15 00:51:18,609 - INFO - Fold 3, Epoch 20: Val Acc: 0.47%
2025-08-15 00:51:20,922 - INFO - Fold 3, Epoch 30: Val Acc: 0.44%
2025-08-15 00:51:24,692 - INFO - Fold 3, Epoch 40: Val Acc: 0.50%
2025-08-15 00:51:26,999 - INFO - Fold 3, Epoch 50: Val Acc: 0.59%
2025-08-15 00:51:29,139 - INFO - Fold 3, Epoch 60: Val Acc: 0.50%
2025-08-15 00:51:30,849 - INFO - Fold 3, Epoch 70: Val Acc: 0.50%
2025-08-15 00:51:32,692 - INFO - Fold 3, Epoch 80: Val Acc: 0.62%
2025-08-15 00:51:35,006 - INFO - Fold 3, Epoch 90: Val Acc: 0.53%
2025-08-15 00:51:38,577 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-15 00:51:40,896 - INFO - Fold 3, Epoch 110: Val Acc: 0.56%
2025-08-15 00:51:42,893 - INFO - Fold 3, Epoch 120: Val Acc: 0.50%
2025-08-15 00:51:46,466 - INFO - Fold 3, Epoch 130: Val Acc: 0.50%
2025-08-15 00:51:48,492 - INFO - Fold 3, Epoch 140: Val Acc: 0.53%
2025-08-15 00:51:50,595 - INFO - Fold 3, Epoch 150: Val Acc: 0.75%
2025-08-15 00:51:52,909 - INFO - Fold 3, Epoch 160: Val Acc: 0.66%
2025-08-15 00:51:55,221 - INFO - Fold 3, Epoch 170: Val Acc: 0.53%
2025-08-15 00:51:57,532 - INFO - Fold 3, Epoch 180: Val Acc: 0.50%
2025-08-15 00:51:59,842 - INFO - Fold 3, Epoch 190: Val Acc: 0.75%
2025-08-15 00:52:02,156 - INFO - Fold 3, Epoch 200: Val Acc: 0.66%
2025-08-15 00:52:04,469 - INFO - Fold 3, Epoch 210: Val Acc: 0.53%
2025-08-15 00:52:06,778 - INFO - Fold 3, Epoch 220: Val Acc: 0.50%
2025-08-15 00:52:10,448 - INFO - Fold 3, Epoch 230: Val Acc: 0.56%
2025-08-15 00:52:12,533 - INFO - Fold 3, Epoch 240: Val Acc: 0.72%
2025-08-15 00:52:14,495 - INFO - Fold 3, Epoch 250: Val Acc: 0.50%
2025-08-15 00:52:17,892 - INFO - Fold 3, Epoch 260: Val Acc: 0.66%
2025-08-15 00:52:19,888 - INFO - Fold 3, Epoch 270: Val Acc: 0.50%
2025-08-15 00:52:21,846 - INFO - Fold 3, Epoch 280: Val Acc: 0.69%
2025-08-15 00:52:23,680 - INFO - Fold 3, Epoch 290: Val Acc: 0.53%
2025-08-15 00:52:25,653 - INFO - Fold 3, Epoch 300: Val Acc: 0.53%
2025-08-15 00:52:27,422 - INFO - Fold 3, Epoch 310: Val Acc: 0.53%
2025-08-15 00:52:29,136 - INFO - Fold 3, Epoch 320: Val Acc: 0.62%
2025-08-15 00:52:31,071 - INFO - Fold 3, Epoch 330: Val Acc: 0.75%
2025-08-15 00:52:34,473 - INFO - Fold 3, Epoch 340: Val Acc: 0.50%
2025-08-15 00:52:36,789 - INFO - Fold 3, Epoch 350: Val Acc: 0.56%
2025-08-15 00:52:38,854 - INFO - Fold 3, Epoch 360: Val Acc: 0.53%
2025-08-15 00:52:40,787 - INFO - Fold 3, Epoch 370: Val Acc: 0.81%
2025-08-15 00:52:42,826 - INFO - Fold 3, Epoch 380: Val Acc: 0.66%
2025-08-15 00:52:44,846 - INFO - Fold 3, Epoch 390: Val Acc: 0.59%
2025-08-15 00:52:47,083 - INFO - Fold 3, Epoch 400: Val Acc: 0.53%
2025-08-15 00:52:49,319 - INFO - Fold 3, Epoch 410: Val Acc: 0.50%
2025-08-15 00:52:51,552 - INFO - Fold 3, Epoch 420: Val Acc: 0.69%
2025-08-15 00:52:53,779 - INFO - Fold 3, Epoch 430: Val Acc: 0.56%
2025-08-15 00:52:54,452 - INFO - Early stopping at epoch 433
2025-08-15 00:52:57,364 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.984975258509318), 'std': np.float64(0.08110243427022137)}, 'train_accuracy': {'mean': np.float64(0.7256944444444445), 'std': np.float64(0.08933805784908755)}, 'val_loss': {'mean': np.float64(4.309761206309001), 'std': np.float64(0.1852909856829392)}, 'val_accuracy': {'mean': np.float64(0.84375), 'std': np.float64(0.05103103630798288)}, 'epoch': {'mean': np.float64(196.0), 'std': np.float64(115.34296684236972)}}
[I 2025-08-15 00:52:57,376] Trial 120 finished with value: -0.84375 and parameters: {'learning_rate': 0.0004648404745013422, 'batch_size': 32, 'num_epochs': 976, 'temperature': 0.4290679087617985, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4768220631717741, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.17687507071558414, 'crop_size': 0.5758779033650161}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 120 finished with value: -0.84375 and parameters: {'learning_rate': 0.0004648404745013422, 'batch_size': 32, 'num_epochs': 976, 'temperature': 0.4290679087617985, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4768220631717741, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.17687507071558414, 'crop_size': 0.5758779033650161}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:52:57,466 - INFO - Using device: cuda
2025-08-15 00:53:07,298 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:53:07,300 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:53:07,300 - INFO - Starting training for fold 1/3
2025-08-15 00:53:14,978 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-15 00:53:17,060 - INFO - Fold 1, Epoch 20: Val Acc: 0.62%
2025-08-15 00:53:20,846 - INFO - Fold 1, Epoch 30: Val Acc: 0.56%
2025-08-15 00:53:22,484 - INFO - Fold 1, Epoch 40: Val Acc: 0.75%
2025-08-15 00:53:27,667 - INFO - Fold 1, Epoch 50: Val Acc: 0.81%
2025-08-15 00:53:29,214 - INFO - Fold 1, Epoch 60: Val Acc: 0.81%
2025-08-15 00:53:30,760 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-15 00:53:34,602 - INFO - Fold 1, Epoch 80: Val Acc: 0.78%
2025-08-15 00:53:36,724 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-15 00:53:38,577 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-15 00:53:40,225 - INFO - Fold 1, Epoch 110: Val Acc: 0.81%
2025-08-15 00:53:42,227 - INFO - Fold 1, Epoch 120: Val Acc: 0.81%
2025-08-15 00:53:44,128 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-15 00:53:45,686 - INFO - Fold 1, Epoch 140: Val Acc: 0.84%
2025-08-15 00:53:47,240 - INFO - Fold 1, Epoch 150: Val Acc: 0.72%
2025-08-15 00:53:48,796 - INFO - Fold 1, Epoch 160: Val Acc: 0.72%
2025-08-15 00:53:50,352 - INFO - Fold 1, Epoch 170: Val Acc: 0.66%
2025-08-15 00:53:51,750 - INFO - Early stopping at epoch 179
2025-08-15 00:53:55,982 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:53:55,986 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:53:55,986 - INFO - Starting training for fold 2/3
2025-08-15 00:54:01,789 - INFO - Fold 2, Epoch 10: Val Acc: 0.44%
2025-08-15 00:54:06,264 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-15 00:54:09,380 - INFO - Fold 2, Epoch 30: Val Acc: 0.78%
2025-08-15 00:54:12,677 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-15 00:54:15,926 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-15 00:54:17,986 - INFO - Fold 2, Epoch 60: Val Acc: 0.88%
2025-08-15 00:54:20,059 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-15 00:54:22,139 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-15 00:54:23,963 - INFO - Fold 2, Epoch 90: Val Acc: 0.59%
2025-08-15 00:54:26,053 - INFO - Fold 2, Epoch 100: Val Acc: 0.84%
2025-08-15 00:54:28,130 - INFO - Fold 2, Epoch 110: Val Acc: 0.62%
2025-08-15 00:54:30,192 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-15 00:54:32,186 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-15 00:54:34,235 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-15 00:54:36,091 - INFO - Early stopping at epoch 149
2025-08-15 00:54:38,641 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:54:38,644 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:54:38,644 - INFO - Starting training for fold 3/3
2025-08-15 00:54:43,225 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-15 00:54:46,480 - INFO - Fold 3, Epoch 20: Val Acc: 0.56%
2025-08-15 00:54:49,674 - INFO - Fold 3, Epoch 30: Val Acc: 0.59%
2025-08-15 00:54:51,758 - INFO - Fold 3, Epoch 40: Val Acc: 0.78%
2025-08-15 00:54:54,919 - INFO - Fold 3, Epoch 50: Val Acc: 0.66%
2025-08-15 00:54:58,183 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-15 00:55:00,279 - INFO - Fold 3, Epoch 70: Val Acc: 0.78%
2025-08-15 00:55:02,236 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-15 00:55:04,292 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-15 00:55:06,388 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-15 00:55:09,554 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-15 00:55:11,648 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-15 00:55:13,748 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-15 00:55:15,852 - INFO - Fold 3, Epoch 140: Val Acc: 0.84%
2025-08-15 00:55:19,179 - INFO - Fold 3, Epoch 150: Val Acc: 0.53%
2025-08-15 00:55:21,279 - INFO - Fold 3, Epoch 160: Val Acc: 0.66%
2025-08-15 00:55:23,380 - INFO - Fold 3, Epoch 170: Val Acc: 0.66%
2025-08-15 00:55:25,479 - INFO - Fold 3, Epoch 180: Val Acc: 0.69%
2025-08-15 00:55:28,658 - INFO - Fold 3, Epoch 190: Val Acc: 0.59%
2025-08-15 00:55:30,751 - INFO - Fold 3, Epoch 200: Val Acc: 0.62%
2025-08-15 00:55:32,854 - INFO - Fold 3, Epoch 210: Val Acc: 0.69%
2025-08-15 00:55:34,949 - INFO - Fold 3, Epoch 220: Val Acc: 0.56%
2025-08-15 00:55:36,933 - INFO - Fold 3, Epoch 230: Val Acc: 0.50%
2025-08-15 00:55:38,581 - INFO - Fold 3, Epoch 240: Val Acc: 0.69%
2025-08-15 00:55:40,296 - INFO - Fold 3, Epoch 250: Val Acc: 0.72%
2025-08-15 00:55:42,148 - INFO - Fold 3, Epoch 260: Val Acc: 0.72%
2025-08-15 00:55:43,794 - INFO - Fold 3, Epoch 270: Val Acc: 0.72%
2025-08-15 00:55:45,441 - INFO - Fold 3, Epoch 280: Val Acc: 0.50%
2025-08-15 00:55:47,282 - INFO - Early stopping at epoch 289
2025-08-15 00:55:48,122 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.925505744086372), 'std': np.float64(0.1063528409233139)}, 'train_accuracy': {'mean': np.float64(0.798611111111111), 'std': np.float64(0.01964185503295969)}, 'val_loss': {'mean': np.float64(4.181310653686523), 'std': np.float64(0.05313874602631432)}, 'val_accuracy': {'mean': np.float64(0.9270833333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(104.66666666666667), 'std': np.float64(60.18490028422596)}}
[I 2025-08-15 00:55:48,128] Trial 121 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0006428994110582725, 'batch_size': 32, 'num_epochs': 915, 'temperature': 0.4979371508662697, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3283927166207974, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1999172438285186, 'crop_size': 0.5263485464842296}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 121 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0006428994110582725, 'batch_size': 32, 'num_epochs': 915, 'temperature': 0.4979371508662697, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3283927166207974, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1999172438285186, 'crop_size': 0.5263485464842296}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:55:48,167 - INFO - Using device: cuda
2025-08-15 00:55:57,928 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:55:57,930 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:55:57,930 - INFO - Starting training for fold 1/3
2025-08-15 00:56:04,277 - INFO - Fold 1, Epoch 10: Val Acc: 0.69%
2025-08-15 00:56:07,475 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-15 00:56:11,658 - INFO - Fold 1, Epoch 30: Val Acc: 0.81%
2025-08-15 00:56:13,184 - INFO - Fold 1, Epoch 40: Val Acc: 0.81%
2025-08-15 00:56:14,827 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-15 00:56:16,455 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-15 00:56:18,067 - INFO - Fold 1, Epoch 70: Val Acc: 0.84%
2025-08-15 00:56:19,716 - INFO - Fold 1, Epoch 80: Val Acc: 0.78%
2025-08-15 00:56:21,388 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-15 00:56:22,995 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-15 00:56:24,595 - INFO - Fold 1, Epoch 110: Val Acc: 0.81%
2025-08-15 00:56:26,108 - INFO - Fold 1, Epoch 120: Val Acc: 0.66%
2025-08-15 00:56:27,367 - INFO - Early stopping at epoch 129
2025-08-15 00:56:29,580 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:56:29,582 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:56:29,583 - INFO - Starting training for fold 2/3
2025-08-15 00:56:33,502 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-15 00:56:36,244 - INFO - Fold 2, Epoch 20: Val Acc: 0.72%
2025-08-15 00:56:38,034 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-15 00:56:40,811 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-15 00:56:42,594 - INFO - Fold 2, Epoch 50: Val Acc: 0.66%
2025-08-15 00:56:45,347 - INFO - Fold 2, Epoch 60: Val Acc: 0.69%
2025-08-15 00:56:47,038 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-15 00:56:48,820 - INFO - Fold 2, Epoch 80: Val Acc: 0.72%
2025-08-15 00:56:51,540 - INFO - Fold 2, Epoch 90: Val Acc: 0.91%
2025-08-15 00:56:53,318 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-15 00:56:55,046 - INFO - Fold 2, Epoch 110: Val Acc: 0.88%
2025-08-15 00:56:56,568 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-15 00:56:58,368 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-15 00:57:00,160 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-15 00:57:01,946 - INFO - Fold 2, Epoch 150: Val Acc: 0.91%
2025-08-15 00:57:03,724 - INFO - Fold 2, Epoch 160: Val Acc: 0.78%
2025-08-15 00:57:05,520 - INFO - Fold 2, Epoch 170: Val Acc: 0.69%
2025-08-15 00:57:07,326 - INFO - Fold 2, Epoch 180: Val Acc: 0.62%
2025-08-15 00:57:07,856 - INFO - Early stopping at epoch 183
2025-08-15 00:57:09,861 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:57:09,864 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:57:09,865 - INFO - Starting training for fold 3/3
2025-08-15 00:57:16,718 - INFO - Fold 3, Epoch 10: Val Acc: 0.69%
2025-08-15 00:57:19,419 - INFO - Fold 3, Epoch 20: Val Acc: 0.72%
2025-08-15 00:57:22,130 - INFO - Fold 3, Epoch 30: Val Acc: 0.69%
2025-08-15 00:57:23,620 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-15 00:57:26,030 - INFO - Fold 3, Epoch 50: Val Acc: 0.66%
2025-08-15 00:57:27,526 - INFO - Fold 3, Epoch 60: Val Acc: 0.59%
2025-08-15 00:57:30,309 - INFO - Fold 3, Epoch 70: Val Acc: 0.78%
2025-08-15 00:57:32,171 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-15 00:57:33,805 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-15 00:57:35,586 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-15 00:57:37,443 - INFO - Fold 3, Epoch 110: Val Acc: 0.62%
2025-08-15 00:57:39,197 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-15 00:57:41,040 - INFO - Fold 3, Epoch 130: Val Acc: 0.69%
2025-08-15 00:57:42,913 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-15 00:57:44,746 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-15 00:57:46,439 - INFO - Fold 3, Epoch 160: Val Acc: 0.75%
2025-08-15 00:57:49,174 - INFO - Fold 3, Epoch 170: Val Acc: 0.75%
2025-08-15 00:57:50,984 - INFO - Fold 3, Epoch 180: Val Acc: 0.78%
2025-08-15 00:57:52,655 - INFO - Fold 3, Epoch 190: Val Acc: 0.78%
2025-08-15 00:57:54,337 - INFO - Fold 3, Epoch 200: Val Acc: 0.72%
2025-08-15 00:57:56,124 - INFO - Fold 3, Epoch 210: Val Acc: 0.59%
2025-08-15 00:57:57,820 - INFO - Fold 3, Epoch 220: Val Acc: 0.75%
2025-08-15 00:58:00,289 - INFO - Fold 3, Epoch 230: Val Acc: 0.78%
2025-08-15 00:58:02,050 - INFO - Fold 3, Epoch 240: Val Acc: 0.62%
2025-08-15 00:58:03,849 - INFO - Fold 3, Epoch 250: Val Acc: 0.81%
2025-08-15 00:58:05,628 - INFO - Fold 3, Epoch 260: Val Acc: 0.69%
2025-08-15 00:58:07,454 - INFO - Fold 3, Epoch 270: Val Acc: 0.66%
2025-08-15 00:58:09,289 - INFO - Fold 3, Epoch 280: Val Acc: 0.72%
2025-08-15 00:58:11,082 - INFO - Fold 3, Epoch 290: Val Acc: 0.72%
2025-08-15 00:58:12,872 - INFO - Fold 3, Epoch 300: Val Acc: 0.81%
2025-08-15 00:58:14,654 - INFO - Fold 3, Epoch 310: Val Acc: 0.81%
2025-08-15 00:58:16,431 - INFO - Fold 3, Epoch 320: Val Acc: 0.81%
2025-08-15 00:58:16,975 - INFO - Early stopping at epoch 323
2025-08-15 00:58:17,735 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.888713147905138), 'std': np.float64(0.15216526899084273)}, 'train_accuracy': {'mean': np.float64(0.7604166666666666), 'std': np.float64(0.07266822755714011)}, 'val_loss': {'mean': np.float64(4.167470614115397), 'std': np.float64(0.05161409372059621)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(110.66666666666667), 'std': np.float64(81.7530155746903)}}
[I 2025-08-15 00:58:17,763] Trial 122 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0008181291809587569, 'batch_size': 32, 'num_epochs': 905, 'temperature': 0.46593961038217185, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.43193846924938434, 'num_layers': 3, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1928987594037629, 'crop_size': 0.5304104706924915}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 122 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0008181291809587569, 'batch_size': 32, 'num_epochs': 905, 'temperature': 0.46593961038217185, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.43193846924938434, 'num_layers': 3, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1928987594037629, 'crop_size': 0.5304104706924915}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 00:58:17,826 - INFO - Using device: cuda
2025-08-15 00:58:27,597 - INFO - --- Starting Fold 1/3 ---
2025-08-15 00:58:27,599 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:58:27,599 - INFO - Starting training for fold 1/3
2025-08-15 00:58:36,759 - INFO - Fold 1, Epoch 10: Val Acc: 0.69%
2025-08-15 00:58:40,714 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-15 00:58:44,394 - INFO - Fold 1, Epoch 30: Val Acc: 0.75%
2025-08-15 00:58:46,471 - INFO - Fold 1, Epoch 40: Val Acc: 0.75%
2025-08-15 00:58:48,537 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-15 00:58:50,594 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-15 00:58:52,671 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-15 00:58:54,751 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-15 00:58:56,776 - INFO - Fold 1, Epoch 90: Val Acc: 0.78%
2025-08-15 00:58:58,786 - INFO - Fold 1, Epoch 100: Val Acc: 0.66%
2025-08-15 00:59:00,795 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-15 00:59:02,797 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-15 00:59:03,793 - INFO - Early stopping at epoch 125
2025-08-15 00:59:06,721 - INFO - --- Starting Fold 2/3 ---
2025-08-15 00:59:06,723 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:59:06,724 - INFO - Starting training for fold 2/3
2025-08-15 00:59:12,190 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-15 00:59:19,296 - INFO - Fold 2, Epoch 20: Val Acc: 0.72%
2025-08-15 00:59:22,470 - INFO - Fold 2, Epoch 30: Val Acc: 0.81%
2025-08-15 00:59:25,214 - INFO - Fold 2, Epoch 40: Val Acc: 0.88%
2025-08-15 00:59:27,378 - INFO - Fold 2, Epoch 50: Val Acc: 0.72%
2025-08-15 00:59:29,453 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-15 00:59:31,328 - INFO - Fold 2, Epoch 70: Val Acc: 0.81%
2025-08-15 00:59:34,716 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-15 00:59:36,792 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-15 00:59:38,874 - INFO - Fold 2, Epoch 100: Val Acc: 0.88%
2025-08-15 00:59:40,954 - INFO - Fold 2, Epoch 110: Val Acc: 0.62%
2025-08-15 00:59:43,046 - INFO - Fold 2, Epoch 120: Val Acc: 0.62%
2025-08-15 00:59:45,145 - INFO - Fold 2, Epoch 130: Val Acc: 0.81%
2025-08-15 00:59:47,241 - INFO - Fold 2, Epoch 140: Val Acc: 0.66%
2025-08-15 00:59:49,346 - INFO - Fold 2, Epoch 150: Val Acc: 0.72%
2025-08-15 00:59:51,448 - INFO - Fold 2, Epoch 160: Val Acc: 0.69%
2025-08-15 00:59:53,501 - INFO - Fold 2, Epoch 170: Val Acc: 0.75%
2025-08-15 00:59:54,970 - INFO - Early stopping at epoch 177
2025-08-15 00:59:57,489 - INFO - --- Starting Fold 3/3 ---
2025-08-15 00:59:57,492 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 00:59:57,493 - INFO - Starting training for fold 3/3
2025-08-15 01:00:04,420 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-15 01:00:07,589 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-15 01:00:11,085 - INFO - Fold 3, Epoch 30: Val Acc: 0.69%
2025-08-15 01:00:14,407 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-15 01:00:17,602 - INFO - Fold 3, Epoch 50: Val Acc: 0.75%
2025-08-15 01:00:22,350 - INFO - Fold 3, Epoch 60: Val Acc: 0.91%
2025-08-15 01:00:24,378 - INFO - Fold 3, Epoch 70: Val Acc: 0.81%
2025-08-15 01:00:26,387 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-15 01:00:28,232 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-15 01:00:30,149 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-15 01:00:31,704 - INFO - Fold 3, Epoch 110: Val Acc: 0.62%
2025-08-15 01:00:33,705 - INFO - Fold 3, Epoch 120: Val Acc: 0.69%
2025-08-15 01:00:35,712 - INFO - Fold 3, Epoch 130: Val Acc: 0.78%
2025-08-15 01:00:37,708 - INFO - Fold 3, Epoch 140: Val Acc: 0.81%
2025-08-15 01:00:39,718 - INFO - Fold 3, Epoch 150: Val Acc: 0.81%
2025-08-15 01:00:41,784 - INFO - Early stopping at epoch 160
2025-08-15 01:00:42,656 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.944420576095581), 'std': np.float64(0.08548742166514871)}, 'train_accuracy': {'mean': np.float64(0.767361111111111), 'std': np.float64(0.06874649261535881)}, 'val_loss': {'mean': np.float64(4.166874885559082), 'std': np.float64(0.05207690904847714)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(53.0), 'std': np.float64(21.64871050817269)}}
[I 2025-08-15 01:00:42,664] Trial 123 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0006402460622896098, 'batch_size': 32, 'num_epochs': 938, 'temperature': 0.4903271278526468, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.49005174940088225, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19738154934083538, 'crop_size': 0.683431515144569}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 123 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0006402460622896098, 'batch_size': 32, 'num_epochs': 938, 'temperature': 0.4903271278526468, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.49005174940088225, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19738154934083538, 'crop_size': 0.683431515144569}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:00:42,702 - INFO - Using device: cuda
2025-08-15 01:00:52,350 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:00:52,361 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:00:52,361 - INFO - Starting training for fold 1/3
2025-08-15 01:01:01,302 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-15 01:01:05,720 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-15 01:01:08,030 - INFO - Fold 1, Epoch 30: Val Acc: 0.53%
2025-08-15 01:01:10,331 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-15 01:01:14,799 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-15 01:01:17,123 - INFO - Fold 1, Epoch 60: Val Acc: 0.62%
2025-08-15 01:01:21,613 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-15 01:01:23,927 - INFO - Fold 1, Epoch 80: Val Acc: 0.75%
2025-08-15 01:01:26,217 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-15 01:01:28,537 - INFO - Fold 1, Epoch 100: Val Acc: 0.84%
2025-08-15 01:01:30,856 - INFO - Fold 1, Epoch 110: Val Acc: 0.59%
2025-08-15 01:01:33,118 - INFO - Fold 1, Epoch 120: Val Acc: 0.66%
2025-08-15 01:01:37,485 - INFO - Fold 1, Epoch 130: Val Acc: 0.81%
2025-08-15 01:01:39,703 - INFO - Fold 1, Epoch 140: Val Acc: 0.69%
2025-08-15 01:01:41,931 - INFO - Fold 1, Epoch 150: Val Acc: 0.81%
2025-08-15 01:01:44,158 - INFO - Fold 1, Epoch 160: Val Acc: 0.66%
2025-08-15 01:01:46,395 - INFO - Fold 1, Epoch 170: Val Acc: 0.72%
2025-08-15 01:01:48,637 - INFO - Fold 1, Epoch 180: Val Acc: 0.72%
2025-08-15 01:01:50,854 - INFO - Fold 1, Epoch 190: Val Acc: 0.75%
2025-08-15 01:01:53,083 - INFO - Fold 1, Epoch 200: Val Acc: 0.66%
2025-08-15 01:01:55,314 - INFO - Fold 1, Epoch 210: Val Acc: 0.75%
2025-08-15 01:01:57,534 - INFO - Fold 1, Epoch 220: Val Acc: 0.66%
2025-08-15 01:01:57,976 - INFO - Early stopping at epoch 222
2025-08-15 01:02:01,674 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:02:01,677 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:02:01,677 - INFO - Starting training for fold 2/3
2025-08-15 01:02:09,925 - INFO - Fold 2, Epoch 10: Val Acc: 0.69%
2025-08-15 01:02:13,738 - INFO - Fold 2, Epoch 20: Val Acc: 0.56%
2025-08-15 01:02:15,909 - INFO - Fold 2, Epoch 30: Val Acc: 0.56%
2025-08-15 01:02:19,610 - INFO - Fold 2, Epoch 40: Val Acc: 0.66%
2025-08-15 01:02:21,932 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-15 01:02:24,244 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-15 01:02:28,026 - INFO - Fold 2, Epoch 70: Val Acc: 0.81%
2025-08-15 01:02:31,272 - INFO - Fold 2, Epoch 80: Val Acc: 0.66%
2025-08-15 01:02:33,027 - INFO - Fold 2, Epoch 90: Val Acc: 0.84%
2025-08-15 01:02:35,266 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-15 01:02:37,479 - INFO - Fold 2, Epoch 110: Val Acc: 0.84%
2025-08-15 01:02:41,056 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-15 01:02:43,280 - INFO - Fold 2, Epoch 130: Val Acc: 0.84%
2025-08-15 01:02:45,505 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-15 01:02:47,718 - INFO - Fold 2, Epoch 150: Val Acc: 0.78%
2025-08-15 01:02:49,923 - INFO - Fold 2, Epoch 160: Val Acc: 0.66%
2025-08-15 01:02:52,146 - INFO - Fold 2, Epoch 170: Val Acc: 0.88%
2025-08-15 01:02:54,369 - INFO - Fold 2, Epoch 180: Val Acc: 0.84%
2025-08-15 01:02:56,606 - INFO - Fold 2, Epoch 190: Val Acc: 0.81%
2025-08-15 01:02:58,816 - INFO - Fold 2, Epoch 200: Val Acc: 0.75%
2025-08-15 01:03:00,779 - INFO - Fold 2, Epoch 210: Val Acc: 0.69%
2025-08-15 01:03:02,036 - INFO - Early stopping at epoch 216
2025-08-15 01:03:03,144 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:03:03,145 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:03:03,146 - INFO - Starting training for fold 3/3
2025-08-15 01:03:09,701 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-15 01:03:11,924 - INFO - Fold 3, Epoch 20: Val Acc: 0.50%
2025-08-15 01:03:17,031 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-15 01:03:20,786 - INFO - Fold 3, Epoch 40: Val Acc: 0.59%
2025-08-15 01:03:23,070 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-15 01:03:28,282 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-15 01:03:30,513 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-15 01:03:34,155 - INFO - Fold 3, Epoch 80: Val Acc: 0.91%
2025-08-15 01:03:36,467 - INFO - Fold 3, Epoch 90: Val Acc: 0.66%
2025-08-15 01:03:38,703 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-15 01:03:40,937 - INFO - Fold 3, Epoch 110: Val Acc: 0.72%
2025-08-15 01:03:43,156 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-15 01:03:45,372 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-15 01:03:47,587 - INFO - Fold 3, Epoch 140: Val Acc: 0.78%
2025-08-15 01:03:49,638 - INFO - Fold 3, Epoch 150: Val Acc: 0.66%
2025-08-15 01:03:51,652 - INFO - Fold 3, Epoch 160: Val Acc: 0.66%
2025-08-15 01:03:53,862 - INFO - Fold 3, Epoch 170: Val Acc: 0.78%
2025-08-15 01:03:55,680 - INFO - Early stopping at epoch 180
2025-08-15 01:03:56,762 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.95179729991489), 'std': np.float64(0.03922779859359218)}, 'train_accuracy': {'mean': np.float64(0.7152777777777778), 'std': np.float64(0.039283710065919325)}, 'val_loss': {'mean': np.float64(4.1445488929748535), 'std': np.float64(0.014430442715570183)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.0)}, 'epoch': {'mean': np.float64(105.0), 'std': np.float64(18.547236990991408)}}
[I 2025-08-15 01:03:56,768] Trial 124 finished with value: -0.90625 and parameters: {'learning_rate': 0.0003370295086192785, 'batch_size': 32, 'num_epochs': 920, 'temperature': 0.4351833016391332, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.461949763888207, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19999230668777743, 'crop_size': 0.5250752773332361}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 124 finished with value: -0.90625 and parameters: {'learning_rate': 0.0003370295086192785, 'batch_size': 32, 'num_epochs': 920, 'temperature': 0.4351833016391332, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.461949763888207, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19999230668777743, 'crop_size': 0.5250752773332361}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:03:56,807 - INFO - Using device: cuda
2025-08-15 01:04:06,599 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:04:06,601 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:04:06,601 - INFO - Starting training for fold 1/3
2025-08-15 01:04:14,176 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-15 01:04:19,940 - INFO - Fold 1, Epoch 20: Val Acc: 0.53%
2025-08-15 01:04:21,977 - INFO - Fold 1, Epoch 30: Val Acc: 0.56%
2025-08-15 01:04:24,071 - INFO - Fold 1, Epoch 40: Val Acc: 0.75%
2025-08-15 01:04:28,032 - INFO - Fold 1, Epoch 50: Val Acc: 0.47%
2025-08-15 01:04:30,131 - INFO - Fold 1, Epoch 60: Val Acc: 0.59%
2025-08-15 01:04:32,224 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-15 01:04:34,316 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-15 01:04:36,400 - INFO - Fold 1, Epoch 90: Val Acc: 0.66%
2025-08-15 01:04:38,499 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-15 01:04:40,576 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-15 01:04:42,648 - INFO - Fold 1, Epoch 120: Val Acc: 0.59%
2025-08-15 01:04:44,734 - INFO - Fold 1, Epoch 130: Val Acc: 0.75%
2025-08-15 01:04:46,487 - INFO - Fold 1, Epoch 140: Val Acc: 0.78%
2025-08-15 01:04:48,346 - INFO - Early stopping at epoch 149
2025-08-15 01:04:51,509 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:04:51,513 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:04:51,513 - INFO - Starting training for fold 2/3
2025-08-15 01:04:58,530 - INFO - Fold 2, Epoch 10: Val Acc: 0.75%
2025-08-15 01:05:00,634 - INFO - Fold 2, Epoch 20: Val Acc: 0.72%
2025-08-15 01:05:04,892 - INFO - Fold 2, Epoch 30: Val Acc: 0.75%
2025-08-15 01:05:06,933 - INFO - Fold 2, Epoch 40: Val Acc: 0.81%
2025-08-15 01:05:08,999 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-15 01:05:11,090 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-15 01:05:13,137 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-15 01:05:16,478 - INFO - Fold 2, Epoch 80: Val Acc: 0.72%
2025-08-15 01:05:18,405 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-15 01:05:20,421 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-15 01:05:22,437 - INFO - Fold 2, Epoch 110: Val Acc: 0.88%
2025-08-15 01:05:24,438 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-15 01:05:26,457 - INFO - Fold 2, Epoch 130: Val Acc: 0.72%
2025-08-15 01:05:28,472 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-15 01:05:30,483 - INFO - Fold 2, Epoch 150: Val Acc: 0.88%
2025-08-15 01:05:32,490 - INFO - Fold 2, Epoch 160: Val Acc: 0.75%
2025-08-15 01:05:35,683 - INFO - Fold 2, Epoch 170: Val Acc: 0.78%
2025-08-15 01:05:37,687 - INFO - Fold 2, Epoch 180: Val Acc: 0.78%
2025-08-15 01:05:39,692 - INFO - Fold 2, Epoch 190: Val Acc: 0.75%
2025-08-15 01:05:41,693 - INFO - Fold 2, Epoch 200: Val Acc: 0.75%
2025-08-15 01:05:43,696 - INFO - Fold 2, Epoch 210: Val Acc: 0.75%
2025-08-15 01:05:45,713 - INFO - Fold 2, Epoch 220: Val Acc: 0.75%
2025-08-15 01:05:47,734 - INFO - Fold 2, Epoch 230: Val Acc: 0.78%
2025-08-15 01:05:49,722 - INFO - Fold 2, Epoch 240: Val Acc: 0.78%
2025-08-15 01:05:51,695 - INFO - Fold 2, Epoch 250: Val Acc: 0.88%
2025-08-15 01:05:53,509 - INFO - Fold 2, Epoch 260: Val Acc: 0.72%
2025-08-15 01:05:55,201 - INFO - Early stopping at epoch 269
2025-08-15 01:05:57,474 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:05:57,476 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:05:57,476 - INFO - Starting training for fold 3/3
2025-08-15 01:06:04,329 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-15 01:06:06,340 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-15 01:06:09,531 - INFO - Fold 3, Epoch 30: Val Acc: 0.62%
2025-08-15 01:06:12,438 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-15 01:06:14,148 - INFO - Fold 3, Epoch 50: Val Acc: 0.59%
2025-08-15 01:06:15,963 - INFO - Fold 3, Epoch 60: Val Acc: 0.53%
2025-08-15 01:06:18,996 - INFO - Fold 3, Epoch 70: Val Acc: 0.81%
2025-08-15 01:06:22,094 - INFO - Fold 3, Epoch 80: Val Acc: 0.88%
2025-08-15 01:06:24,262 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-15 01:06:27,255 - INFO - Fold 3, Epoch 100: Val Acc: 0.56%
2025-08-15 01:06:28,982 - INFO - Fold 3, Epoch 110: Val Acc: 0.69%
2025-08-15 01:06:30,704 - INFO - Fold 3, Epoch 120: Val Acc: 0.69%
2025-08-15 01:06:32,759 - INFO - Fold 3, Epoch 130: Val Acc: 0.62%
2025-08-15 01:06:34,865 - INFO - Fold 3, Epoch 140: Val Acc: 0.62%
2025-08-15 01:06:36,968 - INFO - Fold 3, Epoch 150: Val Acc: 0.75%
2025-08-15 01:06:38,863 - INFO - Fold 3, Epoch 160: Val Acc: 0.72%
2025-08-15 01:06:40,710 - INFO - Fold 3, Epoch 170: Val Acc: 0.62%
2025-08-15 01:06:42,679 - INFO - Fold 3, Epoch 180: Val Acc: 0.75%
2025-08-15 01:06:44,577 - INFO - Fold 3, Epoch 190: Val Acc: 0.69%
2025-08-15 01:06:45,825 - INFO - Early stopping at epoch 196
2025-08-15 01:06:46,665 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.8820653756459556), 'std': np.float64(0.05549490871504854)}, 'train_accuracy': {'mean': np.float64(0.7951388888888888), 'std': np.float64(0.04019387813468829)}, 'val_loss': {'mean': np.float64(4.222346941630046), 'std': np.float64(0.017204753235742016)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.04419417382415922)}, 'epoch': {'mean': np.float64(103.66666666666667), 'std': np.float64(49.37160677510461)}}
[I 2025-08-15 01:06:46,671] Trial 125 finished with value: -0.90625 and parameters: {'learning_rate': 0.0007376722875473085, 'batch_size': 32, 'num_epochs': 890, 'temperature': 0.318087462736726, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.2591474909095048, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0199027774679347, 'crop_size': 0.5614918640264003}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 125 finished with value: -0.90625 and parameters: {'learning_rate': 0.0007376722875473085, 'batch_size': 32, 'num_epochs': 890, 'temperature': 0.318087462736726, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.2591474909095048, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0199027774679347, 'crop_size': 0.5614918640264003}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:06:46,714 - INFO - Using device: cuda
2025-08-15 01:06:56,762 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:06:56,763 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:06:56,764 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 01:07:05,834 - INFO - Fold 1, Epoch 10: Val Acc: 0.38%
2025-08-15 01:07:10,135 - INFO - Fold 1, Epoch 20: Val Acc: 0.69%
2025-08-15 01:07:12,258 - INFO - Fold 1, Epoch 30: Val Acc: 0.44%
2025-08-15 01:07:14,228 - INFO - Fold 1, Epoch 40: Val Acc: 0.56%
2025-08-15 01:07:16,230 - INFO - Fold 1, Epoch 50: Val Acc: 0.50%
2025-08-15 01:07:18,451 - INFO - Fold 1, Epoch 60: Val Acc: 0.59%
2025-08-15 01:07:20,720 - INFO - Fold 1, Epoch 70: Val Acc: 0.47%
2025-08-15 01:07:22,929 - INFO - Fold 1, Epoch 80: Val Acc: 0.56%
2025-08-15 01:07:24,921 - INFO - Fold 1, Epoch 90: Val Acc: 0.44%
2025-08-15 01:07:26,938 - INFO - Fold 1, Epoch 100: Val Acc: 0.50%
2025-08-15 01:07:28,916 - INFO - Fold 1, Epoch 110: Val Acc: 0.56%
2025-08-15 01:07:30,893 - INFO - Early stopping at epoch 120
2025-08-15 01:07:34,411 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:07:34,414 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:07:34,414 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 01:07:39,687 - INFO - Fold 2, Epoch 10: Val Acc: 0.59%
2025-08-15 01:07:43,410 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-15 01:07:45,677 - INFO - Fold 2, Epoch 30: Val Acc: 0.56%
2025-08-15 01:07:49,392 - INFO - Fold 2, Epoch 40: Val Acc: 0.53%
2025-08-15 01:07:51,447 - INFO - Fold 2, Epoch 50: Val Acc: 0.44%
2025-08-15 01:07:53,703 - INFO - Fold 2, Epoch 60: Val Acc: 0.59%
2025-08-15 01:07:55,964 - INFO - Fold 2, Epoch 70: Val Acc: 0.59%
2025-08-15 01:07:59,694 - INFO - Fold 2, Epoch 80: Val Acc: 0.50%
2025-08-15 01:08:02,055 - INFO - Fold 2, Epoch 90: Val Acc: 0.50%
2025-08-15 01:08:04,398 - INFO - Fold 2, Epoch 100: Val Acc: 0.56%
2025-08-15 01:08:06,762 - INFO - Fold 2, Epoch 110: Val Acc: 0.66%
2025-08-15 01:08:09,119 - INFO - Fold 2, Epoch 120: Val Acc: 0.38%
2025-08-15 01:08:11,461 - INFO - Fold 2, Epoch 130: Val Acc: 0.53%
2025-08-15 01:08:13,731 - INFO - Fold 2, Epoch 140: Val Acc: 0.47%
2025-08-15 01:08:15,976 - INFO - Fold 2, Epoch 150: Val Acc: 0.50%
2025-08-15 01:08:17,979 - INFO - Fold 2, Epoch 160: Val Acc: 0.44%
2025-08-15 01:08:19,831 - INFO - Fold 2, Epoch 170: Val Acc: 0.56%
2025-08-15 01:08:21,312 - INFO - Early stopping at epoch 178
2025-08-15 01:08:22,404 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:08:22,407 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:08:22,408 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 01:08:30,190 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-15 01:08:34,155 - INFO - Fold 3, Epoch 20: Val Acc: 0.47%
2025-08-15 01:08:37,995 - INFO - Fold 3, Epoch 30: Val Acc: 0.44%
2025-08-15 01:08:40,253 - INFO - Fold 3, Epoch 40: Val Acc: 0.41%
2025-08-15 01:08:42,405 - INFO - Fold 3, Epoch 50: Val Acc: 0.50%
2025-08-15 01:08:44,660 - INFO - Fold 3, Epoch 60: Val Acc: 0.56%
2025-08-15 01:08:46,922 - INFO - Fold 3, Epoch 70: Val Acc: 0.47%
2025-08-15 01:08:49,182 - INFO - Fold 3, Epoch 80: Val Acc: 0.47%
2025-08-15 01:08:51,368 - INFO - Fold 3, Epoch 90: Val Acc: 0.62%
2025-08-15 01:08:53,606 - INFO - Fold 3, Epoch 100: Val Acc: 0.44%
2025-08-15 01:08:55,860 - INFO - Fold 3, Epoch 110: Val Acc: 0.62%
2025-08-15 01:08:58,125 - INFO - Fold 3, Epoch 120: Val Acc: 0.53%
2025-08-15 01:08:59,897 - INFO - Early stopping at epoch 128
2025-08-15 01:09:03,106 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(5.298497094048394), 'std': np.float64(0.31993977888542063)}, 'train_accuracy': {'mean': np.float64(0.5868055555555557), 'std': np.float64(0.012991865926298411)}, 'val_loss': {'mean': np.float64(5.424802144368489), 'std': np.float64(0.26330390177764007)}, 'val_accuracy': {'mean': np.float64(0.6979166666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(41.0), 'std': np.float64(25.664502073226878)}}
[I 2025-08-15 01:09:03,118] Trial 126 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 0.0005500376657886048, 'batch_size': 32, 'num_epochs': 870, 'temperature': 0.05174263012201645, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4254674043464224, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18964889932886714, 'crop_size': 0.5088888562909354}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 126 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 0.0005500376657886048, 'batch_size': 32, 'num_epochs': 870, 'temperature': 0.05174263012201645, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4254674043464224, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18964889932886714, 'crop_size': 0.5088888562909354}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:09:03,202 - INFO - Using device: cuda
2025-08-15 01:09:12,855 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:09:12,857 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:09:12,857 - INFO - Starting training for fold 1/3
2025-08-15 01:09:21,893 - INFO - Fold 1, Epoch 10: Val Acc: 0.41%
2025-08-15 01:09:24,271 - INFO - Fold 1, Epoch 20: Val Acc: 0.62%
2025-08-15 01:09:31,090 - INFO - Fold 1, Epoch 30: Val Acc: 0.53%
2025-08-15 01:09:33,331 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-15 01:09:35,547 - INFO - Fold 1, Epoch 50: Val Acc: 0.69%
2025-08-15 01:09:39,954 - INFO - Fold 1, Epoch 60: Val Acc: 0.62%
2025-08-15 01:09:42,175 - INFO - Fold 1, Epoch 70: Val Acc: 0.62%
2025-08-15 01:09:44,393 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-15 01:09:46,686 - INFO - Fold 1, Epoch 90: Val Acc: 0.50%
2025-08-15 01:09:48,981 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-15 01:09:51,097 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-15 01:09:52,995 - INFO - Fold 1, Epoch 120: Val Acc: 0.81%
2025-08-15 01:09:54,699 - INFO - Fold 1, Epoch 130: Val Acc: 0.72%
2025-08-15 01:10:01,628 - INFO - Fold 1, Epoch 140: Val Acc: 0.84%
2025-08-15 01:10:03,910 - INFO - Fold 1, Epoch 150: Val Acc: 0.50%
2025-08-15 01:10:06,206 - INFO - Fold 1, Epoch 160: Val Acc: 0.62%
2025-08-15 01:10:08,532 - INFO - Fold 1, Epoch 170: Val Acc: 0.66%
2025-08-15 01:10:10,849 - INFO - Fold 1, Epoch 180: Val Acc: 0.69%
2025-08-15 01:10:13,169 - INFO - Fold 1, Epoch 190: Val Acc: 0.72%
2025-08-15 01:10:15,477 - INFO - Fold 1, Epoch 200: Val Acc: 0.62%
2025-08-15 01:10:17,775 - INFO - Fold 1, Epoch 210: Val Acc: 0.62%
2025-08-15 01:10:20,073 - INFO - Fold 1, Epoch 220: Val Acc: 0.69%
2025-08-15 01:10:22,307 - INFO - Fold 1, Epoch 230: Val Acc: 0.75%
2025-08-15 01:10:23,192 - INFO - Early stopping at epoch 234
2025-08-15 01:10:26,825 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:10:26,828 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:10:26,828 - INFO - Starting training for fold 2/3
2025-08-15 01:10:33,372 - INFO - Fold 2, Epoch 10: Val Acc: 0.78%
2025-08-15 01:10:35,626 - INFO - Fold 2, Epoch 20: Val Acc: 0.47%
2025-08-15 01:10:37,843 - INFO - Fold 2, Epoch 30: Val Acc: 0.66%
2025-08-15 01:10:41,511 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-15 01:10:43,728 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-15 01:10:45,935 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-15 01:10:48,148 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-15 01:10:51,726 - INFO - Fold 2, Epoch 80: Val Acc: 0.81%
2025-08-15 01:10:53,948 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-15 01:10:57,529 - INFO - Fold 2, Epoch 100: Val Acc: 0.69%
2025-08-15 01:10:59,742 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-15 01:11:01,953 - INFO - Fold 2, Epoch 120: Val Acc: 0.84%
2025-08-15 01:11:03,993 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-15 01:11:06,223 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-15 01:11:08,453 - INFO - Fold 2, Epoch 150: Val Acc: 0.84%
2025-08-15 01:11:10,669 - INFO - Fold 2, Epoch 160: Val Acc: 0.75%
2025-08-15 01:11:12,896 - INFO - Fold 2, Epoch 170: Val Acc: 0.66%
2025-08-15 01:11:15,113 - INFO - Fold 2, Epoch 180: Val Acc: 0.84%
2025-08-15 01:11:16,827 - INFO - Fold 2, Epoch 190: Val Acc: 0.66%
2025-08-15 01:11:17,339 - INFO - Early stopping at epoch 193
2025-08-15 01:11:18,429 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:11:18,431 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:11:18,431 - INFO - Starting training for fold 3/3
2025-08-15 01:11:26,230 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-15 01:11:28,455 - INFO - Fold 3, Epoch 20: Val Acc: 0.72%
2025-08-15 01:11:31,841 - INFO - Fold 3, Epoch 30: Val Acc: 0.62%
2025-08-15 01:11:33,545 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-15 01:11:35,427 - INFO - Fold 3, Epoch 50: Val Acc: 0.75%
2025-08-15 01:11:39,074 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-15 01:11:41,297 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-15 01:11:44,927 - INFO - Fold 3, Epoch 80: Val Acc: 0.62%
2025-08-15 01:11:47,146 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-15 01:11:49,357 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-15 01:11:51,533 - INFO - Fold 3, Epoch 110: Val Acc: 0.81%
2025-08-15 01:11:53,386 - INFO - Fold 3, Epoch 120: Val Acc: 0.84%
2025-08-15 01:11:55,592 - INFO - Fold 3, Epoch 130: Val Acc: 0.59%
2025-08-15 01:11:57,801 - INFO - Fold 3, Epoch 140: Val Acc: 0.84%
2025-08-15 01:12:01,397 - INFO - Fold 3, Epoch 150: Val Acc: 0.75%
2025-08-15 01:12:03,209 - INFO - Fold 3, Epoch 160: Val Acc: 0.78%
2025-08-15 01:12:05,231 - INFO - Fold 3, Epoch 170: Val Acc: 0.59%
2025-08-15 01:12:07,512 - INFO - Fold 3, Epoch 180: Val Acc: 0.56%
2025-08-15 01:12:09,574 - INFO - Fold 3, Epoch 190: Val Acc: 0.66%
2025-08-15 01:12:11,359 - INFO - Fold 3, Epoch 200: Val Acc: 0.69%
2025-08-15 01:12:13,126 - INFO - Fold 3, Epoch 210: Val Acc: 0.75%
2025-08-15 01:12:15,049 - INFO - Fold 3, Epoch 220: Val Acc: 0.75%
2025-08-15 01:12:16,974 - INFO - Fold 3, Epoch 230: Val Acc: 0.69%
2025-08-15 01:12:18,734 - INFO - Fold 3, Epoch 240: Val Acc: 0.72%
2025-08-15 01:12:19,397 - INFO - Early stopping at epoch 243
2025-08-15 01:12:22,455 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.8966544469197593), 'std': np.float64(0.06734378561540162)}, 'train_accuracy': {'mean': np.float64(0.7638888888888888), 'std': np.float64(0.021404215288086736)}, 'val_loss': {'mean': np.float64(4.236373583475749), 'std': np.float64(0.07084130008332803)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(122.33333333333333), 'std': np.float64(21.761331658599286)}}
[I 2025-08-15 01:12:22,466] Trial 127 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0004897046849596265, 'batch_size': 32, 'num_epochs': 972, 'temperature': 0.30363409224916843, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4462896288389396, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0739165929140758, 'crop_size': 0.5447586541238473}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 127 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0004897046849596265, 'batch_size': 32, 'num_epochs': 972, 'temperature': 0.30363409224916843, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4462896288389396, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0739165929140758, 'crop_size': 0.5447586541238473}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:12:22,554 - INFO - Using device: cuda
2025-08-15 01:12:32,002 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:12:32,003 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:12:32,004 - INFO - Starting training for fold 1/3
2025-08-15 01:12:39,835 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-15 01:12:41,628 - INFO - Fold 1, Epoch 20: Val Acc: 0.66%
2025-08-15 01:12:43,483 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-15 01:12:47,362 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-15 01:12:49,364 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-15 01:12:51,097 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-15 01:12:52,682 - INFO - Fold 1, Epoch 70: Val Acc: 0.75%
2025-08-15 01:12:54,665 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-15 01:12:56,671 - INFO - Fold 1, Epoch 90: Val Acc: 0.81%
2025-08-15 01:12:58,668 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-15 01:13:00,670 - INFO - Fold 1, Epoch 110: Val Acc: 0.72%
2025-08-15 01:13:02,687 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-15 01:13:04,526 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-15 01:13:05,923 - INFO - Early stopping at epoch 138
2025-08-15 01:13:08,785 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:13:08,805 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:13:08,806 - INFO - Starting training for fold 2/3
2025-08-15 01:13:15,674 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 01:13:19,970 - INFO - Fold 2, Epoch 20: Val Acc: 0.69%
2025-08-15 01:13:23,066 - INFO - Fold 2, Epoch 30: Val Acc: 0.78%
2025-08-15 01:13:24,968 - INFO - Fold 2, Epoch 40: Val Acc: 0.78%
2025-08-15 01:13:26,797 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-15 01:13:28,593 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-15 01:13:30,188 - INFO - Fold 2, Epoch 70: Val Acc: 0.84%
2025-08-15 01:13:31,745 - INFO - Fold 2, Epoch 80: Val Acc: 0.66%
2025-08-15 01:13:33,300 - INFO - Fold 2, Epoch 90: Val Acc: 0.88%
2025-08-15 01:13:34,907 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-15 01:13:36,912 - INFO - Fold 2, Epoch 110: Val Acc: 0.88%
2025-08-15 01:13:38,691 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-15 01:13:40,019 - INFO - Early stopping at epoch 127
2025-08-15 01:13:42,535 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:13:42,539 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:13:42,539 - INFO - Starting training for fold 3/3
2025-08-15 01:13:47,930 - INFO - Fold 3, Epoch 10: Val Acc: 0.72%
2025-08-15 01:13:51,271 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-15 01:13:54,456 - INFO - Fold 3, Epoch 30: Val Acc: 0.78%
2025-08-15 01:13:57,849 - INFO - Fold 3, Epoch 40: Val Acc: 0.62%
2025-08-15 01:13:59,927 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-15 01:14:02,010 - INFO - Fold 3, Epoch 60: Val Acc: 0.66%
2025-08-15 01:14:05,342 - INFO - Fold 3, Epoch 70: Val Acc: 0.62%
2025-08-15 01:14:07,349 - INFO - Fold 3, Epoch 80: Val Acc: 0.84%
2025-08-15 01:14:09,350 - INFO - Fold 3, Epoch 90: Val Acc: 0.62%
2025-08-15 01:14:11,246 - INFO - Fold 3, Epoch 100: Val Acc: 0.62%
2025-08-15 01:14:13,147 - INFO - Fold 3, Epoch 110: Val Acc: 0.84%
2025-08-15 01:14:14,983 - INFO - Fold 3, Epoch 120: Val Acc: 0.53%
2025-08-15 01:14:16,832 - INFO - Fold 3, Epoch 130: Val Acc: 0.75%
2025-08-15 01:14:18,622 - INFO - Fold 3, Epoch 140: Val Acc: 0.66%
2025-08-15 01:14:20,571 - INFO - Fold 3, Epoch 150: Val Acc: 0.88%
2025-08-15 01:14:23,599 - INFO - Fold 3, Epoch 160: Val Acc: 0.69%
2025-08-15 01:14:25,651 - INFO - Fold 3, Epoch 170: Val Acc: 0.47%
2025-08-15 01:14:27,758 - INFO - Fold 3, Epoch 180: Val Acc: 0.69%
2025-08-15 01:14:29,858 - INFO - Fold 3, Epoch 190: Val Acc: 0.72%
2025-08-15 01:14:31,946 - INFO - Fold 3, Epoch 200: Val Acc: 0.62%
2025-08-15 01:14:34,043 - INFO - Fold 3, Epoch 210: Val Acc: 0.69%
2025-08-15 01:14:36,040 - INFO - Fold 3, Epoch 220: Val Acc: 0.69%
2025-08-15 01:14:38,027 - INFO - Fold 3, Epoch 230: Val Acc: 0.66%
2025-08-15 01:14:40,118 - INFO - Fold 3, Epoch 240: Val Acc: 0.78%
2025-08-15 01:14:43,427 - INFO - Fold 3, Epoch 250: Val Acc: 0.56%
2025-08-15 01:14:45,516 - INFO - Fold 3, Epoch 260: Val Acc: 0.94%
2025-08-15 01:14:47,386 - INFO - Fold 3, Epoch 270: Val Acc: 0.72%
2025-08-15 01:14:49,036 - INFO - Fold 3, Epoch 280: Val Acc: 0.59%
2025-08-15 01:14:50,684 - INFO - Fold 3, Epoch 290: Val Acc: 0.62%
2025-08-15 01:14:52,344 - INFO - Fold 3, Epoch 300: Val Acc: 0.78%
2025-08-15 01:14:54,125 - INFO - Fold 3, Epoch 310: Val Acc: 0.69%
2025-08-15 01:14:56,170 - INFO - Fold 3, Epoch 320: Val Acc: 0.62%
2025-08-15 01:14:58,248 - INFO - Fold 3, Epoch 330: Val Acc: 0.62%
2025-08-15 01:15:00,275 - INFO - Fold 3, Epoch 340: Val Acc: 0.62%
2025-08-15 01:15:00,679 - INFO - Early stopping at epoch 342
2025-08-15 01:15:03,113 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9182776610056567), 'std': np.float64(0.1428053506366097)}, 'train_accuracy': {'mean': np.float64(0.767361111111111), 'std': np.float64(0.11326046132152834)}, 'val_loss': {'mean': np.float64(4.198487599690755), 'std': np.float64(0.036530485659295016)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(101.33333333333333), 'std': np.float64(98.86129452700666)}}
[I 2025-08-15 01:15:03,123] Trial 128 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0006742102240323934, 'batch_size': 32, 'num_epochs': 820, 'temperature': 0.3378501700966191, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4841007090228964, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.05787783872910459, 'crop_size': 0.5347191764504639}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 128 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0006742102240323934, 'batch_size': 32, 'num_epochs': 820, 'temperature': 0.3378501700966191, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4841007090228964, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.05787783872910459, 'crop_size': 0.5347191764504639}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:15:03,212 - INFO - Using device: cuda
2025-08-15 01:15:13,123 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:15:13,124 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:15:13,125 - INFO - Starting training for fold 1/3
2025-08-15 01:15:28,793 - INFO - Fold 1, Epoch 10: Val Acc: 0.54%
2025-08-15 01:15:31,931 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-15 01:15:41,710 - INFO - Fold 1, Epoch 30: Val Acc: 0.69%
2025-08-15 01:15:47,120 - INFO - Fold 1, Epoch 40: Val Acc: 0.65%
2025-08-15 01:15:53,071 - INFO - Fold 1, Epoch 50: Val Acc: 0.77%
2025-08-15 01:15:59,213 - INFO - Fold 1, Epoch 60: Val Acc: 0.79%
2025-08-15 01:16:03,200 - INFO - Fold 1, Epoch 70: Val Acc: 0.60%
2025-08-15 01:16:07,144 - INFO - Fold 1, Epoch 80: Val Acc: 0.71%
2025-08-15 01:16:10,827 - INFO - Fold 1, Epoch 90: Val Acc: 0.73%
2025-08-15 01:16:16,651 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-15 01:16:20,243 - INFO - Fold 1, Epoch 110: Val Acc: 0.79%
2025-08-15 01:16:25,738 - INFO - Fold 1, Epoch 120: Val Acc: 0.67%
2025-08-15 01:16:29,433 - INFO - Fold 1, Epoch 130: Val Acc: 0.58%
2025-08-15 01:16:33,257 - INFO - Fold 1, Epoch 140: Val Acc: 0.83%
2025-08-15 01:16:37,036 - INFO - Fold 1, Epoch 150: Val Acc: 0.56%
2025-08-15 01:16:40,831 - INFO - Fold 1, Epoch 160: Val Acc: 0.62%
2025-08-15 01:16:44,627 - INFO - Fold 1, Epoch 170: Val Acc: 0.73%
2025-08-15 01:16:48,434 - INFO - Fold 1, Epoch 180: Val Acc: 0.71%
2025-08-15 01:16:52,252 - INFO - Fold 1, Epoch 190: Val Acc: 0.69%
2025-08-15 01:16:56,052 - INFO - Fold 1, Epoch 200: Val Acc: 0.77%
2025-08-15 01:16:59,689 - INFO - Fold 1, Epoch 210: Val Acc: 0.85%
2025-08-15 01:17:00,024 - INFO - Early stopping at epoch 211
2025-08-15 01:17:03,454 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:17:03,457 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:17:03,457 - INFO - Starting training for fold 2/3
2025-08-15 01:17:13,991 - INFO - Fold 2, Epoch 10: Val Acc: 0.65%
2025-08-15 01:17:18,744 - INFO - Fold 2, Epoch 20: Val Acc: 0.60%
2025-08-15 01:17:24,802 - INFO - Fold 2, Epoch 30: Val Acc: 0.83%
2025-08-15 01:17:28,156 - INFO - Fold 2, Epoch 40: Val Acc: 0.71%
2025-08-15 01:17:31,347 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-15 01:17:36,206 - INFO - Fold 2, Epoch 60: Val Acc: 0.79%
2025-08-15 01:17:40,967 - INFO - Fold 2, Epoch 70: Val Acc: 0.79%
2025-08-15 01:17:44,806 - INFO - Fold 2, Epoch 80: Val Acc: 0.79%
2025-08-15 01:17:48,288 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-15 01:17:51,503 - INFO - Fold 2, Epoch 100: Val Acc: 0.79%
2025-08-15 01:17:54,784 - INFO - Fold 2, Epoch 110: Val Acc: 0.83%
2025-08-15 01:17:58,721 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-15 01:18:04,058 - INFO - Fold 2, Epoch 130: Val Acc: 0.73%
2025-08-15 01:18:06,805 - INFO - Fold 2, Epoch 140: Val Acc: 0.73%
2025-08-15 01:18:10,147 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-15 01:18:13,289 - INFO - Fold 2, Epoch 160: Val Acc: 0.81%
2025-08-15 01:18:17,092 - INFO - Fold 2, Epoch 170: Val Acc: 0.69%
2025-08-15 01:18:20,906 - INFO - Fold 2, Epoch 180: Val Acc: 0.79%
2025-08-15 01:18:26,210 - INFO - Fold 2, Epoch 190: Val Acc: 0.90%
2025-08-15 01:18:30,944 - INFO - Fold 2, Epoch 200: Val Acc: 0.75%
2025-08-15 01:18:33,918 - INFO - Fold 2, Epoch 210: Val Acc: 0.81%
2025-08-15 01:18:36,906 - INFO - Fold 2, Epoch 220: Val Acc: 0.79%
2025-08-15 01:18:40,086 - INFO - Fold 2, Epoch 230: Val Acc: 0.75%
2025-08-15 01:18:43,139 - INFO - Fold 2, Epoch 240: Val Acc: 0.83%
2025-08-15 01:18:46,211 - INFO - Fold 2, Epoch 250: Val Acc: 0.69%
2025-08-15 01:18:49,608 - INFO - Fold 2, Epoch 260: Val Acc: 0.69%
2025-08-15 01:18:52,806 - INFO - Fold 2, Epoch 270: Val Acc: 0.69%
2025-08-15 01:18:56,358 - INFO - Fold 2, Epoch 280: Val Acc: 0.81%
2025-08-15 01:19:00,157 - INFO - Fold 2, Epoch 290: Val Acc: 0.67%
2025-08-15 01:19:02,790 - INFO - Early stopping at epoch 297
2025-08-15 01:19:05,735 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:19:05,738 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:19:05,738 - INFO - Starting training for fold 3/3
2025-08-15 01:19:12,440 - INFO - Fold 3, Epoch 10: Val Acc: 0.65%
2025-08-15 01:19:19,162 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-15 01:19:27,467 - INFO - Fold 3, Epoch 30: Val Acc: 0.77%
2025-08-15 01:19:32,731 - INFO - Fold 3, Epoch 40: Val Acc: 0.73%
2025-08-15 01:19:37,986 - INFO - Fold 3, Epoch 50: Val Acc: 0.79%
2025-08-15 01:19:41,772 - INFO - Fold 3, Epoch 60: Val Acc: 0.73%
2025-08-15 01:19:45,579 - INFO - Fold 3, Epoch 70: Val Acc: 0.81%
2025-08-15 01:19:53,490 - INFO - Fold 3, Epoch 80: Val Acc: 0.71%
2025-08-15 01:19:57,286 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-15 01:20:00,198 - INFO - Fold 3, Epoch 100: Val Acc: 0.77%
2025-08-15 01:20:03,163 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-15 01:20:05,931 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-15 01:20:09,219 - INFO - Fold 3, Epoch 130: Val Acc: 0.65%
2025-08-15 01:20:12,688 - INFO - Fold 3, Epoch 140: Val Acc: 0.69%
2025-08-15 01:20:15,585 - INFO - Fold 3, Epoch 150: Val Acc: 0.83%
2025-08-15 01:20:19,554 - INFO - Fold 3, Epoch 160: Val Acc: 0.69%
2025-08-15 01:20:23,549 - INFO - Fold 3, Epoch 170: Val Acc: 0.62%
2025-08-15 01:20:26,893 - INFO - Early stopping at epoch 179
2025-08-15 01:20:27,967 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.1745612091488304), 'std': np.float64(0.0843625353245884)}, 'train_accuracy': {'mean': np.float64(0.7430555555555557), 'std': np.float64(0.03540985773328324)}, 'val_loss': {'mean': np.float64(3.5303927792443166), 'std': np.float64(0.048408487356838066)}, 'val_accuracy': {'mean': np.float64(0.888888888888889), 'std': np.float64(0.03540985773328321)}, 'epoch': {'mean': np.float64(128.0), 'std': np.float64(49.82636517614612)}}
[I 2025-08-15 01:20:27,974] Trial 129 finished with value: -0.888888888888889 and parameters: {'learning_rate': 0.0005966474497398405, 'batch_size': 16, 'num_epochs': 909, 'temperature': 0.49952871000888477, 'embedding_dim': 128, 'hidden_dim': 512, 'dropout': 0.4657726157252577, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1872474479463135, 'crop_size': 0.5162400020198721}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 129 finished with value: -0.888888888888889 and parameters: {'learning_rate': 0.0005966474497398405, 'batch_size': 16, 'num_epochs': 909, 'temperature': 0.49952871000888477, 'embedding_dim': 128, 'hidden_dim': 512, 'dropout': 0.4657726157252577, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1872474479463135, 'crop_size': 0.5162400020198721}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:20:28,013 - INFO - Using device: cuda
2025-08-15 01:20:37,853 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:20:37,854 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:20:37,854 - WARNING - Fold 1 has insufficient pairs to form a batch. Skipping.
2025-08-15 01:20:37,854 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:20:37,855 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:20:37,856 - WARNING - Fold 2 has insufficient pairs to form a batch. Skipping.
2025-08-15 01:20:37,856 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:20:37,857 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:20:37,857 - WARNING - Fold 3 has insufficient pairs to form a batch. Skipping.
2025-08-15 01:20:37,857 - WARNING - No folds completed successfully to aggregate metrics.
[I 2025-08-15 01:20:37,859] Trial 130 finished with value: inf and parameters: {'learning_rate': 0.0008152948746862971, 'batch_size': 64, 'num_epochs': 367, 'temperature': 0.39150369269124263, 'embedding_dim': 256, 'hidden_dim': 128, 'dropout': 0.4535921079700911, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.11299333695876547, 'crop_size': 0.5527829399801636}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 130 finished with value: inf and parameters: {'learning_rate': 0.0008152948746862971, 'batch_size': 64, 'num_epochs': 367, 'temperature': 0.39150369269124263, 'embedding_dim': 256, 'hidden_dim': 128, 'dropout': 0.4535921079700911, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.11299333695876547, 'crop_size': 0.5527829399801636}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:20:37,899 - INFO - Using device: cuda
2025-08-15 01:20:47,691 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:20:47,692 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:20:47,692 - INFO - Starting training for fold 1/3
2025-08-15 01:20:56,826 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-15 01:21:00,387 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-15 01:21:02,402 - INFO - Fold 1, Epoch 30: Val Acc: 0.59%
2025-08-15 01:21:06,309 - INFO - Fold 1, Epoch 40: Val Acc: 0.50%
2025-08-15 01:21:08,312 - INFO - Fold 1, Epoch 50: Val Acc: 0.81%
2025-08-15 01:21:12,998 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-15 01:21:14,543 - INFO - Fold 1, Epoch 70: Val Acc: 0.59%
2025-08-15 01:21:16,095 - INFO - Fold 1, Epoch 80: Val Acc: 0.62%
2025-08-15 01:21:19,479 - INFO - Fold 1, Epoch 90: Val Acc: 0.66%
2025-08-15 01:21:21,281 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-15 01:21:23,280 - INFO - Fold 1, Epoch 110: Val Acc: 0.78%
2025-08-15 01:21:25,114 - INFO - Fold 1, Epoch 120: Val Acc: 0.66%
2025-08-15 01:21:27,117 - INFO - Fold 1, Epoch 130: Val Acc: 0.75%
2025-08-15 01:21:29,117 - INFO - Fold 1, Epoch 140: Val Acc: 0.66%
2025-08-15 01:21:31,131 - INFO - Fold 1, Epoch 150: Val Acc: 0.62%
2025-08-15 01:21:32,952 - INFO - Fold 1, Epoch 160: Val Acc: 0.66%
2025-08-15 01:21:34,507 - INFO - Fold 1, Epoch 170: Val Acc: 0.59%
2025-08-15 01:21:36,063 - INFO - Fold 1, Epoch 180: Val Acc: 0.72%
2025-08-15 01:21:37,152 - INFO - Early stopping at epoch 187
2025-08-15 01:21:40,085 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:21:40,088 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:21:40,089 - INFO - Starting training for fold 2/3
2025-08-15 01:21:45,680 - INFO - Fold 2, Epoch 10: Val Acc: 0.53%
2025-08-15 01:21:47,553 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-15 01:21:50,830 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-15 01:21:54,018 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-15 01:21:57,046 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-15 01:21:58,924 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-15 01:22:02,110 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-15 01:22:04,200 - INFO - Fold 2, Epoch 80: Val Acc: 0.78%
2025-08-15 01:22:06,281 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-15 01:22:08,369 - INFO - Fold 2, Epoch 100: Val Acc: 0.88%
2025-08-15 01:22:10,459 - INFO - Fold 2, Epoch 110: Val Acc: 0.84%
2025-08-15 01:22:12,509 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-15 01:22:14,511 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-15 01:22:16,521 - INFO - Fold 2, Epoch 140: Val Acc: 0.81%
2025-08-15 01:22:18,302 - INFO - Fold 2, Epoch 150: Val Acc: 0.72%
2025-08-15 01:22:19,843 - INFO - Fold 2, Epoch 160: Val Acc: 0.84%
2025-08-15 01:22:20,307 - INFO - Early stopping at epoch 163
2025-08-15 01:22:21,142 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:22:21,144 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:22:21,144 - INFO - Starting training for fold 3/3
2025-08-15 01:22:28,023 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-15 01:22:29,969 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-15 01:22:33,030 - INFO - Fold 3, Epoch 30: Val Acc: 0.53%
2025-08-15 01:22:36,340 - INFO - Fold 3, Epoch 40: Val Acc: 0.72%
2025-08-15 01:22:39,576 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-15 01:22:41,533 - INFO - Fold 3, Epoch 60: Val Acc: 0.72%
2025-08-15 01:22:43,542 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-15 01:22:45,459 - INFO - Fold 3, Epoch 80: Val Acc: 0.78%
2025-08-15 01:22:47,384 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-15 01:22:49,272 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-15 01:22:52,464 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-15 01:22:54,315 - INFO - Fold 3, Epoch 120: Val Acc: 0.62%
2025-08-15 01:22:56,150 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-15 01:22:57,981 - INFO - Fold 3, Epoch 140: Val Acc: 0.88%
2025-08-15 01:22:59,803 - INFO - Fold 3, Epoch 150: Val Acc: 0.53%
2025-08-15 01:23:01,632 - INFO - Fold 3, Epoch 160: Val Acc: 0.62%
2025-08-15 01:23:03,480 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-15 01:23:05,178 - INFO - Fold 3, Epoch 180: Val Acc: 0.59%
2025-08-15 01:23:06,999 - INFO - Fold 3, Epoch 190: Val Acc: 0.72%
2025-08-15 01:23:08,651 - INFO - Fold 3, Epoch 200: Val Acc: 0.75%
2025-08-15 01:23:09,641 - INFO - Early stopping at epoch 206
2025-08-15 01:23:10,756 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9542445076836485), 'std': np.float64(0.07255566179300627)}, 'train_accuracy': {'mean': np.float64(0.767361111111111), 'std': np.float64(0.025983731852596764)}, 'val_loss': {'mean': np.float64(4.159587542215983), 'std': np.float64(0.06835731501795096)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.0)}, 'epoch': {'mean': np.float64(84.33333333333333), 'std': np.float64(17.594190960528863)}}
[I 2025-08-15 01:23:10,800] Trial 131 finished with value: -0.90625 and parameters: {'learning_rate': 0.0005289505531211336, 'batch_size': 32, 'num_epochs': 928, 'temperature': 0.3655994305776255, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3347852514366818, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19223381793653874, 'crop_size': 0.5425105037869024}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 131 finished with value: -0.90625 and parameters: {'learning_rate': 0.0005289505531211336, 'batch_size': 32, 'num_epochs': 928, 'temperature': 0.3655994305776255, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3347852514366818, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19223381793653874, 'crop_size': 0.5425105037869024}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:23:10,840 - INFO - Using device: cuda
2025-08-15 01:23:20,604 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:23:20,606 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:23:20,606 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 01:23:26,462 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-15 01:23:34,477 - INFO - Fold 1, Epoch 20: Val Acc: 0.75%
2025-08-15 01:23:36,583 - INFO - Fold 1, Epoch 30: Val Acc: 0.66%
2025-08-15 01:23:38,323 - INFO - Fold 1, Epoch 40: Val Acc: 0.56%
2025-08-15 01:23:40,343 - INFO - Fold 1, Epoch 50: Val Acc: 0.53%
2025-08-15 01:23:44,155 - INFO - Fold 1, Epoch 60: Val Acc: 0.66%
2025-08-15 01:23:46,234 - INFO - Fold 1, Epoch 70: Val Acc: 0.59%
2025-08-15 01:23:48,326 - INFO - Fold 1, Epoch 80: Val Acc: 0.75%
2025-08-15 01:23:52,260 - INFO - Fold 1, Epoch 90: Val Acc: 0.59%
2025-08-15 01:23:54,258 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-15 01:23:56,273 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-15 01:23:58,273 - INFO - Fold 1, Epoch 120: Val Acc: 0.84%
2025-08-15 01:24:00,278 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-15 01:24:02,278 - INFO - Fold 1, Epoch 140: Val Acc: 0.53%
2025-08-15 01:24:04,152 - INFO - Fold 1, Epoch 150: Val Acc: 0.69%
2025-08-15 01:24:08,140 - INFO - Fold 1, Epoch 160: Val Acc: 0.78%
2025-08-15 01:24:10,155 - INFO - Fold 1, Epoch 170: Val Acc: 0.62%
2025-08-15 01:24:12,164 - INFO - Fold 1, Epoch 180: Val Acc: 0.62%
2025-08-15 01:24:14,179 - INFO - Fold 1, Epoch 190: Val Acc: 0.62%
2025-08-15 01:24:16,198 - INFO - Fold 1, Epoch 200: Val Acc: 0.72%
2025-08-15 01:24:18,216 - INFO - Fold 1, Epoch 210: Val Acc: 0.56%
2025-08-15 01:24:20,229 - INFO - Fold 1, Epoch 220: Val Acc: 0.62%
2025-08-15 01:24:22,236 - INFO - Fold 1, Epoch 230: Val Acc: 0.62%
2025-08-15 01:24:24,250 - INFO - Fold 1, Epoch 240: Val Acc: 0.66%
2025-08-15 01:24:26,261 - INFO - Fold 1, Epoch 250: Val Acc: 0.75%
2025-08-15 01:24:26,662 - INFO - Early stopping at epoch 252
2025-08-15 01:24:29,672 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:24:29,674 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:24:29,675 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 01:24:36,591 - INFO - Fold 2, Epoch 10: Val Acc: 0.62%
2025-08-15 01:24:39,430 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-15 01:24:43,794 - INFO - Fold 2, Epoch 30: Val Acc: 0.62%
2025-08-15 01:24:45,794 - INFO - Fold 2, Epoch 40: Val Acc: 0.56%
2025-08-15 01:24:49,005 - INFO - Fold 2, Epoch 50: Val Acc: 0.59%
2025-08-15 01:24:51,014 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-15 01:24:54,311 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-15 01:24:56,301 - INFO - Fold 2, Epoch 80: Val Acc: 0.53%
2025-08-15 01:24:58,304 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-15 01:25:01,459 - INFO - Fold 2, Epoch 100: Val Acc: 0.69%
2025-08-15 01:25:03,028 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-15 01:25:04,588 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-15 01:25:06,147 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-15 01:25:07,704 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-15 01:25:09,267 - INFO - Fold 2, Epoch 150: Val Acc: 0.78%
2025-08-15 01:25:11,032 - INFO - Fold 2, Epoch 160: Val Acc: 0.75%
2025-08-15 01:25:13,020 - INFO - Fold 2, Epoch 170: Val Acc: 0.62%
2025-08-15 01:25:15,068 - INFO - Fold 2, Epoch 180: Val Acc: 0.75%
2025-08-15 01:25:19,066 - INFO - Fold 2, Epoch 190: Val Acc: 0.62%
2025-08-15 01:25:22,412 - INFO - Fold 2, Epoch 200: Val Acc: 0.88%
2025-08-15 01:25:24,449 - INFO - Fold 2, Epoch 210: Val Acc: 0.72%
2025-08-15 01:25:26,474 - INFO - Fold 2, Epoch 220: Val Acc: 0.81%
2025-08-15 01:25:28,491 - INFO - Fold 2, Epoch 230: Val Acc: 0.66%
2025-08-15 01:25:30,541 - INFO - Fold 2, Epoch 240: Val Acc: 0.75%
2025-08-15 01:25:32,620 - INFO - Fold 2, Epoch 250: Val Acc: 0.78%
2025-08-15 01:25:34,646 - INFO - Fold 2, Epoch 260: Val Acc: 0.78%
2025-08-15 01:25:36,600 - INFO - Fold 2, Epoch 270: Val Acc: 0.72%
2025-08-15 01:25:38,396 - INFO - Fold 2, Epoch 280: Val Acc: 0.81%
2025-08-15 01:25:40,158 - INFO - Fold 2, Epoch 290: Val Acc: 0.75%
2025-08-15 01:25:40,342 - INFO - Early stopping at epoch 291
2025-08-15 01:25:42,864 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:25:42,868 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:25:42,868 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 01:25:47,221 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-15 01:25:49,280 - INFO - Fold 3, Epoch 20: Val Acc: 0.44%
2025-08-15 01:25:51,321 - INFO - Fold 3, Epoch 30: Val Acc: 0.62%
2025-08-15 01:25:53,278 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-15 01:25:55,188 - INFO - Fold 3, Epoch 50: Val Acc: 0.62%
2025-08-15 01:25:58,186 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-15 01:26:00,077 - INFO - Fold 3, Epoch 70: Val Acc: 0.59%
2025-08-15 01:26:01,988 - INFO - Fold 3, Epoch 80: Val Acc: 0.53%
2025-08-15 01:26:03,959 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-15 01:26:07,035 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-15 01:26:10,178 - INFO - Fold 3, Epoch 110: Val Acc: 0.88%
2025-08-15 01:26:12,184 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-15 01:26:14,154 - INFO - Fold 3, Epoch 130: Val Acc: 0.78%
2025-08-15 01:26:15,946 - INFO - Fold 3, Epoch 140: Val Acc: 0.69%
2025-08-15 01:26:17,955 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-15 01:26:19,973 - INFO - Fold 3, Epoch 160: Val Acc: 0.62%
2025-08-15 01:26:21,979 - INFO - Fold 3, Epoch 170: Val Acc: 0.78%
2025-08-15 01:26:23,994 - INFO - Fold 3, Epoch 180: Val Acc: 0.78%
2025-08-15 01:26:25,999 - INFO - Fold 3, Epoch 190: Val Acc: 0.84%
2025-08-15 01:26:28,012 - INFO - Fold 3, Epoch 200: Val Acc: 0.78%
2025-08-15 01:26:28,414 - INFO - Early stopping at epoch 202
2025-08-15 01:26:29,263 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.8971979353162975), 'std': np.float64(0.0508259332752398)}, 'train_accuracy': {'mean': np.float64(0.7361111111111112), 'std': np.float64(0.051967463705193624)}, 'val_loss': {'mean': np.float64(4.465436935424805), 'std': np.float64(0.15043791207194057)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(147.33333333333334), 'std': np.float64(36.42648609032841)}}
[I 2025-08-15 01:26:29,272] Trial 132 finished with value: -0.90625 and parameters: {'learning_rate': 0.00044566795102919015, 'batch_size': 32, 'num_epochs': 864, 'temperature': 0.10136234078904373, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.31477510192923164, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19564549794422284, 'crop_size': 0.5240065366608276}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 132 finished with value: -0.90625 and parameters: {'learning_rate': 0.00044566795102919015, 'batch_size': 32, 'num_epochs': 864, 'temperature': 0.10136234078904373, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.31477510192923164, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19564549794422284, 'crop_size': 0.5240065366608276}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:26:29,312 - INFO - Using device: cuda
2025-08-15 01:26:38,903 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:26:38,904 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:26:38,905 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 01:26:46,592 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-15 01:26:48,599 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-15 01:26:50,493 - INFO - Fold 1, Epoch 30: Val Acc: 0.59%
2025-08-15 01:26:52,033 - INFO - Fold 1, Epoch 40: Val Acc: 0.56%
2025-08-15 01:26:55,559 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-15 01:26:57,442 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-15 01:26:59,267 - INFO - Fold 1, Epoch 70: Val Acc: 0.44%
2025-08-15 01:27:01,041 - INFO - Fold 1, Epoch 80: Val Acc: 0.59%
2025-08-15 01:27:04,568 - INFO - Fold 1, Epoch 90: Val Acc: 0.53%
2025-08-15 01:27:06,500 - INFO - Fold 1, Epoch 100: Val Acc: 0.62%
2025-08-15 01:27:08,267 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-15 01:27:10,147 - INFO - Fold 1, Epoch 120: Val Acc: 0.53%
2025-08-15 01:27:11,883 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-15 01:27:13,648 - INFO - Fold 1, Epoch 140: Val Acc: 0.69%
2025-08-15 01:27:15,461 - INFO - Fold 1, Epoch 150: Val Acc: 0.50%
2025-08-15 01:27:17,272 - INFO - Fold 1, Epoch 160: Val Acc: 0.59%
2025-08-15 01:27:18,999 - INFO - Fold 1, Epoch 170: Val Acc: 0.56%
2025-08-15 01:27:20,542 - INFO - Fold 1, Epoch 180: Val Acc: 0.53%
2025-08-15 01:27:21,456 - INFO - Early stopping at epoch 185
2025-08-15 01:27:24,546 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:27:24,548 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:27:24,549 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 01:27:32,771 - INFO - Fold 2, Epoch 10: Val Acc: 0.69%
2025-08-15 01:27:36,048 - INFO - Fold 2, Epoch 20: Val Acc: 0.75%
2025-08-15 01:27:39,298 - INFO - Fold 2, Epoch 30: Val Acc: 0.81%
2025-08-15 01:27:42,475 - INFO - Fold 2, Epoch 40: Val Acc: 0.66%
2025-08-15 01:27:44,569 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-15 01:27:46,662 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-15 01:27:48,750 - INFO - Fold 2, Epoch 70: Val Acc: 0.84%
2025-08-15 01:27:51,984 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-15 01:27:53,818 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-15 01:27:55,498 - INFO - Fold 2, Epoch 100: Val Acc: 0.88%
2025-08-15 01:27:57,508 - INFO - Fold 2, Epoch 110: Val Acc: 0.84%
2025-08-15 01:27:59,514 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-15 01:28:01,528 - INFO - Fold 2, Epoch 130: Val Acc: 0.72%
2025-08-15 01:28:03,542 - INFO - Fold 2, Epoch 140: Val Acc: 0.62%
2025-08-15 01:28:05,555 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-15 01:28:07,566 - INFO - Fold 2, Epoch 160: Val Acc: 0.69%
2025-08-15 01:28:09,575 - INFO - Fold 2, Epoch 170: Val Acc: 0.78%
2025-08-15 01:28:10,784 - INFO - Early stopping at epoch 176
2025-08-15 01:28:15,882 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:28:15,884 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:28:15,884 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 01:28:23,126 - INFO - Fold 3, Epoch 10: Val Acc: 0.66%
2025-08-15 01:28:26,362 - INFO - Fold 3, Epoch 20: Val Acc: 0.50%
2025-08-15 01:28:28,365 - INFO - Fold 3, Epoch 30: Val Acc: 0.75%
2025-08-15 01:28:30,395 - INFO - Fold 3, Epoch 40: Val Acc: 0.81%
2025-08-15 01:28:32,506 - INFO - Fold 3, Epoch 50: Val Acc: 0.75%
2025-08-15 01:28:34,538 - INFO - Fold 3, Epoch 60: Val Acc: 0.81%
2025-08-15 01:28:36,531 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-15 01:28:38,541 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-15 01:28:40,562 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-15 01:28:42,388 - INFO - Fold 3, Epoch 100: Val Acc: 0.78%
2025-08-15 01:28:43,945 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-15 01:28:45,346 - INFO - Early stopping at epoch 119
2025-08-15 01:28:46,175 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.8994486596849227), 'std': np.float64(0.23332527589016666)}, 'train_accuracy': {'mean': np.float64(0.8055555555555555), 'std': np.float64(0.1063430057716219)}, 'val_loss': {'mean': np.float64(4.535791556040446), 'std': np.float64(0.0679443762737094)}, 'val_accuracy': {'mean': np.float64(0.8541666666666666), 'std': np.float64(0.07795119555779044)}, 'epoch': {'mean': np.float64(59.0), 'std': np.float64(29.223278392404914)}}
[I 2025-08-15 01:28:46,181] Trial 133 finished with value: -0.8541666666666666 and parameters: {'learning_rate': 0.000670385373838823, 'batch_size': 32, 'num_epochs': 800, 'temperature': 0.11342914864439596, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.32315303137998885, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19691504807165378, 'crop_size': 0.822882858792596}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 133 finished with value: -0.8541666666666666 and parameters: {'learning_rate': 0.000670385373838823, 'batch_size': 32, 'num_epochs': 800, 'temperature': 0.11342914864439596, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.32315303137998885, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19691504807165378, 'crop_size': 0.822882858792596}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:28:46,220 - INFO - Using device: cuda
2025-08-15 01:28:56,248 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:28:56,249 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:28:56,250 - INFO - Starting training for fold 1/3
2025-08-15 01:29:03,749 - INFO - Fold 1, Epoch 10: Val Acc: 0.34%
2025-08-15 01:29:05,746 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-15 01:29:09,465 - INFO - Fold 1, Epoch 30: Val Acc: 0.81%
2025-08-15 01:29:11,568 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-15 01:29:15,463 - INFO - Fold 1, Epoch 50: Val Acc: 0.69%
2025-08-15 01:29:17,475 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-15 01:29:19,488 - INFO - Fold 1, Epoch 70: Val Acc: 0.75%
2025-08-15 01:29:21,484 - INFO - Fold 1, Epoch 80: Val Acc: 0.69%
2025-08-15 01:29:23,230 - INFO - Fold 1, Epoch 90: Val Acc: 0.59%
2025-08-15 01:29:24,795 - INFO - Fold 1, Epoch 100: Val Acc: 0.84%
2025-08-15 01:29:26,360 - INFO - Fold 1, Epoch 110: Val Acc: 0.72%
2025-08-15 01:29:27,915 - INFO - Fold 1, Epoch 120: Val Acc: 0.72%
2025-08-15 01:29:29,471 - INFO - Fold 1, Epoch 130: Val Acc: 0.56%
2025-08-15 01:29:31,399 - INFO - Fold 1, Epoch 140: Val Acc: 0.75%
2025-08-15 01:29:32,592 - INFO - Early stopping at epoch 146
2025-08-15 01:29:35,546 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:29:35,549 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:29:35,550 - INFO - Starting training for fold 2/3
2025-08-15 01:29:39,822 - INFO - Fold 2, Epoch 10: Val Acc: 0.59%
2025-08-15 01:29:45,101 - INFO - Fold 2, Epoch 20: Val Acc: 0.56%
2025-08-15 01:29:48,314 - INFO - Fold 2, Epoch 30: Val Acc: 0.75%
2025-08-15 01:29:52,716 - INFO - Fold 2, Epoch 40: Val Acc: 0.78%
2025-08-15 01:29:54,725 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-15 01:29:56,658 - INFO - Fold 2, Epoch 60: Val Acc: 0.69%
2025-08-15 01:29:58,437 - INFO - Fold 2, Epoch 70: Val Acc: 0.66%
2025-08-15 01:30:00,457 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-15 01:30:03,597 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-15 01:30:05,599 - INFO - Fold 2, Epoch 100: Val Acc: 0.81%
2025-08-15 01:30:07,604 - INFO - Fold 2, Epoch 110: Val Acc: 0.81%
2025-08-15 01:30:10,669 - INFO - Fold 2, Epoch 120: Val Acc: 0.62%
2025-08-15 01:30:12,591 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-15 01:30:15,739 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-15 01:30:17,523 - INFO - Fold 2, Epoch 150: Val Acc: 0.78%
2025-08-15 01:30:19,487 - INFO - Fold 2, Epoch 160: Val Acc: 0.81%
2025-08-15 01:30:21,498 - INFO - Fold 2, Epoch 170: Val Acc: 0.75%
2025-08-15 01:30:23,511 - INFO - Fold 2, Epoch 180: Val Acc: 0.78%
2025-08-15 01:30:25,525 - INFO - Fold 2, Epoch 190: Val Acc: 0.62%
2025-08-15 01:30:27,528 - INFO - Fold 2, Epoch 200: Val Acc: 0.78%
2025-08-15 01:30:29,578 - INFO - Fold 2, Epoch 210: Val Acc: 0.59%
2025-08-15 01:30:31,670 - INFO - Fold 2, Epoch 220: Val Acc: 0.81%
2025-08-15 01:30:33,765 - INFO - Fold 2, Epoch 230: Val Acc: 0.69%
2025-08-15 01:30:35,432 - INFO - Early stopping at epoch 238
2025-08-15 01:30:38,043 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:30:38,045 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:30:38,045 - INFO - Starting training for fold 3/3
2025-08-15 01:30:45,258 - INFO - Fold 3, Epoch 10: Val Acc: 0.47%
2025-08-15 01:30:49,827 - INFO - Fold 3, Epoch 20: Val Acc: 0.75%
2025-08-15 01:30:51,929 - INFO - Fold 3, Epoch 30: Val Acc: 0.78%
2025-08-15 01:30:56,395 - INFO - Fold 3, Epoch 40: Val Acc: 0.78%
2025-08-15 01:30:58,254 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-15 01:31:00,188 - INFO - Fold 3, Epoch 60: Val Acc: 0.66%
2025-08-15 01:31:03,597 - INFO - Fold 3, Epoch 70: Val Acc: 0.62%
2025-08-15 01:31:05,684 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-15 01:31:07,754 - INFO - Fold 3, Epoch 90: Val Acc: 0.78%
2025-08-15 01:31:09,762 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-15 01:31:11,588 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-15 01:31:13,144 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-15 01:31:14,888 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-15 01:31:16,639 - INFO - Fold 3, Epoch 140: Val Acc: 0.66%
2025-08-15 01:31:18,198 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-15 01:31:19,752 - INFO - Fold 3, Epoch 160: Val Acc: 0.66%
2025-08-15 01:31:20,372 - INFO - Early stopping at epoch 164
2025-08-15 01:31:21,225 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9489711920420327), 'std': np.float64(0.014853120090925294)}, 'train_accuracy': {'mean': np.float64(0.7395833333333334), 'std': np.float64(0.06133167268283228)}, 'val_loss': {'mean': np.float64(4.261619408925374), 'std': np.float64(0.07433515773340815)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(81.66666666666667), 'std': np.float64(39.81066300488964)}}
[I 2025-08-15 01:31:21,231] Trial 134 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0006129871141073852, 'batch_size': 32, 'num_epochs': 846, 'temperature': 0.4404415715680731, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3691649289181529, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.14368716995609482, 'crop_size': 0.5653023176277074}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 134 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0006129871141073852, 'batch_size': 32, 'num_epochs': 846, 'temperature': 0.4404415715680731, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3691649289181529, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.14368716995609482, 'crop_size': 0.5653023176277074}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:31:21,269 - INFO - Using device: cuda
2025-08-15 01:31:31,121 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:31:31,123 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:31:31,123 - INFO - Starting training for fold 1/3
2025-08-15 01:31:39,872 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-15 01:31:44,271 - INFO - Fold 1, Epoch 20: Val Acc: 0.66%
2025-08-15 01:31:50,423 - INFO - Fold 1, Epoch 30: Val Acc: 0.72%
2025-08-15 01:31:54,823 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-15 01:31:56,955 - INFO - Fold 1, Epoch 50: Val Acc: 0.81%
2025-08-15 01:31:59,082 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-15 01:32:01,206 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-15 01:32:03,328 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-15 01:32:05,446 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-15 01:32:07,580 - INFO - Fold 1, Epoch 100: Val Acc: 0.56%
2025-08-15 01:32:09,428 - INFO - Fold 1, Epoch 110: Val Acc: 0.75%
2025-08-15 01:32:11,317 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-15 01:32:13,148 - INFO - Fold 1, Epoch 130: Val Acc: 0.75%
2025-08-15 01:32:13,677 - INFO - Early stopping at epoch 133
2025-08-15 01:32:17,358 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:32:17,361 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:32:17,361 - INFO - Starting training for fold 2/3
2025-08-15 01:32:22,326 - INFO - Fold 2, Epoch 10: Val Acc: 0.59%
2025-08-15 01:32:27,181 - INFO - Fold 2, Epoch 20: Val Acc: 0.81%
2025-08-15 01:32:29,283 - INFO - Fold 2, Epoch 30: Val Acc: 0.66%
2025-08-15 01:32:32,696 - INFO - Fold 2, Epoch 40: Val Acc: 0.81%
2025-08-15 01:32:34,823 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-15 01:32:38,389 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-15 01:32:40,176 - INFO - Fold 2, Epoch 70: Val Acc: 0.84%
2025-08-15 01:32:42,225 - INFO - Fold 2, Epoch 80: Val Acc: 0.84%
2025-08-15 01:32:45,758 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-15 01:32:47,952 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-15 01:32:50,009 - INFO - Fold 2, Epoch 110: Val Acc: 0.53%
2025-08-15 01:32:51,866 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-15 01:32:53,711 - INFO - Fold 2, Epoch 130: Val Acc: 0.72%
2025-08-15 01:32:55,521 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-15 01:32:57,344 - INFO - Fold 2, Epoch 150: Val Acc: 0.78%
2025-08-15 01:32:59,190 - INFO - Fold 2, Epoch 160: Val Acc: 0.75%
2025-08-15 01:33:01,043 - INFO - Fold 2, Epoch 170: Val Acc: 0.69%
2025-08-15 01:33:03,100 - INFO - Fold 2, Epoch 180: Val Acc: 0.84%
2025-08-15 01:33:04,383 - INFO - Early stopping at epoch 186
2025-08-15 01:33:07,441 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:33:07,444 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:33:07,444 - INFO - Starting training for fold 3/3
2025-08-15 01:33:11,240 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-15 01:33:16,173 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-15 01:33:19,587 - INFO - Fold 3, Epoch 30: Val Acc: 0.72%
2025-08-15 01:33:21,706 - INFO - Fold 3, Epoch 40: Val Acc: 0.78%
2025-08-15 01:33:25,333 - INFO - Fold 3, Epoch 50: Val Acc: 0.84%
2025-08-15 01:33:27,447 - INFO - Fold 3, Epoch 60: Val Acc: 0.81%
2025-08-15 01:33:29,384 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-15 01:33:31,185 - INFO - Fold 3, Epoch 80: Val Acc: 0.84%
2025-08-15 01:33:33,015 - INFO - Fold 3, Epoch 90: Val Acc: 0.59%
2025-08-15 01:33:36,275 - INFO - Fold 3, Epoch 100: Val Acc: 0.78%
2025-08-15 01:33:38,103 - INFO - Fold 3, Epoch 110: Val Acc: 0.69%
2025-08-15 01:33:40,065 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-15 01:33:42,174 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-15 01:33:44,285 - INFO - Fold 3, Epoch 140: Val Acc: 0.59%
2025-08-15 01:33:46,392 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-15 01:33:48,169 - INFO - Fold 3, Epoch 160: Val Acc: 0.69%
2025-08-15 01:33:50,120 - INFO - Fold 3, Epoch 170: Val Acc: 0.78%
2025-08-15 01:33:52,235 - INFO - Fold 3, Epoch 180: Val Acc: 0.75%
2025-08-15 01:33:54,354 - INFO - Fold 3, Epoch 190: Val Acc: 0.66%
2025-08-15 01:33:54,568 - INFO - Early stopping at epoch 191
2025-08-15 01:33:55,655 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.955666409598456), 'std': np.float64(0.05461069653370657)}, 'train_accuracy': {'mean': np.float64(0.7361111111111112), 'std': np.float64(0.04280843057617347)}, 'val_loss': {'mean': np.float64(4.205753008524577), 'std': np.float64(0.05073944996775464)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(69.0), 'std': np.float64(26.242459234352765)}}
[I 2025-08-15 01:33:55,661] Trial 135 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0007205489375118475, 'batch_size': 32, 'num_epochs': 575, 'temperature': 0.4158075358299181, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.30165192498548865, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.5529575610489514}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 135 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0007205489375118475, 'batch_size': 32, 'num_epochs': 575, 'temperature': 0.4158075358299181, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.30165192498548865, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.5529575610489514}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:33:55,701 - INFO - Using device: cuda
2025-08-15 01:34:05,269 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:34:05,274 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:34:05,274 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 01:34:11,564 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-15 01:34:15,980 - INFO - Fold 1, Epoch 20: Val Acc: 0.62%
2025-08-15 01:34:17,385 - INFO - Fold 1, Epoch 30: Val Acc: 0.75%
2025-08-15 01:34:18,815 - INFO - Fold 1, Epoch 40: Val Acc: 0.47%
2025-08-15 01:34:20,367 - INFO - Fold 1, Epoch 50: Val Acc: 0.56%
2025-08-15 01:34:23,521 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-15 01:34:25,405 - INFO - Fold 1, Epoch 70: Val Acc: 0.75%
2025-08-15 01:34:27,201 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-15 01:34:28,998 - INFO - Fold 1, Epoch 90: Val Acc: 0.66%
2025-08-15 01:34:30,795 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-15 01:34:32,585 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-15 01:34:35,806 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-15 01:34:37,580 - INFO - Fold 1, Epoch 130: Val Acc: 0.59%
2025-08-15 01:34:39,364 - INFO - Fold 1, Epoch 140: Val Acc: 0.78%
2025-08-15 01:34:42,549 - INFO - Fold 1, Epoch 150: Val Acc: 0.72%
2025-08-15 01:34:44,328 - INFO - Fold 1, Epoch 160: Val Acc: 0.84%
2025-08-15 01:34:46,111 - INFO - Fold 1, Epoch 170: Val Acc: 0.62%
2025-08-15 01:34:47,909 - INFO - Fold 1, Epoch 180: Val Acc: 0.78%
2025-08-15 01:34:49,688 - INFO - Fold 1, Epoch 190: Val Acc: 0.66%
2025-08-15 01:34:51,480 - INFO - Fold 1, Epoch 200: Val Acc: 0.66%
2025-08-15 01:34:52,878 - INFO - Fold 1, Epoch 210: Val Acc: 0.81%
2025-08-15 01:34:54,536 - INFO - Fold 1, Epoch 220: Val Acc: 0.75%
2025-08-15 01:34:56,329 - INFO - Fold 1, Epoch 230: Val Acc: 0.53%
2025-08-15 01:34:58,110 - INFO - Fold 1, Epoch 240: Val Acc: 0.72%
2025-08-15 01:34:58,464 - INFO - Early stopping at epoch 242
2025-08-15 01:35:00,673 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:35:00,676 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:35:00,676 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 01:35:06,632 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-15 01:35:08,952 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-15 01:35:10,353 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-15 01:35:11,752 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-15 01:35:15,272 - INFO - Fold 2, Epoch 50: Val Acc: 0.66%
2025-08-15 01:35:17,070 - INFO - Fold 2, Epoch 60: Val Acc: 0.69%
2025-08-15 01:35:18,846 - INFO - Fold 2, Epoch 70: Val Acc: 0.53%
2025-08-15 01:35:20,620 - INFO - Fold 2, Epoch 80: Val Acc: 0.81%
2025-08-15 01:35:22,404 - INFO - Fold 2, Epoch 90: Val Acc: 0.88%
2025-08-15 01:35:24,194 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-15 01:35:25,984 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-15 01:35:27,776 - INFO - Fold 2, Epoch 120: Val Acc: 0.88%
2025-08-15 01:35:29,578 - INFO - Fold 2, Epoch 130: Val Acc: 0.66%
2025-08-15 01:35:31,371 - INFO - Fold 2, Epoch 140: Val Acc: 0.81%
2025-08-15 01:35:32,446 - INFO - Early stopping at epoch 146
2025-08-15 01:35:34,346 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:35:34,349 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:35:34,350 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 01:35:39,173 - INFO - Fold 3, Epoch 10: Val Acc: 0.47%
2025-08-15 01:35:41,879 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-15 01:35:43,672 - INFO - Fold 3, Epoch 30: Val Acc: 0.62%
2025-08-15 01:35:47,379 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-15 01:35:50,084 - INFO - Fold 3, Epoch 50: Val Acc: 0.81%
2025-08-15 01:35:51,701 - INFO - Fold 3, Epoch 60: Val Acc: 0.72%
2025-08-15 01:35:53,324 - INFO - Fold 3, Epoch 70: Val Acc: 0.56%
2025-08-15 01:35:54,948 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-15 01:35:56,593 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-15 01:35:58,316 - INFO - Fold 3, Epoch 100: Val Acc: 0.62%
2025-08-15 01:36:00,168 - INFO - Fold 3, Epoch 110: Val Acc: 0.72%
2025-08-15 01:36:02,021 - INFO - Fold 3, Epoch 120: Val Acc: 0.56%
2025-08-15 01:36:03,867 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-15 01:36:05,722 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-15 01:36:05,904 - INFO - Early stopping at epoch 141
2025-08-15 01:36:06,575 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.105007542504205), 'std': np.float64(0.22351700288945356)}, 'train_accuracy': {'mean': np.float64(0.7465277777777778), 'std': np.float64(0.08172640483291543)}, 'val_loss': {'mean': np.float64(4.730796655019124), 'std': np.float64(0.10426396740925994)}, 'val_accuracy': {'mean': np.float64(0.8645833333333334), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(75.33333333333333), 'std': np.float64(46.4781908234628)}}
[I 2025-08-15 01:36:06,581] Trial 136 finished with value: -0.8645833333333334 and parameters: {'learning_rate': 0.0009310858777658721, 'batch_size': 32, 'num_epochs': 893, 'temperature': 0.0664867407393159, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.440798603590381, 'num_layers': 3, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1089055212590034, 'crop_size': 0.536294062525757}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 136 finished with value: -0.8645833333333334 and parameters: {'learning_rate': 0.0009310858777658721, 'batch_size': 32, 'num_epochs': 893, 'temperature': 0.0664867407393159, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.440798603590381, 'num_layers': 3, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1089055212590034, 'crop_size': 0.536294062525757}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:36:06,621 - INFO - Using device: cuda
2025-08-15 01:36:16,270 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:36:16,272 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:36:16,272 - INFO - Starting training for fold 1/3
2025-08-15 01:36:23,152 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-15 01:36:25,377 - INFO - Fold 1, Epoch 20: Val Acc: 0.53%
2025-08-15 01:36:27,691 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-15 01:36:32,171 - INFO - Fold 1, Epoch 40: Val Acc: 0.50%
2025-08-15 01:36:34,203 - INFO - Fold 1, Epoch 50: Val Acc: 0.44%
2025-08-15 01:36:36,409 - INFO - Fold 1, Epoch 60: Val Acc: 0.53%
2025-08-15 01:36:38,265 - INFO - Fold 1, Epoch 70: Val Acc: 0.53%
2025-08-15 01:36:40,561 - INFO - Fold 1, Epoch 80: Val Acc: 0.56%
2025-08-15 01:36:42,342 - INFO - Fold 1, Epoch 90: Val Acc: 0.50%
2025-08-15 01:36:44,122 - INFO - Fold 1, Epoch 100: Val Acc: 0.53%
2025-08-15 01:36:46,328 - INFO - Fold 1, Epoch 110: Val Acc: 0.44%
2025-08-15 01:36:48,609 - INFO - Fold 1, Epoch 120: Val Acc: 0.47%
2025-08-15 01:36:50,909 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-15 01:36:52,077 - INFO - Early stopping at epoch 135
2025-08-15 01:36:55,604 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:36:55,610 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:36:55,611 - INFO - Starting training for fold 2/3
2025-08-15 01:37:02,643 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-15 01:37:05,029 - INFO - Fold 2, Epoch 20: Val Acc: 0.47%
2025-08-15 01:37:08,721 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-15 01:37:11,144 - INFO - Fold 2, Epoch 40: Val Acc: 0.47%
2025-08-15 01:37:13,492 - INFO - Fold 2, Epoch 50: Val Acc: 0.56%
2025-08-15 01:37:15,690 - INFO - Fold 2, Epoch 60: Val Acc: 0.47%
2025-08-15 01:37:17,487 - INFO - Fold 2, Epoch 70: Val Acc: 0.53%
2025-08-15 01:37:19,690 - INFO - Fold 2, Epoch 80: Val Acc: 0.50%
2025-08-15 01:37:21,968 - INFO - Fold 2, Epoch 90: Val Acc: 0.47%
2025-08-15 01:37:23,770 - INFO - Fold 2, Epoch 100: Val Acc: 0.50%
2025-08-15 01:37:25,560 - INFO - Fold 2, Epoch 110: Val Acc: 0.41%
2025-08-15 01:37:27,878 - INFO - Fold 2, Epoch 120: Val Acc: 0.59%
2025-08-15 01:37:30,277 - INFO - Early stopping at epoch 130
2025-08-15 01:37:31,342 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:37:31,344 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:37:31,344 - INFO - Starting training for fold 3/3
2025-08-15 01:37:36,809 - INFO - Fold 3, Epoch 10: Val Acc: 0.47%
2025-08-15 01:37:40,528 - INFO - Fold 3, Epoch 20: Val Acc: 0.41%
2025-08-15 01:37:42,745 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-15 01:37:46,369 - INFO - Fold 3, Epoch 40: Val Acc: 0.56%
2025-08-15 01:37:48,666 - INFO - Fold 3, Epoch 50: Val Acc: 0.50%
2025-08-15 01:37:50,962 - INFO - Fold 3, Epoch 60: Val Acc: 0.47%
2025-08-15 01:37:53,266 - INFO - Fold 3, Epoch 70: Val Acc: 0.50%
2025-08-15 01:37:55,585 - INFO - Fold 3, Epoch 80: Val Acc: 0.47%
2025-08-15 01:37:57,888 - INFO - Fold 3, Epoch 90: Val Acc: 0.53%
2025-08-15 01:37:59,892 - INFO - Fold 3, Epoch 100: Val Acc: 0.53%
2025-08-15 01:38:01,677 - INFO - Fold 3, Epoch 110: Val Acc: 0.53%
2025-08-15 01:38:03,669 - INFO - Fold 3, Epoch 120: Val Acc: 0.53%
2025-08-15 01:38:05,979 - INFO - Fold 3, Epoch 130: Val Acc: 0.53%
2025-08-15 01:38:07,129 - INFO - Early stopping at epoch 135
2025-08-15 01:38:10,003 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.167109383477105), 'std': np.float64(0.03357238454788451)}, 'train_accuracy': {'mean': np.float64(0.5694444444444445), 'std': np.float64(0.04019387813468828)}, 'val_loss': {'mean': np.float64(4.242953777313232), 'std': np.float64(0.05824635404285674)}, 'val_accuracy': {'mean': np.float64(0.6979166666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(32.333333333333336), 'std': np.float64(2.357022603955158)}}
[I 2025-08-15 01:38:10,014] Trial 137 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 0.000509088946587762, 'batch_size': 32, 'num_epochs': 953, 'temperature': 0.1940916879656321, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.338755419908997, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.18266919922395514, 'crop_size': 0.5271548519138151}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 137 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 0.000509088946587762, 'batch_size': 32, 'num_epochs': 953, 'temperature': 0.1940916879656321, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.338755419908997, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.18266919922395514, 'crop_size': 0.5271548519138151}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:38:10,097 - INFO - Using device: cuda
2025-08-15 01:38:19,897 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:38:19,899 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:38:19,899 - INFO - Starting training for fold 1/3
2025-08-15 01:38:35,560 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-15 01:38:37,720 - INFO - Fold 1, Epoch 20: Val Acc: 0.66%
2025-08-15 01:38:39,886 - INFO - Fold 1, Epoch 30: Val Acc: 0.69%
2025-08-15 01:38:41,926 - INFO - Fold 1, Epoch 40: Val Acc: 0.53%
2025-08-15 01:38:44,076 - INFO - Fold 1, Epoch 50: Val Acc: 0.56%
2025-08-15 01:38:46,252 - INFO - Fold 1, Epoch 60: Val Acc: 0.56%
2025-08-15 01:38:48,423 - INFO - Fold 1, Epoch 70: Val Acc: 0.56%
2025-08-15 01:38:50,591 - INFO - Fold 1, Epoch 80: Val Acc: 0.47%
2025-08-15 01:38:52,663 - INFO - Fold 1, Epoch 90: Val Acc: 0.53%
2025-08-15 01:38:54,537 - INFO - Fold 1, Epoch 100: Val Acc: 0.53%
2025-08-15 01:38:56,071 - INFO - Early stopping at epoch 108
2025-08-15 01:38:59,576 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:38:59,578 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:38:59,578 - INFO - Starting training for fold 2/3
2025-08-15 01:39:07,304 - INFO - Fold 2, Epoch 10: Val Acc: 0.84%
2025-08-15 01:39:11,911 - INFO - Fold 2, Epoch 20: Val Acc: 0.84%
2025-08-15 01:39:13,813 - INFO - Fold 2, Epoch 30: Val Acc: 0.81%
2025-08-15 01:39:15,698 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-15 01:39:17,587 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-15 01:39:19,441 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-15 01:39:21,324 - INFO - Fold 2, Epoch 70: Val Acc: 0.66%
2025-08-15 01:39:23,164 - INFO - Fold 2, Epoch 80: Val Acc: 0.78%
2025-08-15 01:39:25,039 - INFO - Fold 2, Epoch 90: Val Acc: 0.62%
2025-08-15 01:39:26,967 - INFO - Fold 2, Epoch 100: Val Acc: 0.62%
2025-08-15 01:39:28,832 - INFO - Fold 2, Epoch 110: Val Acc: 0.66%
2025-08-15 01:39:29,220 - INFO - Early stopping at epoch 112
2025-08-15 01:39:32,261 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:39:32,263 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:39:32,263 - INFO - Starting training for fold 3/3
2025-08-15 01:39:42,941 - INFO - Fold 3, Epoch 10: Val Acc: 0.94%
2025-08-15 01:39:44,897 - INFO - Fold 3, Epoch 20: Val Acc: 0.78%
2025-08-15 01:39:46,642 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-15 01:39:48,369 - INFO - Fold 3, Epoch 40: Val Acc: 0.69%
2025-08-15 01:39:50,273 - INFO - Fold 3, Epoch 50: Val Acc: 0.53%
2025-08-15 01:39:52,316 - INFO - Fold 3, Epoch 60: Val Acc: 0.72%
2025-08-15 01:39:54,482 - INFO - Fold 3, Epoch 70: Val Acc: 0.56%
2025-08-15 01:39:56,632 - INFO - Fold 3, Epoch 80: Val Acc: 0.59%
2025-08-15 01:39:58,775 - INFO - Fold 3, Epoch 90: Val Acc: 0.56%
2025-08-15 01:40:00,941 - INFO - Fold 3, Epoch 100: Val Acc: 0.50%
2025-08-15 01:40:03,112 - INFO - Early stopping at epoch 110
2025-08-15 01:40:04,164 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.913060559166802), 'std': np.float64(0.012635708048221518)}, 'train_accuracy': {'mean': np.float64(0.8263888888888888), 'std': np.float64(0.017704928866641653)}, 'val_loss': {'mean': np.float64(4.168187777201335), 'std': np.float64(0.06089849789654235)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.09660019266141358)}, 'epoch': {'mean': np.float64(9.0), 'std': np.float64(1.632993161855452)}}
[I 2025-08-15 01:40:04,173] Trial 138 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0005627036063860685, 'batch_size': 32, 'num_epochs': 305, 'temperature': 0.4730496838519295, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.2761827842448481, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07989603672784315}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 138 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0005627036063860685, 'batch_size': 32, 'num_epochs': 305, 'temperature': 0.4730496838519295, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.2761827842448481, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07989603672784315}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:40:04,213 - INFO - Using device: cuda
2025-08-15 01:40:14,116 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:40:14,123 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:40:14,123 - INFO - Starting training for fold 1/3
2025-08-15 01:40:22,025 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-15 01:40:29,419 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-15 01:40:31,424 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-15 01:40:33,425 - INFO - Fold 1, Epoch 40: Val Acc: 0.62%
2025-08-15 01:40:37,064 - INFO - Fold 1, Epoch 50: Val Acc: 0.78%
2025-08-15 01:40:39,139 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-15 01:40:42,973 - INFO - Fold 1, Epoch 70: Val Acc: 0.59%
2025-08-15 01:40:44,969 - INFO - Fold 1, Epoch 80: Val Acc: 0.75%
2025-08-15 01:40:48,880 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-15 01:40:50,495 - INFO - Fold 1, Epoch 100: Val Acc: 0.81%
2025-08-15 01:40:52,291 - INFO - Fold 1, Epoch 110: Val Acc: 0.75%
2025-08-15 01:40:53,907 - INFO - Fold 1, Epoch 120: Val Acc: 0.78%
2025-08-15 01:40:55,448 - INFO - Fold 1, Epoch 130: Val Acc: 0.81%
2025-08-15 01:40:56,990 - INFO - Fold 1, Epoch 140: Val Acc: 0.66%
2025-08-15 01:40:58,531 - INFO - Fold 1, Epoch 150: Val Acc: 0.75%
2025-08-15 01:41:00,415 - INFO - Fold 1, Epoch 160: Val Acc: 0.78%
2025-08-15 01:41:02,418 - INFO - Fold 1, Epoch 170: Val Acc: 0.66%
2025-08-15 01:41:04,425 - INFO - Fold 1, Epoch 180: Val Acc: 0.62%
2025-08-15 01:41:05,823 - INFO - Early stopping at epoch 187
2025-08-15 01:41:08,771 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:41:08,785 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:41:08,785 - INFO - Starting training for fold 2/3
2025-08-15 01:41:13,076 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 01:41:16,499 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-15 01:41:18,224 - INFO - Fold 2, Epoch 30: Val Acc: 0.56%
2025-08-15 01:41:21,188 - INFO - Fold 2, Epoch 40: Val Acc: 0.66%
2025-08-15 01:41:22,852 - INFO - Fold 2, Epoch 50: Val Acc: 0.56%
2025-08-15 01:41:24,408 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-15 01:41:25,967 - INFO - Fold 2, Epoch 70: Val Acc: 0.69%
2025-08-15 01:41:27,535 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-15 01:41:29,091 - INFO - Fold 2, Epoch 90: Val Acc: 0.59%
2025-08-15 01:41:32,101 - INFO - Fold 2, Epoch 100: Val Acc: 0.62%
2025-08-15 01:41:34,115 - INFO - Fold 2, Epoch 110: Val Acc: 0.66%
2025-08-15 01:41:38,553 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-15 01:41:41,724 - INFO - Fold 2, Epoch 130: Val Acc: 0.72%
2025-08-15 01:41:43,724 - INFO - Fold 2, Epoch 140: Val Acc: 0.62%
2025-08-15 01:41:45,727 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-15 01:41:47,568 - INFO - Fold 2, Epoch 160: Val Acc: 0.56%
2025-08-15 01:41:49,352 - INFO - Fold 2, Epoch 170: Val Acc: 0.69%
2025-08-15 01:41:51,333 - INFO - Fold 2, Epoch 180: Val Acc: 0.81%
2025-08-15 01:41:53,344 - INFO - Fold 2, Epoch 190: Val Acc: 0.81%
2025-08-15 01:41:55,221 - INFO - Fold 2, Epoch 200: Val Acc: 0.69%
2025-08-15 01:41:56,953 - INFO - Fold 2, Epoch 210: Val Acc: 0.75%
2025-08-15 01:41:58,767 - INFO - Fold 2, Epoch 220: Val Acc: 0.72%
2025-08-15 01:42:00,576 - INFO - Early stopping at epoch 229
2025-08-15 01:42:01,415 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:42:01,417 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:42:01,417 - INFO - Starting training for fold 3/3
2025-08-15 01:42:07,179 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-15 01:42:10,377 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-15 01:42:12,143 - INFO - Fold 3, Epoch 30: Val Acc: 0.53%
2025-08-15 01:42:14,097 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-15 01:42:16,154 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-15 01:42:18,090 - INFO - Fold 3, Epoch 60: Val Acc: 0.62%
2025-08-15 01:42:21,223 - INFO - Fold 3, Epoch 70: Val Acc: 0.56%
2025-08-15 01:42:23,227 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-15 01:42:25,232 - INFO - Fold 3, Epoch 90: Val Acc: 0.56%
2025-08-15 01:42:27,238 - INFO - Fold 3, Epoch 100: Val Acc: 0.78%
2025-08-15 01:42:29,249 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-15 01:42:31,146 - INFO - Fold 3, Epoch 120: Val Acc: 0.66%
2025-08-15 01:42:33,166 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-15 01:42:35,158 - INFO - Fold 3, Epoch 140: Val Acc: 0.88%
2025-08-15 01:42:38,394 - INFO - Fold 3, Epoch 150: Val Acc: 0.75%
2025-08-15 01:42:40,408 - INFO - Fold 3, Epoch 160: Val Acc: 0.75%
2025-08-15 01:42:42,425 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-15 01:42:44,411 - INFO - Fold 3, Epoch 180: Val Acc: 0.81%
2025-08-15 01:42:46,014 - INFO - Fold 3, Epoch 190: Val Acc: 0.91%
2025-08-15 01:42:47,574 - INFO - Fold 3, Epoch 200: Val Acc: 0.75%
2025-08-15 01:42:49,235 - INFO - Fold 3, Epoch 210: Val Acc: 0.75%
2025-08-15 01:42:51,069 - INFO - Fold 3, Epoch 220: Val Acc: 0.84%
2025-08-15 01:42:53,017 - INFO - Fold 3, Epoch 230: Val Acc: 0.78%
2025-08-15 01:42:55,041 - INFO - Fold 3, Epoch 240: Val Acc: 0.75%
2025-08-15 01:42:56,873 - INFO - Early stopping at epoch 249
2025-08-15 01:42:57,725 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.008651892344157), 'std': np.float64(0.00470767950269865)}, 'train_accuracy': {'mean': np.float64(0.736111111111111), 'std': np.float64(0.02455231879119953)}, 'val_loss': {'mean': np.float64(4.1990898450215655), 'std': np.float64(0.028115071549979803)}, 'val_accuracy': {'mean': np.float64(0.9270833333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(120.66666666666667), 'std': np.float64(25.837096500101467)}}
[I 2025-08-15 01:42:57,731] Trial 139 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.00013614354257425348, 'batch_size': 32, 'num_epochs': 879, 'temperature': 0.3480845419490742, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.28466225842695986, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19091575187898677, 'crop_size': 0.5719857117069753}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 139 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.00013614354257425348, 'batch_size': 32, 'num_epochs': 879, 'temperature': 0.3480845419490742, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.28466225842695986, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19091575187898677, 'crop_size': 0.5719857117069753}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:42:57,781 - INFO - Using device: cuda
2025-08-15 01:43:07,584 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:43:07,586 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:43:07,586 - INFO - Starting training for fold 1/3
2025-08-15 01:43:13,556 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-15 01:43:15,543 - INFO - Fold 1, Epoch 20: Val Acc: 0.38%
2025-08-15 01:43:17,222 - INFO - Fold 1, Epoch 30: Val Acc: 0.66%
2025-08-15 01:43:19,311 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-15 01:43:21,192 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-15 01:43:24,840 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-15 01:43:27,015 - INFO - Fold 1, Epoch 70: Val Acc: 0.50%
2025-08-15 01:43:29,116 - INFO - Fold 1, Epoch 80: Val Acc: 0.59%
2025-08-15 01:43:33,101 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-15 01:43:35,205 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-15 01:43:37,243 - INFO - Fold 1, Epoch 110: Val Acc: 0.75%
2025-08-15 01:43:39,005 - INFO - Fold 1, Epoch 120: Val Acc: 0.59%
2025-08-15 01:43:41,013 - INFO - Fold 1, Epoch 130: Val Acc: 0.75%
2025-08-15 01:43:42,834 - INFO - Fold 1, Epoch 140: Val Acc: 0.78%
2025-08-15 01:43:44,605 - INFO - Fold 1, Epoch 150: Val Acc: 0.75%
2025-08-15 01:43:46,388 - INFO - Fold 1, Epoch 160: Val Acc: 0.75%
2025-08-15 01:43:48,159 - INFO - Fold 1, Epoch 170: Val Acc: 0.78%
2025-08-15 01:43:49,988 - INFO - Fold 1, Epoch 180: Val Acc: 0.50%
2025-08-15 01:43:50,531 - INFO - Early stopping at epoch 183
2025-08-15 01:43:53,643 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:43:53,655 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:43:53,655 - INFO - Starting training for fold 2/3
2025-08-15 01:44:00,461 - INFO - Fold 2, Epoch 10: Val Acc: 0.47%
2025-08-15 01:44:02,010 - INFO - Fold 2, Epoch 20: Val Acc: 0.44%
2025-08-15 01:44:04,707 - INFO - Fold 2, Epoch 30: Val Acc: 0.59%
2025-08-15 01:44:06,633 - INFO - Fold 2, Epoch 40: Val Acc: 0.56%
2025-08-15 01:44:08,659 - INFO - Fold 2, Epoch 50: Val Acc: 0.62%
2025-08-15 01:44:10,669 - INFO - Fold 2, Epoch 60: Val Acc: 0.53%
2025-08-15 01:44:12,673 - INFO - Fold 2, Epoch 70: Val Acc: 0.53%
2025-08-15 01:44:14,656 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-15 01:44:16,656 - INFO - Fold 2, Epoch 90: Val Acc: 0.62%
2025-08-15 01:44:18,668 - INFO - Fold 2, Epoch 100: Val Acc: 0.69%
2025-08-15 01:44:20,683 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-15 01:44:23,794 - INFO - Fold 2, Epoch 120: Val Acc: 0.66%
2025-08-15 01:44:25,700 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-15 01:44:28,712 - INFO - Fold 2, Epoch 140: Val Acc: 0.69%
2025-08-15 01:44:30,452 - INFO - Fold 2, Epoch 150: Val Acc: 0.72%
2025-08-15 01:44:32,459 - INFO - Fold 2, Epoch 160: Val Acc: 0.78%
2025-08-15 01:44:34,405 - INFO - Fold 2, Epoch 170: Val Acc: 0.69%
2025-08-15 01:44:36,412 - INFO - Fold 2, Epoch 180: Val Acc: 0.66%
2025-08-15 01:44:38,414 - INFO - Fold 2, Epoch 190: Val Acc: 0.53%
2025-08-15 01:44:40,422 - INFO - Fold 2, Epoch 200: Val Acc: 0.75%
2025-08-15 01:44:42,348 - INFO - Fold 2, Epoch 210: Val Acc: 0.72%
2025-08-15 01:44:43,900 - INFO - Fold 2, Epoch 220: Val Acc: 0.78%
2025-08-15 01:44:45,460 - INFO - Fold 2, Epoch 230: Val Acc: 0.75%
2025-08-15 01:44:45,615 - INFO - Early stopping at epoch 231
2025-08-15 01:44:46,473 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:44:46,474 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:44:46,475 - INFO - Starting training for fold 3/3
2025-08-15 01:44:53,114 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-15 01:44:54,965 - INFO - Fold 3, Epoch 20: Val Acc: 0.50%
2025-08-15 01:44:58,062 - INFO - Fold 3, Epoch 30: Val Acc: 0.44%
2025-08-15 01:44:59,863 - INFO - Fold 3, Epoch 40: Val Acc: 0.53%
2025-08-15 01:45:01,736 - INFO - Fold 3, Epoch 50: Val Acc: 0.50%
2025-08-15 01:45:03,746 - INFO - Fold 3, Epoch 60: Val Acc: 0.56%
2025-08-15 01:45:05,586 - INFO - Fold 3, Epoch 70: Val Acc: 0.47%
2025-08-15 01:45:07,355 - INFO - Fold 3, Epoch 80: Val Acc: 0.56%
2025-08-15 01:45:11,549 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-15 01:45:13,467 - INFO - Fold 3, Epoch 100: Val Acc: 0.56%
2025-08-15 01:45:15,245 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-15 01:45:17,255 - INFO - Fold 3, Epoch 120: Val Acc: 0.69%
2025-08-15 01:45:19,271 - INFO - Fold 3, Epoch 130: Val Acc: 0.62%
2025-08-15 01:45:21,286 - INFO - Fold 3, Epoch 140: Val Acc: 0.75%
2025-08-15 01:45:23,303 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-15 01:45:25,190 - INFO - Fold 3, Epoch 160: Val Acc: 0.81%
2025-08-15 01:45:28,109 - INFO - Fold 3, Epoch 170: Val Acc: 0.84%
2025-08-15 01:45:29,973 - INFO - Fold 3, Epoch 180: Val Acc: 0.81%
2025-08-15 01:45:31,612 - INFO - Fold 3, Epoch 190: Val Acc: 0.75%
2025-08-15 01:45:33,615 - INFO - Fold 3, Epoch 200: Val Acc: 0.72%
2025-08-15 01:45:35,615 - INFO - Fold 3, Epoch 210: Val Acc: 0.75%
2025-08-15 01:45:38,733 - INFO - Fold 3, Epoch 220: Val Acc: 0.78%
2025-08-15 01:45:40,752 - INFO - Fold 3, Epoch 230: Val Acc: 0.84%
2025-08-15 01:45:42,774 - INFO - Fold 3, Epoch 240: Val Acc: 0.75%
2025-08-15 01:45:44,720 - INFO - Fold 3, Epoch 250: Val Acc: 0.88%
2025-08-15 01:45:46,594 - INFO - Fold 3, Epoch 260: Val Acc: 0.66%
2025-08-15 01:45:48,174 - INFO - Fold 3, Epoch 270: Val Acc: 0.78%
2025-08-15 01:45:50,164 - INFO - Fold 3, Epoch 280: Val Acc: 0.84%
2025-08-15 01:45:52,178 - INFO - Fold 3, Epoch 290: Val Acc: 0.81%
2025-08-15 01:45:54,209 - INFO - Fold 3, Epoch 300: Val Acc: 0.72%
2025-08-15 01:45:57,432 - INFO - Fold 3, Epoch 310: Val Acc: 0.78%
2025-08-15 01:45:59,531 - INFO - Fold 3, Epoch 320: Val Acc: 0.72%
2025-08-15 01:46:01,615 - INFO - Fold 3, Epoch 330: Val Acc: 0.72%
2025-08-15 01:46:03,710 - INFO - Fold 3, Epoch 340: Val Acc: 0.69%
2025-08-15 01:46:05,739 - INFO - Fold 3, Epoch 350: Val Acc: 0.75%
2025-08-15 01:46:07,397 - INFO - Fold 3, Epoch 360: Val Acc: 0.78%
2025-08-15 01:46:09,042 - INFO - Fold 3, Epoch 370: Val Acc: 0.62%
2025-08-15 01:46:10,691 - INFO - Fold 3, Epoch 380: Val Acc: 0.81%
2025-08-15 01:46:12,338 - INFO - Fold 3, Epoch 390: Val Acc: 0.78%
2025-08-15 01:46:14,055 - INFO - Fold 3, Epoch 400: Val Acc: 0.72%
2025-08-15 01:46:15,125 - INFO - Early stopping at epoch 406
2025-08-15 01:46:17,666 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.012718439102173), 'std': np.float64(0.08652473599790104)}, 'train_accuracy': {'mean': np.float64(0.7152777777777777), 'std': np.float64(0.04836245929577821)}, 'val_loss': {'mean': np.float64(4.252739588419597), 'std': np.float64(0.0493061114381616)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(172.33333333333334), 'std': np.float64(95.83434782071728)}}
[I 2025-08-15 01:46:17,676] Trial 140 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.00019940104305614476, 'batch_size': 32, 'num_epochs': 991, 'temperature': 0.35124534374624516, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.25688553866621033, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.17553808152944483, 'crop_size': 0.5808614945139549}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 140 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.00019940104305614476, 'batch_size': 32, 'num_epochs': 991, 'temperature': 0.35124534374624516, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.25688553866621033, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.17553808152944483, 'crop_size': 0.5808614945139549}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:46:17,765 - INFO - Using device: cuda
2025-08-15 01:46:27,700 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:46:27,701 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:46:27,702 - INFO - Starting training for fold 1/3
2025-08-15 01:46:35,132 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-15 01:46:36,841 - INFO - Fold 1, Epoch 20: Val Acc: 0.53%
2025-08-15 01:46:40,382 - INFO - Fold 1, Epoch 30: Val Acc: 0.59%
2025-08-15 01:46:44,179 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-15 01:46:47,713 - INFO - Fold 1, Epoch 50: Val Acc: 0.69%
2025-08-15 01:46:49,606 - INFO - Fold 1, Epoch 60: Val Acc: 0.56%
2025-08-15 01:46:53,180 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-15 01:46:54,947 - INFO - Fold 1, Epoch 80: Val Acc: 0.62%
2025-08-15 01:46:58,515 - INFO - Fold 1, Epoch 90: Val Acc: 0.50%
2025-08-15 01:47:00,498 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-15 01:47:02,496 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-15 01:47:04,496 - INFO - Fold 1, Epoch 120: Val Acc: 0.72%
2025-08-15 01:47:06,408 - INFO - Fold 1, Epoch 130: Val Acc: 0.72%
2025-08-15 01:47:07,948 - INFO - Fold 1, Epoch 140: Val Acc: 0.59%
2025-08-15 01:47:09,491 - INFO - Fold 1, Epoch 150: Val Acc: 0.56%
2025-08-15 01:47:11,030 - INFO - Fold 1, Epoch 160: Val Acc: 0.59%
2025-08-15 01:47:14,605 - INFO - Fold 1, Epoch 170: Val Acc: 0.62%
2025-08-15 01:47:16,428 - INFO - Fold 1, Epoch 180: Val Acc: 0.56%
2025-08-15 01:47:18,439 - INFO - Fold 1, Epoch 190: Val Acc: 0.72%
2025-08-15 01:47:20,518 - INFO - Fold 1, Epoch 200: Val Acc: 0.84%
2025-08-15 01:47:22,138 - INFO - Fold 1, Epoch 210: Val Acc: 0.69%
2025-08-15 01:47:23,688 - INFO - Fold 1, Epoch 220: Val Acc: 0.62%
2025-08-15 01:47:25,398 - INFO - Fold 1, Epoch 230: Val Acc: 0.66%
2025-08-15 01:47:27,311 - INFO - Fold 1, Epoch 240: Val Acc: 0.72%
2025-08-15 01:47:29,298 - INFO - Fold 1, Epoch 250: Val Acc: 0.53%
2025-08-15 01:47:31,295 - INFO - Fold 1, Epoch 260: Val Acc: 0.50%
2025-08-15 01:47:32,299 - INFO - Early stopping at epoch 265
2025-08-15 01:47:35,340 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:47:35,343 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:47:35,343 - INFO - Starting training for fold 2/3
2025-08-15 01:47:42,502 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-15 01:47:46,922 - INFO - Fold 2, Epoch 20: Val Acc: 0.69%
2025-08-15 01:47:49,030 - INFO - Fold 2, Epoch 30: Val Acc: 0.56%
2025-08-15 01:47:53,655 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-15 01:47:56,792 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-15 01:47:58,889 - INFO - Fold 2, Epoch 60: Val Acc: 0.78%
2025-08-15 01:48:00,904 - INFO - Fold 2, Epoch 70: Val Acc: 0.81%
2025-08-15 01:48:02,919 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-15 01:48:04,905 - INFO - Fold 2, Epoch 90: Val Acc: 0.62%
2025-08-15 01:48:06,831 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-15 01:48:10,111 - INFO - Fold 2, Epoch 110: Val Acc: 0.78%
2025-08-15 01:48:12,133 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-15 01:48:16,199 - INFO - Fold 2, Epoch 130: Val Acc: 0.66%
2025-08-15 01:48:18,211 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-15 01:48:20,216 - INFO - Fold 2, Epoch 150: Val Acc: 0.81%
2025-08-15 01:48:22,230 - INFO - Fold 2, Epoch 160: Val Acc: 0.78%
2025-08-15 01:48:24,260 - INFO - Fold 2, Epoch 170: Val Acc: 0.72%
2025-08-15 01:48:26,112 - INFO - Fold 2, Epoch 180: Val Acc: 0.75%
2025-08-15 01:48:28,130 - INFO - Fold 2, Epoch 190: Val Acc: 0.62%
2025-08-15 01:48:30,204 - INFO - Fold 2, Epoch 200: Val Acc: 0.78%
2025-08-15 01:48:32,279 - INFO - Fold 2, Epoch 210: Val Acc: 0.78%
2025-08-15 01:48:34,355 - INFO - Fold 2, Epoch 220: Val Acc: 0.81%
2025-08-15 01:48:35,605 - INFO - Early stopping at epoch 226
2025-08-15 01:48:38,159 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:48:38,163 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:48:38,163 - INFO - Starting training for fold 3/3
2025-08-15 01:48:42,830 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-15 01:48:44,824 - INFO - Fold 3, Epoch 20: Val Acc: 0.47%
2025-08-15 01:48:46,820 - INFO - Fold 3, Epoch 30: Val Acc: 0.56%
2025-08-15 01:48:48,818 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-15 01:48:50,817 - INFO - Fold 3, Epoch 50: Val Acc: 0.66%
2025-08-15 01:48:52,815 - INFO - Fold 3, Epoch 60: Val Acc: 0.56%
2025-08-15 01:48:54,813 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-15 01:48:56,813 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-15 01:48:58,804 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-15 01:49:00,773 - INFO - Fold 3, Epoch 100: Val Acc: 0.81%
2025-08-15 01:49:01,302 - INFO - Early stopping at epoch 103
2025-08-15 01:49:02,189 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.048957877688938), 'std': np.float64(0.08599675347218247)}, 'train_accuracy': {'mean': np.float64(0.7083333333333334), 'std': np.float64(0.04500514373894352)}, 'val_loss': {'mean': np.float64(4.172047773996989), 'std': np.float64(0.0894285525161551)}, 'val_accuracy': {'mean': np.float64(0.8541666666666666), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(97.0), 'std': np.float64(69.03622237637282)}}
[I 2025-08-15 01:49:02,195] Trial 141 finished with value: -0.8541666666666666 and parameters: {'learning_rate': 0.00016328201343281972, 'batch_size': 32, 'num_epochs': 889, 'temperature': 0.327843291032131, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.2913704126188824, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18825227343612883, 'crop_size': 0.559455935153498}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 141 finished with value: -0.8541666666666666 and parameters: {'learning_rate': 0.00016328201343281972, 'batch_size': 32, 'num_epochs': 889, 'temperature': 0.327843291032131, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.2913704126188824, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18825227343612883, 'crop_size': 0.559455935153498}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:49:02,235 - INFO - Using device: cuda
2025-08-15 01:49:11,626 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:49:11,628 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:49:11,628 - INFO - Starting training for fold 1/3
2025-08-15 01:49:21,284 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-15 01:49:23,213 - INFO - Fold 1, Epoch 20: Val Acc: 0.62%
2025-08-15 01:49:25,218 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-15 01:49:27,233 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-15 01:49:29,239 - INFO - Fold 1, Epoch 50: Val Acc: 0.50%
2025-08-15 01:49:31,245 - INFO - Fold 1, Epoch 60: Val Acc: 0.56%
2025-08-15 01:49:33,156 - INFO - Fold 1, Epoch 70: Val Acc: 0.50%
2025-08-15 01:49:34,991 - INFO - Fold 1, Epoch 80: Val Acc: 0.59%
2025-08-15 01:49:36,973 - INFO - Fold 1, Epoch 90: Val Acc: 0.66%
2025-08-15 01:49:40,773 - INFO - Fold 1, Epoch 100: Val Acc: 0.50%
2025-08-15 01:49:42,743 - INFO - Fold 1, Epoch 110: Val Acc: 0.47%
2025-08-15 01:49:44,670 - INFO - Fold 1, Epoch 120: Val Acc: 0.59%
2025-08-15 01:49:46,496 - INFO - Fold 1, Epoch 130: Val Acc: 0.59%
2025-08-15 01:49:48,283 - INFO - Fold 1, Epoch 140: Val Acc: 0.47%
2025-08-15 01:49:49,955 - INFO - Fold 1, Epoch 150: Val Acc: 0.50%
2025-08-15 01:49:51,734 - INFO - Fold 1, Epoch 160: Val Acc: 0.56%
2025-08-15 01:49:53,546 - INFO - Fold 1, Epoch 170: Val Acc: 0.47%
2025-08-15 01:49:57,187 - INFO - Fold 1, Epoch 180: Val Acc: 0.53%
2025-08-15 01:49:59,151 - INFO - Fold 1, Epoch 190: Val Acc: 0.66%
2025-08-15 01:50:01,210 - INFO - Fold 1, Epoch 200: Val Acc: 0.53%
2025-08-15 01:50:03,298 - INFO - Fold 1, Epoch 210: Val Acc: 0.53%
2025-08-15 01:50:05,254 - INFO - Fold 1, Epoch 220: Val Acc: 0.38%
2025-08-15 01:50:06,900 - INFO - Fold 1, Epoch 230: Val Acc: 0.44%
2025-08-15 01:50:08,546 - INFO - Fold 1, Epoch 240: Val Acc: 0.62%
2025-08-15 01:50:10,208 - INFO - Fold 1, Epoch 250: Val Acc: 0.62%
2025-08-15 01:50:12,088 - INFO - Fold 1, Epoch 260: Val Acc: 0.53%
2025-08-15 01:50:14,172 - INFO - Fold 1, Epoch 270: Val Acc: 0.62%
2025-08-15 01:50:15,990 - INFO - Early stopping at epoch 279
2025-08-15 01:50:18,967 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:50:18,969 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:50:18,970 - INFO - Starting training for fold 2/3
2025-08-15 01:50:24,710 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-15 01:50:27,550 - INFO - Fold 2, Epoch 20: Val Acc: 0.53%
2025-08-15 01:50:29,386 - INFO - Fold 2, Epoch 30: Val Acc: 0.53%
2025-08-15 01:50:32,584 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-15 01:50:34,593 - INFO - Fold 2, Epoch 50: Val Acc: 0.38%
2025-08-15 01:50:37,704 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-15 01:50:39,791 - INFO - Fold 2, Epoch 70: Val Acc: 0.62%
2025-08-15 01:50:41,686 - INFO - Fold 2, Epoch 80: Val Acc: 0.56%
2025-08-15 01:50:43,499 - INFO - Fold 2, Epoch 90: Val Acc: 0.59%
2025-08-15 01:50:45,243 - INFO - Fold 2, Epoch 100: Val Acc: 0.59%
2025-08-15 01:50:47,249 - INFO - Fold 2, Epoch 110: Val Acc: 0.53%
2025-08-15 01:50:49,067 - INFO - Fold 2, Epoch 120: Val Acc: 0.59%
2025-08-15 01:50:50,856 - INFO - Fold 2, Epoch 130: Val Acc: 0.56%
2025-08-15 01:50:53,975 - INFO - Fold 2, Epoch 140: Val Acc: 0.47%
2025-08-15 01:50:55,971 - INFO - Fold 2, Epoch 150: Val Acc: 0.41%
2025-08-15 01:50:57,970 - INFO - Fold 2, Epoch 160: Val Acc: 0.59%
2025-08-15 01:50:59,988 - INFO - Fold 2, Epoch 170: Val Acc: 0.72%
2025-08-15 01:51:02,012 - INFO - Fold 2, Epoch 180: Val Acc: 0.56%
2025-08-15 01:51:04,734 - INFO - Fold 2, Epoch 190: Val Acc: 0.62%
2025-08-15 01:51:06,301 - INFO - Fold 2, Epoch 200: Val Acc: 0.50%
2025-08-15 01:51:08,370 - INFO - Fold 2, Epoch 210: Val Acc: 0.56%
2025-08-15 01:51:10,273 - INFO - Fold 2, Epoch 220: Val Acc: 0.62%
2025-08-15 01:51:12,012 - INFO - Fold 2, Epoch 230: Val Acc: 0.56%
2025-08-15 01:51:13,777 - INFO - Fold 2, Epoch 240: Val Acc: 0.59%
2025-08-15 01:51:15,574 - INFO - Fold 2, Epoch 250: Val Acc: 0.75%
2025-08-15 01:51:17,469 - INFO - Fold 2, Epoch 260: Val Acc: 0.75%
2025-08-15 01:51:19,475 - INFO - Fold 2, Epoch 270: Val Acc: 0.59%
2025-08-15 01:51:21,248 - INFO - Fold 2, Epoch 280: Val Acc: 0.75%
2025-08-15 01:51:24,153 - INFO - Fold 2, Epoch 290: Val Acc: 0.69%
2025-08-15 01:51:26,146 - INFO - Fold 2, Epoch 300: Val Acc: 0.72%
2025-08-15 01:51:28,154 - INFO - Fold 2, Epoch 310: Val Acc: 0.72%
2025-08-15 01:51:30,173 - INFO - Fold 2, Epoch 320: Val Acc: 0.62%
2025-08-15 01:51:32,045 - INFO - Fold 2, Epoch 330: Val Acc: 0.62%
2025-08-15 01:51:34,043 - INFO - Fold 2, Epoch 340: Val Acc: 0.72%
2025-08-15 01:51:35,941 - INFO - Fold 2, Epoch 350: Val Acc: 0.75%
2025-08-15 01:51:37,949 - INFO - Fold 2, Epoch 360: Val Acc: 0.81%
2025-08-15 01:51:39,606 - INFO - Fold 2, Epoch 370: Val Acc: 0.75%
2025-08-15 01:51:41,615 - INFO - Fold 2, Epoch 380: Val Acc: 0.75%
2025-08-15 01:51:42,028 - INFO - Early stopping at epoch 382
2025-08-15 01:51:44,733 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:51:44,736 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:51:44,737 - INFO - Starting training for fold 3/3
2025-08-15 01:51:49,313 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-15 01:51:52,675 - INFO - Fold 3, Epoch 20: Val Acc: 0.56%
2025-08-15 01:51:54,468 - INFO - Fold 3, Epoch 30: Val Acc: 0.47%
2025-08-15 01:51:56,295 - INFO - Fold 3, Epoch 40: Val Acc: 0.47%
2025-08-15 01:51:59,304 - INFO - Fold 3, Epoch 50: Val Acc: 0.50%
2025-08-15 01:52:00,881 - INFO - Fold 3, Epoch 60: Val Acc: 0.50%
2025-08-15 01:52:04,168 - INFO - Fold 3, Epoch 70: Val Acc: 0.66%
2025-08-15 01:52:06,191 - INFO - Fold 3, Epoch 80: Val Acc: 0.66%
2025-08-15 01:52:08,055 - INFO - Fold 3, Epoch 90: Val Acc: 0.50%
2025-08-15 01:52:09,615 - INFO - Fold 3, Epoch 100: Val Acc: 0.66%
2025-08-15 01:52:11,500 - INFO - Fold 3, Epoch 110: Val Acc: 0.44%
2025-08-15 01:52:13,510 - INFO - Fold 3, Epoch 120: Val Acc: 0.66%
2025-08-15 01:52:15,515 - INFO - Fold 3, Epoch 130: Val Acc: 0.62%
2025-08-15 01:52:17,523 - INFO - Fold 3, Epoch 140: Val Acc: 0.38%
2025-08-15 01:52:19,344 - INFO - Fold 3, Epoch 150: Val Acc: 0.59%
2025-08-15 01:52:21,338 - INFO - Fold 3, Epoch 160: Val Acc: 0.56%
2025-08-15 01:52:23,152 - INFO - Early stopping at epoch 169
2025-08-15 01:52:23,994 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.07725535498725), 'std': np.float64(0.039519026701081365)}, 'train_accuracy': {'mean': np.float64(0.607638888888889), 'std': np.float64(0.06606353330014045)}, 'val_loss': {'mean': np.float64(4.165996551513672), 'std': np.float64(0.035541243221180054)}, 'val_accuracy': {'mean': np.float64(0.7604166666666666), 'std': np.float64(0.05892556509887896)}, 'epoch': {'mean': np.float64(175.66666666666666), 'std': np.float64(86.97253717250189)}}
[I 2025-08-15 01:52:24,000] Trial 142 finished with value: -0.7604166666666666 and parameters: {'learning_rate': 5.276343108827183e-05, 'batch_size': 32, 'num_epochs': 413, 'temperature': 0.37579380116410155, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3016954912246144, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19188365579221853, 'crop_size': 0.5460770062870097}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 142 finished with value: -0.7604166666666666 and parameters: {'learning_rate': 5.276343108827183e-05, 'batch_size': 32, 'num_epochs': 413, 'temperature': 0.37579380116410155, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3016954912246144, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19188365579221853, 'crop_size': 0.5460770062870097}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:52:24,041 - INFO - Using device: cuda
2025-08-15 01:52:34,018 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:52:34,020 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:52:34,020 - INFO - Starting training for fold 1/3
2025-08-15 01:52:41,398 - INFO - Fold 1, Epoch 10: Val Acc: 0.44%
2025-08-15 01:52:45,105 - INFO - Fold 1, Epoch 20: Val Acc: 0.47%
2025-08-15 01:52:47,191 - INFO - Fold 1, Epoch 30: Val Acc: 0.56%
2025-08-15 01:52:49,264 - INFO - Fold 1, Epoch 40: Val Acc: 0.47%
2025-08-15 01:52:51,348 - INFO - Fold 1, Epoch 50: Val Acc: 0.50%
2025-08-15 01:52:56,635 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-15 01:52:58,188 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-15 01:53:01,681 - INFO - Fold 1, Epoch 80: Val Acc: 0.59%
2025-08-15 01:53:03,246 - INFO - Fold 1, Epoch 90: Val Acc: 0.59%
2025-08-15 01:53:04,799 - INFO - Fold 1, Epoch 100: Val Acc: 0.62%
2025-08-15 01:53:06,563 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-15 01:53:08,305 - INFO - Fold 1, Epoch 120: Val Acc: 0.41%
2025-08-15 01:53:09,944 - INFO - Fold 1, Epoch 130: Val Acc: 0.59%
2025-08-15 01:53:13,705 - INFO - Fold 1, Epoch 140: Val Acc: 0.62%
2025-08-15 01:53:15,782 - INFO - Fold 1, Epoch 150: Val Acc: 0.56%
2025-08-15 01:53:19,758 - INFO - Fold 1, Epoch 160: Val Acc: 0.75%
2025-08-15 01:53:21,825 - INFO - Fold 1, Epoch 170: Val Acc: 0.69%
2025-08-15 01:53:25,714 - INFO - Fold 1, Epoch 180: Val Acc: 0.81%
2025-08-15 01:53:27,710 - INFO - Fold 1, Epoch 190: Val Acc: 0.69%
2025-08-15 01:53:29,484 - INFO - Fold 1, Epoch 200: Val Acc: 0.78%
2025-08-15 01:53:31,175 - INFO - Fold 1, Epoch 210: Val Acc: 0.84%
2025-08-15 01:53:33,171 - INFO - Fold 1, Epoch 220: Val Acc: 0.75%
2025-08-15 01:53:35,167 - INFO - Fold 1, Epoch 230: Val Acc: 0.53%
2025-08-15 01:53:37,168 - INFO - Fold 1, Epoch 240: Val Acc: 0.62%
2025-08-15 01:53:39,184 - INFO - Fold 1, Epoch 250: Val Acc: 0.66%
2025-08-15 01:53:41,157 - INFO - Fold 1, Epoch 260: Val Acc: 0.59%
2025-08-15 01:53:43,059 - INFO - Fold 1, Epoch 270: Val Acc: 0.75%
2025-08-15 01:53:46,867 - INFO - Fold 1, Epoch 280: Val Acc: 0.59%
2025-08-15 01:53:48,765 - INFO - Fold 1, Epoch 290: Val Acc: 0.66%
2025-08-15 01:53:50,659 - INFO - Fold 1, Epoch 300: Val Acc: 0.69%
2025-08-15 01:53:52,511 - INFO - Fold 1, Epoch 310: Val Acc: 0.62%
2025-08-15 01:53:54,331 - INFO - Fold 1, Epoch 320: Val Acc: 0.66%
2025-08-15 01:53:56,220 - INFO - Fold 1, Epoch 330: Val Acc: 0.78%
2025-08-15 01:53:58,036 - INFO - Fold 1, Epoch 340: Val Acc: 0.75%
2025-08-15 01:53:59,900 - INFO - Fold 1, Epoch 350: Val Acc: 0.78%
2025-08-15 01:54:01,999 - INFO - Fold 1, Epoch 360: Val Acc: 0.66%
2025-08-15 01:54:04,007 - INFO - Fold 1, Epoch 370: Val Acc: 0.75%
2025-08-15 01:54:04,610 - INFO - Early stopping at epoch 373
2025-08-15 01:54:07,557 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:54:07,568 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:54:07,569 - INFO - Starting training for fold 2/3
2025-08-15 01:54:10,966 - INFO - Fold 2, Epoch 10: Val Acc: 0.53%
2025-08-15 01:54:14,134 - INFO - Fold 2, Epoch 20: Val Acc: 0.47%
2025-08-15 01:54:16,051 - INFO - Fold 2, Epoch 30: Val Acc: 0.56%
2025-08-15 01:54:18,053 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-15 01:54:20,044 - INFO - Fold 2, Epoch 50: Val Acc: 0.56%
2025-08-15 01:54:23,203 - INFO - Fold 2, Epoch 60: Val Acc: 0.50%
2025-08-15 01:54:25,229 - INFO - Fold 2, Epoch 70: Val Acc: 0.56%
2025-08-15 01:54:28,472 - INFO - Fold 2, Epoch 80: Val Acc: 0.62%
2025-08-15 01:54:30,487 - INFO - Fold 2, Epoch 90: Val Acc: 0.66%
2025-08-15 01:54:32,558 - INFO - Fold 2, Epoch 100: Val Acc: 0.62%
2025-08-15 01:54:34,656 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-15 01:54:36,734 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-15 01:54:39,920 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-15 01:54:41,970 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-15 01:54:43,905 - INFO - Fold 2, Epoch 150: Val Acc: 0.59%
2025-08-15 01:54:45,460 - INFO - Fold 2, Epoch 160: Val Acc: 0.56%
2025-08-15 01:54:47,440 - INFO - Fold 2, Epoch 170: Val Acc: 0.59%
2025-08-15 01:54:49,444 - INFO - Fold 2, Epoch 180: Val Acc: 0.72%
2025-08-15 01:54:52,737 - INFO - Fold 2, Epoch 190: Val Acc: 0.72%
2025-08-15 01:54:54,737 - INFO - Fold 2, Epoch 200: Val Acc: 0.66%
2025-08-15 01:54:56,663 - INFO - Fold 2, Epoch 210: Val Acc: 0.78%
2025-08-15 01:54:58,470 - INFO - Fold 2, Epoch 220: Val Acc: 0.69%
2025-08-15 01:55:00,237 - INFO - Fold 2, Epoch 230: Val Acc: 0.72%
2025-08-15 01:55:01,909 - INFO - Fold 2, Epoch 240: Val Acc: 0.53%
2025-08-15 01:55:03,783 - INFO - Fold 2, Epoch 250: Val Acc: 0.69%
2025-08-15 01:55:05,785 - INFO - Fold 2, Epoch 260: Val Acc: 0.72%
2025-08-15 01:55:09,044 - INFO - Fold 2, Epoch 270: Val Acc: 0.59%
2025-08-15 01:55:11,038 - INFO - Fold 2, Epoch 280: Val Acc: 0.44%
2025-08-15 01:55:13,053 - INFO - Fold 2, Epoch 290: Val Acc: 0.75%
2025-08-15 01:55:15,131 - INFO - Fold 2, Epoch 300: Val Acc: 0.75%
2025-08-15 01:55:17,043 - INFO - Fold 2, Epoch 310: Val Acc: 0.69%
2025-08-15 01:55:18,850 - INFO - Fold 2, Epoch 320: Val Acc: 0.66%
2025-08-15 01:55:20,798 - INFO - Fold 2, Epoch 330: Val Acc: 0.72%
2025-08-15 01:55:22,757 - INFO - Fold 2, Epoch 340: Val Acc: 0.66%
2025-08-15 01:55:24,543 - INFO - Fold 2, Epoch 350: Val Acc: 0.78%
2025-08-15 01:55:26,327 - INFO - Fold 2, Epoch 360: Val Acc: 0.81%
2025-08-15 01:55:27,058 - INFO - Early stopping at epoch 364
2025-08-15 01:55:27,895 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:55:27,898 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:55:27,898 - INFO - Starting training for fold 3/3
2025-08-15 01:55:32,278 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-15 01:55:35,416 - INFO - Fold 3, Epoch 20: Val Acc: 0.56%
2025-08-15 01:55:38,437 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-15 01:55:40,441 - INFO - Fold 3, Epoch 40: Val Acc: 0.59%
2025-08-15 01:55:42,465 - INFO - Fold 3, Epoch 50: Val Acc: 0.59%
2025-08-15 01:55:45,549 - INFO - Fold 3, Epoch 60: Val Acc: 0.59%
2025-08-15 01:55:47,571 - INFO - Fold 3, Epoch 70: Val Acc: 0.53%
2025-08-15 01:55:49,587 - INFO - Fold 3, Epoch 80: Val Acc: 0.62%
2025-08-15 01:55:51,379 - INFO - Fold 3, Epoch 90: Val Acc: 0.59%
2025-08-15 01:55:53,364 - INFO - Fold 3, Epoch 100: Val Acc: 0.59%
2025-08-15 01:55:55,355 - INFO - Fold 3, Epoch 110: Val Acc: 0.62%
2025-08-15 01:55:57,380 - INFO - Fold 3, Epoch 120: Val Acc: 0.66%
2025-08-15 01:55:59,389 - INFO - Fold 3, Epoch 130: Val Acc: 0.66%
2025-08-15 01:56:01,212 - INFO - Fold 3, Epoch 140: Val Acc: 0.62%
2025-08-15 01:56:03,230 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-15 01:56:03,829 - INFO - Early stopping at epoch 153
2025-08-15 01:56:04,668 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.038323322931926), 'std': np.float64(0.038278132851569245)}, 'train_accuracy': {'mean': np.float64(0.6527777777777778), 'std': np.float64(0.06383602885711888)}, 'val_loss': {'mean': np.float64(4.15729284286499), 'std': np.float64(0.04130622192982425)}, 'val_accuracy': {'mean': np.float64(0.875), 'std': np.float64(0.04419417382415922)}, 'epoch': {'mean': np.float64(195.66666666666666), 'std': np.float64(101.65409758369584)}}
[I 2025-08-15 01:56:04,675] Trial 143 finished with value: -0.875 and parameters: {'learning_rate': 8.776664749620688e-05, 'batch_size': 32, 'num_epochs': 859, 'temperature': 0.45082292294936904, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3455322134906485, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.09260925871541924, 'crop_size': 0.57110792211126}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 143 finished with value: -0.875 and parameters: {'learning_rate': 8.776664749620688e-05, 'batch_size': 32, 'num_epochs': 859, 'temperature': 0.45082292294936904, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.3455322134906485, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.09260925871541924, 'crop_size': 0.57110792211126}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:56:04,716 - INFO - Using device: cuda
2025-08-15 01:56:14,471 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:56:14,472 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:56:14,472 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 01:56:23,454 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-15 01:56:27,992 - INFO - Fold 1, Epoch 20: Val Acc: 0.47%
2025-08-15 01:56:30,234 - INFO - Fold 1, Epoch 30: Val Acc: 0.59%
2025-08-15 01:56:34,452 - INFO - Fold 1, Epoch 40: Val Acc: 0.41%
2025-08-15 01:56:36,691 - INFO - Fold 1, Epoch 50: Val Acc: 0.56%
2025-08-15 01:56:38,928 - INFO - Fold 1, Epoch 60: Val Acc: 0.56%
2025-08-15 01:56:41,149 - INFO - Fold 1, Epoch 70: Val Acc: 0.50%
2025-08-15 01:56:43,384 - INFO - Fold 1, Epoch 80: Val Acc: 0.59%
2025-08-15 01:56:45,624 - INFO - Fold 1, Epoch 90: Val Acc: 0.62%
2025-08-15 01:56:47,634 - INFO - Fold 1, Epoch 100: Val Acc: 0.62%
2025-08-15 01:56:49,519 - INFO - Fold 1, Epoch 110: Val Acc: 0.56%
2025-08-15 01:56:51,746 - INFO - Fold 1, Epoch 120: Val Acc: 0.81%
2025-08-15 01:56:53,985 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-15 01:56:55,767 - INFO - Early stopping at epoch 138
2025-08-15 01:56:59,561 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:56:59,564 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:56:59,565 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 01:57:06,497 - INFO - Fold 2, Epoch 10: Val Acc: 0.53%
2025-08-15 01:57:08,794 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-15 01:57:11,100 - INFO - Fold 2, Epoch 30: Val Acc: 0.62%
2025-08-15 01:57:13,416 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-15 01:57:17,160 - INFO - Fold 2, Epoch 50: Val Acc: 0.53%
2025-08-15 01:57:19,459 - INFO - Fold 2, Epoch 60: Val Acc: 0.62%
2025-08-15 01:57:21,746 - INFO - Fold 2, Epoch 70: Val Acc: 0.69%
2025-08-15 01:57:23,962 - INFO - Fold 2, Epoch 80: Val Acc: 0.59%
2025-08-15 01:57:26,172 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-15 01:57:28,391 - INFO - Fold 2, Epoch 100: Val Acc: 0.56%
2025-08-15 01:57:30,618 - INFO - Fold 2, Epoch 110: Val Acc: 0.53%
2025-08-15 01:57:32,749 - INFO - Fold 2, Epoch 120: Val Acc: 0.47%
2025-08-15 01:57:35,935 - INFO - Fold 2, Epoch 130: Val Acc: 0.38%
2025-08-15 01:57:37,665 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-15 01:57:39,532 - INFO - Fold 2, Epoch 150: Val Acc: 0.66%
2025-08-15 01:57:41,470 - INFO - Fold 2, Epoch 160: Val Acc: 0.59%
2025-08-15 01:57:43,408 - INFO - Fold 2, Epoch 170: Val Acc: 0.69%
2025-08-15 01:57:45,321 - INFO - Fold 2, Epoch 180: Val Acc: 0.72%
2025-08-15 01:57:47,260 - INFO - Fold 2, Epoch 190: Val Acc: 0.66%
2025-08-15 01:57:49,127 - INFO - Fold 2, Epoch 200: Val Acc: 0.62%
2025-08-15 01:57:51,023 - INFO - Fold 2, Epoch 210: Val Acc: 0.75%
2025-08-15 01:57:52,923 - INFO - Fold 2, Epoch 220: Val Acc: 0.53%
2025-08-15 01:57:53,733 - INFO - Early stopping at epoch 224
2025-08-15 01:57:56,567 - INFO - --- Starting Fold 3/3 ---
2025-08-15 01:57:56,569 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:57:56,570 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 01:58:01,592 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-15 01:58:05,074 - INFO - Fold 3, Epoch 20: Val Acc: 0.47%
2025-08-15 01:58:07,253 - INFO - Fold 3, Epoch 30: Val Acc: 0.41%
2025-08-15 01:58:09,452 - INFO - Fold 3, Epoch 40: Val Acc: 0.56%
2025-08-15 01:58:11,682 - INFO - Fold 3, Epoch 50: Val Acc: 0.56%
2025-08-15 01:58:13,916 - INFO - Fold 3, Epoch 60: Val Acc: 0.66%
2025-08-15 01:58:16,160 - INFO - Fold 3, Epoch 70: Val Acc: 0.59%
2025-08-15 01:58:18,154 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-15 01:58:20,125 - INFO - Fold 3, Epoch 90: Val Acc: 0.78%
2025-08-15 01:58:22,059 - INFO - Fold 3, Epoch 100: Val Acc: 0.56%
2025-08-15 01:58:23,966 - INFO - Fold 3, Epoch 110: Val Acc: 0.62%
2025-08-15 01:58:27,378 - INFO - Fold 3, Epoch 120: Val Acc: 0.53%
2025-08-15 01:58:29,440 - INFO - Fold 3, Epoch 130: Val Acc: 0.62%
2025-08-15 01:58:31,660 - INFO - Fold 3, Epoch 140: Val Acc: 0.53%
2025-08-15 01:58:33,873 - INFO - Fold 3, Epoch 150: Val Acc: 0.66%
2025-08-15 01:58:36,106 - INFO - Fold 3, Epoch 160: Val Acc: 0.50%
2025-08-15 01:58:38,331 - INFO - Fold 3, Epoch 170: Val Acc: 0.59%
2025-08-15 01:58:40,559 - INFO - Fold 3, Epoch 180: Val Acc: 0.66%
2025-08-15 01:58:42,792 - INFO - Fold 3, Epoch 190: Val Acc: 0.75%
2025-08-15 01:58:45,023 - INFO - Fold 3, Epoch 200: Val Acc: 0.69%
2025-08-15 01:58:47,255 - INFO - Fold 3, Epoch 210: Val Acc: 0.69%
2025-08-15 01:58:47,699 - INFO - Early stopping at epoch 212
2025-08-15 01:58:48,782 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.556096659766303), 'std': np.float64(0.28416354932909604)}, 'train_accuracy': {'mean': np.float64(0.6944444444444445), 'std': np.float64(0.04910463758239917)}, 'val_loss': {'mean': np.float64(4.886332988739014), 'std': np.float64(0.3482000547354483)}, 'val_accuracy': {'mean': np.float64(0.8229166666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(90.33333333333333), 'std': np.float64(38.029228525204424)}}
[I 2025-08-15 01:58:48,788] Trial 144 finished with value: -0.8229166666666666 and parameters: {'learning_rate': 0.00022464897931680715, 'batch_size': 32, 'num_epochs': 922, 'temperature': 0.08560850198121589, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.27992835303367697, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19540316629882074, 'crop_size': 0.5341538866994}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 144 finished with value: -0.8229166666666666 and parameters: {'learning_rate': 0.00022464897931680715, 'batch_size': 32, 'num_epochs': 922, 'temperature': 0.08560850198121589, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.27992835303367697, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19540316629882074, 'crop_size': 0.5341538866994}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 01:58:48,830 - INFO - Using device: cuda
2025-08-15 01:58:58,791 - INFO - --- Starting Fold 1/3 ---
2025-08-15 01:58:58,792 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:58:58,792 - INFO - Starting training for fold 1/3
2025-08-15 01:59:05,320 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-15 01:59:09,670 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-15 01:59:11,884 - INFO - Fold 1, Epoch 30: Val Acc: 0.72%
2025-08-15 01:59:16,351 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-15 01:59:20,449 - INFO - Fold 1, Epoch 50: Val Acc: 0.88%
2025-08-15 01:59:22,754 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-15 01:59:26,927 - INFO - Fold 1, Epoch 70: Val Acc: 0.84%
2025-08-15 01:59:28,891 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-15 01:59:31,180 - INFO - Fold 1, Epoch 90: Val Acc: 0.81%
2025-08-15 01:59:33,292 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-15 01:59:35,305 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-15 01:59:37,335 - INFO - Fold 1, Epoch 120: Val Acc: 0.72%
2025-08-15 01:59:39,280 - INFO - Fold 1, Epoch 130: Val Acc: 0.75%
2025-08-15 01:59:41,508 - INFO - Fold 1, Epoch 140: Val Acc: 0.78%
2025-08-15 01:59:43,849 - INFO - Fold 1, Epoch 150: Val Acc: 0.66%
2025-08-15 01:59:46,176 - INFO - Fold 1, Epoch 160: Val Acc: 0.81%
2025-08-15 01:59:47,354 - INFO - Early stopping at epoch 165
2025-08-15 01:59:50,739 - INFO - --- Starting Fold 2/3 ---
2025-08-15 01:59:50,751 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 01:59:50,752 - INFO - Starting training for fold 2/3
2025-08-15 01:59:57,402 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 02:00:01,094 - INFO - Fold 2, Epoch 20: Val Acc: 0.81%
2025-08-15 02:00:03,427 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-15 02:00:07,175 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-15 02:00:09,484 - INFO - Fold 2, Epoch 50: Val Acc: 0.62%
2025-08-15 02:00:11,721 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-15 02:00:13,950 - INFO - Fold 2, Epoch 70: Val Acc: 0.56%
2025-08-15 02:00:16,189 - INFO - Fold 2, Epoch 80: Val Acc: 0.72%
2025-08-15 02:00:18,166 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-15 02:00:20,136 - INFO - Fold 2, Epoch 100: Val Acc: 0.72%
2025-08-15 02:00:22,106 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-15 02:00:24,056 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-15 02:00:25,839 - INFO - Fold 2, Epoch 130: Val Acc: 0.81%
2025-08-15 02:00:27,036 - INFO - Early stopping at epoch 137
2025-08-15 02:00:28,124 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:00:28,126 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:00:28,127 - INFO - Starting training for fold 3/3
2025-08-15 02:00:34,867 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-15 02:00:39,927 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-15 02:00:42,079 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-15 02:00:44,297 - INFO - Fold 3, Epoch 40: Val Acc: 0.59%
2025-08-15 02:00:46,516 - INFO - Fold 3, Epoch 50: Val Acc: 0.75%
2025-08-15 02:00:48,738 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-15 02:00:52,370 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-15 02:00:54,494 - INFO - Fold 3, Epoch 80: Val Acc: 0.81%
2025-08-15 02:00:56,447 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-15 02:00:59,829 - INFO - Fold 3, Epoch 100: Val Acc: 0.91%
2025-08-15 02:01:01,855 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-15 02:01:03,789 - INFO - Fold 3, Epoch 120: Val Acc: 0.66%
2025-08-15 02:01:05,735 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-15 02:01:09,276 - INFO - Fold 3, Epoch 140: Val Acc: 0.69%
2025-08-15 02:01:11,601 - INFO - Fold 3, Epoch 150: Val Acc: 0.78%
2025-08-15 02:01:13,851 - INFO - Fold 3, Epoch 160: Val Acc: 0.88%
2025-08-15 02:01:16,095 - INFO - Fold 3, Epoch 170: Val Acc: 0.69%
2025-08-15 02:01:18,338 - INFO - Fold 3, Epoch 180: Val Acc: 0.66%
2025-08-15 02:01:20,672 - INFO - Fold 3, Epoch 190: Val Acc: 0.75%
2025-08-15 02:01:22,979 - INFO - Fold 3, Epoch 200: Val Acc: 0.66%
2025-08-15 02:01:25,218 - INFO - Fold 3, Epoch 210: Val Acc: 0.66%
2025-08-15 02:01:27,518 - INFO - Fold 3, Epoch 220: Val Acc: 0.78%
2025-08-15 02:01:29,836 - INFO - Fold 3, Epoch 230: Val Acc: 0.75%
2025-08-15 02:01:30,520 - INFO - Early stopping at epoch 233
2025-08-15 02:01:35,630 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9589654869503446), 'std': np.float64(0.06404184989169122)}, 'train_accuracy': {'mean': np.float64(0.7847222222222223), 'std': np.float64(0.025983731852596822)}, 'val_loss': {'mean': np.float64(4.177897930145264), 'std': np.float64(0.020238389257633913)}, 'val_accuracy': {'mean': np.float64(0.9270833333333334), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(77.33333333333333), 'std': np.float64(40.309910554215925)}}
[I 2025-08-15 02:01:35,641] Trial 145 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.00040259074325568956, 'batch_size': 32, 'num_epochs': 840, 'temperature': 0.39802062716495074, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.23718759986551877, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08692644298514893, 'crop_size': 0.5166250525482736}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 145 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.00040259074325568956, 'batch_size': 32, 'num_epochs': 840, 'temperature': 0.39802062716495074, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.23718759986551877, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08692644298514893, 'crop_size': 0.5166250525482736}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:01:35,731 - INFO - Using device: cuda
2025-08-15 02:01:45,508 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:01:45,510 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:01:45,510 - INFO - Starting training for fold 1/3
2025-08-15 02:01:52,674 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-15 02:01:54,900 - INFO - Fold 1, Epoch 20: Val Acc: 0.53%
2025-08-15 02:01:57,131 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-15 02:02:01,587 - INFO - Fold 1, Epoch 40: Val Acc: 0.50%
2025-08-15 02:02:03,820 - INFO - Fold 1, Epoch 50: Val Acc: 0.56%
2025-08-15 02:02:08,194 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-15 02:02:10,443 - INFO - Fold 1, Epoch 70: Val Acc: 0.50%
2025-08-15 02:02:12,659 - INFO - Fold 1, Epoch 80: Val Acc: 0.56%
2025-08-15 02:02:14,894 - INFO - Fold 1, Epoch 90: Val Acc: 0.56%
2025-08-15 02:02:17,111 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-15 02:02:21,292 - INFO - Fold 1, Epoch 110: Val Acc: 0.59%
2025-08-15 02:02:23,073 - INFO - Fold 1, Epoch 120: Val Acc: 0.62%
2025-08-15 02:02:27,380 - INFO - Fold 1, Epoch 130: Val Acc: 0.81%
2025-08-15 02:02:29,599 - INFO - Fold 1, Epoch 140: Val Acc: 0.53%
2025-08-15 02:02:31,814 - INFO - Fold 1, Epoch 150: Val Acc: 0.66%
2025-08-15 02:02:34,036 - INFO - Fold 1, Epoch 160: Val Acc: 0.72%
2025-08-15 02:02:36,254 - INFO - Fold 1, Epoch 170: Val Acc: 0.78%
2025-08-15 02:02:38,480 - INFO - Fold 1, Epoch 180: Val Acc: 0.59%
2025-08-15 02:02:40,700 - INFO - Fold 1, Epoch 190: Val Acc: 0.53%
2025-08-15 02:02:42,771 - INFO - Fold 1, Epoch 200: Val Acc: 0.62%
2025-08-15 02:02:44,725 - INFO - Fold 1, Epoch 210: Val Acc: 0.50%
2025-08-15 02:02:48,945 - INFO - Fold 1, Epoch 220: Val Acc: 0.69%
2025-08-15 02:02:51,258 - INFO - Fold 1, Epoch 230: Val Acc: 0.62%
2025-08-15 02:02:53,387 - INFO - Fold 1, Epoch 240: Val Acc: 0.81%
2025-08-15 02:02:55,405 - INFO - Fold 1, Epoch 250: Val Acc: 0.75%
2025-08-15 02:02:57,420 - INFO - Fold 1, Epoch 260: Val Acc: 0.66%
2025-08-15 02:02:59,320 - INFO - Fold 1, Epoch 270: Val Acc: 0.53%
2025-08-15 02:03:01,139 - INFO - Fold 1, Epoch 280: Val Acc: 0.84%
2025-08-15 02:03:02,854 - INFO - Fold 1, Epoch 290: Val Acc: 0.66%
2025-08-15 02:03:04,568 - INFO - Fold 1, Epoch 300: Val Acc: 0.84%
2025-08-15 02:03:06,281 - INFO - Fold 1, Epoch 310: Val Acc: 0.53%
2025-08-15 02:03:07,478 - INFO - Early stopping at epoch 317
2025-08-15 02:03:11,506 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:03:11,509 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:03:11,510 - INFO - Starting training for fold 2/3
2025-08-15 02:03:19,689 - INFO - Fold 2, Epoch 10: Val Acc: 0.62%
2025-08-15 02:03:21,706 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-15 02:03:25,079 - INFO - Fold 2, Epoch 30: Val Acc: 0.56%
2025-08-15 02:03:26,941 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-15 02:03:28,785 - INFO - Fold 2, Epoch 50: Val Acc: 0.56%
2025-08-15 02:03:30,624 - INFO - Fold 2, Epoch 60: Val Acc: 0.50%
2025-08-15 02:03:33,869 - INFO - Fold 2, Epoch 70: Val Acc: 0.56%
2025-08-15 02:03:37,370 - INFO - Fold 2, Epoch 80: Val Acc: 0.47%
2025-08-15 02:03:39,289 - INFO - Fold 2, Epoch 90: Val Acc: 0.56%
2025-08-15 02:03:41,400 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-15 02:03:43,330 - INFO - Fold 2, Epoch 110: Val Acc: 0.56%
2025-08-15 02:03:46,706 - INFO - Fold 2, Epoch 120: Val Acc: 0.56%
2025-08-15 02:03:48,872 - INFO - Fold 2, Epoch 130: Val Acc: 0.56%
2025-08-15 02:03:52,624 - INFO - Fold 2, Epoch 140: Val Acc: 0.59%
2025-08-15 02:03:54,867 - INFO - Fold 2, Epoch 150: Val Acc: 0.69%
2025-08-15 02:03:57,101 - INFO - Fold 2, Epoch 160: Val Acc: 0.72%
2025-08-15 02:03:59,432 - INFO - Fold 2, Epoch 170: Val Acc: 0.66%
2025-08-15 02:04:01,754 - INFO - Fold 2, Epoch 180: Val Acc: 0.59%
2025-08-15 02:04:03,983 - INFO - Fold 2, Epoch 190: Val Acc: 0.59%
2025-08-15 02:04:06,012 - INFO - Fold 2, Epoch 200: Val Acc: 0.53%
2025-08-15 02:04:08,095 - INFO - Fold 2, Epoch 210: Val Acc: 0.59%
2025-08-15 02:04:10,318 - INFO - Fold 2, Epoch 220: Val Acc: 0.56%
2025-08-15 02:04:12,130 - INFO - Fold 2, Epoch 230: Val Acc: 0.66%
2025-08-15 02:04:13,149 - INFO - Early stopping at epoch 236
2025-08-15 02:04:16,078 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:04:16,082 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:04:16,082 - INFO - Starting training for fold 3/3
2025-08-15 02:04:24,274 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-15 02:04:26,265 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-15 02:04:28,253 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-15 02:04:30,350 - INFO - Fold 3, Epoch 40: Val Acc: 0.53%
2025-08-15 02:04:33,826 - INFO - Fold 3, Epoch 50: Val Acc: 0.62%
2025-08-15 02:04:38,876 - INFO - Fold 3, Epoch 60: Val Acc: 0.59%
2025-08-15 02:04:41,202 - INFO - Fold 3, Epoch 70: Val Acc: 0.53%
2025-08-15 02:04:43,534 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-15 02:04:47,315 - INFO - Fold 3, Epoch 90: Val Acc: 0.66%
2025-08-15 02:04:50,920 - INFO - Fold 3, Epoch 100: Val Acc: 0.50%
2025-08-15 02:04:52,928 - INFO - Fold 3, Epoch 110: Val Acc: 0.56%
2025-08-15 02:04:56,615 - INFO - Fold 3, Epoch 120: Val Acc: 0.62%
2025-08-15 02:04:58,806 - INFO - Fold 3, Epoch 130: Val Acc: 0.50%
2025-08-15 02:05:00,833 - INFO - Fold 3, Epoch 140: Val Acc: 0.59%
2025-08-15 02:05:02,634 - INFO - Fold 3, Epoch 150: Val Acc: 0.59%
2025-08-15 02:05:04,509 - INFO - Fold 3, Epoch 160: Val Acc: 0.62%
2025-08-15 02:05:06,333 - INFO - Fold 3, Epoch 170: Val Acc: 0.62%
2025-08-15 02:05:08,293 - INFO - Fold 3, Epoch 180: Val Acc: 0.69%
2025-08-15 02:05:10,437 - INFO - Fold 3, Epoch 190: Val Acc: 0.78%
2025-08-15 02:05:12,663 - INFO - Fold 3, Epoch 200: Val Acc: 0.72%
2025-08-15 02:05:17,244 - INFO - Fold 3, Epoch 210: Val Acc: 0.47%
2025-08-15 02:05:19,327 - INFO - Fold 3, Epoch 220: Val Acc: 0.72%
2025-08-15 02:05:21,531 - INFO - Fold 3, Epoch 230: Val Acc: 0.72%
2025-08-15 02:05:23,848 - INFO - Fold 3, Epoch 240: Val Acc: 0.78%
2025-08-15 02:05:26,113 - INFO - Fold 3, Epoch 250: Val Acc: 0.59%
2025-08-15 02:05:28,346 - INFO - Fold 3, Epoch 260: Val Acc: 0.62%
2025-08-15 02:05:30,580 - INFO - Fold 3, Epoch 270: Val Acc: 0.50%
2025-08-15 02:05:32,819 - INFO - Fold 3, Epoch 280: Val Acc: 0.56%
2025-08-15 02:05:35,057 - INFO - Fold 3, Epoch 290: Val Acc: 0.75%
2025-08-15 02:05:37,286 - INFO - Fold 3, Epoch 300: Val Acc: 0.84%
2025-08-15 02:05:38,845 - INFO - Early stopping at epoch 307
2025-08-15 02:05:39,917 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.968916416168213), 'std': np.float64(0.03461794764007698)}, 'train_accuracy': {'mean': np.float64(0.7222222222222223), 'std': np.float64(0.03540985773328324)}, 'val_loss': {'mean': np.float64(4.2252373695373535), 'std': np.float64(0.13755026438422113)}, 'val_accuracy': {'mean': np.float64(0.8645833333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(185.66666666666666), 'std': np.float64(36.05859429071275)}}
[I 2025-08-15 02:05:39,924] Trial 146 finished with value: -0.8645833333333334 and parameters: {'learning_rate': 0.0002563732179074532, 'batch_size': 32, 'num_epochs': 383, 'temperature': 0.40495777392432475, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.22920377833118347, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.08538821139715476, 'crop_size': 0.5159436362790399}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 146 finished with value: -0.8645833333333334 and parameters: {'learning_rate': 0.0002563732179074532, 'batch_size': 32, 'num_epochs': 383, 'temperature': 0.40495777392432475, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.22920377833118347, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.08538821139715476, 'crop_size': 0.5159436362790399}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:05:39,964 - INFO - Using device: cuda
2025-08-15 02:05:49,863 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:05:49,864 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:05:49,865 - INFO - Starting training for fold 1/3
2025-08-15 02:05:56,816 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-15 02:05:58,938 - INFO - Fold 1, Epoch 20: Val Acc: 0.47%
2025-08-15 02:06:01,181 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-15 02:06:05,547 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-15 02:06:10,040 - INFO - Fold 1, Epoch 50: Val Acc: 0.50%
2025-08-15 02:06:12,276 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-15 02:06:14,406 - INFO - Fold 1, Epoch 70: Val Acc: 0.53%
2025-08-15 02:06:16,480 - INFO - Fold 1, Epoch 80: Val Acc: 0.44%
2025-08-15 02:06:20,782 - INFO - Fold 1, Epoch 90: Val Acc: 0.50%
2025-08-15 02:06:22,868 - INFO - Fold 1, Epoch 100: Val Acc: 0.53%
2025-08-15 02:06:24,875 - INFO - Fold 1, Epoch 110: Val Acc: 0.47%
2025-08-15 02:06:26,773 - INFO - Fold 1, Epoch 120: Val Acc: 0.56%
2025-08-15 02:06:29,120 - INFO - Fold 1, Epoch 130: Val Acc: 0.53%
2025-08-15 02:06:31,343 - INFO - Fold 1, Epoch 140: Val Acc: 0.56%
2025-08-15 02:06:33,297 - INFO - Fold 1, Epoch 150: Val Acc: 0.53%
2025-08-15 02:06:35,264 - INFO - Fold 1, Epoch 160: Val Acc: 0.53%
2025-08-15 02:06:37,122 - INFO - Fold 1, Epoch 170: Val Acc: 0.50%
2025-08-15 02:06:38,895 - INFO - Fold 1, Epoch 180: Val Acc: 0.56%
2025-08-15 02:06:39,242 - INFO - Early stopping at epoch 182
2025-08-15 02:06:42,958 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:06:42,960 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:06:42,961 - INFO - Starting training for fold 2/3
2025-08-15 02:06:49,711 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-15 02:06:51,821 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-15 02:06:55,260 - INFO - Fold 2, Epoch 30: Val Acc: 0.50%
2025-08-15 02:06:57,151 - INFO - Fold 2, Epoch 40: Val Acc: 0.53%
2025-08-15 02:06:59,394 - INFO - Fold 2, Epoch 50: Val Acc: 0.34%
2025-08-15 02:07:02,958 - INFO - Fold 2, Epoch 60: Val Acc: 0.50%
2025-08-15 02:07:05,200 - INFO - Fold 2, Epoch 70: Val Acc: 0.56%
2025-08-15 02:07:07,430 - INFO - Fold 2, Epoch 80: Val Acc: 0.47%
2025-08-15 02:07:09,654 - INFO - Fold 2, Epoch 90: Val Acc: 0.56%
2025-08-15 02:07:11,891 - INFO - Fold 2, Epoch 100: Val Acc: 0.50%
2025-08-15 02:07:14,129 - INFO - Fold 2, Epoch 110: Val Acc: 0.62%
2025-08-15 02:07:16,365 - INFO - Fold 2, Epoch 120: Val Acc: 0.50%
2025-08-15 02:07:18,618 - INFO - Fold 2, Epoch 130: Val Acc: 0.38%
2025-08-15 02:07:20,872 - INFO - Fold 2, Epoch 140: Val Acc: 0.44%
2025-08-15 02:07:22,834 - INFO - Fold 2, Epoch 150: Val Acc: 0.53%
2025-08-15 02:07:24,634 - INFO - Early stopping at epoch 158
2025-08-15 02:07:27,668 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:07:27,670 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:07:27,670 - INFO - Starting training for fold 3/3
2025-08-15 02:07:33,016 - INFO - Fold 3, Epoch 10: Val Acc: 0.47%
2025-08-15 02:07:36,694 - INFO - Fold 3, Epoch 20: Val Acc: 0.47%
2025-08-15 02:07:38,671 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-15 02:07:40,800 - INFO - Fold 3, Epoch 40: Val Acc: 0.50%
2025-08-15 02:07:43,041 - INFO - Fold 3, Epoch 50: Val Acc: 0.62%
2025-08-15 02:07:44,883 - INFO - Fold 3, Epoch 60: Val Acc: 0.38%
2025-08-15 02:07:46,615 - INFO - Fold 3, Epoch 70: Val Acc: 0.53%
2025-08-15 02:07:48,347 - INFO - Fold 3, Epoch 80: Val Acc: 0.53%
2025-08-15 02:07:50,079 - INFO - Fold 3, Epoch 90: Val Acc: 0.38%
2025-08-15 02:07:51,812 - INFO - Fold 3, Epoch 100: Val Acc: 0.50%
2025-08-15 02:07:53,760 - INFO - Fold 3, Epoch 110: Val Acc: 0.62%
2025-08-15 02:07:53,934 - INFO - Early stopping at epoch 111
2025-08-15 02:07:55,096 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.14982197019789), 'std': np.float64(0.009576103477719344)}, 'train_accuracy': {'mean': np.float64(0.5590277777777778), 'std': np.float64(0.021404215288086736)}, 'val_loss': {'mean': np.float64(4.176311333974202), 'std': np.float64(0.011458803365812066)}, 'val_accuracy': {'mean': np.float64(0.6666666666666666), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(49.333333333333336), 'std': np.float64(29.48822740612863)}}
[I 2025-08-15 02:07:55,103] Trial 147 finished with value: -0.6666666666666666 and parameters: {'learning_rate': 0.00037426387643237297, 'batch_size': 32, 'num_epochs': 829, 'temperature': 0.3494082944768187, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2427467035947775, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.09780376765837498, 'crop_size': 0.5074808848224834}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 147 finished with value: -0.6666666666666666 and parameters: {'learning_rate': 0.00037426387643237297, 'batch_size': 32, 'num_epochs': 829, 'temperature': 0.3494082944768187, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2427467035947775, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.09780376765837498, 'crop_size': 0.5074808848224834}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:07:55,145 - INFO - Using device: cuda
2025-08-15 02:08:04,985 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:08:04,986 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:08:04,987 - INFO - Starting training for fold 1/3
2025-08-15 02:08:17,076 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-15 02:08:21,521 - INFO - Fold 1, Epoch 20: Val Acc: 0.84%
2025-08-15 02:08:23,829 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-15 02:08:26,077 - INFO - Fold 1, Epoch 40: Val Acc: 0.81%
2025-08-15 02:08:30,570 - INFO - Fold 1, Epoch 50: Val Acc: 0.81%
2025-08-15 02:08:32,799 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-15 02:08:35,035 - INFO - Fold 1, Epoch 70: Val Acc: 0.69%
2025-08-15 02:08:39,333 - INFO - Fold 1, Epoch 80: Val Acc: 0.91%
2025-08-15 02:08:41,659 - INFO - Fold 1, Epoch 90: Val Acc: 0.78%
2025-08-15 02:08:43,900 - INFO - Fold 1, Epoch 100: Val Acc: 0.88%
2025-08-15 02:08:46,137 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-15 02:08:48,300 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-15 02:08:50,520 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-15 02:08:52,459 - INFO - Fold 1, Epoch 140: Val Acc: 0.62%
2025-08-15 02:08:54,177 - INFO - Fold 1, Epoch 150: Val Acc: 0.69%
2025-08-15 02:08:56,090 - INFO - Fold 1, Epoch 160: Val Acc: 0.59%
2025-08-15 02:08:58,415 - INFO - Fold 1, Epoch 170: Val Acc: 0.84%
2025-08-15 02:09:00,729 - INFO - Early stopping at epoch 180
2025-08-15 02:09:04,413 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:09:04,417 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:09:04,417 - INFO - Starting training for fold 2/3
2025-08-15 02:09:11,603 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-15 02:09:13,715 - INFO - Fold 2, Epoch 20: Val Acc: 0.56%
2025-08-15 02:09:16,011 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-15 02:09:19,439 - INFO - Fold 2, Epoch 40: Val Acc: 0.66%
2025-08-15 02:09:23,126 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-15 02:09:25,256 - INFO - Fold 2, Epoch 60: Val Acc: 0.78%
2025-08-15 02:09:28,802 - INFO - Fold 2, Epoch 70: Val Acc: 0.88%
2025-08-15 02:09:31,129 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-15 02:09:33,451 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-15 02:09:35,764 - INFO - Fold 2, Epoch 100: Val Acc: 0.72%
2025-08-15 02:09:38,084 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-15 02:09:40,394 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-15 02:09:42,697 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-15 02:09:44,940 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-15 02:09:46,634 - INFO - Fold 2, Epoch 150: Val Acc: 0.69%
2025-08-15 02:09:49,976 - INFO - Fold 2, Epoch 160: Val Acc: 0.75%
2025-08-15 02:09:51,975 - INFO - Fold 2, Epoch 170: Val Acc: 0.66%
2025-08-15 02:09:53,717 - INFO - Fold 2, Epoch 180: Val Acc: 0.78%
2025-08-15 02:09:55,929 - INFO - Fold 2, Epoch 190: Val Acc: 0.75%
2025-08-15 02:09:58,191 - INFO - Fold 2, Epoch 200: Val Acc: 0.66%
2025-08-15 02:10:00,470 - INFO - Fold 2, Epoch 210: Val Acc: 0.69%
2025-08-15 02:10:02,768 - INFO - Fold 2, Epoch 220: Val Acc: 0.75%
2025-08-15 02:10:05,068 - INFO - Fold 2, Epoch 230: Val Acc: 0.62%
2025-08-15 02:10:07,342 - INFO - Fold 2, Epoch 240: Val Acc: 0.81%
2025-08-15 02:10:09,543 - INFO - Fold 2, Epoch 250: Val Acc: 0.81%
2025-08-15 02:10:10,744 - INFO - Early stopping at epoch 257
2025-08-15 02:10:13,608 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:10:13,611 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:10:13,611 - INFO - Starting training for fold 3/3
2025-08-15 02:10:20,426 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-15 02:10:25,549 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-15 02:10:27,649 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-15 02:10:33,900 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-15 02:10:35,614 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-15 02:10:40,751 - INFO - Fold 3, Epoch 60: Val Acc: 0.69%
2025-08-15 02:10:43,041 - INFO - Fold 3, Epoch 70: Val Acc: 0.62%
2025-08-15 02:10:46,654 - INFO - Fold 3, Epoch 80: Val Acc: 0.88%
2025-08-15 02:10:48,905 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-15 02:10:51,124 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-15 02:10:53,352 - INFO - Fold 3, Epoch 110: Val Acc: 0.72%
2025-08-15 02:10:55,624 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-15 02:10:57,876 - INFO - Fold 3, Epoch 130: Val Acc: 0.78%
2025-08-15 02:11:00,095 - INFO - Fold 3, Epoch 140: Val Acc: 0.75%
2025-08-15 02:11:02,312 - INFO - Fold 3, Epoch 150: Val Acc: 0.78%
2025-08-15 02:11:04,372 - INFO - Fold 3, Epoch 160: Val Acc: 0.69%
2025-08-15 02:11:06,399 - INFO - Fold 3, Epoch 170: Val Acc: 0.66%
2025-08-15 02:11:06,620 - INFO - Early stopping at epoch 171
2025-08-15 02:11:07,723 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.8992293410831027), 'std': np.float64(0.03308031359172313)}, 'train_accuracy': {'mean': np.float64(0.7673611111111112), 'std': np.float64(0.05663023066076419)}, 'val_loss': {'mean': np.float64(4.189688046773274), 'std': np.float64(0.05952912548085982)}, 'val_accuracy': {'mean': np.float64(0.9270833333333334), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(101.66666666666667), 'std': np.float64(38.59476072675611)}}
[I 2025-08-15 02:11:07,730] Trial 148 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.00043333464083632753, 'batch_size': 32, 'num_epochs': 344, 'temperature': 0.2975106936711718, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.17722426092530252, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08669204091580222, 'crop_size': 0.5210515420354109}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 148 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.00043333464083632753, 'batch_size': 32, 'num_epochs': 344, 'temperature': 0.2975106936711718, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.17722426092530252, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08669204091580222, 'crop_size': 0.5210515420354109}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:11:07,771 - INFO - Using device: cuda
2025-08-15 02:11:17,325 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:11:17,327 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:11:17,327 - INFO - Starting training for fold 1/3
2025-08-15 02:11:27,669 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-15 02:11:29,383 - INFO - Fold 1, Epoch 20: Val Acc: 0.66%
2025-08-15 02:11:31,145 - INFO - Fold 1, Epoch 30: Val Acc: 0.56%
2025-08-15 02:11:35,338 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-15 02:11:37,270 - INFO - Fold 1, Epoch 50: Val Acc: 0.59%
2025-08-15 02:11:39,200 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-15 02:11:43,228 - INFO - Fold 1, Epoch 70: Val Acc: 0.75%
2025-08-15 02:11:45,566 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-15 02:11:47,740 - INFO - Fold 1, Epoch 90: Val Acc: 0.81%
2025-08-15 02:11:49,464 - INFO - Fold 1, Epoch 100: Val Acc: 0.66%
2025-08-15 02:11:51,185 - INFO - Fold 1, Epoch 110: Val Acc: 0.75%
2025-08-15 02:11:53,418 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-15 02:11:55,661 - INFO - Fold 1, Epoch 130: Val Acc: 0.81%
2025-08-15 02:12:00,039 - INFO - Fold 1, Epoch 140: Val Acc: 0.91%
2025-08-15 02:12:02,380 - INFO - Fold 1, Epoch 150: Val Acc: 0.53%
2025-08-15 02:12:04,547 - INFO - Fold 1, Epoch 160: Val Acc: 0.75%
2025-08-15 02:12:06,777 - INFO - Fold 1, Epoch 170: Val Acc: 0.78%
2025-08-15 02:12:09,009 - INFO - Fold 1, Epoch 180: Val Acc: 0.72%
2025-08-15 02:12:11,017 - INFO - Fold 1, Epoch 190: Val Acc: 0.66%
2025-08-15 02:12:12,839 - INFO - Fold 1, Epoch 200: Val Acc: 0.78%
2025-08-15 02:12:14,836 - INFO - Fold 1, Epoch 210: Val Acc: 0.84%
2025-08-15 02:12:17,081 - INFO - Fold 1, Epoch 220: Val Acc: 0.66%
2025-08-15 02:12:19,318 - INFO - Fold 1, Epoch 230: Val Acc: 0.59%
2025-08-15 02:12:21,560 - INFO - Early stopping at epoch 240
2025-08-15 02:12:25,071 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:12:25,074 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:12:25,074 - INFO - Starting training for fold 2/3
2025-08-15 02:12:30,584 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-15 02:12:35,706 - INFO - Fold 2, Epoch 20: Val Acc: 0.72%
2025-08-15 02:12:37,702 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-15 02:12:41,200 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-15 02:12:44,400 - INFO - Fold 2, Epoch 50: Val Acc: 0.59%
2025-08-15 02:12:46,366 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-15 02:12:48,359 - INFO - Fold 2, Epoch 70: Val Acc: 0.69%
2025-08-15 02:12:50,369 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-15 02:12:52,375 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-15 02:12:54,356 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-15 02:12:57,678 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-15 02:12:59,663 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-15 02:13:01,647 - INFO - Fold 2, Epoch 130: Val Acc: 0.72%
2025-08-15 02:13:03,855 - INFO - Fold 2, Epoch 140: Val Acc: 0.66%
2025-08-15 02:13:05,990 - INFO - Fold 2, Epoch 150: Val Acc: 0.69%
2025-08-15 02:13:08,238 - INFO - Fold 2, Epoch 160: Val Acc: 0.72%
2025-08-15 02:13:10,423 - INFO - Fold 2, Epoch 170: Val Acc: 0.84%
2025-08-15 02:13:12,677 - INFO - Fold 2, Epoch 180: Val Acc: 0.81%
2025-08-15 02:13:14,950 - INFO - Fold 2, Epoch 190: Val Acc: 0.75%
2025-08-15 02:13:17,116 - INFO - Fold 2, Epoch 200: Val Acc: 0.78%
2025-08-15 02:13:18,238 - INFO - Early stopping at epoch 205
2025-08-15 02:13:19,303 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:13:19,305 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:13:19,306 - INFO - Starting training for fold 3/3
2025-08-15 02:13:24,590 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-15 02:13:28,250 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-15 02:13:31,740 - INFO - Fold 3, Epoch 30: Val Acc: 0.59%
2025-08-15 02:13:33,583 - INFO - Fold 3, Epoch 40: Val Acc: 0.59%
2025-08-15 02:13:37,508 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-15 02:13:39,752 - INFO - Fold 3, Epoch 60: Val Acc: 0.66%
2025-08-15 02:13:41,741 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-15 02:13:43,846 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-15 02:13:46,037 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-15 02:13:49,628 - INFO - Fold 3, Epoch 100: Val Acc: 0.66%
2025-08-15 02:13:51,969 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-15 02:13:54,297 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-15 02:13:56,524 - INFO - Fold 3, Epoch 130: Val Acc: 0.69%
2025-08-15 02:13:58,758 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-15 02:14:00,997 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-15 02:14:03,233 - INFO - Fold 3, Epoch 160: Val Acc: 0.75%
2025-08-15 02:14:05,462 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-15 02:14:07,648 - INFO - Fold 3, Epoch 180: Val Acc: 0.81%
2025-08-15 02:14:09,885 - INFO - Fold 3, Epoch 190: Val Acc: 0.78%
2025-08-15 02:14:10,107 - INFO - Early stopping at epoch 191
2025-08-15 02:14:11,278 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.943623966640896), 'std': np.float64(0.048391486169050243)}, 'train_accuracy': {'mean': np.float64(0.798611111111111), 'std': np.float64(0.04983576421669213)}, 'val_loss': {'mean': np.float64(4.1870072682698565), 'std': np.float64(0.04374866377266091)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(111.0), 'std': np.float64(20.607442021431645)}}
[I 2025-08-15 02:14:11,285] Trial 149 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0004051132337326043, 'batch_size': 32, 'num_epochs': 332, 'temperature': 0.28747874585952815, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.18375468216271656, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08851820300905242, 'crop_size': 0.5233980928701124}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 149 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0004051132337326043, 'batch_size': 32, 'num_epochs': 332, 'temperature': 0.28747874585952815, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.18375468216271656, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08851820300905242, 'crop_size': 0.5233980928701124}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:14:11,326 - INFO - Using device: cuda
2025-08-15 02:14:20,972 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:14:20,974 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:14:20,974 - INFO - Starting training for fold 1/3
2025-08-15 02:14:34,909 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-15 02:14:39,571 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-15 02:14:43,770 - INFO - Fold 1, Epoch 30: Val Acc: 0.72%
2025-08-15 02:14:50,415 - INFO - Fold 1, Epoch 40: Val Acc: 0.81%
2025-08-15 02:14:52,771 - INFO - Fold 1, Epoch 50: Val Acc: 0.78%
2025-08-15 02:14:59,635 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-15 02:15:01,979 - INFO - Fold 1, Epoch 70: Val Acc: 0.81%
2025-08-15 02:15:04,296 - INFO - Fold 1, Epoch 80: Val Acc: 0.81%
2025-08-15 02:15:06,556 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-15 02:15:08,811 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-15 02:15:11,120 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-15 02:15:13,248 - INFO - Fold 1, Epoch 120: Val Acc: 0.66%
2025-08-15 02:15:15,255 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-15 02:15:17,420 - INFO - Fold 1, Epoch 140: Val Acc: 0.78%
2025-08-15 02:15:19,502 - INFO - Fold 1, Epoch 150: Val Acc: 0.72%
2025-08-15 02:15:20,616 - INFO - Early stopping at epoch 155
2025-08-15 02:15:24,314 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:15:24,317 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:15:24,317 - INFO - Starting training for fold 2/3
2025-08-15 02:15:32,755 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 02:15:36,390 - INFO - Fold 2, Epoch 20: Val Acc: 0.72%
2025-08-15 02:15:41,486 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-15 02:15:43,220 - INFO - Fold 2, Epoch 40: Val Acc: 0.78%
2025-08-15 02:15:44,948 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-15 02:15:46,677 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-15 02:15:49,854 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-15 02:15:51,789 - INFO - Fold 2, Epoch 80: Val Acc: 0.72%
2025-08-15 02:15:53,516 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-15 02:15:55,712 - INFO - Fold 2, Epoch 100: Val Acc: 0.72%
2025-08-15 02:15:57,938 - INFO - Fold 2, Epoch 110: Val Acc: 0.62%
2025-08-15 02:16:00,178 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-15 02:16:02,204 - INFO - Fold 2, Epoch 130: Val Acc: 0.81%
2025-08-15 02:16:04,131 - INFO - Fold 2, Epoch 140: Val Acc: 0.88%
2025-08-15 02:16:06,071 - INFO - Fold 2, Epoch 150: Val Acc: 0.56%
2025-08-15 02:16:08,005 - INFO - Fold 2, Epoch 160: Val Acc: 0.78%
2025-08-15 02:16:08,778 - INFO - Early stopping at epoch 164
2025-08-15 02:16:11,822 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:16:11,826 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:16:11,826 - INFO - Starting training for fold 3/3
2025-08-15 02:16:19,757 - INFO - Fold 3, Epoch 10: Val Acc: 0.66%
2025-08-15 02:16:24,703 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-15 02:16:26,654 - INFO - Fold 3, Epoch 30: Val Acc: 0.72%
2025-08-15 02:16:29,974 - INFO - Fold 3, Epoch 40: Val Acc: 0.84%
2025-08-15 02:16:32,141 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-15 02:16:34,377 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-15 02:16:36,296 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-15 02:16:38,471 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-15 02:16:42,132 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-15 02:16:44,289 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-15 02:16:46,520 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-15 02:16:48,758 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-15 02:16:50,993 - INFO - Fold 3, Epoch 130: Val Acc: 0.75%
2025-08-15 02:16:53,233 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-15 02:16:55,477 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-15 02:16:57,721 - INFO - Fold 3, Epoch 160: Val Acc: 0.75%
2025-08-15 02:16:59,957 - INFO - Fold 3, Epoch 170: Val Acc: 0.88%
2025-08-15 02:17:02,178 - INFO - Fold 3, Epoch 180: Val Acc: 0.69%
2025-08-15 02:17:02,619 - INFO - Early stopping at epoch 182
2025-08-15 02:17:03,652 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.937151776419746), 'std': np.float64(0.016117113138988202)}, 'train_accuracy': {'mean': np.float64(0.75), 'std': np.float64(0.02551551815399144)}, 'val_loss': {'mean': np.float64(4.224382241566976), 'std': np.float64(0.0335797928566339)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(66.0), 'std': np.float64(11.224972160321824)}}
[I 2025-08-15 02:17:03,659] Trial 150 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.00044228119769574773, 'batch_size': 32, 'num_epochs': 365, 'temperature': 0.2939670399292491, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.1375397737330386, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.080194864915145, 'crop_size': 0.5382564245173723}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 150 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.00044228119769574773, 'batch_size': 32, 'num_epochs': 365, 'temperature': 0.2939670399292491, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.1375397737330386, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.080194864915145, 'crop_size': 0.5382564245173723}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:17:03,700 - INFO - Using device: cuda
2025-08-15 02:17:13,504 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:17:13,506 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:17:13,506 - INFO - Starting training for fold 1/3
2025-08-15 02:17:22,447 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-15 02:17:27,076 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-15 02:17:29,332 - INFO - Fold 1, Epoch 30: Val Acc: 0.59%
2025-08-15 02:17:33,916 - INFO - Fold 1, Epoch 40: Val Acc: 0.50%
2025-08-15 02:17:36,215 - INFO - Fold 1, Epoch 50: Val Acc: 0.59%
2025-08-15 02:17:42,689 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-15 02:17:46,850 - INFO - Fold 1, Epoch 70: Val Acc: 0.50%
2025-08-15 02:17:48,724 - INFO - Fold 1, Epoch 80: Val Acc: 0.59%
2025-08-15 02:17:50,620 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-15 02:17:52,622 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-15 02:17:54,595 - INFO - Fold 1, Epoch 110: Val Acc: 0.75%
2025-08-15 02:17:56,625 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-15 02:17:58,873 - INFO - Fold 1, Epoch 130: Val Acc: 0.66%
2025-08-15 02:18:03,530 - INFO - Fold 1, Epoch 140: Val Acc: 0.81%
2025-08-15 02:18:05,600 - INFO - Fold 1, Epoch 150: Val Acc: 0.78%
2025-08-15 02:18:07,314 - INFO - Fold 1, Epoch 160: Val Acc: 0.59%
2025-08-15 02:18:09,234 - INFO - Fold 1, Epoch 170: Val Acc: 0.88%
2025-08-15 02:18:11,126 - INFO - Fold 1, Epoch 180: Val Acc: 0.78%
2025-08-15 02:18:12,843 - INFO - Fold 1, Epoch 190: Val Acc: 0.72%
2025-08-15 02:18:14,930 - INFO - Fold 1, Epoch 200: Val Acc: 0.75%
2025-08-15 02:18:16,964 - INFO - Fold 1, Epoch 210: Val Acc: 0.62%
2025-08-15 02:18:18,689 - INFO - Fold 1, Epoch 220: Val Acc: 0.81%
2025-08-15 02:18:20,854 - INFO - Fold 1, Epoch 230: Val Acc: 0.69%
2025-08-15 02:18:21,307 - INFO - Early stopping at epoch 232
2025-08-15 02:18:24,930 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:18:24,934 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:18:24,935 - INFO - Starting training for fold 2/3
2025-08-15 02:18:31,302 - INFO - Fold 2, Epoch 10: Val Acc: 0.47%
2025-08-15 02:18:34,624 - INFO - Fold 2, Epoch 20: Val Acc: 0.78%
2025-08-15 02:18:36,729 - INFO - Fold 2, Epoch 30: Val Acc: 0.59%
2025-08-15 02:18:38,983 - INFO - Fold 2, Epoch 40: Val Acc: 0.56%
2025-08-15 02:18:41,230 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-15 02:18:43,471 - INFO - Fold 2, Epoch 60: Val Acc: 0.62%
2025-08-15 02:18:47,120 - INFO - Fold 2, Epoch 70: Val Acc: 0.56%
2025-08-15 02:18:49,364 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-15 02:18:51,614 - INFO - Fold 2, Epoch 90: Val Acc: 0.75%
2025-08-15 02:18:53,866 - INFO - Fold 2, Epoch 100: Val Acc: 0.81%
2025-08-15 02:18:56,112 - INFO - Fold 2, Epoch 110: Val Acc: 0.66%
2025-08-15 02:18:58,355 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-15 02:19:01,845 - INFO - Fold 2, Epoch 130: Val Acc: 0.91%
2025-08-15 02:19:04,184 - INFO - Fold 2, Epoch 140: Val Acc: 0.84%
2025-08-15 02:19:06,423 - INFO - Fold 2, Epoch 150: Val Acc: 0.78%
2025-08-15 02:19:08,665 - INFO - Fold 2, Epoch 160: Val Acc: 0.72%
2025-08-15 02:19:10,912 - INFO - Fold 2, Epoch 170: Val Acc: 0.81%
2025-08-15 02:19:13,164 - INFO - Fold 2, Epoch 180: Val Acc: 0.72%
2025-08-15 02:19:15,413 - INFO - Fold 2, Epoch 190: Val Acc: 0.88%
2025-08-15 02:19:17,660 - INFO - Fold 2, Epoch 200: Val Acc: 0.78%
2025-08-15 02:19:19,890 - INFO - Fold 2, Epoch 210: Val Acc: 0.81%
2025-08-15 02:19:22,130 - INFO - Fold 2, Epoch 220: Val Acc: 0.91%
2025-08-15 02:19:24,356 - INFO - Early stopping at epoch 230
2025-08-15 02:19:27,516 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:19:27,519 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:19:27,519 - INFO - Starting training for fold 3/3
2025-08-15 02:19:34,077 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-15 02:19:36,101 - INFO - Fold 3, Epoch 20: Val Acc: 0.44%
2025-08-15 02:19:38,015 - INFO - Fold 3, Epoch 30: Val Acc: 0.62%
2025-08-15 02:19:39,943 - INFO - Fold 3, Epoch 40: Val Acc: 0.59%
2025-08-15 02:19:42,042 - INFO - Fold 3, Epoch 50: Val Acc: 0.59%
2025-08-15 02:19:44,260 - INFO - Fold 3, Epoch 60: Val Acc: 0.50%
2025-08-15 02:19:46,504 - INFO - Fold 3, Epoch 70: Val Acc: 0.59%
2025-08-15 02:19:51,379 - INFO - Fold 3, Epoch 80: Val Acc: 0.59%
2025-08-15 02:19:53,510 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-15 02:19:55,727 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-15 02:19:59,297 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-15 02:20:01,544 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-15 02:20:05,147 - INFO - Fold 3, Epoch 130: Val Acc: 0.66%
2025-08-15 02:20:08,699 - INFO - Fold 3, Epoch 140: Val Acc: 0.91%
2025-08-15 02:20:10,947 - INFO - Fold 3, Epoch 150: Val Acc: 0.81%
2025-08-15 02:20:13,195 - INFO - Fold 3, Epoch 160: Val Acc: 0.72%
2025-08-15 02:20:15,087 - INFO - Fold 3, Epoch 170: Val Acc: 0.84%
2025-08-15 02:20:17,339 - INFO - Fold 3, Epoch 180: Val Acc: 0.81%
2025-08-15 02:20:19,593 - INFO - Fold 3, Epoch 190: Val Acc: 0.69%
2025-08-15 02:20:21,835 - INFO - Fold 3, Epoch 200: Val Acc: 0.78%
2025-08-15 02:20:24,085 - INFO - Fold 3, Epoch 210: Val Acc: 0.75%
2025-08-15 02:20:26,325 - INFO - Fold 3, Epoch 220: Val Acc: 0.84%
2025-08-15 02:20:28,504 - INFO - Fold 3, Epoch 230: Val Acc: 0.78%
2025-08-15 02:20:30,455 - INFO - Early stopping at epoch 240
2025-08-15 02:20:31,486 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.994343731138441), 'std': np.float64(0.05834883687440892)}, 'train_accuracy': {'mean': np.float64(0.7083333333333334), 'std': np.float64(0.014731391274719792)}, 'val_loss': {'mean': np.float64(4.239828904469808), 'std': np.float64(0.042598737590544784)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(133.0), 'std': np.float64(4.320493798938574)}}
[I 2025-08-15 02:20:31,494] Trial 151 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.00013327843760372362, 'batch_size': 32, 'num_epochs': 260, 'temperature': 0.30895963379349056, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.21929879428262272, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07113532929546067, 'crop_size': 0.518385197152301}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 151 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.00013327843760372362, 'batch_size': 32, 'num_epochs': 260, 'temperature': 0.30895963379349056, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.21929879428262272, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07113532929546067, 'crop_size': 0.518385197152301}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:20:31,544 - INFO - Using device: cuda
2025-08-15 02:20:41,354 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:20:41,356 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:20:41,356 - INFO - Starting training for fold 1/3
2025-08-15 02:20:50,778 - INFO - Fold 1, Epoch 10: Val Acc: 0.62%
2025-08-15 02:20:53,038 - INFO - Fold 1, Epoch 20: Val Acc: 0.75%
2025-08-15 02:20:55,289 - INFO - Fold 1, Epoch 30: Val Acc: 0.81%
2025-08-15 02:20:57,548 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-15 02:20:59,782 - INFO - Fold 1, Epoch 50: Val Acc: 0.78%
2025-08-15 02:21:02,020 - INFO - Fold 1, Epoch 60: Val Acc: 0.75%
2025-08-15 02:21:06,312 - INFO - Fold 1, Epoch 70: Val Acc: 0.59%
2025-08-15 02:21:08,402 - INFO - Fold 1, Epoch 80: Val Acc: 0.78%
2025-08-15 02:21:10,705 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-15 02:21:15,408 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-15 02:21:17,462 - INFO - Fold 1, Epoch 110: Val Acc: 0.59%
2025-08-15 02:21:19,469 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-15 02:21:21,564 - INFO - Fold 1, Epoch 130: Val Acc: 0.88%
2025-08-15 02:21:23,619 - INFO - Fold 1, Epoch 140: Val Acc: 0.78%
2025-08-15 02:21:25,784 - INFO - Fold 1, Epoch 150: Val Acc: 0.59%
2025-08-15 02:21:28,048 - INFO - Fold 1, Epoch 160: Val Acc: 0.69%
2025-08-15 02:21:30,284 - INFO - Fold 1, Epoch 170: Val Acc: 0.69%
2025-08-15 02:21:32,515 - INFO - Fold 1, Epoch 180: Val Acc: 0.75%
2025-08-15 02:21:34,756 - INFO - Fold 1, Epoch 190: Val Acc: 0.66%
2025-08-15 02:21:35,875 - INFO - Early stopping at epoch 195
2025-08-15 02:21:39,407 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:21:39,410 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:21:39,411 - INFO - Starting training for fold 2/3
2025-08-15 02:21:47,301 - INFO - Fold 2, Epoch 10: Val Acc: 0.44%
2025-08-15 02:21:50,880 - INFO - Fold 2, Epoch 20: Val Acc: 0.53%
2025-08-15 02:21:54,364 - INFO - Fold 2, Epoch 30: Val Acc: 0.66%
2025-08-15 02:21:57,743 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-15 02:22:01,316 - INFO - Fold 2, Epoch 50: Val Acc: 0.84%
2025-08-15 02:22:04,868 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-15 02:22:06,959 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-15 02:22:09,199 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-15 02:22:11,271 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-15 02:22:12,982 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-15 02:22:14,705 - INFO - Fold 2, Epoch 110: Val Acc: 0.66%
2025-08-15 02:22:16,714 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-15 02:22:18,851 - INFO - Fold 2, Epoch 130: Val Acc: 0.72%
2025-08-15 02:22:21,087 - INFO - Fold 2, Epoch 140: Val Acc: 0.81%
2025-08-15 02:22:23,092 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-15 02:22:24,628 - INFO - Early stopping at epoch 158
2025-08-15 02:22:25,667 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:22:25,669 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:22:25,670 - INFO - Starting training for fold 3/3
2025-08-15 02:22:32,115 - INFO - Fold 3, Epoch 10: Val Acc: 0.41%
2025-08-15 02:22:35,790 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-15 02:22:38,038 - INFO - Fold 3, Epoch 30: Val Acc: 0.72%
2025-08-15 02:22:40,281 - INFO - Fold 3, Epoch 40: Val Acc: 0.56%
2025-08-15 02:22:43,978 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-15 02:22:46,134 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-15 02:22:47,858 - INFO - Fold 3, Epoch 70: Val Acc: 0.75%
2025-08-15 02:22:49,687 - INFO - Fold 3, Epoch 80: Val Acc: 0.78%
2025-08-15 02:22:51,400 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-15 02:22:54,981 - INFO - Fold 3, Epoch 100: Val Acc: 0.88%
2025-08-15 02:22:57,213 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-15 02:22:59,438 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-15 02:23:01,668 - INFO - Fold 3, Epoch 130: Val Acc: 0.78%
2025-08-15 02:23:05,298 - INFO - Fold 3, Epoch 140: Val Acc: 0.78%
2025-08-15 02:23:07,523 - INFO - Fold 3, Epoch 150: Val Acc: 0.78%
2025-08-15 02:23:09,580 - INFO - Fold 3, Epoch 160: Val Acc: 0.75%
2025-08-15 02:23:11,551 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-15 02:23:13,504 - INFO - Fold 3, Epoch 180: Val Acc: 0.84%
2025-08-15 02:23:15,671 - INFO - Fold 3, Epoch 190: Val Acc: 0.81%
2025-08-15 02:23:17,900 - INFO - Fold 3, Epoch 200: Val Acc: 0.72%
2025-08-15 02:23:19,733 - INFO - Fold 3, Epoch 210: Val Acc: 0.72%
2025-08-15 02:23:21,965 - INFO - Fold 3, Epoch 220: Val Acc: 0.69%
2025-08-15 02:23:24,191 - INFO - Fold 3, Epoch 230: Val Acc: 0.84%
2025-08-15 02:23:26,205 - INFO - Early stopping at epoch 239
2025-08-15 02:23:29,213 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.97381681866116), 'std': np.float64(0.02224748845767625)}, 'train_accuracy': {'mean': np.float64(0.8055555555555555), 'std': np.float64(0.027340305118096573)}, 'val_loss': {'mean': np.float64(4.222853819529216), 'std': np.float64(0.032363131711482175)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(96.33333333333333), 'std': np.float64(33.10924677823738)}}
[I 2025-08-15 02:23:29,223] Trial 152 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.00034069187030775784, 'batch_size': 32, 'num_epochs': 941, 'temperature': 0.38173121826307993, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.17440470699852603, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.09577264365049817, 'crop_size': 0.5470000298939772}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 152 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.00034069187030775784, 'batch_size': 32, 'num_epochs': 941, 'temperature': 0.38173121826307993, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.17440470699852603, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.09577264365049817, 'crop_size': 0.5470000298939772}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:23:29,317 - INFO - Using device: cuda
2025-08-15 02:23:39,345 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:23:39,347 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:23:39,347 - INFO - Starting training for fold 1/3
2025-08-15 02:23:48,294 - INFO - Fold 1, Epoch 10: Val Acc: 0.62%
2025-08-15 02:23:50,601 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-15 02:23:55,047 - INFO - Fold 1, Epoch 30: Val Acc: 0.81%
2025-08-15 02:23:59,378 - INFO - Fold 1, Epoch 40: Val Acc: 0.66%
2025-08-15 02:24:01,553 - INFO - Fold 1, Epoch 50: Val Acc: 0.69%
2025-08-15 02:24:03,777 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-15 02:24:06,009 - INFO - Fold 1, Epoch 70: Val Acc: 0.69%
2025-08-15 02:24:12,486 - INFO - Fold 1, Epoch 80: Val Acc: 0.84%
2025-08-15 02:24:14,349 - INFO - Fold 1, Epoch 90: Val Acc: 0.78%
2025-08-15 02:24:18,821 - INFO - Fold 1, Epoch 100: Val Acc: 0.78%
2025-08-15 02:24:21,054 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-15 02:24:23,290 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-15 02:24:25,517 - INFO - Fold 1, Epoch 130: Val Acc: 0.75%
2025-08-15 02:24:27,756 - INFO - Fold 1, Epoch 140: Val Acc: 0.59%
2025-08-15 02:24:29,984 - INFO - Fold 1, Epoch 150: Val Acc: 0.62%
2025-08-15 02:24:32,220 - INFO - Fold 1, Epoch 160: Val Acc: 0.78%
2025-08-15 02:24:34,455 - INFO - Fold 1, Epoch 170: Val Acc: 0.78%
2025-08-15 02:24:36,680 - INFO - Fold 1, Epoch 180: Val Acc: 0.59%
2025-08-15 02:24:38,922 - INFO - Fold 1, Epoch 190: Val Acc: 0.75%
2025-08-15 02:24:39,645 - INFO - Early stopping at epoch 194
2025-08-15 02:24:43,273 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:24:43,276 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:24:43,276 - INFO - Starting training for fold 2/3
2025-08-15 02:24:49,963 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-15 02:24:53,632 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-15 02:24:57,275 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-15 02:24:59,499 - INFO - Fold 2, Epoch 40: Val Acc: 0.66%
2025-08-15 02:25:02,964 - INFO - Fold 2, Epoch 50: Val Acc: 0.62%
2025-08-15 02:25:04,666 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-15 02:25:06,779 - INFO - Fold 2, Epoch 70: Val Acc: 0.81%
2025-08-15 02:25:10,494 - INFO - Fold 2, Epoch 80: Val Acc: 0.72%
2025-08-15 02:25:12,732 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-15 02:25:14,960 - INFO - Fold 2, Epoch 100: Val Acc: 0.81%
2025-08-15 02:25:17,038 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-15 02:25:19,035 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-15 02:25:21,014 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-15 02:25:22,946 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-15 02:25:26,300 - INFO - Fold 2, Epoch 150: Val Acc: 0.69%
2025-08-15 02:25:28,271 - INFO - Fold 2, Epoch 160: Val Acc: 0.78%
2025-08-15 02:25:30,243 - INFO - Fold 2, Epoch 170: Val Acc: 0.81%
2025-08-15 02:25:32,344 - INFO - Fold 2, Epoch 180: Val Acc: 0.72%
2025-08-15 02:25:34,557 - INFO - Fold 2, Epoch 190: Val Acc: 0.59%
2025-08-15 02:25:36,772 - INFO - Fold 2, Epoch 200: Val Acc: 0.84%
2025-08-15 02:25:38,989 - INFO - Fold 2, Epoch 210: Val Acc: 0.69%
2025-08-15 02:25:41,208 - INFO - Fold 2, Epoch 220: Val Acc: 0.81%
2025-08-15 02:25:43,432 - INFO - Fold 2, Epoch 230: Val Acc: 0.72%
2025-08-15 02:25:45,650 - INFO - Fold 2, Epoch 240: Val Acc: 0.75%
2025-08-15 02:25:47,271 - INFO - Early stopping at epoch 248
2025-08-15 02:25:48,334 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:25:48,336 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:25:48,336 - INFO - Starting training for fold 3/3
2025-08-15 02:25:57,703 - INFO - Fold 3, Epoch 10: Val Acc: 0.75%
2025-08-15 02:26:00,005 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-15 02:26:03,664 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-15 02:26:05,769 - INFO - Fold 3, Epoch 40: Val Acc: 0.69%
2025-08-15 02:26:07,779 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-15 02:26:11,150 - INFO - Fold 3, Epoch 60: Val Acc: 0.62%
2025-08-15 02:26:13,077 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-15 02:26:15,139 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-15 02:26:17,346 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-15 02:26:19,448 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-15 02:26:21,362 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-15 02:26:23,058 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-15 02:26:27,778 - INFO - Fold 3, Epoch 130: Val Acc: 0.88%
2025-08-15 02:26:29,702 - INFO - Fold 3, Epoch 140: Val Acc: 0.78%
2025-08-15 02:26:31,931 - INFO - Fold 3, Epoch 150: Val Acc: 0.62%
2025-08-15 02:26:34,135 - INFO - Fold 3, Epoch 160: Val Acc: 0.62%
2025-08-15 02:26:36,362 - INFO - Fold 3, Epoch 170: Val Acc: 0.84%
2025-08-15 02:26:38,499 - INFO - Fold 3, Epoch 180: Val Acc: 0.69%
2025-08-15 02:26:40,655 - INFO - Fold 3, Epoch 190: Val Acc: 0.72%
2025-08-15 02:26:42,879 - INFO - Fold 3, Epoch 200: Val Acc: 0.72%
2025-08-15 02:26:45,108 - INFO - Fold 3, Epoch 210: Val Acc: 0.75%
2025-08-15 02:26:47,345 - INFO - Fold 3, Epoch 220: Val Acc: 0.62%
2025-08-15 02:26:48,682 - INFO - Early stopping at epoch 226
2025-08-15 02:26:49,742 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9411449432373047), 'std': np.float64(0.038502747771677615)}, 'train_accuracy': {'mean': np.float64(0.7534722222222223), 'std': np.float64(0.04195502074164781)}, 'val_loss': {'mean': np.float64(4.286753972371419), 'std': np.float64(0.08785629547250944)}, 'val_accuracy': {'mean': np.float64(0.9375), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(121.66666666666667), 'std': np.float64(22.17105219775452)}}
[I 2025-08-15 02:26:49,749] Trial 153 finished with value: -0.9375 and parameters: {'learning_rate': 0.0002993757468820272, 'batch_size': 32, 'num_epochs': 911, 'temperature': 0.3302586386054941, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.20546243706455475, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07665706058765871, 'crop_size': 0.5292996054097349}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 153 finished with value: -0.9375 and parameters: {'learning_rate': 0.0002993757468820272, 'batch_size': 32, 'num_epochs': 911, 'temperature': 0.3302586386054941, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.20546243706455475, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07665706058765871, 'crop_size': 0.5292996054097349}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:26:49,790 - INFO - Using device: cuda
2025-08-15 02:26:59,646 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:26:59,648 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:26:59,648 - INFO - Starting training for fold 1/3
2025-08-15 02:27:09,134 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-15 02:27:13,429 - INFO - Fold 1, Epoch 20: Val Acc: 0.62%
2025-08-15 02:27:15,361 - INFO - Fold 1, Epoch 30: Val Acc: 0.66%
2025-08-15 02:27:19,615 - INFO - Fold 1, Epoch 40: Val Acc: 0.78%
2025-08-15 02:27:21,579 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-15 02:27:23,553 - INFO - Fold 1, Epoch 60: Val Acc: 0.66%
2025-08-15 02:27:27,837 - INFO - Fold 1, Epoch 70: Val Acc: 0.81%
2025-08-15 02:27:30,236 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-15 02:27:32,553 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-15 02:27:34,787 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-15 02:27:39,419 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-15 02:27:41,654 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-15 02:27:45,863 - INFO - Fold 1, Epoch 130: Val Acc: 0.75%
2025-08-15 02:27:50,107 - INFO - Fold 1, Epoch 140: Val Acc: 0.78%
2025-08-15 02:27:52,336 - INFO - Fold 1, Epoch 150: Val Acc: 0.81%
2025-08-15 02:27:54,427 - INFO - Fold 1, Epoch 160: Val Acc: 0.66%
2025-08-15 02:27:56,370 - INFO - Fold 1, Epoch 170: Val Acc: 0.66%
2025-08-15 02:27:58,315 - INFO - Fold 1, Epoch 180: Val Acc: 0.75%
2025-08-15 02:28:00,177 - INFO - Fold 1, Epoch 190: Val Acc: 0.72%
2025-08-15 02:28:01,895 - INFO - Fold 1, Epoch 200: Val Acc: 0.62%
2025-08-15 02:28:03,611 - INFO - Fold 1, Epoch 210: Val Acc: 0.66%
2025-08-15 02:28:05,357 - INFO - Fold 1, Epoch 220: Val Acc: 0.78%
2025-08-15 02:28:07,075 - INFO - Fold 1, Epoch 230: Val Acc: 0.66%
2025-08-15 02:28:07,417 - INFO - Early stopping at epoch 232
2025-08-15 02:28:11,062 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:28:11,065 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:28:11,066 - INFO - Starting training for fold 2/3
2025-08-15 02:28:21,095 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-15 02:28:24,330 - INFO - Fold 2, Epoch 20: Val Acc: 0.53%
2025-08-15 02:28:27,508 - INFO - Fold 2, Epoch 30: Val Acc: 0.59%
2025-08-15 02:28:29,676 - INFO - Fold 2, Epoch 40: Val Acc: 0.50%
2025-08-15 02:28:33,243 - INFO - Fold 2, Epoch 50: Val Acc: 0.72%
2025-08-15 02:28:35,473 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-15 02:28:37,705 - INFO - Fold 2, Epoch 70: Val Acc: 0.88%
2025-08-15 02:28:39,941 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-15 02:28:42,171 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-15 02:28:44,394 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-15 02:28:46,611 - INFO - Fold 2, Epoch 110: Val Acc: 0.78%
2025-08-15 02:28:50,372 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-15 02:28:52,596 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-15 02:28:54,814 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-15 02:28:57,040 - INFO - Fold 2, Epoch 150: Val Acc: 0.84%
2025-08-15 02:28:59,094 - INFO - Fold 2, Epoch 160: Val Acc: 0.72%
2025-08-15 02:29:01,223 - INFO - Fold 2, Epoch 170: Val Acc: 0.78%
2025-08-15 02:29:03,309 - INFO - Fold 2, Epoch 180: Val Acc: 0.78%
2025-08-15 02:29:05,247 - INFO - Fold 2, Epoch 190: Val Acc: 0.81%
2025-08-15 02:29:07,385 - INFO - Fold 2, Epoch 200: Val Acc: 0.69%
2025-08-15 02:29:09,618 - INFO - Fold 2, Epoch 210: Val Acc: 0.75%
2025-08-15 02:29:11,174 - INFO - Early stopping at epoch 217
2025-08-15 02:29:14,025 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:29:14,030 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:29:14,030 - INFO - Starting training for fold 3/3
2025-08-15 02:29:23,497 - INFO - Fold 3, Epoch 10: Val Acc: 0.66%
2025-08-15 02:29:27,126 - INFO - Fold 3, Epoch 20: Val Acc: 0.56%
2025-08-15 02:29:29,357 - INFO - Fold 3, Epoch 30: Val Acc: 0.72%
2025-08-15 02:29:33,000 - INFO - Fold 3, Epoch 40: Val Acc: 0.78%
2025-08-15 02:29:36,493 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-15 02:29:38,726 - INFO - Fold 3, Epoch 60: Val Acc: 0.72%
2025-08-15 02:29:40,934 - INFO - Fold 3, Epoch 70: Val Acc: 0.75%
2025-08-15 02:29:42,801 - INFO - Fold 3, Epoch 80: Val Acc: 0.69%
2025-08-15 02:29:45,885 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-15 02:29:48,114 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-15 02:29:51,815 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-15 02:29:53,784 - INFO - Fold 3, Epoch 120: Val Acc: 0.84%
2025-08-15 02:29:56,012 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-15 02:29:58,256 - INFO - Fold 3, Epoch 140: Val Acc: 0.81%
2025-08-15 02:30:00,497 - INFO - Fold 3, Epoch 150: Val Acc: 0.81%
2025-08-15 02:30:02,808 - INFO - Fold 3, Epoch 160: Val Acc: 0.59%
2025-08-15 02:30:05,114 - INFO - Fold 3, Epoch 170: Val Acc: 0.78%
2025-08-15 02:30:09,020 - INFO - Fold 3, Epoch 180: Val Acc: 0.72%
2025-08-15 02:30:11,253 - INFO - Fold 3, Epoch 190: Val Acc: 0.88%
2025-08-15 02:30:13,478 - INFO - Fold 3, Epoch 200: Val Acc: 0.69%
2025-08-15 02:30:15,697 - INFO - Fold 3, Epoch 210: Val Acc: 0.81%
2025-08-15 02:30:17,805 - INFO - Fold 3, Epoch 220: Val Acc: 0.75%
2025-08-15 02:30:20,031 - INFO - Fold 3, Epoch 230: Val Acc: 0.78%
2025-08-15 02:30:22,313 - INFO - Fold 3, Epoch 240: Val Acc: 0.50%
2025-08-15 02:30:24,549 - INFO - Fold 3, Epoch 250: Val Acc: 0.84%
2025-08-15 02:30:26,763 - INFO - Fold 3, Epoch 260: Val Acc: 0.69%
2025-08-15 02:30:28,997 - INFO - Fold 3, Epoch 270: Val Acc: 0.53%
2025-08-15 02:30:30,777 - INFO - Early stopping at epoch 278
2025-08-15 02:30:31,835 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9059312873416476), 'std': np.float64(0.03392392304487202)}, 'train_accuracy': {'mean': np.float64(0.78125), 'std': np.float64(0.0)}, 'val_loss': {'mean': np.float64(4.21218729019165), 'std': np.float64(0.054475201221728414)}, 'val_accuracy': {'mean': np.float64(0.9479166666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(141.33333333333334), 'std': np.float64(25.952948879762307)}}
[I 2025-08-15 02:30:31,842] Trial 154 finished with value: -0.9479166666666666 and parameters: {'learning_rate': 0.00029104481073119985, 'batch_size': 32, 'num_epochs': 295, 'temperature': 0.3237884207254674, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.20145091831078346, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07560109007382021, 'crop_size': 0.5312985289543445}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 154 finished with value: -0.9479166666666666 and parameters: {'learning_rate': 0.00029104481073119985, 'batch_size': 32, 'num_epochs': 295, 'temperature': 0.3237884207254674, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.20145091831078346, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07560109007382021, 'crop_size': 0.5312985289543445}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:30:31,884 - INFO - Using device: cuda
2025-08-15 02:30:41,711 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:30:41,713 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:30:41,713 - INFO - Starting training for fold 1/3
2025-08-15 02:30:50,868 - INFO - Fold 1, Epoch 10: Val Acc: 0.62%
2025-08-15 02:30:57,304 - INFO - Fold 1, Epoch 20: Val Acc: 0.81%
2025-08-15 02:30:59,640 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-15 02:31:04,153 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-15 02:31:06,473 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-15 02:31:10,880 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-15 02:31:13,109 - INFO - Fold 1, Epoch 70: Val Acc: 0.88%
2025-08-15 02:31:15,210 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-15 02:31:17,427 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-15 02:31:19,657 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-15 02:31:21,887 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-15 02:31:23,894 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-15 02:31:25,650 - INFO - Fold 1, Epoch 130: Val Acc: 0.72%
2025-08-15 02:31:29,261 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:31:29,273 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:31:29,273 - INFO - Starting training for fold 2/3
2025-08-15 02:31:38,363 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-15 02:31:43,424 - INFO - Fold 2, Epoch 20: Val Acc: 0.75%
2025-08-15 02:31:47,133 - INFO - Fold 2, Epoch 30: Val Acc: 0.84%
2025-08-15 02:31:49,151 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-15 02:31:52,859 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-15 02:31:55,091 - INFO - Fold 2, Epoch 60: Val Acc: 0.78%
2025-08-15 02:31:57,322 - INFO - Fold 2, Epoch 70: Val Acc: 0.81%
2025-08-15 02:31:59,550 - INFO - Fold 2, Epoch 80: Val Acc: 0.78%
2025-08-15 02:32:01,515 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-15 02:32:03,217 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-15 02:32:04,919 - INFO - Fold 2, Epoch 110: Val Acc: 0.59%
2025-08-15 02:32:06,989 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-15 02:32:09,224 - INFO - Fold 2, Epoch 130: Val Acc: 0.56%
2025-08-15 02:32:12,270 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:32:12,273 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:32:12,273 - INFO - Starting training for fold 3/3
2025-08-15 02:32:20,567 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-15 02:32:25,597 - INFO - Fold 3, Epoch 20: Val Acc: 0.72%
2025-08-15 02:32:27,799 - INFO - Fold 3, Epoch 30: Val Acc: 0.72%
2025-08-15 02:32:31,588 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-15 02:32:34,893 - INFO - Fold 3, Epoch 50: Val Acc: 0.81%
2025-08-15 02:32:36,606 - INFO - Fold 3, Epoch 60: Val Acc: 0.66%
2025-08-15 02:32:39,648 - INFO - Fold 3, Epoch 70: Val Acc: 0.56%
2025-08-15 02:32:41,827 - INFO - Fold 3, Epoch 80: Val Acc: 0.78%
2025-08-15 02:32:44,057 - INFO - Fold 3, Epoch 90: Val Acc: 0.78%
2025-08-15 02:32:46,289 - INFO - Fold 3, Epoch 100: Val Acc: 0.81%
2025-08-15 02:32:48,530 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-15 02:32:50,763 - INFO - Fold 3, Epoch 120: Val Acc: 0.66%
2025-08-15 02:32:52,991 - INFO - Fold 3, Epoch 130: Val Acc: 0.78%
2025-08-15 02:32:55,839 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.941317531797621), 'std': np.float64(0.02028608279347693)}, 'train_accuracy': {'mean': np.float64(0.7916666666666666), 'std': np.float64(0.01701034543599428)}, 'val_loss': {'mean': np.float64(4.222233136494954), 'std': np.float64(0.048042345866900614)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(53.666666666666664), 'std': np.float64(9.741092797468305)}}
[I 2025-08-15 02:32:55,848] Trial 155 finished with value: -0.90625 and parameters: {'learning_rate': 0.0007717240701077952, 'batch_size': 32, 'num_epochs': 130, 'temperature': 0.32669582409838216, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.19859544899833476, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06640498908673262, 'crop_size': 0.5306241754662557}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 155 finished with value: -0.90625 and parameters: {'learning_rate': 0.0007717240701077952, 'batch_size': 32, 'num_epochs': 130, 'temperature': 0.32669582409838216, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.19859544899833476, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06640498908673262, 'crop_size': 0.5306241754662557}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:32:55,939 - INFO - Using device: cuda
2025-08-15 02:33:05,986 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:33:05,987 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:33:05,987 - INFO - Starting training for fold 1/3
2025-08-15 02:33:15,140 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-15 02:33:19,719 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-15 02:33:21,938 - INFO - Fold 1, Epoch 30: Val Acc: 0.56%
2025-08-15 02:33:24,165 - INFO - Fold 1, Epoch 40: Val Acc: 0.66%
2025-08-15 02:33:26,395 - INFO - Fold 1, Epoch 50: Val Acc: 0.53%
2025-08-15 02:33:28,624 - INFO - Fold 1, Epoch 60: Val Acc: 0.66%
2025-08-15 02:33:35,154 - INFO - Fold 1, Epoch 70: Val Acc: 0.56%
2025-08-15 02:33:39,565 - INFO - Fold 1, Epoch 80: Val Acc: 0.56%
2025-08-15 02:33:44,059 - INFO - Fold 1, Epoch 90: Val Acc: 0.62%
2025-08-15 02:33:46,278 - INFO - Fold 1, Epoch 100: Val Acc: 0.66%
2025-08-15 02:33:48,515 - INFO - Fold 1, Epoch 110: Val Acc: 0.47%
2025-08-15 02:33:50,747 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-15 02:33:52,980 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-15 02:33:55,271 - INFO - Fold 1, Epoch 140: Val Acc: 0.69%
2025-08-15 02:33:57,575 - INFO - Fold 1, Epoch 150: Val Acc: 0.53%
2025-08-15 02:34:02,053 - INFO - Fold 1, Epoch 160: Val Acc: 0.81%
2025-08-15 02:34:04,333 - INFO - Fold 1, Epoch 170: Val Acc: 0.81%
2025-08-15 02:34:06,642 - INFO - Fold 1, Epoch 180: Val Acc: 0.69%
2025-08-15 02:34:08,905 - INFO - Fold 1, Epoch 190: Val Acc: 0.69%
2025-08-15 02:34:10,889 - INFO - Fold 1, Epoch 200: Val Acc: 0.75%
2025-08-15 02:34:15,209 - INFO - Fold 1, Epoch 210: Val Acc: 0.72%
2025-08-15 02:34:17,146 - INFO - Fold 1, Epoch 220: Val Acc: 0.78%
2025-08-15 02:34:21,133 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:34:21,135 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:34:21,136 - INFO - Starting training for fold 2/3
2025-08-15 02:34:26,378 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-15 02:34:29,964 - INFO - Fold 2, Epoch 20: Val Acc: 0.72%
2025-08-15 02:34:32,274 - INFO - Fold 2, Epoch 30: Val Acc: 0.53%
2025-08-15 02:34:34,495 - INFO - Fold 2, Epoch 40: Val Acc: 0.53%
2025-08-15 02:34:36,737 - INFO - Fold 2, Epoch 50: Val Acc: 0.56%
2025-08-15 02:34:38,907 - INFO - Fold 2, Epoch 60: Val Acc: 0.56%
2025-08-15 02:34:42,496 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-15 02:34:46,165 - INFO - Fold 2, Epoch 80: Val Acc: 0.59%
2025-08-15 02:34:48,379 - INFO - Fold 2, Epoch 90: Val Acc: 0.56%
2025-08-15 02:34:51,988 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-15 02:34:54,207 - INFO - Fold 2, Epoch 110: Val Acc: 0.59%
2025-08-15 02:34:56,426 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-15 02:34:58,338 - INFO - Fold 2, Epoch 130: Val Acc: 0.62%
2025-08-15 02:35:00,561 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-15 02:35:02,787 - INFO - Fold 2, Epoch 150: Val Acc: 0.72%
2025-08-15 02:35:05,010 - INFO - Fold 2, Epoch 160: Val Acc: 0.66%
2025-08-15 02:35:07,219 - INFO - Fold 2, Epoch 170: Val Acc: 0.66%
2025-08-15 02:35:09,431 - INFO - Fold 2, Epoch 180: Val Acc: 0.72%
2025-08-15 02:35:11,639 - INFO - Fold 2, Epoch 190: Val Acc: 0.78%
2025-08-15 02:35:11,860 - INFO - Early stopping at epoch 191
2025-08-15 02:35:12,901 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:35:12,903 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:35:12,903 - INFO - Starting training for fold 3/3
2025-08-15 02:35:21,541 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-15 02:35:24,795 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-15 02:35:27,009 - INFO - Fold 3, Epoch 30: Val Acc: 0.59%
2025-08-15 02:35:30,560 - INFO - Fold 3, Epoch 40: Val Acc: 0.44%
2025-08-15 02:35:32,775 - INFO - Fold 3, Epoch 50: Val Acc: 0.59%
2025-08-15 02:35:34,999 - INFO - Fold 3, Epoch 60: Val Acc: 0.38%
2025-08-15 02:35:37,211 - INFO - Fold 3, Epoch 70: Val Acc: 0.34%
2025-08-15 02:35:39,413 - INFO - Fold 3, Epoch 80: Val Acc: 0.66%
2025-08-15 02:35:41,606 - INFO - Fold 3, Epoch 90: Val Acc: 0.56%
2025-08-15 02:35:45,219 - INFO - Fold 3, Epoch 100: Val Acc: 0.62%
2025-08-15 02:35:46,925 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-15 02:35:49,049 - INFO - Fold 3, Epoch 120: Val Acc: 0.56%
2025-08-15 02:35:50,769 - INFO - Fold 3, Epoch 130: Val Acc: 0.59%
2025-08-15 02:35:52,469 - INFO - Fold 3, Epoch 140: Val Acc: 0.53%
2025-08-15 02:35:54,401 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-15 02:35:58,078 - INFO - Fold 3, Epoch 160: Val Acc: 0.56%
2025-08-15 02:36:00,011 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-15 02:36:01,896 - INFO - Fold 3, Epoch 180: Val Acc: 0.69%
2025-08-15 02:36:03,837 - INFO - Fold 3, Epoch 190: Val Acc: 0.69%
2025-08-15 02:36:05,691 - INFO - Fold 3, Epoch 200: Val Acc: 0.72%
2025-08-15 02:36:07,621 - INFO - Fold 3, Epoch 210: Val Acc: 0.72%
2025-08-15 02:36:09,609 - INFO - Fold 3, Epoch 220: Val Acc: 0.69%
2025-08-15 02:36:12,951 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.993702146742079), 'std': np.float64(0.036742785435311995)}, 'train_accuracy': {'mean': np.float64(0.7118055555555557), 'std': np.float64(0.0603407888784124)}, 'val_loss': {'mean': np.float64(4.189380327860515), 'std': np.float64(0.015803801100080363)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(147.33333333333334), 'std': np.float64(45.02838610871542)}}
[I 2025-08-15 02:36:12,964] Trial 156 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0001056414045180921, 'batch_size': 32, 'num_epochs': 222, 'temperature': 0.34182351237542424, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.20711034461447214, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0783544538977403, 'crop_size': 0.5548483039001704}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 156 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0001056414045180921, 'batch_size': 32, 'num_epochs': 222, 'temperature': 0.34182351237542424, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.20711034461447214, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0783544538977403, 'crop_size': 0.5548483039001704}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:36:13,055 - INFO - Using device: cuda
2025-08-15 02:36:22,761 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:36:22,763 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:36:22,763 - INFO - Starting training for fold 1/3
2025-08-15 02:36:33,909 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-15 02:36:40,628 - INFO - Fold 1, Epoch 20: Val Acc: 0.53%
2025-08-15 02:36:47,261 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-15 02:36:53,649 - INFO - Fold 1, Epoch 40: Val Acc: 0.78%
2025-08-15 02:36:55,855 - INFO - Fold 1, Epoch 50: Val Acc: 0.72%
2025-08-15 02:36:58,176 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-15 02:37:00,430 - INFO - Fold 1, Epoch 70: Val Acc: 0.69%
2025-08-15 02:37:02,439 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-15 02:37:06,634 - INFO - Fold 1, Epoch 90: Val Acc: 0.66%
2025-08-15 02:37:08,578 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-15 02:37:10,735 - INFO - Fold 1, Epoch 110: Val Acc: 0.75%
2025-08-15 02:37:12,935 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-15 02:37:15,094 - INFO - Fold 1, Epoch 130: Val Acc: 0.66%
2025-08-15 02:37:17,325 - INFO - Fold 1, Epoch 140: Val Acc: 0.59%
2025-08-15 02:37:19,404 - INFO - Fold 1, Epoch 150: Val Acc: 0.62%
2025-08-15 02:37:21,391 - INFO - Fold 1, Epoch 160: Val Acc: 0.72%
2025-08-15 02:37:23,439 - INFO - Fold 1, Epoch 170: Val Acc: 0.69%
2025-08-15 02:37:25,716 - INFO - Fold 1, Epoch 180: Val Acc: 0.59%
2025-08-15 02:37:26,604 - INFO - Early stopping at epoch 184
2025-08-15 02:37:30,212 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:37:30,214 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:37:30,214 - INFO - Starting training for fold 2/3
2025-08-15 02:37:36,603 - INFO - Fold 2, Epoch 10: Val Acc: 0.53%
2025-08-15 02:37:40,349 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-15 02:37:43,691 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-15 02:37:47,259 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-15 02:37:49,411 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-15 02:37:52,990 - INFO - Fold 2, Epoch 60: Val Acc: 0.91%
2025-08-15 02:37:55,227 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-15 02:37:57,387 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-15 02:37:59,625 - INFO - Fold 2, Epoch 90: Val Acc: 0.75%
2025-08-15 02:38:01,872 - INFO - Fold 2, Epoch 100: Val Acc: 0.81%
2025-08-15 02:38:04,123 - INFO - Fold 2, Epoch 110: Val Acc: 0.81%
2025-08-15 02:38:06,376 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-15 02:38:10,103 - INFO - Fold 2, Epoch 130: Val Acc: 0.72%
2025-08-15 02:38:12,318 - INFO - Fold 2, Epoch 140: Val Acc: 0.69%
2025-08-15 02:38:14,563 - INFO - Fold 2, Epoch 150: Val Acc: 0.66%
2025-08-15 02:38:16,782 - INFO - Fold 2, Epoch 160: Val Acc: 0.81%
2025-08-15 02:38:19,045 - INFO - Fold 2, Epoch 170: Val Acc: 0.66%
2025-08-15 02:38:21,298 - INFO - Fold 2, Epoch 180: Val Acc: 0.72%
2025-08-15 02:38:23,498 - INFO - Fold 2, Epoch 190: Val Acc: 0.72%
2025-08-15 02:38:25,428 - INFO - Fold 2, Epoch 200: Val Acc: 0.81%
2025-08-15 02:38:27,421 - INFO - Fold 2, Epoch 210: Val Acc: 0.81%
2025-08-15 02:38:29,669 - INFO - Fold 2, Epoch 220: Val Acc: 0.84%
2025-08-15 02:38:30,998 - INFO - Early stopping at epoch 226
2025-08-15 02:38:34,117 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:38:34,124 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:38:34,124 - INFO - Starting training for fold 3/3
2025-08-15 02:38:40,945 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-15 02:38:45,797 - INFO - Fold 3, Epoch 20: Val Acc: 0.78%
2025-08-15 02:38:49,448 - INFO - Fold 3, Epoch 30: Val Acc: 0.62%
2025-08-15 02:38:53,344 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-15 02:38:55,832 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-15 02:38:58,324 - INFO - Fold 3, Epoch 60: Val Acc: 0.69%
2025-08-15 02:39:01,827 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-15 02:39:04,075 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-15 02:39:06,323 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-15 02:39:08,590 - INFO - Fold 3, Epoch 100: Val Acc: 0.66%
2025-08-15 02:39:10,835 - INFO - Fold 3, Epoch 110: Val Acc: 0.72%
2025-08-15 02:39:14,414 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-15 02:39:16,537 - INFO - Fold 3, Epoch 130: Val Acc: 0.69%
2025-08-15 02:39:18,662 - INFO - Fold 3, Epoch 140: Val Acc: 0.66%
2025-08-15 02:39:20,778 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-15 02:39:22,984 - INFO - Fold 3, Epoch 160: Val Acc: 0.56%
2025-08-15 02:39:25,223 - INFO - Fold 3, Epoch 170: Val Acc: 0.53%
2025-08-15 02:39:27,459 - INFO - Fold 3, Epoch 180: Val Acc: 0.62%
2025-08-15 02:39:29,706 - INFO - Fold 3, Epoch 190: Val Acc: 0.59%
2025-08-15 02:39:31,959 - INFO - Fold 3, Epoch 200: Val Acc: 0.69%
2025-08-15 02:39:34,211 - INFO - Fold 3, Epoch 210: Val Acc: 0.75%
2025-08-15 02:39:36,239 - INFO - Early stopping at epoch 219
2025-08-15 02:39:39,070 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9162323474884033), 'std': np.float64(0.005464276698863478)}, 'train_accuracy': {'mean': np.float64(0.7881944444444445), 'std': np.float64(0.021404215288086698)}, 'val_loss': {'mean': np.float64(4.252950509389241), 'std': np.float64(0.04200026627529815)}, 'val_accuracy': {'mean': np.float64(0.9375), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(108.66666666666667), 'std': np.float64(18.372685039360892)}}
[I 2025-08-15 02:39:39,084] Trial 157 finished with value: -0.9375 and parameters: {'learning_rate': 0.0004866518408592306, 'batch_size': 32, 'num_epochs': 286, 'temperature': 0.36013101662200026, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.19064566838921707, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07489932802617236, 'crop_size': 0.5415198975781939}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 157 finished with value: -0.9375 and parameters: {'learning_rate': 0.0004866518408592306, 'batch_size': 32, 'num_epochs': 286, 'temperature': 0.36013101662200026, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.19064566838921707, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07489932802617236, 'crop_size': 0.5415198975781939}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:39:39,182 - INFO - Using device: cuda
2025-08-15 02:39:49,364 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:39:49,365 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:39:49,365 - INFO - Starting training for fold 1/3
2025-08-15 02:39:56,219 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-15 02:40:00,566 - INFO - Fold 1, Epoch 20: Val Acc: 0.72%
2025-08-15 02:40:04,977 - INFO - Fold 1, Epoch 30: Val Acc: 0.72%
2025-08-15 02:40:09,240 - INFO - Fold 1, Epoch 40: Val Acc: 0.88%
2025-08-15 02:40:11,477 - INFO - Fold 1, Epoch 50: Val Acc: 0.56%
2025-08-15 02:40:13,573 - INFO - Fold 1, Epoch 60: Val Acc: 0.88%
2025-08-15 02:40:15,793 - INFO - Fold 1, Epoch 70: Val Acc: 0.62%
2025-08-15 02:40:18,056 - INFO - Fold 1, Epoch 80: Val Acc: 0.69%
2025-08-15 02:40:20,306 - INFO - Fold 1, Epoch 90: Val Acc: 0.59%
2025-08-15 02:40:22,644 - INFO - Fold 1, Epoch 100: Val Acc: 0.62%
2025-08-15 02:40:24,983 - INFO - Fold 1, Epoch 110: Val Acc: 0.56%
2025-08-15 02:40:27,324 - INFO - Fold 1, Epoch 120: Val Acc: 0.81%
2025-08-15 02:40:29,663 - INFO - Fold 1, Epoch 130: Val Acc: 0.78%
2025-08-15 02:40:31,788 - INFO - Early stopping at epoch 140
2025-08-15 02:40:34,765 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:40:34,768 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:40:34,769 - INFO - Starting training for fold 2/3
2025-08-15 02:40:43,336 - INFO - Fold 2, Epoch 10: Val Acc: 0.81%
2025-08-15 02:40:45,602 - INFO - Fold 2, Epoch 20: Val Acc: 0.78%
2025-08-15 02:40:47,848 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-15 02:40:50,040 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-15 02:40:54,870 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-15 02:40:58,264 - INFO - Fold 2, Epoch 60: Val Acc: 0.91%
2025-08-15 02:41:00,255 - INFO - Fold 2, Epoch 70: Val Acc: 0.62%
2025-08-15 02:41:02,153 - INFO - Fold 2, Epoch 80: Val Acc: 0.88%
2025-08-15 02:41:04,125 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-15 02:41:06,067 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-15 02:41:07,882 - INFO - Fold 2, Epoch 110: Val Acc: 0.81%
2025-08-15 02:41:09,884 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-15 02:41:11,801 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-15 02:41:13,744 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-15 02:41:15,988 - INFO - Fold 2, Epoch 150: Val Acc: 0.72%
2025-08-15 02:41:18,251 - INFO - Early stopping at epoch 160
2025-08-15 02:41:21,788 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:41:21,790 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:41:21,790 - INFO - Starting training for fold 3/3
2025-08-15 02:41:28,154 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-15 02:41:33,122 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-15 02:41:36,599 - INFO - Fold 3, Epoch 30: Val Acc: 0.69%
2025-08-15 02:41:38,329 - INFO - Fold 3, Epoch 40: Val Acc: 0.59%
2025-08-15 02:41:41,789 - INFO - Fold 3, Epoch 50: Val Acc: 0.75%
2025-08-15 02:41:44,102 - INFO - Fold 3, Epoch 60: Val Acc: 0.88%
2025-08-15 02:41:46,362 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-15 02:41:48,324 - INFO - Fold 3, Epoch 80: Val Acc: 0.84%
2025-08-15 02:41:50,255 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-15 02:41:52,489 - INFO - Fold 3, Epoch 100: Val Acc: 0.81%
2025-08-15 02:41:54,468 - INFO - Fold 3, Epoch 110: Val Acc: 0.62%
2025-08-15 02:41:56,409 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-15 02:41:58,390 - INFO - Fold 3, Epoch 130: Val Acc: 0.62%
2025-08-15 02:42:00,356 - INFO - Fold 3, Epoch 140: Val Acc: 0.78%
2025-08-15 02:42:01,702 - INFO - Early stopping at epoch 146
2025-08-15 02:42:02,742 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.975746340221829), 'std': np.float64(0.02156873898964653)}, 'train_accuracy': {'mean': np.float64(0.7847222222222223), 'std': np.float64(0.054680610236193125)}, 'val_loss': {'mean': np.float64(4.245502948760986), 'std': np.float64(0.09980635084766772)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(47.666666666666664), 'std': np.float64(8.379870059984356)}}
[I 2025-08-15 02:42:02,748] Trial 158 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.000635322303881995, 'batch_size': 32, 'num_epochs': 294, 'temperature': 0.3695676340117491, 'embedding_dim': 256, 'hidden_dim': 128, 'dropout': 0.22179875378098127, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07577166987195783, 'crop_size': 0.5422965975857822}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 158 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.000635322303881995, 'batch_size': 32, 'num_epochs': 294, 'temperature': 0.3695676340117491, 'embedding_dim': 256, 'hidden_dim': 128, 'dropout': 0.22179875378098127, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07577166987195783, 'crop_size': 0.5422965975857822}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:42:02,788 - INFO - Using device: cuda
2025-08-15 02:42:12,646 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:42:12,654 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:42:12,654 - INFO - Starting training for fold 1/3
2025-08-15 02:42:25,435 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-15 02:42:33,393 - INFO - Fold 1, Epoch 20: Val Acc: 0.67%
2025-08-15 02:42:41,798 - INFO - Fold 1, Epoch 30: Val Acc: 0.73%
2025-08-15 02:42:45,669 - INFO - Fold 1, Epoch 40: Val Acc: 0.73%
2025-08-15 02:42:54,280 - INFO - Fold 1, Epoch 50: Val Acc: 0.77%
2025-08-15 02:42:57,959 - INFO - Fold 1, Epoch 60: Val Acc: 0.71%
2025-08-15 02:43:01,148 - INFO - Fold 1, Epoch 70: Val Acc: 0.71%
2025-08-15 02:43:06,908 - INFO - Fold 1, Epoch 80: Val Acc: 0.71%
2025-08-15 02:43:10,755 - INFO - Fold 1, Epoch 90: Val Acc: 0.67%
2025-08-15 02:43:14,610 - INFO - Fold 1, Epoch 100: Val Acc: 0.71%
2025-08-15 02:43:17,849 - INFO - Fold 1, Epoch 110: Val Acc: 0.60%
2025-08-15 02:43:20,855 - INFO - Fold 1, Epoch 120: Val Acc: 0.77%
2025-08-15 02:43:24,532 - INFO - Fold 1, Epoch 130: Val Acc: 0.71%
2025-08-15 02:43:28,233 - INFO - Fold 1, Epoch 140: Val Acc: 0.58%
2025-08-15 02:43:34,211 - INFO - Fold 1, Epoch 150: Val Acc: 0.67%
2025-08-15 02:43:38,080 - INFO - Fold 1, Epoch 160: Val Acc: 0.75%
2025-08-15 02:43:41,957 - INFO - Fold 1, Epoch 170: Val Acc: 0.65%
2025-08-15 02:43:45,851 - INFO - Fold 1, Epoch 180: Val Acc: 0.67%
2025-08-15 02:43:49,588 - INFO - Fold 1, Epoch 190: Val Acc: 0.69%
2025-08-15 02:43:53,314 - INFO - Fold 1, Epoch 200: Val Acc: 0.73%
2025-08-15 02:43:57,089 - INFO - Fold 1, Epoch 210: Val Acc: 0.69%
2025-08-15 02:44:00,638 - INFO - Fold 1, Epoch 220: Val Acc: 0.62%
2025-08-15 02:44:04,063 - INFO - Fold 1, Epoch 230: Val Acc: 0.69%
2025-08-15 02:44:07,583 - INFO - Fold 1, Epoch 240: Val Acc: 0.77%
2025-08-15 02:44:11,001 - INFO - Early stopping at epoch 249
2025-08-15 02:44:14,637 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:44:14,640 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:44:14,640 - INFO - Starting training for fold 2/3
2025-08-15 02:44:25,629 - INFO - Fold 2, Epoch 10: Val Acc: 0.52%
2025-08-15 02:44:32,299 - INFO - Fold 2, Epoch 20: Val Acc: 0.67%
2025-08-15 02:44:36,019 - INFO - Fold 2, Epoch 30: Val Acc: 0.67%
2025-08-15 02:44:40,736 - INFO - Fold 2, Epoch 40: Val Acc: 0.67%
2025-08-15 02:44:44,360 - INFO - Fold 2, Epoch 50: Val Acc: 0.58%
2025-08-15 02:44:49,596 - INFO - Fold 2, Epoch 60: Val Acc: 0.83%
2025-08-15 02:44:53,146 - INFO - Fold 2, Epoch 70: Val Acc: 0.77%
2025-08-15 02:44:56,199 - INFO - Fold 2, Epoch 80: Val Acc: 0.83%
2025-08-15 02:44:59,825 - INFO - Fold 2, Epoch 90: Val Acc: 0.79%
2025-08-15 02:45:03,365 - INFO - Fold 2, Epoch 100: Val Acc: 0.67%
2025-08-15 02:45:06,820 - INFO - Fold 2, Epoch 110: Val Acc: 0.77%
2025-08-15 02:45:10,528 - INFO - Fold 2, Epoch 120: Val Acc: 0.79%
2025-08-15 02:45:14,255 - INFO - Fold 2, Epoch 130: Val Acc: 0.79%
2025-08-15 02:45:17,785 - INFO - Fold 2, Epoch 140: Val Acc: 0.88%
2025-08-15 02:45:21,662 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-15 02:45:23,867 - INFO - Early stopping at epoch 156
2025-08-15 02:45:26,710 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:45:26,716 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:45:26,716 - INFO - Starting training for fold 3/3
2025-08-15 02:45:36,568 - INFO - Fold 3, Epoch 10: Val Acc: 0.69%
2025-08-15 02:45:40,130 - INFO - Fold 3, Epoch 20: Val Acc: 0.65%
2025-08-15 02:45:45,158 - INFO - Fold 3, Epoch 30: Val Acc: 0.67%
2025-08-15 02:45:50,061 - INFO - Fold 3, Epoch 40: Val Acc: 0.88%
2025-08-15 02:45:53,128 - INFO - Fold 3, Epoch 50: Val Acc: 0.81%
2025-08-15 02:45:56,861 - INFO - Fold 3, Epoch 60: Val Acc: 0.73%
2025-08-15 02:46:00,210 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-15 02:46:05,498 - INFO - Fold 3, Epoch 80: Val Acc: 0.77%
2025-08-15 02:46:09,210 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-15 02:46:12,753 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-15 02:46:16,005 - INFO - Fold 3, Epoch 110: Val Acc: 0.79%
2025-08-15 02:46:18,659 - INFO - Fold 3, Epoch 120: Val Acc: 0.73%
2025-08-15 02:46:21,486 - INFO - Fold 3, Epoch 130: Val Acc: 0.67%
2025-08-15 02:46:24,139 - INFO - Fold 3, Epoch 140: Val Acc: 0.77%
2025-08-15 02:46:27,536 - INFO - Fold 3, Epoch 150: Val Acc: 0.81%
2025-08-15 02:46:31,102 - INFO - Fold 3, Epoch 160: Val Acc: 0.75%
2025-08-15 02:46:34,278 - INFO - Fold 3, Epoch 170: Val Acc: 0.56%
2025-08-15 02:46:36,262 - INFO - Early stopping at epoch 176
2025-08-15 02:46:39,274 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.1767751508288913), 'std': np.float64(0.018665993661743617)}, 'train_accuracy': {'mean': np.float64(0.763888888888889), 'std': np.float64(0.029869184955009058)}, 'val_loss': {'mean': np.float64(3.4899327490064835), 'std': np.float64(0.08928813245488311)}, 'val_accuracy': {'mean': np.float64(0.875), 'std': np.float64(0.01701034543599428)}, 'epoch': {'mean': np.float64(92.66666666666667), 'std': np.float64(39.96943276499625)}}
[I 2025-08-15 02:46:39,287] Trial 159 finished with value: -0.875 and parameters: {'learning_rate': 0.00030082763127747277, 'batch_size': 16, 'num_epochs': 286, 'temperature': 0.3564186725272273, 'embedding_dim': 256, 'hidden_dim': 512, 'dropout': 0.2001670801805758, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.5516804095723196}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 159 finished with value: -0.875 and parameters: {'learning_rate': 0.00030082763127747277, 'batch_size': 16, 'num_epochs': 286, 'temperature': 0.3564186725272273, 'embedding_dim': 256, 'hidden_dim': 512, 'dropout': 0.2001670801805758, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.5516804095723196}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:46:39,377 - INFO - Using device: cuda
2025-08-15 02:46:49,269 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:46:49,271 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:46:49,271 - WARNING - Fold 1 has insufficient pairs to form a batch. Skipping.
2025-08-15 02:46:49,271 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:46:49,272 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:46:49,273 - WARNING - Fold 2 has insufficient pairs to form a batch. Skipping.
2025-08-15 02:46:49,273 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:46:49,274 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:46:49,274 - WARNING - Fold 3 has insufficient pairs to form a batch. Skipping.
2025-08-15 02:46:49,274 - WARNING - No folds completed successfully to aggregate metrics.
[I 2025-08-15 02:46:49,276] Trial 160 finished with value: inf and parameters: {'learning_rate': 0.0005051124984942462, 'batch_size': 64, 'num_epochs': 242, 'temperature': 0.31458444540680747, 'embedding_dim': 512, 'hidden_dim': 256, 'dropout': 0.19300289621719538, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06741173330239278, 'crop_size': 0.5320357219373912}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 160 finished with value: inf and parameters: {'learning_rate': 0.0005051124984942462, 'batch_size': 64, 'num_epochs': 242, 'temperature': 0.31458444540680747, 'embedding_dim': 512, 'hidden_dim': 256, 'dropout': 0.19300289621719538, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06741173330239278, 'crop_size': 0.5320357219373912}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:46:49,319 - INFO - Using device: cuda
2025-08-15 02:46:59,216 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:46:59,218 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:46:59,218 - INFO - Starting training for fold 1/3
2025-08-15 02:47:10,526 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-15 02:47:12,828 - INFO - Fold 1, Epoch 20: Val Acc: 0.62%
2025-08-15 02:47:17,387 - INFO - Fold 1, Epoch 30: Val Acc: 0.66%
2025-08-15 02:47:23,561 - INFO - Fold 1, Epoch 40: Val Acc: 0.78%
2025-08-15 02:47:25,518 - INFO - Fold 1, Epoch 50: Val Acc: 0.69%
2025-08-15 02:47:29,903 - INFO - Fold 1, Epoch 60: Val Acc: 0.91%
2025-08-15 02:47:31,938 - INFO - Fold 1, Epoch 70: Val Acc: 0.78%
2025-08-15 02:47:34,180 - INFO - Fold 1, Epoch 80: Val Acc: 0.62%
2025-08-15 02:47:36,426 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-15 02:47:38,669 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-15 02:47:40,915 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-15 02:47:43,144 - INFO - Fold 1, Epoch 120: Val Acc: 0.81%
2025-08-15 02:47:45,392 - INFO - Fold 1, Epoch 130: Val Acc: 0.75%
2025-08-15 02:47:47,605 - INFO - Fold 1, Epoch 140: Val Acc: 0.81%
2025-08-15 02:47:49,838 - INFO - Fold 1, Epoch 150: Val Acc: 0.59%
2025-08-15 02:47:50,726 - INFO - Early stopping at epoch 154
2025-08-15 02:47:54,177 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:47:54,180 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:47:54,181 - INFO - Starting training for fold 2/3
2025-08-15 02:48:00,916 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 02:48:06,019 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-15 02:48:08,252 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-15 02:48:12,545 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-15 02:48:14,765 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-15 02:48:16,980 - INFO - Fold 2, Epoch 60: Val Acc: 0.69%
2025-08-15 02:48:20,637 - INFO - Fold 2, Epoch 70: Val Acc: 0.84%
2025-08-15 02:48:22,942 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-15 02:48:25,244 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-15 02:48:27,541 - INFO - Fold 2, Epoch 100: Val Acc: 0.84%
2025-08-15 02:48:29,861 - INFO - Fold 2, Epoch 110: Val Acc: 0.81%
2025-08-15 02:48:32,176 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-15 02:48:34,496 - INFO - Fold 2, Epoch 130: Val Acc: 0.81%
2025-08-15 02:48:36,825 - INFO - Fold 2, Epoch 140: Val Acc: 0.84%
2025-08-15 02:48:39,142 - INFO - Fold 2, Epoch 150: Val Acc: 0.72%
2025-08-15 02:48:41,450 - INFO - Fold 2, Epoch 160: Val Acc: 0.84%
2025-08-15 02:48:43,299 - INFO - Early stopping at epoch 168
2025-08-15 02:48:44,358 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:48:44,360 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:48:44,361 - INFO - Starting training for fold 3/3
2025-08-15 02:48:49,751 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-15 02:48:56,455 - INFO - Fold 3, Epoch 20: Val Acc: 0.72%
2025-08-15 02:48:58,690 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-15 02:49:00,918 - INFO - Fold 3, Epoch 40: Val Acc: 0.78%
2025-08-15 02:49:03,146 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-15 02:49:05,383 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-15 02:49:10,448 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-15 02:49:12,676 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-15 02:49:14,889 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-15 02:49:17,106 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-15 02:49:19,329 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-15 02:49:21,551 - INFO - Fold 3, Epoch 120: Val Acc: 0.84%
2025-08-15 02:49:23,778 - INFO - Fold 3, Epoch 130: Val Acc: 0.69%
2025-08-15 02:49:26,001 - INFO - Fold 3, Epoch 140: Val Acc: 0.62%
2025-08-15 02:49:28,223 - INFO - Fold 3, Epoch 150: Val Acc: 0.75%
2025-08-15 02:49:30,455 - INFO - Fold 3, Epoch 160: Val Acc: 0.75%
2025-08-15 02:49:32,453 - INFO - Early stopping at epoch 169
2025-08-15 02:49:33,511 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9778229660458035), 'std': np.float64(0.02125004456718811)}, 'train_accuracy': {'mean': np.float64(0.7569444444444443), 'std': np.float64(0.009820927516479791)}, 'val_loss': {'mean': np.float64(4.231248060862224), 'std': np.float64(0.0502717161475984)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.0)}, 'epoch': {'mean': np.float64(62.666666666666664), 'std': np.float64(6.847546194724712)}}
[I 2025-08-15 02:49:33,518] Trial 161 finished with value: -0.90625 and parameters: {'learning_rate': 0.0004755499797919654, 'batch_size': 32, 'num_epochs': 903, 'temperature': 0.335396001833536, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.18749896671529545, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0717528502379891, 'crop_size': 0.5397947901597949}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 161 finished with value: -0.90625 and parameters: {'learning_rate': 0.0004755499797919654, 'batch_size': 32, 'num_epochs': 903, 'temperature': 0.335396001833536, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.18749896671529545, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0717528502379891, 'crop_size': 0.5397947901597949}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:49:33,560 - INFO - Using device: cuda
2025-08-15 02:49:43,410 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:49:43,411 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:49:43,411 - INFO - Starting training for fold 1/3
2025-08-15 02:49:54,995 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-15 02:50:01,581 - INFO - Fold 1, Epoch 20: Val Acc: 0.62%
2025-08-15 02:50:03,311 - INFO - Fold 1, Epoch 30: Val Acc: 0.66%
2025-08-15 02:50:07,944 - INFO - Fold 1, Epoch 40: Val Acc: 0.78%
2025-08-15 02:50:12,447 - INFO - Fold 1, Epoch 50: Val Acc: 0.72%
2025-08-15 02:50:14,521 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-15 02:50:16,651 - INFO - Fold 1, Epoch 70: Val Acc: 0.78%
2025-08-15 02:50:18,752 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-15 02:50:21,060 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-15 02:50:23,373 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-15 02:50:25,682 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-15 02:50:27,998 - INFO - Fold 1, Epoch 120: Val Acc: 0.72%
2025-08-15 02:50:30,322 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-15 02:50:32,237 - INFO - Fold 1, Epoch 140: Val Acc: 0.66%
2025-08-15 02:50:32,600 - INFO - Early stopping at epoch 142
2025-08-15 02:50:36,246 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:50:36,248 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:50:36,248 - INFO - Starting training for fold 2/3
2025-08-15 02:50:44,272 - INFO - Fold 2, Epoch 10: Val Acc: 0.59%
2025-08-15 02:50:49,117 - INFO - Fold 2, Epoch 20: Val Acc: 0.69%
2025-08-15 02:50:53,892 - INFO - Fold 2, Epoch 30: Val Acc: 0.84%
2025-08-15 02:50:56,211 - INFO - Fold 2, Epoch 40: Val Acc: 0.81%
2025-08-15 02:50:58,475 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-15 02:51:02,227 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-15 02:51:04,471 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-15 02:51:06,711 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-15 02:51:08,948 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-15 02:51:11,173 - INFO - Fold 2, Epoch 100: Val Acc: 0.91%
2025-08-15 02:51:13,402 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-15 02:51:15,458 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-15 02:51:17,697 - INFO - Fold 2, Epoch 130: Val Acc: 0.84%
2025-08-15 02:51:19,932 - INFO - Fold 2, Epoch 140: Val Acc: 0.84%
2025-08-15 02:51:22,153 - INFO - Fold 2, Epoch 150: Val Acc: 0.62%
2025-08-15 02:51:22,605 - INFO - Early stopping at epoch 152
2025-08-15 02:51:25,506 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:51:25,508 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:51:25,508 - INFO - Starting training for fold 3/3
2025-08-15 02:51:33,670 - INFO - Fold 3, Epoch 10: Val Acc: 0.72%
2025-08-15 02:51:35,953 - INFO - Fold 3, Epoch 20: Val Acc: 0.66%
2025-08-15 02:51:40,981 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-15 02:51:44,622 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-15 02:51:46,917 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-15 02:51:50,430 - INFO - Fold 3, Epoch 60: Val Acc: 0.72%
2025-08-15 02:51:52,492 - INFO - Fold 3, Epoch 70: Val Acc: 0.78%
2025-08-15 02:51:54,245 - INFO - Fold 3, Epoch 80: Val Acc: 0.69%
2025-08-15 02:51:55,957 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-15 02:51:57,669 - INFO - Fold 3, Epoch 100: Val Acc: 0.62%
2025-08-15 02:51:59,381 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-15 02:52:01,340 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-15 02:52:03,265 - INFO - Fold 3, Epoch 130: Val Acc: 0.78%
2025-08-15 02:52:06,883 - INFO - Fold 3, Epoch 140: Val Acc: 0.81%
2025-08-15 02:52:09,038 - INFO - Fold 3, Epoch 150: Val Acc: 0.66%
2025-08-15 02:52:11,192 - INFO - Fold 3, Epoch 160: Val Acc: 0.72%
2025-08-15 02:52:13,412 - INFO - Fold 3, Epoch 170: Val Acc: 0.81%
2025-08-15 02:52:15,610 - INFO - Fold 3, Epoch 180: Val Acc: 0.72%
2025-08-15 02:52:17,826 - INFO - Fold 3, Epoch 190: Val Acc: 0.69%
2025-08-15 02:52:20,045 - INFO - Fold 3, Epoch 200: Val Acc: 0.69%
2025-08-15 02:52:22,322 - INFO - Fold 3, Epoch 210: Val Acc: 0.62%
2025-08-15 02:52:24,621 - INFO - Fold 3, Epoch 220: Val Acc: 0.84%
2025-08-15 02:52:26,884 - INFO - Fold 3, Epoch 230: Val Acc: 0.81%
2025-08-15 02:52:27,576 - INFO - Early stopping at epoch 233
2025-08-15 02:52:30,512 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.929288996590509), 'std': np.float64(0.044051199382063644)}, 'train_accuracy': {'mean': np.float64(0.8020833333333334), 'std': np.float64(0.05953620902598007)}, 'val_loss': {'mean': np.float64(4.195286750793457), 'std': np.float64(0.07849153149237857)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.06421264586426018)}, 'epoch': {'mean': np.float64(74.66666666666667), 'std': np.float64(40.74582459862878)}}
[I 2025-08-15 02:52:30,519] Trial 162 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0005882064152125671, 'batch_size': 32, 'num_epochs': 876, 'temperature': 0.36553289966203945, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.15008606630912477, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08139671461539522, 'crop_size': 0.5654817952459813}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 162 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0005882064152125671, 'batch_size': 32, 'num_epochs': 876, 'temperature': 0.36553289966203945, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.15008606630912477, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08139671461539522, 'crop_size': 0.5654817952459813}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:52:30,562 - INFO - Using device: cuda
2025-08-15 02:52:40,379 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:52:40,380 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:52:40,380 - INFO - Starting training for fold 1/3
2025-08-15 02:52:49,729 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-15 02:52:56,518 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-15 02:52:58,758 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-15 02:53:00,994 - INFO - Fold 1, Epoch 40: Val Acc: 0.62%
2025-08-15 02:53:03,234 - INFO - Fold 1, Epoch 50: Val Acc: 0.50%
2025-08-15 02:53:12,653 - INFO - Fold 1, Epoch 60: Val Acc: 0.84%
2025-08-15 02:53:17,201 - INFO - Fold 1, Epoch 70: Val Acc: 0.56%
2025-08-15 02:53:19,435 - INFO - Fold 1, Epoch 80: Val Acc: 0.78%
2025-08-15 02:53:21,671 - INFO - Fold 1, Epoch 90: Val Acc: 0.78%
2025-08-15 02:53:23,904 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-15 02:53:26,130 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-15 02:53:28,331 - INFO - Fold 1, Epoch 120: Val Acc: 0.72%
2025-08-15 02:53:30,406 - INFO - Fold 1, Epoch 130: Val Acc: 0.81%
2025-08-15 02:53:32,645 - INFO - Fold 1, Epoch 140: Val Acc: 0.66%
2025-08-15 02:53:34,375 - INFO - Fold 1, Epoch 150: Val Acc: 0.78%
2025-08-15 02:53:36,087 - INFO - Fold 1, Epoch 160: Val Acc: 0.69%
2025-08-15 02:53:37,550 - INFO - Early stopping at epoch 168
2025-08-15 02:53:43,914 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:53:43,915 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:53:43,915 - INFO - Starting training for fold 2/3
2025-08-15 02:53:50,764 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 02:53:53,006 - INFO - Fold 2, Epoch 20: Val Acc: 0.53%
2025-08-15 02:53:54,964 - INFO - Fold 2, Epoch 30: Val Acc: 0.59%
2025-08-15 02:53:58,560 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-15 02:54:02,288 - INFO - Fold 2, Epoch 50: Val Acc: 0.62%
2025-08-15 02:54:05,981 - INFO - Fold 2, Epoch 60: Val Acc: 0.62%
2025-08-15 02:54:08,200 - INFO - Fold 2, Epoch 70: Val Acc: 0.62%
2025-08-15 02:54:10,044 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-15 02:54:11,912 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-15 02:54:13,950 - INFO - Fold 2, Epoch 100: Val Acc: 0.72%
2025-08-15 02:54:16,179 - INFO - Fold 2, Epoch 110: Val Acc: 0.78%
2025-08-15 02:54:18,404 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-15 02:54:20,637 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-15 02:54:24,379 - INFO - Fold 2, Epoch 140: Val Acc: 0.84%
2025-08-15 02:54:26,615 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-15 02:54:28,852 - INFO - Fold 2, Epoch 160: Val Acc: 0.72%
2025-08-15 02:54:31,085 - INFO - Fold 2, Epoch 170: Val Acc: 0.75%
2025-08-15 02:54:33,311 - INFO - Fold 2, Epoch 180: Val Acc: 0.88%
2025-08-15 02:54:35,279 - INFO - Fold 2, Epoch 190: Val Acc: 0.75%
2025-08-15 02:54:37,225 - INFO - Fold 2, Epoch 200: Val Acc: 0.81%
2025-08-15 02:54:39,228 - INFO - Fold 2, Epoch 210: Val Acc: 0.78%
2025-08-15 02:54:41,212 - INFO - Fold 2, Epoch 220: Val Acc: 0.78%
2025-08-15 02:54:43,159 - INFO - Fold 2, Epoch 230: Val Acc: 0.78%
2025-08-15 02:54:44,158 - INFO - Early stopping at epoch 235
2025-08-15 02:54:47,322 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:54:47,325 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:54:47,326 - INFO - Starting training for fold 3/3
2025-08-15 02:54:53,850 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-15 02:54:55,856 - INFO - Fold 3, Epoch 20: Val Acc: 0.47%
2025-08-15 02:54:58,092 - INFO - Fold 3, Epoch 30: Val Acc: 0.59%
2025-08-15 02:55:01,683 - INFO - Fold 3, Epoch 40: Val Acc: 0.53%
2025-08-15 02:55:05,194 - INFO - Fold 3, Epoch 50: Val Acc: 0.75%
2025-08-15 02:55:06,917 - INFO - Fold 3, Epoch 60: Val Acc: 0.62%
2025-08-15 02:55:08,630 - INFO - Fold 3, Epoch 70: Val Acc: 0.56%
2025-08-15 02:55:10,344 - INFO - Fold 3, Epoch 80: Val Acc: 0.81%
2025-08-15 02:55:13,796 - INFO - Fold 3, Epoch 90: Val Acc: 0.78%
2025-08-15 02:55:17,509 - INFO - Fold 3, Epoch 100: Val Acc: 0.81%
2025-08-15 02:55:19,812 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-15 02:55:22,138 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-15 02:55:24,403 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-15 02:55:26,643 - INFO - Fold 3, Epoch 140: Val Acc: 0.84%
2025-08-15 02:55:28,875 - INFO - Fold 3, Epoch 150: Val Acc: 0.81%
2025-08-15 02:55:31,101 - INFO - Fold 3, Epoch 160: Val Acc: 0.81%
2025-08-15 02:55:33,320 - INFO - Fold 3, Epoch 170: Val Acc: 0.84%
2025-08-15 02:55:35,577 - INFO - Fold 3, Epoch 180: Val Acc: 0.81%
2025-08-15 02:55:37,915 - INFO - Fold 3, Epoch 190: Val Acc: 0.66%
2025-08-15 02:55:39,076 - INFO - Early stopping at epoch 195
2025-08-15 02:55:40,127 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.980535401238335), 'std': np.float64(0.043318730119920455)}, 'train_accuracy': {'mean': np.float64(0.75), 'std': np.float64(0.022502571869471726)}, 'val_loss': {'mean': np.float64(4.14874792098999), 'std': np.float64(0.0878580856912898)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(98.33333333333333), 'std': np.float64(27.52372713779069)}}
[I 2025-08-15 02:55:40,133] Trial 163 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.00022896268153120417, 'batch_size': 32, 'num_epochs': 269, 'temperature': 0.40333407155671114, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.1647303638244479, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07608507444870578, 'crop_size': 0.5584789029887819}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 163 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.00022896268153120417, 'batch_size': 32, 'num_epochs': 269, 'temperature': 0.40333407155671114, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.1647303638244479, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07608507444870578, 'crop_size': 0.5584789029887819}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:55:40,180 - INFO - Using device: cuda
2025-08-15 02:55:49,900 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:55:49,901 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:55:49,902 - INFO - Starting training for fold 1/3
2025-08-15 02:55:53,407 - INFO - Fold 1, Epoch 10: Val Acc: 0.66%
2025-08-15 02:55:54,938 - INFO - Fold 1, Epoch 20: Val Acc: 0.53%
2025-08-15 02:55:57,478 - INFO - Fold 1, Epoch 30: Val Acc: 0.72%
2025-08-15 02:55:59,625 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-15 02:56:01,588 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-15 02:56:03,039 - INFO - Fold 1, Epoch 60: Val Acc: 0.84%
2025-08-15 02:56:04,469 - INFO - Fold 1, Epoch 70: Val Acc: 0.62%
2025-08-15 02:56:06,332 - INFO - Fold 1, Epoch 80: Val Acc: 0.75%
2025-08-15 02:56:07,527 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-15 02:56:08,884 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-15 02:56:10,304 - INFO - Fold 1, Epoch 110: Val Acc: 0.78%
2025-08-15 02:56:11,734 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-15 02:56:13,134 - INFO - Fold 1, Epoch 130: Val Acc: 0.84%
2025-08-15 02:56:14,560 - INFO - Fold 1, Epoch 140: Val Acc: 0.62%
2025-08-15 02:56:15,975 - INFO - Fold 1, Epoch 150: Val Acc: 0.69%
2025-08-15 02:56:17,410 - INFO - Fold 1, Epoch 160: Val Acc: 0.75%
2025-08-15 02:56:18,850 - INFO - Fold 1, Epoch 170: Val Acc: 0.72%
2025-08-15 02:56:18,990 - INFO - Early stopping at epoch 171
2025-08-15 02:56:19,869 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:56:19,872 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:56:19,872 - INFO - Starting training for fold 2/3
2025-08-15 02:56:22,714 - INFO - Fold 2, Epoch 10: Val Acc: 0.53%
2025-08-15 02:56:25,034 - INFO - Fold 2, Epoch 20: Val Acc: 0.69%
2025-08-15 02:56:27,247 - INFO - Fold 2, Epoch 30: Val Acc: 0.75%
2025-08-15 02:56:29,004 - INFO - Fold 2, Epoch 40: Val Acc: 0.78%
2025-08-15 02:56:30,319 - INFO - Fold 2, Epoch 50: Val Acc: 0.72%
2025-08-15 02:56:31,711 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-15 02:56:33,102 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-15 02:56:34,495 - INFO - Fold 2, Epoch 80: Val Acc: 0.66%
2025-08-15 02:56:35,793 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-15 02:56:37,162 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-15 02:56:38,403 - INFO - Fold 2, Epoch 110: Val Acc: 0.81%
2025-08-15 02:56:39,755 - INFO - Fold 2, Epoch 120: Val Acc: 0.66%
2025-08-15 02:56:41,114 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-15 02:56:42,198 - INFO - Early stopping at epoch 138
2025-08-15 02:56:42,434 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:56:42,436 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:56:42,436 - INFO - Starting training for fold 3/3
2025-08-15 02:56:45,760 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-15 02:56:47,569 - INFO - Fold 3, Epoch 20: Val Acc: 0.78%
2025-08-15 02:56:49,061 - INFO - Fold 3, Epoch 30: Val Acc: 0.75%
2025-08-15 02:56:51,039 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-15 02:56:52,478 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-15 02:56:53,879 - INFO - Fold 3, Epoch 60: Val Acc: 0.81%
2025-08-15 02:56:55,722 - INFO - Fold 3, Epoch 70: Val Acc: 0.75%
2025-08-15 02:56:57,080 - INFO - Fold 3, Epoch 80: Val Acc: 0.78%
2025-08-15 02:56:58,426 - INFO - Fold 3, Epoch 90: Val Acc: 0.66%
2025-08-15 02:56:59,724 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-15 02:57:01,136 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-15 02:57:02,569 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-15 02:57:03,992 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-15 02:57:05,379 - INFO - Fold 3, Epoch 140: Val Acc: 0.75%
2025-08-15 02:57:06,640 - INFO - Fold 3, Epoch 150: Val Acc: 0.78%
2025-08-15 02:57:07,978 - INFO - Fold 3, Epoch 160: Val Acc: 0.84%
2025-08-15 02:57:09,055 - INFO - Early stopping at epoch 168
2025-08-15 02:57:09,761 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.005481719970703), 'std': np.float64(0.06570547144864011)}, 'train_accuracy': {'mean': np.float64(0.7465277777777777), 'std': np.float64(0.021404215288086698)}, 'val_loss': {'mean': np.float64(4.160337924957275), 'std': np.float64(0.044720524016259984)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(58.0), 'std': np.float64(14.89966442575134)}}
[I 2025-08-15 02:57:09,769] Trial 164 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0003634690473289325, 'batch_size': 32, 'num_epochs': 917, 'temperature': 0.3826954925335112, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2107241937791643, 'num_layers': 1, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.10034981466814498, 'crop_size': 0.5126848571175768}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 164 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0003634690473289325, 'batch_size': 32, 'num_epochs': 917, 'temperature': 0.3826954925335112, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2107241937791643, 'num_layers': 1, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.10034981466814498, 'crop_size': 0.5126848571175768}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:57:09,855 - INFO - Using device: cuda
2025-08-15 02:57:19,857 - INFO - --- Starting Fold 1/3 ---
2025-08-15 02:57:19,859 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:57:19,859 - INFO - Starting training for fold 1/3
2025-08-15 02:57:28,836 - INFO - Fold 1, Epoch 10: Val Acc: 0.41%
2025-08-15 02:57:35,320 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-15 02:57:39,837 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-15 02:57:46,335 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-15 02:57:48,090 - INFO - Fold 1, Epoch 50: Val Acc: 0.59%
2025-08-15 02:57:49,910 - INFO - Fold 1, Epoch 60: Val Acc: 0.66%
2025-08-15 02:57:52,134 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-15 02:57:54,347 - INFO - Fold 1, Epoch 80: Val Acc: 0.81%
2025-08-15 02:57:56,589 - INFO - Fold 1, Epoch 90: Val Acc: 0.66%
2025-08-15 02:58:01,165 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-15 02:58:03,401 - INFO - Fold 1, Epoch 110: Val Acc: 0.59%
2025-08-15 02:58:05,629 - INFO - Fold 1, Epoch 120: Val Acc: 0.66%
2025-08-15 02:58:07,856 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-15 02:58:10,029 - INFO - Fold 1, Epoch 140: Val Acc: 0.72%
2025-08-15 02:58:12,259 - INFO - Fold 1, Epoch 150: Val Acc: 0.59%
2025-08-15 02:58:14,256 - INFO - Fold 1, Epoch 160: Val Acc: 0.66%
2025-08-15 02:58:16,115 - INFO - Fold 1, Epoch 170: Val Acc: 0.62%
2025-08-15 02:58:18,350 - INFO - Fold 1, Epoch 180: Val Acc: 0.62%
2025-08-15 02:58:20,580 - INFO - Fold 1, Epoch 190: Val Acc: 0.78%
2025-08-15 02:58:21,920 - INFO - Early stopping at epoch 196
2025-08-15 02:58:25,524 - INFO - --- Starting Fold 2/3 ---
2025-08-15 02:58:25,526 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:58:25,526 - INFO - Starting training for fold 2/3
2025-08-15 02:58:35,232 - INFO - Fold 2, Epoch 10: Val Acc: 0.62%
2025-08-15 02:58:39,924 - INFO - Fold 2, Epoch 20: Val Acc: 0.69%
2025-08-15 02:58:43,384 - INFO - Fold 2, Epoch 30: Val Acc: 0.81%
2025-08-15 02:58:45,704 - INFO - Fold 2, Epoch 40: Val Acc: 0.81%
2025-08-15 02:58:49,342 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-15 02:58:51,304 - INFO - Fold 2, Epoch 60: Val Acc: 0.88%
2025-08-15 02:58:53,589 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-15 02:58:55,761 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-15 02:58:57,897 - INFO - Fold 2, Epoch 90: Val Acc: 0.62%
2025-08-15 02:59:00,200 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-15 02:59:02,503 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-15 02:59:04,388 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-15 02:59:06,537 - INFO - Fold 2, Epoch 130: Val Acc: 0.66%
2025-08-15 02:59:08,788 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-15 02:59:10,534 - INFO - Early stopping at epoch 149
2025-08-15 02:59:13,582 - INFO - --- Starting Fold 3/3 ---
2025-08-15 02:59:13,584 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 02:59:13,585 - INFO - Starting training for fold 3/3
2025-08-15 02:59:17,243 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-15 02:59:22,402 - INFO - Fold 3, Epoch 20: Val Acc: 0.75%
2025-08-15 02:59:24,370 - INFO - Fold 3, Epoch 30: Val Acc: 0.69%
2025-08-15 02:59:26,194 - INFO - Fold 3, Epoch 40: Val Acc: 0.62%
2025-08-15 02:59:28,422 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-15 02:59:30,650 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-15 02:59:32,893 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-15 02:59:35,051 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-15 02:59:36,770 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-15 02:59:40,429 - INFO - Fold 3, Epoch 100: Val Acc: 0.66%
2025-08-15 02:59:42,654 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-15 02:59:44,894 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-15 02:59:46,968 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-15 02:59:48,815 - INFO - Fold 3, Epoch 140: Val Acc: 0.62%
2025-08-15 02:59:50,781 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-15 02:59:52,740 - INFO - Fold 3, Epoch 160: Val Acc: 0.69%
2025-08-15 02:59:54,724 - INFO - Fold 3, Epoch 170: Val Acc: 0.69%
2025-08-15 02:59:56,651 - INFO - Fold 3, Epoch 180: Val Acc: 0.75%
2025-08-15 02:59:58,594 - INFO - Fold 3, Epoch 190: Val Acc: 0.81%
2025-08-15 02:59:58,789 - INFO - Early stopping at epoch 191
2025-08-15 02:59:59,809 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.925282769733005), 'std': np.float64(0.06899731387189932)}, 'train_accuracy': {'mean': np.float64(0.78125), 'std': np.float64(0.0)}, 'val_loss': {'mean': np.float64(4.343721071879069), 'std': np.float64(0.07577385366441794)}, 'val_accuracy': {'mean': np.float64(0.9270833333333334), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(77.66666666666667), 'std': np.float64(21.076579946049648)}}
[I 2025-08-15 02:59:59,815] Trial 165 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0006910912259401272, 'batch_size': 32, 'num_epochs': 853, 'temperature': 0.3260881436484443, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.25105178600830763, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06010712549552981, 'crop_size': 0.5305166610245561}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 165 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0006910912259401272, 'batch_size': 32, 'num_epochs': 853, 'temperature': 0.3260881436484443, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.25105178600830763, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06010712549552981, 'crop_size': 0.5305166610245561}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 02:59:59,858 - INFO - Using device: cuda
2025-08-15 03:00:09,442 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:00:09,443 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:00:09,444 - INFO - Starting training for fold 1/3
2025-08-15 03:00:18,412 - INFO - Fold 1, Epoch 10: Val Acc: 0.69%
2025-08-15 03:00:22,887 - INFO - Fold 1, Epoch 20: Val Acc: 0.78%
2025-08-15 03:00:25,238 - INFO - Fold 1, Epoch 30: Val Acc: 0.69%
2025-08-15 03:00:29,785 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-15 03:00:34,417 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-15 03:00:36,663 - INFO - Fold 1, Epoch 60: Val Acc: 0.66%
2025-08-15 03:00:38,971 - INFO - Fold 1, Epoch 70: Val Acc: 0.81%
2025-08-15 03:00:41,293 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-15 03:00:43,606 - INFO - Fold 1, Epoch 90: Val Acc: 0.62%
2025-08-15 03:00:45,932 - INFO - Fold 1, Epoch 100: Val Acc: 0.78%
2025-08-15 03:00:48,261 - INFO - Fold 1, Epoch 110: Val Acc: 0.59%
2025-08-15 03:00:50,577 - INFO - Fold 1, Epoch 120: Val Acc: 0.59%
2025-08-15 03:00:52,887 - INFO - Fold 1, Epoch 130: Val Acc: 0.66%
2025-08-15 03:00:55,127 - INFO - Fold 1, Epoch 140: Val Acc: 0.84%
2025-08-15 03:00:56,243 - INFO - Early stopping at epoch 145
2025-08-15 03:00:59,768 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:00:59,770 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:00:59,771 - INFO - Starting training for fold 2/3
2025-08-15 03:01:04,813 - INFO - Fold 2, Epoch 10: Val Acc: 0.59%
2025-08-15 03:01:08,577 - INFO - Fold 2, Epoch 20: Val Acc: 0.75%
2025-08-15 03:01:10,801 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-15 03:01:14,639 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-15 03:01:16,863 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-15 03:01:19,040 - INFO - Fold 2, Epoch 60: Val Acc: 0.84%
2025-08-15 03:01:20,896 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-15 03:01:23,108 - INFO - Fold 2, Epoch 80: Val Acc: 0.78%
2025-08-15 03:01:25,345 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-15 03:01:27,575 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-15 03:01:29,808 - INFO - Fold 2, Epoch 110: Val Acc: 0.66%
2025-08-15 03:01:32,040 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-15 03:01:34,088 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-15 03:01:34,777 - INFO - Early stopping at epoch 134
2025-08-15 03:01:35,818 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:01:35,828 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:01:35,829 - INFO - Starting training for fold 3/3
2025-08-15 03:01:44,307 - INFO - Fold 3, Epoch 10: Val Acc: 0.72%
2025-08-15 03:01:47,861 - INFO - Fold 3, Epoch 20: Val Acc: 0.78%
2025-08-15 03:01:52,775 - INFO - Fold 3, Epoch 30: Val Acc: 0.88%
2025-08-15 03:01:55,009 - INFO - Fold 3, Epoch 40: Val Acc: 0.78%
2025-08-15 03:01:58,541 - INFO - Fold 3, Epoch 50: Val Acc: 0.88%
2025-08-15 03:02:00,620 - INFO - Fold 3, Epoch 60: Val Acc: 0.88%
2025-08-15 03:02:02,841 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-15 03:02:05,058 - INFO - Fold 3, Epoch 80: Val Acc: 0.84%
2025-08-15 03:02:07,278 - INFO - Fold 3, Epoch 90: Val Acc: 0.66%
2025-08-15 03:02:09,503 - INFO - Fold 3, Epoch 100: Val Acc: 0.78%
2025-08-15 03:02:11,721 - INFO - Fold 3, Epoch 110: Val Acc: 0.62%
2025-08-15 03:02:13,950 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-15 03:02:16,189 - INFO - Fold 3, Epoch 130: Val Acc: 0.84%
2025-08-15 03:02:18,415 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-15 03:02:19,323 - INFO - Early stopping at epoch 144
2025-08-15 03:02:22,406 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.917310953140259), 'std': np.float64(0.02143944523194305)}, 'train_accuracy': {'mean': np.float64(0.7291666666666666), 'std': np.float64(0.038975597778895185)}, 'val_loss': {'mean': np.float64(4.2305270830790205), 'std': np.float64(0.021165945636109813)}, 'val_accuracy': {'mean': np.float64(0.9270833333333334), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(40.0), 'std': np.float64(4.96655480858378)}}
[I 2025-08-15 03:02:22,413] Trial 166 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0008504368401636179, 'batch_size': 32, 'num_epochs': 305, 'temperature': 0.4283360445352138, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2241472559162493, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07551517336367257, 'crop_size': 0.5466677254520657}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 166 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0008504368401636179, 'batch_size': 32, 'num_epochs': 305, 'temperature': 0.4283360445352138, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2241472559162493, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07551517336367257, 'crop_size': 0.5466677254520657}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:02:22,456 - INFO - Using device: cuda
2025-08-15 03:02:32,285 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:02:32,286 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:02:32,286 - INFO - Starting training for fold 1/3
2025-08-15 03:02:41,456 - INFO - Fold 1, Epoch 10: Val Acc: 0.62%
2025-08-15 03:02:43,768 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-15 03:02:45,963 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-15 03:02:48,055 - INFO - Fold 1, Epoch 40: Val Acc: 0.50%
2025-08-15 03:02:50,282 - INFO - Fold 1, Epoch 50: Val Acc: 0.47%
2025-08-15 03:02:52,522 - INFO - Fold 1, Epoch 60: Val Acc: 0.59%
2025-08-15 03:02:54,533 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-15 03:02:56,590 - INFO - Fold 1, Epoch 80: Val Acc: 0.47%
2025-08-15 03:02:58,540 - INFO - Fold 1, Epoch 90: Val Acc: 0.53%
2025-08-15 03:03:02,809 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-15 03:03:04,842 - INFO - Fold 1, Epoch 110: Val Acc: 0.47%
2025-08-15 03:03:06,918 - INFO - Fold 1, Epoch 120: Val Acc: 0.50%
2025-08-15 03:03:09,160 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-15 03:03:11,401 - INFO - Fold 1, Epoch 140: Val Acc: 0.66%
2025-08-15 03:03:15,763 - INFO - Fold 1, Epoch 150: Val Acc: 0.53%
2025-08-15 03:03:18,001 - INFO - Fold 1, Epoch 160: Val Acc: 0.62%
2025-08-15 03:03:23,433 - INFO - Fold 1, Epoch 170: Val Acc: 0.53%
2025-08-15 03:03:27,571 - INFO - Fold 1, Epoch 180: Val Acc: 0.78%
2025-08-15 03:03:29,623 - INFO - Fold 1, Epoch 190: Val Acc: 0.62%
2025-08-15 03:03:31,579 - INFO - Fold 1, Epoch 200: Val Acc: 0.66%
2025-08-15 03:03:33,578 - INFO - Fold 1, Epoch 210: Val Acc: 0.56%
2025-08-15 03:03:35,532 - INFO - Fold 1, Epoch 220: Val Acc: 0.53%
2025-08-15 03:03:37,487 - INFO - Fold 1, Epoch 230: Val Acc: 0.62%
2025-08-15 03:03:39,397 - INFO - Fold 1, Epoch 240: Val Acc: 0.59%
2025-08-15 03:03:41,623 - INFO - Fold 1, Epoch 250: Val Acc: 0.56%
2025-08-15 03:03:43,858 - INFO - Fold 1, Epoch 260: Val Acc: 0.56%
2025-08-15 03:03:46,044 - INFO - Fold 1, Epoch 270: Val Acc: 0.72%
2025-08-15 03:03:50,371 - INFO - Fold 1, Epoch 280: Val Acc: 0.56%
2025-08-15 03:03:52,326 - INFO - Fold 1, Epoch 290: Val Acc: 0.81%
2025-08-15 03:03:54,255 - INFO - Fold 1, Epoch 300: Val Acc: 0.59%
2025-08-15 03:03:56,133 - INFO - Fold 1, Epoch 310: Val Acc: 0.66%
2025-08-15 03:03:58,197 - INFO - Fold 1, Epoch 320: Val Acc: 0.78%
2025-08-15 03:04:00,216 - INFO - Fold 1, Epoch 330: Val Acc: 0.66%
2025-08-15 03:04:02,533 - INFO - Fold 1, Epoch 340: Val Acc: 0.69%
2025-08-15 03:04:04,850 - INFO - Fold 1, Epoch 350: Val Acc: 0.81%
2025-08-15 03:04:07,167 - INFO - Fold 1, Epoch 360: Val Acc: 0.72%
2025-08-15 03:04:11,506 - INFO - Fold 1, Epoch 370: Val Acc: 0.75%
2025-08-15 03:04:13,319 - INFO - Fold 1, Epoch 380: Val Acc: 0.72%
2025-08-15 03:04:15,239 - INFO - Fold 1, Epoch 390: Val Acc: 0.75%
2025-08-15 03:04:17,281 - INFO - Fold 1, Epoch 400: Val Acc: 0.81%
2025-08-15 03:04:19,483 - INFO - Fold 1, Epoch 410: Val Acc: 0.62%
2025-08-15 03:04:21,805 - INFO - Fold 1, Epoch 420: Val Acc: 0.72%
2025-08-15 03:04:24,110 - INFO - Fold 1, Epoch 430: Val Acc: 0.78%
2025-08-15 03:04:26,207 - INFO - Fold 1, Epoch 440: Val Acc: 0.69%
2025-08-15 03:04:28,266 - INFO - Fold 1, Epoch 450: Val Acc: 0.69%
2025-08-15 03:04:30,267 - INFO - Fold 1, Epoch 460: Val Acc: 0.72%
2025-08-15 03:04:30,470 - INFO - Early stopping at epoch 461
2025-08-15 03:04:34,070 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:04:34,072 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:04:34,073 - INFO - Starting training for fold 2/3
2025-08-15 03:04:40,760 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-15 03:04:42,986 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-15 03:04:45,220 - INFO - Fold 2, Epoch 30: Val Acc: 0.50%
2025-08-15 03:04:50,622 - INFO - Fold 2, Epoch 40: Val Acc: 0.53%
2025-08-15 03:04:52,857 - INFO - Fold 2, Epoch 50: Val Acc: 0.66%
2025-08-15 03:04:55,085 - INFO - Fold 2, Epoch 60: Val Acc: 0.53%
2025-08-15 03:04:58,807 - INFO - Fold 2, Epoch 70: Val Acc: 0.50%
2025-08-15 03:05:01,027 - INFO - Fold 2, Epoch 80: Val Acc: 0.56%
2025-08-15 03:05:02,957 - INFO - Fold 2, Epoch 90: Val Acc: 0.56%
2025-08-15 03:05:05,201 - INFO - Fold 2, Epoch 100: Val Acc: 0.69%
2025-08-15 03:05:07,433 - INFO - Fold 2, Epoch 110: Val Acc: 0.47%
2025-08-15 03:05:09,665 - INFO - Fold 2, Epoch 120: Val Acc: 0.66%
2025-08-15 03:05:11,551 - INFO - Fold 2, Epoch 130: Val Acc: 0.62%
2025-08-15 03:05:13,276 - INFO - Fold 2, Epoch 140: Val Acc: 0.50%
2025-08-15 03:05:15,502 - INFO - Fold 2, Epoch 150: Val Acc: 0.69%
2025-08-15 03:05:17,737 - INFO - Fold 2, Epoch 160: Val Acc: 0.59%
2025-08-15 03:05:19,075 - INFO - Early stopping at epoch 166
2025-08-15 03:05:20,120 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:05:20,122 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:05:20,122 - INFO - Starting training for fold 3/3
2025-08-15 03:05:25,597 - INFO - Fold 3, Epoch 10: Val Acc: 0.41%
2025-08-15 03:05:29,286 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-15 03:05:31,504 - INFO - Fold 3, Epoch 30: Val Acc: 0.50%
2025-08-15 03:05:38,478 - INFO - Fold 3, Epoch 40: Val Acc: 0.47%
2025-08-15 03:05:40,507 - INFO - Fold 3, Epoch 50: Val Acc: 0.47%
2025-08-15 03:05:42,495 - INFO - Fold 3, Epoch 60: Val Acc: 0.56%
2025-08-15 03:05:44,580 - INFO - Fold 3, Epoch 70: Val Acc: 0.53%
2025-08-15 03:05:46,547 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-15 03:05:48,445 - INFO - Fold 3, Epoch 90: Val Acc: 0.50%
2025-08-15 03:05:50,628 - INFO - Fold 3, Epoch 100: Val Acc: 0.62%
2025-08-15 03:05:52,952 - INFO - Fold 3, Epoch 110: Val Acc: 0.62%
2025-08-15 03:05:55,274 - INFO - Fold 3, Epoch 120: Val Acc: 0.62%
2025-08-15 03:05:57,595 - INFO - Fold 3, Epoch 130: Val Acc: 0.53%
2025-08-15 03:05:59,680 - INFO - Early stopping at epoch 139
2025-08-15 03:06:00,768 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.099601931042142), 'std': np.float64(0.09318894968190751)}, 'train_accuracy': {'mean': np.float64(0.5798611111111112), 'std': np.float64(0.05126674673692148)}, 'val_loss': {'mean': np.float64(4.281612714131673), 'std': np.float64(0.010640444087978092)}, 'val_accuracy': {'mean': np.float64(0.8020833333333334), 'std': np.float64(0.05311478659992484)}, 'epoch': {'mean': np.float64(154.33333333333334), 'std': np.float64(145.84542806988804)}}
[I 2025-08-15 03:06:00,779] Trial 167 finished with value: -0.8020833333333334 and parameters: {'learning_rate': 3.257378559156377e-05, 'batch_size': 32, 'num_epochs': 462, 'temperature': 0.3493608391331277, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2141194419414103, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.09160236057125863, 'crop_size': 0.5224300043090445}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 167 finished with value: -0.8020833333333334 and parameters: {'learning_rate': 3.257378559156377e-05, 'batch_size': 32, 'num_epochs': 462, 'temperature': 0.3493608391331277, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2141194419414103, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.09160236057125863, 'crop_size': 0.5224300043090445}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:06:00,837 - INFO - Using device: cuda
2025-08-15 03:06:10,746 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:06:10,747 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:06:10,747 - INFO - Starting training for fold 1/3
2025-08-15 03:06:17,878 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-15 03:06:20,190 - INFO - Fold 1, Epoch 20: Val Acc: 0.38%
2025-08-15 03:06:22,553 - INFO - Fold 1, Epoch 30: Val Acc: 0.53%
2025-08-15 03:06:27,506 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-15 03:06:29,836 - INFO - Fold 1, Epoch 50: Val Acc: 0.38%
2025-08-15 03:06:32,131 - INFO - Fold 1, Epoch 60: Val Acc: 0.50%
2025-08-15 03:06:34,405 - INFO - Fold 1, Epoch 70: Val Acc: 0.59%
2025-08-15 03:06:36,492 - INFO - Fold 1, Epoch 80: Val Acc: 0.50%
2025-08-15 03:06:40,846 - INFO - Fold 1, Epoch 90: Val Acc: 0.38%
2025-08-15 03:06:43,116 - INFO - Fold 1, Epoch 100: Val Acc: 0.56%
2025-08-15 03:06:47,636 - INFO - Fold 1, Epoch 110: Val Acc: 0.44%
2025-08-15 03:06:49,897 - INFO - Fold 1, Epoch 120: Val Acc: 0.44%
2025-08-15 03:06:52,161 - INFO - Fold 1, Epoch 130: Val Acc: 0.59%
2025-08-15 03:06:54,499 - INFO - Fold 1, Epoch 140: Val Acc: 0.53%
2025-08-15 03:06:59,450 - INFO - Fold 1, Epoch 150: Val Acc: 0.59%
2025-08-15 03:07:01,718 - INFO - Fold 1, Epoch 160: Val Acc: 0.56%
2025-08-15 03:07:03,982 - INFO - Fold 1, Epoch 170: Val Acc: 0.59%
2025-08-15 03:07:06,240 - INFO - Fold 1, Epoch 180: Val Acc: 0.56%
2025-08-15 03:07:08,515 - INFO - Fold 1, Epoch 190: Val Acc: 0.47%
2025-08-15 03:07:10,784 - INFO - Fold 1, Epoch 200: Val Acc: 0.44%
2025-08-15 03:07:13,049 - INFO - Fold 1, Epoch 210: Val Acc: 0.62%
2025-08-15 03:07:15,315 - INFO - Fold 1, Epoch 220: Val Acc: 0.59%
2025-08-15 03:07:17,580 - INFO - Fold 1, Epoch 230: Val Acc: 0.44%
2025-08-15 03:07:19,812 - INFO - Fold 1, Epoch 240: Val Acc: 0.56%
2025-08-15 03:07:20,510 - INFO - Early stopping at epoch 244
2025-08-15 03:07:24,440 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:07:24,442 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:07:24,443 - INFO - Starting training for fold 2/3
2025-08-15 03:07:29,921 - INFO - Fold 2, Epoch 10: Val Acc: 0.47%
2025-08-15 03:07:32,173 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-15 03:07:34,268 - INFO - Fold 2, Epoch 30: Val Acc: 0.62%
2025-08-15 03:07:36,527 - INFO - Fold 2, Epoch 40: Val Acc: 0.56%
2025-08-15 03:07:39,797 - INFO - Fold 2, Epoch 50: Val Acc: 0.62%
2025-08-15 03:07:43,176 - INFO - Fold 2, Epoch 60: Val Acc: 0.47%
2025-08-15 03:07:45,126 - INFO - Fold 2, Epoch 70: Val Acc: 0.47%
2025-08-15 03:07:47,109 - INFO - Fold 2, Epoch 80: Val Acc: 0.50%
2025-08-15 03:07:50,754 - INFO - Fold 2, Epoch 90: Val Acc: 0.47%
2025-08-15 03:07:53,034 - INFO - Fold 2, Epoch 100: Val Acc: 0.53%
2025-08-15 03:07:55,370 - INFO - Fold 2, Epoch 110: Val Acc: 0.50%
2025-08-15 03:07:57,708 - INFO - Fold 2, Epoch 120: Val Acc: 0.53%
2025-08-15 03:08:00,037 - INFO - Fold 2, Epoch 130: Val Acc: 0.53%
2025-08-15 03:08:02,381 - INFO - Fold 2, Epoch 140: Val Acc: 0.44%
2025-08-15 03:08:04,721 - INFO - Fold 2, Epoch 150: Val Acc: 0.50%
2025-08-15 03:08:06,938 - INFO - Fold 2, Epoch 160: Val Acc: 0.50%
2025-08-15 03:08:08,992 - INFO - Fold 2, Epoch 170: Val Acc: 0.47%
2025-08-15 03:08:11,112 - INFO - Fold 2, Epoch 180: Val Acc: 0.53%
2025-08-15 03:08:12,152 - INFO - Early stopping at epoch 185
2025-08-15 03:08:15,148 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:08:15,150 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:08:15,150 - INFO - Starting training for fold 3/3
2025-08-15 03:08:20,353 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-15 03:08:22,307 - INFO - Fold 3, Epoch 20: Val Acc: 0.50%
2025-08-15 03:08:24,245 - INFO - Fold 3, Epoch 30: Val Acc: 0.44%
2025-08-15 03:08:26,191 - INFO - Fold 3, Epoch 40: Val Acc: 0.44%
2025-08-15 03:08:31,129 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-15 03:08:33,517 - INFO - Fold 3, Epoch 60: Val Acc: 0.56%
2025-08-15 03:08:35,812 - INFO - Fold 3, Epoch 70: Val Acc: 0.56%
2025-08-15 03:08:38,079 - INFO - Fold 3, Epoch 80: Val Acc: 0.47%
2025-08-15 03:08:40,342 - INFO - Fold 3, Epoch 90: Val Acc: 0.53%
2025-08-15 03:08:42,613 - INFO - Fold 3, Epoch 100: Val Acc: 0.47%
2025-08-15 03:08:44,872 - INFO - Fold 3, Epoch 110: Val Acc: 0.69%
2025-08-15 03:08:47,131 - INFO - Fold 3, Epoch 120: Val Acc: 0.50%
2025-08-15 03:08:49,402 - INFO - Fold 3, Epoch 130: Val Acc: 0.47%
2025-08-15 03:08:51,669 - INFO - Fold 3, Epoch 140: Val Acc: 0.53%
2025-08-15 03:08:53,936 - INFO - Early stopping at epoch 150
2025-08-15 03:08:54,971 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.144425921969943), 'std': np.float64(0.018131798834966597)}, 'train_accuracy': {'mean': np.float64(0.5416666666666666), 'std': np.float64(0.008505172717997162)}, 'val_loss': {'mean': np.float64(4.163521607716878), 'std': np.float64(0.02725200101994427)}, 'val_accuracy': {'mean': np.float64(0.7395833333333334), 'std': np.float64(0.03897559777889522)}, 'epoch': {'mean': np.float64(92.0), 'std': np.float64(38.79003308411411)}}
[I 2025-08-15 03:08:54,987] Trial 168 finished with value: -0.7395833333333334 and parameters: {'learning_rate': 0.00031990862422904664, 'batch_size': 32, 'num_epochs': 961, 'temperature': 0.3926347808719333, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2398602787062458, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.08421750111512673}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 168 finished with value: -0.7395833333333334 and parameters: {'learning_rate': 0.00031990862422904664, 'batch_size': 32, 'num_epochs': 961, 'temperature': 0.3926347808719333, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2398602787062458, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': False, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.08421750111512673}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:08:55,030 - INFO - Using device: cuda
2025-08-15 03:09:04,696 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:09:04,697 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:09:04,698 - INFO - Starting training for fold 1/3
2025-08-15 03:09:15,858 - INFO - Fold 1, Epoch 10: Val Acc: 0.69%
2025-08-15 03:09:17,771 - INFO - Fold 1, Epoch 20: Val Acc: 0.75%
2025-08-15 03:09:24,252 - INFO - Fold 1, Epoch 30: Val Acc: 0.78%
2025-08-15 03:09:26,414 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-15 03:09:28,228 - INFO - Fold 1, Epoch 50: Val Acc: 0.72%
2025-08-15 03:09:30,365 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-15 03:09:32,343 - INFO - Fold 1, Epoch 70: Val Acc: 0.84%
2025-08-15 03:09:34,180 - INFO - Fold 1, Epoch 80: Val Acc: 0.62%
2025-08-15 03:09:36,367 - INFO - Fold 1, Epoch 90: Val Acc: 0.66%
2025-08-15 03:09:38,623 - INFO - Fold 1, Epoch 100: Val Acc: 0.56%
2025-08-15 03:09:40,695 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-15 03:09:42,925 - INFO - Fold 1, Epoch 120: Val Acc: 0.66%
2025-08-15 03:09:44,933 - INFO - Early stopping at epoch 129
2025-08-15 03:09:48,489 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:09:48,492 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:09:48,492 - INFO - Starting training for fold 2/3
2025-08-15 03:09:55,191 - INFO - Fold 2, Epoch 10: Val Acc: 0.72%
2025-08-15 03:09:57,585 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-15 03:10:03,089 - INFO - Fold 2, Epoch 30: Val Acc: 0.81%
2025-08-15 03:10:05,059 - INFO - Fold 2, Epoch 40: Val Acc: 0.78%
2025-08-15 03:10:07,110 - INFO - Fold 2, Epoch 50: Val Acc: 0.72%
2025-08-15 03:10:09,326 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-15 03:10:12,926 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-15 03:10:16,536 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-15 03:10:18,732 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-15 03:10:20,947 - INFO - Fold 2, Epoch 100: Val Acc: 0.69%
2025-08-15 03:10:23,165 - INFO - Fold 2, Epoch 110: Val Acc: 0.62%
2025-08-15 03:10:25,393 - INFO - Fold 2, Epoch 120: Val Acc: 0.84%
2025-08-15 03:10:27,605 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-15 03:10:29,820 - INFO - Fold 2, Epoch 140: Val Acc: 0.88%
2025-08-15 03:10:32,044 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-15 03:10:34,264 - INFO - Fold 2, Epoch 160: Val Acc: 0.84%
2025-08-15 03:10:36,477 - INFO - Fold 2, Epoch 170: Val Acc: 0.53%
2025-08-15 03:10:37,787 - INFO - Early stopping at epoch 176
2025-08-15 03:10:40,754 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:10:40,757 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:10:40,758 - INFO - Starting training for fold 3/3
2025-08-15 03:10:47,592 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-15 03:10:49,816 - INFO - Fold 3, Epoch 20: Val Acc: 0.84%
2025-08-15 03:10:52,039 - INFO - Fold 3, Epoch 30: Val Acc: 0.62%
2025-08-15 03:10:54,258 - INFO - Fold 3, Epoch 40: Val Acc: 0.56%
2025-08-15 03:10:56,437 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-15 03:10:58,399 - INFO - Fold 3, Epoch 60: Val Acc: 0.66%
2025-08-15 03:11:00,426 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-15 03:11:04,107 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-15 03:11:06,326 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-15 03:11:08,550 - INFO - Fold 3, Epoch 100: Val Acc: 0.84%
2025-08-15 03:11:10,768 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-15 03:11:12,992 - INFO - Fold 3, Epoch 120: Val Acc: 0.69%
2025-08-15 03:11:15,213 - INFO - Fold 3, Epoch 130: Val Acc: 0.78%
2025-08-15 03:11:17,142 - INFO - Fold 3, Epoch 140: Val Acc: 0.62%
2025-08-15 03:11:19,147 - INFO - Fold 3, Epoch 150: Val Acc: 0.75%
2025-08-15 03:11:22,519 - INFO - Fold 3, Epoch 160: Val Acc: 0.69%
2025-08-15 03:11:24,683 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-15 03:11:26,878 - INFO - Fold 3, Epoch 180: Val Acc: 0.72%
2025-08-15 03:11:29,082 - INFO - Fold 3, Epoch 190: Val Acc: 0.78%
2025-08-15 03:11:30,971 - INFO - Fold 3, Epoch 200: Val Acc: 0.81%
2025-08-15 03:11:32,779 - INFO - Fold 3, Epoch 210: Val Acc: 0.59%
2025-08-15 03:11:34,995 - INFO - Fold 3, Epoch 220: Val Acc: 0.78%
2025-08-15 03:11:37,221 - INFO - Fold 3, Epoch 230: Val Acc: 0.78%
2025-08-15 03:11:39,446 - INFO - Fold 3, Epoch 240: Val Acc: 0.66%
2025-08-15 03:11:41,518 - INFO - Fold 3, Epoch 250: Val Acc: 0.69%
2025-08-15 03:11:42,186 - INFO - Early stopping at epoch 253
2025-08-15 03:11:45,207 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9185250335269504), 'std': np.float64(0.05881428255750029)}, 'train_accuracy': {'mean': np.float64(0.7916666666666666), 'std': np.float64(0.03897559777889522)}, 'val_loss': {'mean': np.float64(4.26935338973999), 'std': np.float64(0.012453784825015246)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(85.0), 'std': np.float64(51.11425111127685)}}
[I 2025-08-15 03:11:45,219] Trial 169 finished with value: -0.90625 and parameters: {'learning_rate': 0.0005484932054600092, 'batch_size': 32, 'num_epochs': 891, 'temperature': 0.3411819738504078, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.18843936271150144, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.10645740809407189, 'crop_size': 0.5032675283481993}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 169 finished with value: -0.90625 and parameters: {'learning_rate': 0.0005484932054600092, 'batch_size': 32, 'num_epochs': 891, 'temperature': 0.3411819738504078, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.18843936271150144, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.10645740809407189, 'crop_size': 0.5032675283481993}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:11:45,311 - INFO - Using device: cuda
2025-08-15 03:11:55,181 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:11:55,183 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:11:55,183 - INFO - Starting training for fold 1/3
2025-08-15 03:12:05,366 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-15 03:12:12,726 - INFO - Fold 1, Epoch 20: Val Acc: 0.66%
2025-08-15 03:12:17,794 - INFO - Fold 1, Epoch 30: Val Acc: 0.56%
2025-08-15 03:12:22,936 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-15 03:12:28,055 - INFO - Fold 1, Epoch 50: Val Acc: 0.50%
2025-08-15 03:12:30,297 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-15 03:12:32,753 - INFO - Fold 1, Epoch 70: Val Acc: 0.62%
2025-08-15 03:12:37,838 - INFO - Fold 1, Epoch 80: Val Acc: 0.62%
2025-08-15 03:12:40,293 - INFO - Fold 1, Epoch 90: Val Acc: 0.78%
2025-08-15 03:12:42,756 - INFO - Fold 1, Epoch 100: Val Acc: 0.81%
2025-08-15 03:12:45,201 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-15 03:12:47,656 - INFO - Fold 1, Epoch 120: Val Acc: 0.78%
2025-08-15 03:12:50,116 - INFO - Fold 1, Epoch 130: Val Acc: 0.75%
2025-08-15 03:12:52,572 - INFO - Fold 1, Epoch 140: Val Acc: 0.53%
2025-08-15 03:12:55,040 - INFO - Fold 1, Epoch 150: Val Acc: 0.75%
2025-08-15 03:12:57,501 - INFO - Fold 1, Epoch 160: Val Acc: 0.72%
2025-08-15 03:12:59,958 - INFO - Fold 1, Epoch 170: Val Acc: 0.62%
2025-08-15 03:13:00,695 - INFO - Early stopping at epoch 173
2025-08-15 03:13:04,729 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:13:04,732 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:13:04,733 - INFO - Starting training for fold 2/3
2025-08-15 03:13:15,500 - INFO - Fold 2, Epoch 10: Val Acc: 0.69%
2025-08-15 03:13:19,350 - INFO - Fold 2, Epoch 20: Val Acc: 0.62%
2025-08-15 03:13:21,386 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-15 03:13:25,024 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-15 03:13:27,481 - INFO - Fold 2, Epoch 50: Val Acc: 0.62%
2025-08-15 03:13:31,241 - INFO - Fold 2, Epoch 60: Val Acc: 0.62%
2025-08-15 03:13:33,265 - INFO - Fold 2, Epoch 70: Val Acc: 0.81%
2025-08-15 03:13:35,382 - INFO - Fold 2, Epoch 80: Val Acc: 0.81%
2025-08-15 03:13:37,915 - INFO - Fold 2, Epoch 90: Val Acc: 0.75%
2025-08-15 03:13:40,443 - INFO - Fold 2, Epoch 100: Val Acc: 0.81%
2025-08-15 03:13:42,981 - INFO - Fold 2, Epoch 110: Val Acc: 0.91%
2025-08-15 03:13:45,479 - INFO - Fold 2, Epoch 120: Val Acc: 0.66%
2025-08-15 03:13:47,770 - INFO - Fold 2, Epoch 130: Val Acc: 0.81%
2025-08-15 03:13:50,314 - INFO - Fold 2, Epoch 140: Val Acc: 0.84%
2025-08-15 03:13:52,702 - INFO - Fold 2, Epoch 150: Val Acc: 0.81%
2025-08-15 03:13:53,075 - INFO - Early stopping at epoch 152
2025-08-15 03:13:54,344 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:13:54,346 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:13:54,347 - INFO - Starting training for fold 3/3
2025-08-15 03:14:03,828 - INFO - Fold 3, Epoch 10: Val Acc: 0.66%
2025-08-15 03:14:09,543 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-15 03:14:13,466 - INFO - Fold 3, Epoch 30: Val Acc: 0.75%
2025-08-15 03:14:15,451 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-15 03:14:17,474 - INFO - Fold 3, Epoch 50: Val Acc: 0.81%
2025-08-15 03:14:19,765 - INFO - Fold 3, Epoch 60: Val Acc: 0.69%
2025-08-15 03:14:22,138 - INFO - Fold 3, Epoch 70: Val Acc: 0.66%
2025-08-15 03:14:25,911 - INFO - Fold 3, Epoch 80: Val Acc: 0.88%
2025-08-15 03:14:30,071 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-15 03:14:32,027 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-15 03:14:34,233 - INFO - Fold 3, Epoch 110: Val Acc: 0.69%
2025-08-15 03:14:36,496 - INFO - Fold 3, Epoch 120: Val Acc: 0.66%
2025-08-15 03:14:38,952 - INFO - Fold 3, Epoch 130: Val Acc: 0.78%
2025-08-15 03:14:41,417 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-15 03:14:43,590 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-15 03:14:45,946 - INFO - Fold 3, Epoch 160: Val Acc: 0.75%
2025-08-15 03:14:48,071 - INFO - Fold 3, Epoch 170: Val Acc: 0.66%
2025-08-15 03:14:50,167 - INFO - Fold 3, Epoch 180: Val Acc: 0.69%
2025-08-15 03:14:50,382 - INFO - Early stopping at epoch 181
2025-08-15 03:14:53,642 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9720371299319797), 'std': np.float64(0.03177547578098622)}, 'train_accuracy': {'mean': np.float64(0.7569444444444445), 'std': np.float64(0.004910463758239948)}, 'val_loss': {'mean': np.float64(4.2134528160095215), 'std': np.float64(0.1038357500380988)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(67.66666666666667), 'std': np.float64(12.229290885229426)}}
[I 2025-08-15 03:14:53,654] Trial 170 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0003962438521865698, 'batch_size': 32, 'num_epochs': 880, 'temperature': 0.31440776059251047, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.47391171894540957, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.051667719694045836, 'crop_size': 0.5382897965541226}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 170 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0003962438521865698, 'batch_size': 32, 'num_epochs': 880, 'temperature': 0.31440776059251047, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.47391171894540957, 'num_layers': 6, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.051667719694045836, 'crop_size': 0.5382897965541226}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:14:53,747 - INFO - Using device: cuda
2025-08-15 03:15:03,555 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:15:03,557 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:15:03,557 - INFO - Starting training for fold 1/3
2025-08-15 03:15:14,758 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-15 03:15:21,142 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-15 03:15:23,131 - INFO - Fold 1, Epoch 30: Val Acc: 0.72%
2025-08-15 03:15:29,350 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-15 03:15:33,138 - INFO - Fold 1, Epoch 50: Val Acc: 0.84%
2025-08-15 03:15:37,009 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-15 03:15:38,724 - INFO - Fold 1, Epoch 70: Val Acc: 0.62%
2025-08-15 03:15:40,631 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-15 03:15:42,344 - INFO - Fold 1, Epoch 90: Val Acc: 0.81%
2025-08-15 03:15:44,056 - INFO - Fold 1, Epoch 100: Val Acc: 0.66%
2025-08-15 03:15:45,769 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-15 03:15:47,482 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-15 03:15:49,208 - INFO - Fold 1, Epoch 130: Val Acc: 0.66%
2025-08-15 03:15:51,192 - INFO - Fold 1, Epoch 140: Val Acc: 0.62%
2025-08-15 03:15:53,184 - INFO - Fold 1, Epoch 150: Val Acc: 0.62%
2025-08-15 03:15:54,484 - INFO - Early stopping at epoch 156
2025-08-15 03:15:58,055 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:15:58,057 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:15:58,058 - INFO - Starting training for fold 2/3
2025-08-15 03:16:01,988 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-15 03:16:08,422 - INFO - Fold 2, Epoch 20: Val Acc: 0.62%
2025-08-15 03:16:13,254 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-15 03:16:15,278 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-15 03:16:17,505 - INFO - Fold 2, Epoch 50: Val Acc: 0.62%
2025-08-15 03:16:19,707 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-15 03:16:21,947 - INFO - Fold 2, Epoch 70: Val Acc: 0.69%
2025-08-15 03:16:25,441 - INFO - Fold 2, Epoch 80: Val Acc: 0.78%
2025-08-15 03:16:28,827 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-15 03:16:30,835 - INFO - Fold 2, Epoch 100: Val Acc: 0.72%
2025-08-15 03:16:33,166 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-15 03:16:35,171 - INFO - Fold 2, Epoch 120: Val Acc: 0.78%
2025-08-15 03:16:37,504 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-15 03:16:39,686 - INFO - Fold 2, Epoch 140: Val Acc: 0.84%
2025-08-15 03:16:41,819 - INFO - Fold 2, Epoch 150: Val Acc: 0.81%
2025-08-15 03:16:43,943 - INFO - Fold 2, Epoch 160: Val Acc: 0.84%
2025-08-15 03:16:46,171 - INFO - Fold 2, Epoch 170: Val Acc: 0.84%
2025-08-15 03:16:48,392 - INFO - Fold 2, Epoch 180: Val Acc: 0.69%
2025-08-15 03:16:48,581 - INFO - Early stopping at epoch 181
2025-08-15 03:16:51,410 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:16:51,413 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:16:51,413 - INFO - Starting training for fold 3/3
2025-08-15 03:16:58,053 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-15 03:17:03,092 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-15 03:17:05,315 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-15 03:17:09,028 - INFO - Fold 3, Epoch 40: Val Acc: 0.69%
2025-08-15 03:17:11,112 - INFO - Fold 3, Epoch 50: Val Acc: 0.62%
2025-08-15 03:17:13,153 - INFO - Fold 3, Epoch 60: Val Acc: 0.81%
2025-08-15 03:17:16,683 - INFO - Fold 3, Epoch 70: Val Acc: 0.88%
2025-08-15 03:17:20,358 - INFO - Fold 3, Epoch 80: Val Acc: 0.88%
2025-08-15 03:17:22,578 - INFO - Fold 3, Epoch 90: Val Acc: 0.56%
2025-08-15 03:17:24,792 - INFO - Fold 3, Epoch 100: Val Acc: 0.81%
2025-08-15 03:17:27,007 - INFO - Fold 3, Epoch 110: Val Acc: 0.69%
2025-08-15 03:17:29,233 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-15 03:17:31,465 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-15 03:17:33,688 - INFO - Fold 3, Epoch 140: Val Acc: 0.81%
2025-08-15 03:17:35,917 - INFO - Fold 3, Epoch 150: Val Acc: 0.75%
2025-08-15 03:17:38,140 - INFO - Fold 3, Epoch 160: Val Acc: 0.78%
2025-08-15 03:17:40,357 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-15 03:17:42,131 - INFO - Early stopping at epoch 178
2025-08-15 03:17:43,164 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9251906871795654), 'std': np.float64(0.022901970976040558)}, 'train_accuracy': {'mean': np.float64(0.7395833333333334), 'std': np.float64(0.008505172717997117)}, 'val_loss': {'mean': np.float64(4.121096928914388), 'std': np.float64(0.09056301847739713)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(70.66666666666667), 'std': np.float64(11.14550233153366)}}
[I 2025-08-15 03:17:43,170] Trial 171 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.000419866554188736, 'batch_size': 32, 'num_epochs': 322, 'temperature': 0.302318999745944, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.1780447817101292, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08785264462463246, 'crop_size': 0.516925758121089}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 171 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.000419866554188736, 'batch_size': 32, 'num_epochs': 322, 'temperature': 0.302318999745944, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.1780447817101292, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08785264462463246, 'crop_size': 0.516925758121089}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:17:43,213 - INFO - Using device: cuda
2025-08-15 03:17:53,106 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:17:53,107 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:17:53,107 - INFO - Starting training for fold 1/3
2025-08-15 03:17:57,687 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-15 03:18:03,895 - INFO - Fold 1, Epoch 20: Val Acc: 0.81%
2025-08-15 03:18:05,857 - INFO - Fold 1, Epoch 30: Val Acc: 0.53%
2025-08-15 03:18:07,583 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-15 03:18:13,150 - INFO - Fold 1, Epoch 50: Val Acc: 0.66%
2025-08-15 03:18:15,385 - INFO - Fold 1, Epoch 60: Val Acc: 0.66%
2025-08-15 03:18:17,612 - INFO - Fold 1, Epoch 70: Val Acc: 0.78%
2025-08-15 03:18:19,843 - INFO - Fold 1, Epoch 80: Val Acc: 0.62%
2025-08-15 03:18:22,080 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-15 03:18:24,008 - INFO - Fold 1, Epoch 100: Val Acc: 0.62%
2025-08-15 03:18:25,732 - INFO - Fold 1, Epoch 110: Val Acc: 0.88%
2025-08-15 03:18:27,860 - INFO - Fold 1, Epoch 120: Val Acc: 0.78%
2025-08-15 03:18:30,097 - INFO - Fold 1, Epoch 130: Val Acc: 0.72%
2025-08-15 03:18:32,342 - INFO - Fold 1, Epoch 140: Val Acc: 0.75%
2025-08-15 03:18:33,240 - INFO - Early stopping at epoch 144
2025-08-15 03:18:36,747 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:18:36,749 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:18:36,750 - INFO - Starting training for fold 2/3
2025-08-15 03:18:43,666 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 03:18:47,343 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-15 03:18:49,570 - INFO - Fold 2, Epoch 30: Val Acc: 0.53%
2025-08-15 03:18:53,101 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-15 03:18:56,709 - INFO - Fold 2, Epoch 50: Val Acc: 0.84%
2025-08-15 03:18:58,933 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-15 03:19:01,170 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-15 03:19:03,410 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-15 03:19:05,642 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-15 03:19:09,259 - INFO - Fold 2, Epoch 100: Val Acc: 0.72%
2025-08-15 03:19:11,491 - INFO - Fold 2, Epoch 110: Val Acc: 0.81%
2025-08-15 03:19:13,730 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-15 03:19:15,963 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-15 03:19:18,202 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-15 03:19:20,438 - INFO - Fold 2, Epoch 150: Val Acc: 0.81%
2025-08-15 03:19:22,676 - INFO - Fold 2, Epoch 160: Val Acc: 0.88%
2025-08-15 03:19:24,907 - INFO - Fold 2, Epoch 170: Val Acc: 0.72%
2025-08-15 03:19:27,136 - INFO - Fold 2, Epoch 180: Val Acc: 0.72%
2025-08-15 03:19:29,367 - INFO - Fold 2, Epoch 190: Val Acc: 0.84%
2025-08-15 03:19:29,588 - INFO - Early stopping at epoch 191
2025-08-15 03:19:30,618 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:19:30,620 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:19:30,621 - INFO - Starting training for fold 3/3
2025-08-15 03:19:37,276 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-15 03:19:40,815 - INFO - Fold 3, Epoch 20: Val Acc: 0.47%
2025-08-15 03:19:44,187 - INFO - Fold 3, Epoch 30: Val Acc: 0.62%
2025-08-15 03:19:46,024 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-15 03:19:50,921 - INFO - Fold 3, Epoch 50: Val Acc: 0.81%
2025-08-15 03:19:53,162 - INFO - Fold 3, Epoch 60: Val Acc: 0.78%
2025-08-15 03:19:56,837 - INFO - Fold 3, Epoch 70: Val Acc: 0.75%
2025-08-15 03:19:59,063 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-15 03:20:01,072 - INFO - Fold 3, Epoch 90: Val Acc: 0.88%
2025-08-15 03:20:03,294 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-15 03:20:05,009 - INFO - Fold 3, Epoch 110: Val Acc: 0.53%
2025-08-15 03:20:06,787 - INFO - Fold 3, Epoch 120: Val Acc: 0.88%
2025-08-15 03:20:08,502 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-15 03:20:10,501 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-15 03:20:12,724 - INFO - Fold 3, Epoch 150: Val Acc: 0.56%
2025-08-15 03:20:14,943 - INFO - Fold 3, Epoch 160: Val Acc: 0.72%
2025-08-15 03:20:16,719 - INFO - Early stopping at epoch 168
2025-08-15 03:20:17,764 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.97661116388109), 'std': np.float64(0.03565670065489188)}, 'train_accuracy': {'mean': np.float64(0.7534722222222223), 'std': np.float64(0.07233564811110989)}, 'val_loss': {'mean': np.float64(4.291800816853841), 'std': np.float64(0.04113898867967428)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(66.66666666666667), 'std': np.float64(19.189117286165672)}}
[I 2025-08-15 03:20:17,771] Trial 172 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.00045116059539516116, 'batch_size': 32, 'num_epochs': 338, 'temperature': 0.28476893226491723, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.16694322520100727, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08264201809724862, 'crop_size': 0.5259391343524906}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 172 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.00045116059539516116, 'batch_size': 32, 'num_epochs': 338, 'temperature': 0.28476893226491723, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.16694322520100727, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08264201809724862, 'crop_size': 0.5259391343524906}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:20:17,818 - INFO - Using device: cuda
2025-08-15 03:20:27,593 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:20:27,595 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:20:27,595 - INFO - Starting training for fold 1/3
2025-08-15 03:20:36,462 - INFO - Fold 1, Epoch 10: Val Acc: 0.69%
2025-08-15 03:20:41,050 - INFO - Fold 1, Epoch 20: Val Acc: 0.53%
2025-08-15 03:20:43,327 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-15 03:20:47,562 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-15 03:20:49,646 - INFO - Fold 1, Epoch 50: Val Acc: 0.69%
2025-08-15 03:20:51,777 - INFO - Fold 1, Epoch 60: Val Acc: 0.81%
2025-08-15 03:20:54,064 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-15 03:20:56,361 - INFO - Fold 1, Epoch 80: Val Acc: 0.81%
2025-08-15 03:20:58,577 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-15 03:21:00,452 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-15 03:21:02,681 - INFO - Fold 1, Epoch 110: Val Acc: 0.84%
2025-08-15 03:21:04,915 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-15 03:21:07,155 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-15 03:21:08,713 - INFO - Early stopping at epoch 137
2025-08-15 03:21:12,190 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:21:12,192 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:21:12,193 - INFO - Starting training for fold 2/3
2025-08-15 03:21:21,200 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-15 03:21:24,569 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-15 03:21:27,758 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-15 03:21:29,466 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-15 03:21:31,329 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-15 03:21:33,260 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-15 03:21:35,227 - INFO - Fold 2, Epoch 70: Val Acc: 0.69%
2025-08-15 03:21:38,861 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-15 03:21:41,083 - INFO - Fold 2, Epoch 90: Val Acc: 0.75%
2025-08-15 03:21:43,293 - INFO - Fold 2, Epoch 100: Val Acc: 0.81%
2025-08-15 03:21:45,521 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-15 03:21:47,750 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-15 03:21:51,223 - INFO - Fold 2, Epoch 130: Val Acc: 0.91%
2025-08-15 03:21:53,366 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-15 03:21:55,672 - INFO - Fold 2, Epoch 150: Val Acc: 0.69%
2025-08-15 03:21:57,883 - INFO - Fold 2, Epoch 160: Val Acc: 0.72%
2025-08-15 03:22:00,050 - INFO - Fold 2, Epoch 170: Val Acc: 0.72%
2025-08-15 03:22:01,754 - INFO - Fold 2, Epoch 180: Val Acc: 0.69%
2025-08-15 03:22:05,016 - INFO - Fold 2, Epoch 190: Val Acc: 0.81%
2025-08-15 03:22:07,104 - INFO - Fold 2, Epoch 200: Val Acc: 0.62%
2025-08-15 03:22:09,415 - INFO - Fold 2, Epoch 210: Val Acc: 0.91%
2025-08-15 03:22:11,712 - INFO - Fold 2, Epoch 220: Val Acc: 0.81%
2025-08-15 03:22:13,965 - INFO - Fold 2, Epoch 230: Val Acc: 0.53%
2025-08-15 03:22:16,149 - INFO - Fold 2, Epoch 240: Val Acc: 0.88%
2025-08-15 03:22:18,363 - INFO - Fold 2, Epoch 250: Val Acc: 0.78%
2025-08-15 03:22:20,583 - INFO - Fold 2, Epoch 260: Val Acc: 0.75%
2025-08-15 03:22:22,823 - INFO - Fold 2, Epoch 270: Val Acc: 0.75%
2025-08-15 03:22:25,124 - INFO - Fold 2, Epoch 280: Val Acc: 0.66%
2025-08-15 03:22:26,746 - INFO - Early stopping at epoch 287
2025-08-15 03:22:29,579 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:22:29,581 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:22:29,581 - INFO - Starting training for fold 3/3
2025-08-15 03:22:36,331 - INFO - Fold 3, Epoch 10: Val Acc: 0.44%
2025-08-15 03:22:39,980 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-15 03:22:43,803 - INFO - Fold 3, Epoch 30: Val Acc: 0.53%
2025-08-15 03:22:46,113 - INFO - Fold 3, Epoch 40: Val Acc: 0.84%
2025-08-15 03:22:48,418 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-15 03:22:50,727 - INFO - Fold 3, Epoch 60: Val Acc: 0.81%
2025-08-15 03:22:53,023 - INFO - Fold 3, Epoch 70: Val Acc: 0.75%
2025-08-15 03:22:55,314 - INFO - Fold 3, Epoch 80: Val Acc: 0.69%
2025-08-15 03:22:57,556 - INFO - Fold 3, Epoch 90: Val Acc: 0.62%
2025-08-15 03:22:59,784 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-15 03:23:01,996 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-15 03:23:04,220 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-15 03:23:05,576 - INFO - Early stopping at epoch 126
2025-08-15 03:23:06,625 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.91652962896559), 'std': np.float64(0.11247175114714181)}, 'train_accuracy': {'mean': np.float64(0.75), 'std': np.float64(0.08376623667926952)}, 'val_loss': {'mean': np.float64(4.1680959065755205), 'std': np.float64(0.05636418444934768)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(82.33333333333333), 'std': np.float64(73.44083030273796)}}
[I 2025-08-15 03:23:06,632] Trial 173 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.00048587516522027857, 'batch_size': 32, 'num_epochs': 358, 'temperature': 0.2716390403858411, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.19672743180992902, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08790197537129943, 'crop_size': 0.5329467403531476}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 173 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.00048587516522027857, 'batch_size': 32, 'num_epochs': 358, 'temperature': 0.2716390403858411, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.19672743180992902, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.08790197537129943, 'crop_size': 0.5329467403531476}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:23:06,676 - INFO - Using device: cuda
2025-08-15 03:23:16,399 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:23:16,400 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:23:16,400 - INFO - Starting training for fold 1/3
2025-08-15 03:23:23,383 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-15 03:23:27,833 - INFO - Fold 1, Epoch 20: Val Acc: 0.53%
2025-08-15 03:23:36,842 - INFO - Fold 1, Epoch 30: Val Acc: 0.72%
2025-08-15 03:23:38,694 - INFO - Fold 1, Epoch 40: Val Acc: 0.78%
2025-08-15 03:23:40,402 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-15 03:23:44,646 - INFO - Fold 1, Epoch 60: Val Acc: 0.59%
2025-08-15 03:23:46,958 - INFO - Fold 1, Epoch 70: Val Acc: 0.75%
2025-08-15 03:23:49,262 - INFO - Fold 1, Epoch 80: Val Acc: 0.78%
2025-08-15 03:23:51,569 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-15 03:23:53,881 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-15 03:23:56,183 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-15 03:23:58,489 - INFO - Fold 1, Epoch 120: Val Acc: 0.72%
2025-08-15 03:24:00,795 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-15 03:24:03,017 - INFO - Fold 1, Epoch 140: Val Acc: 0.78%
2025-08-15 03:24:05,082 - INFO - Fold 1, Epoch 150: Val Acc: 0.78%
2025-08-15 03:24:06,507 - INFO - Early stopping at epoch 157
2025-08-15 03:24:09,943 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:24:09,946 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:24:09,947 - INFO - Starting training for fold 2/3
2025-08-15 03:24:17,737 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 03:24:19,781 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-15 03:24:23,660 - INFO - Fold 2, Epoch 30: Val Acc: 0.66%
2025-08-15 03:24:26,073 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-15 03:24:28,478 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-15 03:24:30,901 - INFO - Fold 2, Epoch 60: Val Acc: 0.84%
2025-08-15 03:24:34,642 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-15 03:24:36,977 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-15 03:24:40,266 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-15 03:24:42,031 - INFO - Fold 2, Epoch 100: Val Acc: 0.81%
2025-08-15 03:24:44,336 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-15 03:24:46,649 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-15 03:24:48,962 - INFO - Fold 2, Epoch 130: Val Acc: 0.84%
2025-08-15 03:24:51,087 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-15 03:24:53,335 - INFO - Fold 2, Epoch 150: Val Acc: 0.66%
2025-08-15 03:24:55,630 - INFO - Fold 2, Epoch 160: Val Acc: 0.75%
2025-08-15 03:24:57,931 - INFO - Fold 2, Epoch 170: Val Acc: 0.84%
2025-08-15 03:25:00,200 - INFO - Fold 2, Epoch 180: Val Acc: 0.75%
2025-08-15 03:25:02,247 - INFO - Early stopping at epoch 189
2025-08-15 03:25:05,274 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:25:05,276 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:25:05,277 - INFO - Starting training for fold 3/3
2025-08-15 03:25:12,968 - INFO - Fold 3, Epoch 10: Val Acc: 0.69%
2025-08-15 03:25:18,003 - INFO - Fold 3, Epoch 20: Val Acc: 0.81%
2025-08-15 03:25:20,049 - INFO - Fold 3, Epoch 30: Val Acc: 0.75%
2025-08-15 03:25:23,687 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-15 03:25:25,957 - INFO - Fold 3, Epoch 50: Val Acc: 0.59%
2025-08-15 03:25:28,185 - INFO - Fold 3, Epoch 60: Val Acc: 0.84%
2025-08-15 03:25:30,412 - INFO - Fold 3, Epoch 70: Val Acc: 0.84%
2025-08-15 03:25:32,637 - INFO - Fold 3, Epoch 80: Val Acc: 0.66%
2025-08-15 03:25:34,867 - INFO - Fold 3, Epoch 90: Val Acc: 0.91%
2025-08-15 03:25:37,096 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-15 03:25:39,320 - INFO - Fold 3, Epoch 110: Val Acc: 0.72%
2025-08-15 03:25:41,547 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-15 03:25:43,775 - INFO - Fold 3, Epoch 130: Val Acc: 0.66%
2025-08-15 03:25:44,672 - INFO - Early stopping at epoch 134
2025-08-15 03:25:45,715 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.943680736753676), 'std': np.float64(0.05076645920908227)}, 'train_accuracy': {'mean': np.float64(0.7777777777777778), 'std': np.float64(0.04019387813468824)}, 'val_loss': {'mean': np.float64(4.205536683400472), 'std': np.float64(0.03627253327366151)}, 'val_accuracy': {'mean': np.float64(0.9270833333333334), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(59.0), 'std': np.float64(22.55363976538303)}}
[I 2025-08-15 03:25:45,722] Trial 174 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0005837782174313051, 'batch_size': 32, 'num_epochs': 385, 'temperature': 0.36293411137664516, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.14903714170660226, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1841299141272534, 'crop_size': 0.5475964029768856}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 174 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0005837782174313051, 'batch_size': 32, 'num_epochs': 385, 'temperature': 0.36293411137664516, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.14903714170660226, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1841299141272534, 'crop_size': 0.5475964029768856}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:25:45,765 - INFO - Using device: cuda
2025-08-15 03:25:55,363 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:25:55,365 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:25:55,365 - INFO - Starting training for fold 1/3
2025-08-15 03:26:04,666 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-15 03:26:09,193 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-15 03:26:11,415 - INFO - Fold 1, Epoch 30: Val Acc: 0.56%
2025-08-15 03:26:13,628 - INFO - Fold 1, Epoch 40: Val Acc: 0.50%
2025-08-15 03:26:15,840 - INFO - Fold 1, Epoch 50: Val Acc: 0.56%
2025-08-15 03:26:20,210 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-15 03:26:22,585 - INFO - Fold 1, Epoch 70: Val Acc: 0.50%
2025-08-15 03:26:26,900 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-15 03:26:29,212 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-15 03:26:31,136 - INFO - Fold 1, Epoch 100: Val Acc: 0.47%
2025-08-15 03:26:32,957 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-15 03:26:34,784 - INFO - Fold 1, Epoch 120: Val Acc: 0.50%
2025-08-15 03:26:36,957 - INFO - Fold 1, Epoch 130: Val Acc: 0.50%
2025-08-15 03:26:39,279 - INFO - Fold 1, Epoch 140: Val Acc: 0.59%
2025-08-15 03:26:43,696 - INFO - Fold 1, Epoch 150: Val Acc: 0.78%
2025-08-15 03:26:48,110 - INFO - Fold 1, Epoch 160: Val Acc: 0.69%
2025-08-15 03:26:52,306 - INFO - Fold 1, Epoch 170: Val Acc: 0.53%
2025-08-15 03:26:54,624 - INFO - Fold 1, Epoch 180: Val Acc: 0.56%
2025-08-15 03:26:56,925 - INFO - Fold 1, Epoch 190: Val Acc: 0.72%
2025-08-15 03:26:59,228 - INFO - Fold 1, Epoch 200: Val Acc: 0.59%
2025-08-15 03:27:01,512 - INFO - Fold 1, Epoch 210: Val Acc: 0.50%
2025-08-15 03:27:03,799 - INFO - Fold 1, Epoch 220: Val Acc: 0.69%
2025-08-15 03:27:05,953 - INFO - Fold 1, Epoch 230: Val Acc: 0.59%
2025-08-15 03:27:11,557 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:27:11,561 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:27:11,562 - INFO - Starting training for fold 2/3
2025-08-15 03:27:15,397 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-15 03:27:17,369 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-15 03:27:19,606 - INFO - Fold 2, Epoch 30: Val Acc: 0.53%
2025-08-15 03:27:23,170 - INFO - Fold 2, Epoch 40: Val Acc: 0.59%
2025-08-15 03:27:26,806 - INFO - Fold 2, Epoch 50: Val Acc: 0.59%
2025-08-15 03:27:29,079 - INFO - Fold 2, Epoch 60: Val Acc: 0.53%
2025-08-15 03:27:31,315 - INFO - Fold 2, Epoch 70: Val Acc: 0.50%
2025-08-15 03:27:33,044 - INFO - Fold 2, Epoch 80: Val Acc: 0.72%
2025-08-15 03:27:36,167 - INFO - Fold 2, Epoch 90: Val Acc: 0.62%
2025-08-15 03:27:38,276 - INFO - Fold 2, Epoch 100: Val Acc: 0.62%
2025-08-15 03:27:40,599 - INFO - Fold 2, Epoch 110: Val Acc: 0.47%
2025-08-15 03:27:42,845 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-15 03:27:46,380 - INFO - Fold 2, Epoch 130: Val Acc: 0.88%
2025-08-15 03:27:48,700 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-15 03:27:50,932 - INFO - Fold 2, Epoch 150: Val Acc: 0.56%
2025-08-15 03:27:53,096 - INFO - Fold 2, Epoch 160: Val Acc: 0.75%
2025-08-15 03:27:55,024 - INFO - Fold 2, Epoch 170: Val Acc: 0.53%
2025-08-15 03:27:57,073 - INFO - Fold 2, Epoch 180: Val Acc: 0.59%
2025-08-15 03:27:59,073 - INFO - Fold 2, Epoch 190: Val Acc: 0.62%
2025-08-15 03:28:01,053 - INFO - Fold 2, Epoch 200: Val Acc: 0.50%
2025-08-15 03:28:03,053 - INFO - Fold 2, Epoch 210: Val Acc: 0.53%
2025-08-15 03:28:05,293 - INFO - Fold 2, Epoch 220: Val Acc: 0.78%
2025-08-15 03:28:07,494 - INFO - Early stopping at epoch 230
2025-08-15 03:28:10,389 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:28:10,400 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:28:10,401 - INFO - Starting training for fold 3/3
2025-08-15 03:28:16,956 - INFO - Fold 3, Epoch 10: Val Acc: 0.44%
2025-08-15 03:28:19,189 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-15 03:28:21,433 - INFO - Fold 3, Epoch 30: Val Acc: 0.47%
2025-08-15 03:28:25,144 - INFO - Fold 3, Epoch 40: Val Acc: 0.56%
2025-08-15 03:28:27,154 - INFO - Fold 3, Epoch 50: Val Acc: 0.47%
2025-08-15 03:28:28,932 - INFO - Fold 3, Epoch 60: Val Acc: 0.50%
2025-08-15 03:28:32,706 - INFO - Fold 3, Epoch 70: Val Acc: 0.50%
2025-08-15 03:28:35,967 - INFO - Fold 3, Epoch 80: Val Acc: 0.56%
2025-08-15 03:28:37,683 - INFO - Fold 3, Epoch 90: Val Acc: 0.59%
2025-08-15 03:28:40,785 - INFO - Fold 3, Epoch 100: Val Acc: 0.50%
2025-08-15 03:28:44,075 - INFO - Fold 3, Epoch 110: Val Acc: 0.59%
2025-08-15 03:28:46,338 - INFO - Fold 3, Epoch 120: Val Acc: 0.59%
2025-08-15 03:28:48,634 - INFO - Fold 3, Epoch 130: Val Acc: 0.53%
2025-08-15 03:28:50,342 - INFO - Fold 3, Epoch 140: Val Acc: 0.50%
2025-08-15 03:28:52,047 - INFO - Fold 3, Epoch 150: Val Acc: 0.81%
2025-08-15 03:28:54,031 - INFO - Fold 3, Epoch 160: Val Acc: 0.50%
2025-08-15 03:28:55,949 - INFO - Fold 3, Epoch 170: Val Acc: 0.66%
2025-08-15 03:28:57,661 - INFO - Fold 3, Epoch 180: Val Acc: 0.53%
2025-08-15 03:28:59,375 - INFO - Fold 3, Epoch 190: Val Acc: 0.69%
2025-08-15 03:29:01,288 - INFO - Fold 3, Epoch 200: Val Acc: 0.75%
2025-08-15 03:29:02,627 - INFO - Early stopping at epoch 207
2025-08-15 03:29:03,637 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.979365428288778), 'std': np.float64(0.047003539506390066)}, 'train_accuracy': {'mean': np.float64(0.7777777777777777), 'std': np.float64(0.017704928866641618)}, 'val_loss': {'mean': np.float64(4.112397193908691), 'std': np.float64(0.01960820988255245)}, 'val_accuracy': {'mean': np.float64(0.8541666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(134.0), 'std': np.float64(25.152865973217974)}}
[I 2025-08-15 03:29:03,643] Trial 175 finished with value: -0.8541666666666666 and parameters: {'learning_rate': 0.0005215848115483555, 'batch_size': 32, 'num_epochs': 239, 'temperature': 0.32398746609949824, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.17114265868097472, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.0934837277659751, 'crop_size': 0.5227365932415156}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 175 finished with value: -0.8541666666666666 and parameters: {'learning_rate': 0.0005215848115483555, 'batch_size': 32, 'num_epochs': 239, 'temperature': 0.32398746609949824, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.17114265868097472, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': True, 'permutation_enabled': False, 'noise_level': 0.0934837277659751, 'crop_size': 0.5227365932415156}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:29:03,686 - INFO - Using device: cuda
2025-08-15 03:29:13,260 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:29:13,261 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:29:13,261 - INFO - Starting training for fold 1/3
2025-08-15 03:29:24,365 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-15 03:29:28,971 - INFO - Fold 1, Epoch 20: Val Acc: 0.75%
2025-08-15 03:29:31,195 - INFO - Fold 1, Epoch 30: Val Acc: 0.78%
2025-08-15 03:29:33,413 - INFO - Fold 1, Epoch 40: Val Acc: 0.81%
2025-08-15 03:29:35,637 - INFO - Fold 1, Epoch 50: Val Acc: 0.81%
2025-08-15 03:29:37,664 - INFO - Fold 1, Epoch 60: Val Acc: 0.75%
2025-08-15 03:29:42,408 - INFO - Fold 1, Epoch 70: Val Acc: 0.69%
2025-08-15 03:29:44,644 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-15 03:29:46,873 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-15 03:29:49,091 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-15 03:29:50,836 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-15 03:29:52,532 - INFO - Fold 1, Epoch 120: Val Acc: 0.66%
2025-08-15 03:29:54,685 - INFO - Fold 1, Epoch 130: Val Acc: 0.81%
2025-08-15 03:29:56,913 - INFO - Fold 1, Epoch 140: Val Acc: 0.66%
2025-08-15 03:29:59,141 - INFO - Fold 1, Epoch 150: Val Acc: 0.56%
2025-08-15 03:30:01,372 - INFO - Fold 1, Epoch 160: Val Acc: 0.56%
2025-08-15 03:30:02,932 - INFO - Early stopping at epoch 167
2025-08-15 03:30:06,803 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:30:06,806 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:30:06,806 - INFO - Starting training for fold 2/3
2025-08-15 03:30:12,201 - INFO - Fold 2, Epoch 10: Val Acc: 0.59%
2025-08-15 03:30:15,767 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-15 03:30:19,630 - INFO - Fold 2, Epoch 30: Val Acc: 0.75%
2025-08-15 03:30:21,848 - INFO - Fold 2, Epoch 40: Val Acc: 0.62%
2025-08-15 03:30:26,927 - INFO - Fold 2, Epoch 50: Val Acc: 0.88%
2025-08-15 03:30:29,236 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-15 03:30:32,818 - INFO - Fold 2, Epoch 70: Val Acc: 0.84%
2025-08-15 03:30:35,027 - INFO - Fold 2, Epoch 80: Val Acc: 0.78%
2025-08-15 03:30:37,241 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-15 03:30:39,394 - INFO - Fold 2, Epoch 100: Val Acc: 0.72%
2025-08-15 03:30:41,456 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-15 03:30:43,681 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-15 03:30:45,910 - INFO - Fold 2, Epoch 130: Val Acc: 0.69%
2025-08-15 03:30:48,140 - INFO - Fold 2, Epoch 140: Val Acc: 0.84%
2025-08-15 03:30:50,360 - INFO - Fold 2, Epoch 150: Val Acc: 0.78%
2025-08-15 03:30:53,881 - INFO - Fold 2, Epoch 160: Val Acc: 0.94%
2025-08-15 03:30:56,176 - INFO - Fold 2, Epoch 170: Val Acc: 0.91%
2025-08-15 03:30:58,374 - INFO - Fold 2, Epoch 180: Val Acc: 0.91%
2025-08-15 03:31:00,586 - INFO - Fold 2, Epoch 190: Val Acc: 0.81%
2025-08-15 03:31:02,865 - INFO - Fold 2, Epoch 200: Val Acc: 0.78%
2025-08-15 03:31:05,190 - INFO - Fold 2, Epoch 210: Val Acc: 0.81%
2025-08-15 03:31:07,474 - INFO - Fold 2, Epoch 220: Val Acc: 0.75%
2025-08-15 03:31:09,695 - INFO - Fold 2, Epoch 230: Val Acc: 0.69%
2025-08-15 03:31:11,867 - INFO - Fold 2, Epoch 240: Val Acc: 0.62%
2025-08-15 03:31:13,862 - INFO - Fold 2, Epoch 250: Val Acc: 0.66%
2025-08-15 03:31:15,754 - INFO - Early stopping at epoch 260
2025-08-15 03:31:18,600 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:31:18,602 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:31:18,603 - INFO - Starting training for fold 3/3
2025-08-15 03:31:25,170 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-15 03:31:30,050 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-15 03:31:33,405 - INFO - Fold 3, Epoch 30: Val Acc: 0.75%
2025-08-15 03:31:36,752 - INFO - Fold 3, Epoch 40: Val Acc: 0.62%
2025-08-15 03:31:38,693 - INFO - Fold 3, Epoch 50: Val Acc: 0.81%
2025-08-15 03:31:42,078 - INFO - Fold 3, Epoch 60: Val Acc: 0.78%
2025-08-15 03:31:44,113 - INFO - Fold 3, Epoch 70: Val Acc: 0.81%
2025-08-15 03:31:47,272 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-15 03:31:49,423 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-15 03:31:51,629 - INFO - Fold 3, Epoch 100: Val Acc: 0.53%
2025-08-15 03:31:53,844 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-15 03:31:55,735 - INFO - Fold 3, Epoch 120: Val Acc: 0.69%
2025-08-15 03:31:58,836 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-15 03:32:01,050 - INFO - Fold 3, Epoch 140: Val Acc: 0.81%
2025-08-15 03:32:03,251 - INFO - Fold 3, Epoch 150: Val Acc: 0.84%
2025-08-15 03:32:05,258 - INFO - Fold 3, Epoch 160: Val Acc: 0.59%
2025-08-15 03:32:06,964 - INFO - Fold 3, Epoch 170: Val Acc: 0.69%
2025-08-15 03:32:08,675 - INFO - Fold 3, Epoch 180: Val Acc: 0.69%
2025-08-15 03:32:10,382 - INFO - Fold 3, Epoch 190: Val Acc: 0.72%
2025-08-15 03:32:12,178 - INFO - Fold 3, Epoch 200: Val Acc: 0.72%
2025-08-15 03:32:13,933 - INFO - Fold 3, Epoch 210: Val Acc: 0.91%
2025-08-15 03:32:15,643 - INFO - Fold 3, Epoch 220: Val Acc: 0.62%
2025-08-15 03:32:16,837 - INFO - Early stopping at epoch 227
2025-08-15 03:32:17,889 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.867461363474528), 'std': np.float64(0.02945107596198737)}, 'train_accuracy': {'mean': np.float64(0.8090277777777777), 'std': np.float64(0.06152793453704631)}, 'val_loss': {'mean': np.float64(4.2536624272664385), 'std': np.float64(0.031276270418469934)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(117.0), 'std': np.float64(38.49675310984031)}}
[I 2025-08-15 03:32:17,896] Trial 176 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0007508414875071166, 'batch_size': 32, 'num_epochs': 346, 'temperature': 0.4217957731999827, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4931645037057259, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06230093959014641, 'crop_size': 0.5389050218140213}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 176 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0007508414875071166, 'batch_size': 32, 'num_epochs': 346, 'temperature': 0.4217957731999827, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4931645037057259, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06230093959014641, 'crop_size': 0.5389050218140213}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:32:17,938 - INFO - Using device: cuda
2025-08-15 03:32:27,897 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:32:27,899 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:32:27,899 - INFO - Starting training for fold 1/3
2025-08-15 03:32:38,370 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-15 03:32:40,644 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-15 03:32:42,908 - INFO - Fold 1, Epoch 30: Val Acc: 0.53%
2025-08-15 03:32:45,170 - INFO - Fold 1, Epoch 40: Val Acc: 0.44%
2025-08-15 03:32:47,437 - INFO - Fold 1, Epoch 50: Val Acc: 0.53%
2025-08-15 03:32:51,836 - INFO - Fold 1, Epoch 60: Val Acc: 0.56%
2025-08-15 03:32:54,097 - INFO - Fold 1, Epoch 70: Val Acc: 0.50%
2025-08-15 03:32:56,230 - INFO - Fold 1, Epoch 80: Val Acc: 0.50%
2025-08-15 03:33:00,738 - INFO - Fold 1, Epoch 90: Val Acc: 0.41%
2025-08-15 03:33:02,965 - INFO - Fold 1, Epoch 100: Val Acc: 0.47%
2025-08-15 03:33:04,811 - INFO - Fold 1, Epoch 110: Val Acc: 0.50%
2025-08-15 03:33:07,081 - INFO - Fold 1, Epoch 120: Val Acc: 0.47%
2025-08-15 03:33:09,350 - INFO - Fold 1, Epoch 130: Val Acc: 0.41%
2025-08-15 03:33:11,354 - INFO - Fold 1, Epoch 140: Val Acc: 0.50%
2025-08-15 03:33:13,103 - INFO - Fold 1, Epoch 150: Val Acc: 0.50%
2025-08-15 03:33:15,017 - INFO - Fold 1, Epoch 160: Val Acc: 0.50%
2025-08-15 03:33:16,764 - INFO - Fold 1, Epoch 170: Val Acc: 0.50%
2025-08-15 03:33:18,556 - INFO - Fold 1, Epoch 180: Val Acc: 0.47%
2025-08-15 03:33:19,693 - INFO - Early stopping at epoch 185
2025-08-15 03:33:23,221 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:33:23,224 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:33:23,225 - INFO - Starting training for fold 2/3
2025-08-15 03:33:27,046 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-15 03:33:30,789 - INFO - Fold 2, Epoch 20: Val Acc: 0.47%
2025-08-15 03:33:33,018 - INFO - Fold 2, Epoch 30: Val Acc: 0.56%
2025-08-15 03:33:35,274 - INFO - Fold 2, Epoch 40: Val Acc: 0.47%
2025-08-15 03:33:37,514 - INFO - Fold 2, Epoch 50: Val Acc: 0.38%
2025-08-15 03:33:41,026 - INFO - Fold 2, Epoch 60: Val Acc: 0.47%
2025-08-15 03:33:43,109 - INFO - Fold 2, Epoch 70: Val Acc: 0.53%
2025-08-15 03:33:45,341 - INFO - Fold 2, Epoch 80: Val Acc: 0.56%
2025-08-15 03:33:47,152 - INFO - Fold 2, Epoch 90: Val Acc: 0.47%
2025-08-15 03:33:49,421 - INFO - Fold 2, Epoch 100: Val Acc: 0.44%
2025-08-15 03:33:51,705 - INFO - Fold 2, Epoch 110: Val Acc: 0.53%
2025-08-15 03:33:53,979 - INFO - Fold 2, Epoch 120: Val Acc: 0.53%
2025-08-15 03:33:56,261 - INFO - Fold 2, Epoch 130: Val Acc: 0.53%
2025-08-15 03:33:58,580 - INFO - Fold 2, Epoch 140: Val Acc: 0.44%
2025-08-15 03:34:02,289 - INFO - Fold 2, Epoch 150: Val Acc: 0.50%
2025-08-15 03:34:04,562 - INFO - Fold 2, Epoch 160: Val Acc: 0.50%
2025-08-15 03:34:06,826 - INFO - Fold 2, Epoch 170: Val Acc: 0.47%
2025-08-15 03:34:09,101 - INFO - Fold 2, Epoch 180: Val Acc: 0.50%
2025-08-15 03:34:11,362 - INFO - Fold 2, Epoch 190: Val Acc: 0.50%
2025-08-15 03:34:13,619 - INFO - Fold 2, Epoch 200: Val Acc: 0.47%
2025-08-15 03:34:15,888 - INFO - Fold 2, Epoch 210: Val Acc: 0.62%
2025-08-15 03:34:18,163 - INFO - Fold 2, Epoch 220: Val Acc: 0.59%
2025-08-15 03:34:20,429 - INFO - Fold 2, Epoch 230: Val Acc: 0.59%
2025-08-15 03:34:22,704 - INFO - Fold 2, Epoch 240: Val Acc: 0.44%
2025-08-15 03:34:23,163 - INFO - Early stopping at epoch 242
2025-08-15 03:34:24,175 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:34:24,177 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:34:24,177 - INFO - Starting training for fold 3/3
2025-08-15 03:34:32,417 - INFO - Fold 3, Epoch 10: Val Acc: 0.72%
2025-08-15 03:34:34,766 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-15 03:34:37,022 - INFO - Fold 3, Epoch 30: Val Acc: 0.47%
2025-08-15 03:34:39,293 - INFO - Fold 3, Epoch 40: Val Acc: 0.47%
2025-08-15 03:34:41,547 - INFO - Fold 3, Epoch 50: Val Acc: 0.41%
2025-08-15 03:34:43,800 - INFO - Fold 3, Epoch 60: Val Acc: 0.44%
2025-08-15 03:34:46,053 - INFO - Fold 3, Epoch 70: Val Acc: 0.47%
2025-08-15 03:34:48,311 - INFO - Fold 3, Epoch 80: Val Acc: 0.50%
2025-08-15 03:34:50,577 - INFO - Fold 3, Epoch 90: Val Acc: 0.31%
2025-08-15 03:34:52,840 - INFO - Fold 3, Epoch 100: Val Acc: 0.47%
2025-08-15 03:34:55,100 - INFO - Early stopping at epoch 110
2025-08-15 03:34:57,996 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.169670846727159), 'std': np.float64(0.003385952257596999)}, 'train_accuracy': {'mean': np.float64(0.5590277777777778), 'std': np.float64(0.03220006422047121)}, 'val_loss': {'mean': np.float64(4.161435763041179), 'std': np.float64(0.04833897341233433)}, 'val_accuracy': {'mean': np.float64(0.6979166666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(78.0), 'std': np.float64(54.055527006958314)}}
[I 2025-08-15 03:34:58,006] Trial 177 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 0.0002827965181219658, 'batch_size': 32, 'num_epochs': 911, 'temperature': 0.3007694470874489, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.159558269489068, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07151210868091015, 'crop_size': 0.511457369668455}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 177 finished with value: -0.6979166666666666 and parameters: {'learning_rate': 0.0002827965181219658, 'batch_size': 32, 'num_epochs': 911, 'temperature': 0.3007694470874489, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.159558269489068, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': True, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07151210868091015, 'crop_size': 0.511457369668455}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:34:58,100 - INFO - Using device: cuda
2025-08-15 03:35:07,727 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:35:07,734 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:35:07,734 - INFO - Starting training for fold 1/3
2025-08-15 03:35:15,304 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-15 03:35:19,211 - INFO - Fold 1, Epoch 20: Val Acc: 0.72%
2025-08-15 03:35:20,924 - INFO - Fold 1, Epoch 30: Val Acc: 0.75%
2025-08-15 03:35:22,640 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-15 03:35:26,760 - INFO - Fold 1, Epoch 50: Val Acc: 0.72%
2025-08-15 03:35:29,083 - INFO - Fold 1, Epoch 60: Val Acc: 0.62%
2025-08-15 03:35:31,407 - INFO - Fold 1, Epoch 70: Val Acc: 0.69%
2025-08-15 03:35:33,712 - INFO - Fold 1, Epoch 80: Val Acc: 0.78%
2025-08-15 03:35:36,020 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-15 03:35:38,297 - INFO - Fold 1, Epoch 100: Val Acc: 0.81%
2025-08-15 03:35:40,502 - INFO - Fold 1, Epoch 110: Val Acc: 0.84%
2025-08-15 03:35:42,772 - INFO - Fold 1, Epoch 120: Val Acc: 0.66%
2025-08-15 03:35:45,011 - INFO - Fold 1, Epoch 130: Val Acc: 0.47%
2025-08-15 03:35:47,330 - INFO - Fold 1, Epoch 140: Val Acc: 0.72%
2025-08-15 03:35:48,022 - INFO - Early stopping at epoch 143
2025-08-15 03:35:51,552 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:35:51,554 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:35:51,554 - INFO - Starting training for fold 2/3
2025-08-15 03:35:56,850 - INFO - Fold 2, Epoch 10: Val Acc: 0.53%
2025-08-15 03:36:01,813 - INFO - Fold 2, Epoch 20: Val Acc: 0.62%
2025-08-15 03:36:05,536 - INFO - Fold 2, Epoch 30: Val Acc: 0.66%
2025-08-15 03:36:09,123 - INFO - Fold 2, Epoch 40: Val Acc: 0.81%
2025-08-15 03:36:11,424 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-15 03:36:13,733 - INFO - Fold 2, Epoch 60: Val Acc: 0.69%
2025-08-15 03:36:15,966 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-15 03:36:18,026 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-15 03:36:20,265 - INFO - Fold 2, Epoch 90: Val Acc: 0.66%
2025-08-15 03:36:22,073 - INFO - Fold 2, Epoch 100: Val Acc: 0.72%
2025-08-15 03:36:23,766 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-15 03:36:25,480 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-15 03:36:27,188 - INFO - Fold 2, Epoch 130: Val Acc: 0.66%
2025-08-15 03:36:27,361 - INFO - Early stopping at epoch 131
2025-08-15 03:36:30,333 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:36:30,336 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:36:30,336 - INFO - Starting training for fold 3/3
2025-08-15 03:36:37,072 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-15 03:36:39,291 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-15 03:36:44,341 - INFO - Fold 3, Epoch 30: Val Acc: 0.72%
2025-08-15 03:36:47,912 - INFO - Fold 3, Epoch 40: Val Acc: 0.50%
2025-08-15 03:36:51,528 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-15 03:36:55,161 - INFO - Fold 3, Epoch 60: Val Acc: 0.69%
2025-08-15 03:36:57,389 - INFO - Fold 3, Epoch 70: Val Acc: 0.81%
2025-08-15 03:36:59,603 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-15 03:37:01,810 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-15 03:37:03,610 - INFO - Fold 3, Epoch 100: Val Acc: 0.78%
2025-08-15 03:37:05,830 - INFO - Fold 3, Epoch 110: Val Acc: 0.69%
2025-08-15 03:37:09,487 - INFO - Fold 3, Epoch 120: Val Acc: 0.66%
2025-08-15 03:37:11,718 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-15 03:37:13,538 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-15 03:37:15,761 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-15 03:37:17,989 - INFO - Fold 3, Epoch 160: Val Acc: 0.78%
2025-08-15 03:37:20,256 - INFO - Fold 3, Epoch 170: Val Acc: 0.78%
2025-08-15 03:37:22,558 - INFO - Fold 3, Epoch 180: Val Acc: 0.81%
2025-08-15 03:37:24,779 - INFO - Fold 3, Epoch 190: Val Acc: 0.88%
2025-08-15 03:37:27,007 - INFO - Fold 3, Epoch 200: Val Acc: 0.78%
2025-08-15 03:37:28,906 - INFO - Fold 3, Epoch 210: Val Acc: 0.72%
2025-08-15 03:37:29,574 - INFO - Early stopping at epoch 213
2025-08-15 03:37:30,615 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9855469862620043), 'std': np.float64(0.04940402097831996)}, 'train_accuracy': {'mean': np.float64(0.732638888888889), 'std': np.float64(0.04364515656241856)}, 'val_loss': {'mean': np.float64(4.191720167795817), 'std': np.float64(0.057227845505068924)}, 'val_accuracy': {'mean': np.float64(0.9270833333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(61.333333333333336), 'std': np.float64(36.160137659521645)}}
[I 2025-08-15 03:37:30,622] Trial 178 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0006567200522378861, 'batch_size': 32, 'num_epochs': 935, 'temperature': 0.3903814289733004, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.18041828932681286, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1996502982024172, 'crop_size': 0.5304282893387605}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 178 finished with value: -0.9270833333333334 and parameters: {'learning_rate': 0.0006567200522378861, 'batch_size': 32, 'num_epochs': 935, 'temperature': 0.3903814289733004, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.18041828932681286, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1996502982024172, 'crop_size': 0.5304282893387605}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:37:30,665 - INFO - Using device: cuda
2025-08-15 03:37:40,526 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:37:40,527 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:37:40,528 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 03:37:51,333 - INFO - Fold 1, Epoch 10: Val Acc: 0.56%
2025-08-15 03:37:53,461 - INFO - Fold 1, Epoch 20: Val Acc: 0.66%
2025-08-15 03:37:57,639 - INFO - Fold 1, Epoch 30: Val Acc: 0.75%
2025-08-15 03:37:59,718 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-15 03:38:01,810 - INFO - Fold 1, Epoch 50: Val Acc: 0.69%
2025-08-15 03:38:08,109 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-15 03:38:10,188 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-15 03:38:11,986 - INFO - Fold 1, Epoch 80: Val Acc: 0.78%
2025-08-15 03:38:13,671 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-15 03:38:15,777 - INFO - Fold 1, Epoch 100: Val Acc: 0.62%
2025-08-15 03:38:17,995 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-15 03:38:22,325 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-15 03:38:24,440 - INFO - Fold 1, Epoch 130: Val Acc: 0.59%
2025-08-15 03:38:26,556 - INFO - Fold 1, Epoch 140: Val Acc: 0.72%
2025-08-15 03:38:28,710 - INFO - Fold 1, Epoch 150: Val Acc: 0.75%
2025-08-15 03:38:30,852 - INFO - Fold 1, Epoch 160: Val Acc: 0.66%
2025-08-15 03:38:33,064 - INFO - Fold 1, Epoch 170: Val Acc: 0.66%
2025-08-15 03:38:35,268 - INFO - Fold 1, Epoch 180: Val Acc: 0.81%
2025-08-15 03:38:37,506 - INFO - Fold 1, Epoch 190: Val Acc: 0.69%
2025-08-15 03:38:39,794 - INFO - Fold 1, Epoch 200: Val Acc: 0.69%
2025-08-15 03:38:42,094 - INFO - Fold 1, Epoch 210: Val Acc: 0.75%
2025-08-15 03:38:43,449 - INFO - Early stopping at epoch 216
2025-08-15 03:38:46,913 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:38:46,915 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:38:46,916 - INFO - Starting training for fold 2/3
2025-08-15 03:38:52,300 - INFO - Fold 2, Epoch 10: Val Acc: 0.53%
2025-08-15 03:38:55,703 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-15 03:38:58,909 - INFO - Fold 2, Epoch 30: Val Acc: 0.78%
2025-08-15 03:39:02,554 - INFO - Fold 2, Epoch 40: Val Acc: 0.56%
2025-08-15 03:39:06,045 - INFO - Fold 2, Epoch 50: Val Acc: 0.62%
2025-08-15 03:39:07,732 - INFO - Fold 2, Epoch 60: Val Acc: 0.59%
2025-08-15 03:39:09,417 - INFO - Fold 2, Epoch 70: Val Acc: 0.81%
2025-08-15 03:39:11,102 - INFO - Fold 2, Epoch 80: Val Acc: 0.66%
2025-08-15 03:39:12,785 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-15 03:39:14,468 - INFO - Fold 2, Epoch 100: Val Acc: 0.72%
2025-08-15 03:39:16,151 - INFO - Fold 2, Epoch 110: Val Acc: 0.62%
2025-08-15 03:39:19,557 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-15 03:39:21,762 - INFO - Fold 2, Epoch 130: Val Acc: 0.72%
2025-08-15 03:39:23,963 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-15 03:39:26,165 - INFO - Fold 2, Epoch 150: Val Acc: 0.75%
2025-08-15 03:39:28,371 - INFO - Fold 2, Epoch 160: Val Acc: 0.66%
2025-08-15 03:39:30,572 - INFO - Fold 2, Epoch 170: Val Acc: 0.72%
2025-08-15 03:39:32,772 - INFO - Fold 2, Epoch 180: Val Acc: 0.91%
2025-08-15 03:39:34,975 - INFO - Fold 2, Epoch 190: Val Acc: 0.78%
2025-08-15 03:39:37,186 - INFO - Fold 2, Epoch 200: Val Acc: 0.62%
2025-08-15 03:39:39,333 - INFO - Fold 2, Epoch 210: Val Acc: 0.72%
2025-08-15 03:39:39,990 - INFO - Early stopping at epoch 213
2025-08-15 03:39:42,795 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:39:42,797 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:39:42,798 - INFO - Starting training for fold 3/3
2025-08-15 03:39:49,179 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-15 03:39:52,532 - INFO - Fold 3, Epoch 20: Val Acc: 0.41%
2025-08-15 03:39:55,945 - INFO - Fold 3, Epoch 30: Val Acc: 0.69%
2025-08-15 03:39:59,383 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-15 03:40:02,988 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-15 03:40:06,017 - INFO - Fold 3, Epoch 60: Val Acc: 0.88%
2025-08-15 03:40:08,046 - INFO - Fold 3, Epoch 70: Val Acc: 0.84%
2025-08-15 03:40:09,743 - INFO - Fold 3, Epoch 80: Val Acc: 0.69%
2025-08-15 03:40:13,406 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-15 03:40:15,623 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-15 03:40:17,850 - INFO - Fold 3, Epoch 110: Val Acc: 0.59%
2025-08-15 03:40:20,066 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-15 03:40:22,289 - INFO - Fold 3, Epoch 130: Val Acc: 0.75%
2025-08-15 03:40:24,508 - INFO - Fold 3, Epoch 140: Val Acc: 0.84%
2025-08-15 03:40:26,456 - INFO - Fold 3, Epoch 150: Val Acc: 0.62%
2025-08-15 03:40:28,521 - INFO - Fold 3, Epoch 160: Val Acc: 0.91%
2025-08-15 03:40:30,218 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-15 03:40:32,186 - INFO - Fold 3, Epoch 180: Val Acc: 0.81%
2025-08-15 03:40:33,740 - INFO - Early stopping at epoch 187
2025-08-15 03:40:35,098 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9498063723246255), 'std': np.float64(0.05904038320400908)}, 'train_accuracy': {'mean': np.float64(0.7291666666666666), 'std': np.float64(0.025515518153991484)}, 'val_loss': {'mean': np.float64(4.212924321492513), 'std': np.float64(0.09080785920689097)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(104.33333333333333), 'std': np.float64(13.021349989749739)}}
[I 2025-08-15 03:40:35,109] Trial 179 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0004201420434402039, 'batch_size': 32, 'num_epochs': 411, 'temperature': 0.3395475936660261, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.46117695560550087, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.10244934898921852, 'crop_size': 0.5557376311272019}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 179 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0004201420434402039, 'batch_size': 32, 'num_epochs': 411, 'temperature': 0.3395475936660261, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.46117695560550087, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.10244934898921852, 'crop_size': 0.5557376311272019}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:40:35,164 - INFO - Using device: cuda
2025-08-15 03:40:44,839 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:40:44,841 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:40:44,841 - INFO - Starting training for fold 1/3
2025-08-15 03:40:53,767 - INFO - Fold 1, Epoch 10: Val Acc: 0.62%
2025-08-15 03:41:02,748 - INFO - Fold 1, Epoch 20: Val Acc: 0.78%
2025-08-15 03:41:04,986 - INFO - Fold 1, Epoch 30: Val Acc: 0.69%
2025-08-15 03:41:07,223 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-15 03:41:09,446 - INFO - Fold 1, Epoch 50: Val Acc: 0.78%
2025-08-15 03:41:11,681 - INFO - Fold 1, Epoch 60: Val Acc: 0.81%
2025-08-15 03:41:13,620 - INFO - Fold 1, Epoch 70: Val Acc: 0.69%
2025-08-15 03:41:18,300 - INFO - Fold 1, Epoch 80: Val Acc: 0.75%
2025-08-15 03:41:20,539 - INFO - Fold 1, Epoch 90: Val Acc: 0.78%
2025-08-15 03:41:22,782 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-15 03:41:25,006 - INFO - Fold 1, Epoch 110: Val Acc: 0.59%
2025-08-15 03:41:27,236 - INFO - Fold 1, Epoch 120: Val Acc: 0.66%
2025-08-15 03:41:29,467 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-15 03:41:31,713 - INFO - Fold 1, Epoch 140: Val Acc: 0.62%
2025-08-15 03:41:36,332 - INFO - Fold 1, Epoch 150: Val Acc: 0.84%
2025-08-15 03:41:38,573 - INFO - Fold 1, Epoch 160: Val Acc: 0.84%
2025-08-15 03:41:40,812 - INFO - Fold 1, Epoch 170: Val Acc: 0.72%
2025-08-15 03:41:42,886 - INFO - Fold 1, Epoch 180: Val Acc: 0.66%
2025-08-15 03:41:45,040 - INFO - Fold 1, Epoch 190: Val Acc: 0.59%
2025-08-15 03:41:47,264 - INFO - Fold 1, Epoch 200: Val Acc: 0.78%
2025-08-15 03:41:49,483 - INFO - Fold 1, Epoch 210: Val Acc: 0.56%
2025-08-15 03:41:51,705 - INFO - Fold 1, Epoch 220: Val Acc: 0.72%
2025-08-15 03:41:53,935 - INFO - Fold 1, Epoch 230: Val Acc: 0.72%
2025-08-15 03:41:56,159 - INFO - Fold 1, Epoch 240: Val Acc: 0.75%
2025-08-15 03:41:56,992 - INFO - Early stopping at epoch 244
2025-08-15 03:42:00,501 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:42:00,505 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:42:00,505 - INFO - Starting training for fold 2/3
2025-08-15 03:42:12,419 - INFO - Fold 2, Epoch 10: Val Acc: 0.75%
2025-08-15 03:42:15,662 - INFO - Fold 2, Epoch 20: Val Acc: 0.78%
2025-08-15 03:42:17,754 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-15 03:42:20,035 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-15 03:42:22,381 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-15 03:42:26,110 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-15 03:42:28,425 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-15 03:42:30,730 - INFO - Fold 2, Epoch 80: Val Acc: 0.81%
2025-08-15 03:42:33,033 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-15 03:42:35,364 - INFO - Fold 2, Epoch 100: Val Acc: 0.84%
2025-08-15 03:42:37,678 - INFO - Fold 2, Epoch 110: Val Acc: 0.78%
2025-08-15 03:42:39,983 - INFO - Fold 2, Epoch 120: Val Acc: 0.84%
2025-08-15 03:42:42,270 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-15 03:42:44,542 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-15 03:42:46,709 - INFO - Fold 2, Epoch 150: Val Acc: 0.91%
2025-08-15 03:42:46,913 - INFO - Early stopping at epoch 151
2025-08-15 03:42:49,777 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:42:49,780 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:42:49,780 - INFO - Starting training for fold 3/3
2025-08-15 03:42:56,238 - INFO - Fold 3, Epoch 10: Val Acc: 0.72%
2025-08-15 03:42:59,652 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-15 03:43:03,167 - INFO - Fold 3, Epoch 30: Val Acc: 0.78%
2025-08-15 03:43:05,387 - INFO - Fold 3, Epoch 40: Val Acc: 0.72%
2025-08-15 03:43:07,613 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-15 03:43:11,088 - INFO - Fold 3, Epoch 60: Val Acc: 0.62%
2025-08-15 03:43:13,306 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-15 03:43:15,527 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-15 03:43:17,748 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-15 03:43:21,381 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-15 03:43:23,606 - INFO - Fold 3, Epoch 110: Val Acc: 0.75%
2025-08-15 03:43:27,284 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-15 03:43:29,515 - INFO - Fold 3, Epoch 130: Val Acc: 0.69%
2025-08-15 03:43:31,744 - INFO - Fold 3, Epoch 140: Val Acc: 0.69%
2025-08-15 03:43:33,979 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-15 03:43:36,210 - INFO - Fold 3, Epoch 160: Val Acc: 0.81%
2025-08-15 03:43:38,447 - INFO - Fold 3, Epoch 170: Val Acc: 0.59%
2025-08-15 03:43:40,734 - INFO - Fold 3, Epoch 180: Val Acc: 0.53%
2025-08-15 03:43:43,056 - INFO - Fold 3, Epoch 190: Val Acc: 0.69%
2025-08-15 03:43:45,384 - INFO - Fold 3, Epoch 200: Val Acc: 0.72%
2025-08-15 03:43:47,688 - INFO - Fold 3, Epoch 210: Val Acc: 0.62%
2025-08-15 03:43:49,101 - INFO - Early stopping at epoch 217
2025-08-15 03:43:50,125 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.778421296013726), 'std': np.float64(0.10601799950560517)}, 'train_accuracy': {'mean': np.float64(0.8194444444444445), 'std': np.float64(0.057893513890739795)}, 'val_loss': {'mean': np.float64(4.235650380452474), 'std': np.float64(0.04095797957576026)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(103.0), 'std': np.float64(39.06404996924922)}}
[I 2025-08-15 03:43:50,131] Trial 180 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0006194119002198034, 'batch_size': 32, 'num_epochs': 678, 'temperature': 0.24554854477650792, 'embedding_dim': 512, 'hidden_dim': 256, 'dropout': 0.2045675079746324, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1708564377825846, 'crop_size': 0.543698884709665}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 180 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0006194119002198034, 'batch_size': 32, 'num_epochs': 678, 'temperature': 0.24554854477650792, 'embedding_dim': 512, 'hidden_dim': 256, 'dropout': 0.2045675079746324, 'num_layers': 5, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1708564377825846, 'crop_size': 0.543698884709665}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:43:50,178 - INFO - Using device: cuda
2025-08-15 03:44:00,107 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:44:00,109 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:44:00,109 - INFO - Starting training for fold 1/3
2025-08-15 03:44:07,034 - INFO - Fold 1, Epoch 10: Val Acc: 0.62%
2025-08-15 03:44:11,494 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-15 03:44:18,130 - INFO - Fold 1, Epoch 30: Val Acc: 0.78%
2025-08-15 03:44:22,548 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-15 03:44:24,771 - INFO - Fold 1, Epoch 50: Val Acc: 0.72%
2025-08-15 03:44:26,991 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-15 03:44:29,208 - INFO - Fold 1, Epoch 70: Val Acc: 0.78%
2025-08-15 03:44:31,430 - INFO - Fold 1, Epoch 80: Val Acc: 0.78%
2025-08-15 03:44:35,762 - INFO - Fold 1, Epoch 90: Val Acc: 0.59%
2025-08-15 03:44:37,744 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-15 03:44:39,577 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-15 03:44:41,563 - INFO - Fold 1, Epoch 120: Val Acc: 0.78%
2025-08-15 03:44:43,569 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-15 03:44:48,023 - INFO - Fold 1, Epoch 140: Val Acc: 0.81%
2025-08-15 03:44:50,239 - INFO - Fold 1, Epoch 150: Val Acc: 0.69%
2025-08-15 03:44:52,319 - INFO - Fold 1, Epoch 160: Val Acc: 0.56%
2025-08-15 03:44:54,510 - INFO - Fold 1, Epoch 170: Val Acc: 0.72%
2025-08-15 03:44:56,730 - INFO - Fold 1, Epoch 180: Val Acc: 0.66%
2025-08-15 03:44:58,959 - INFO - Fold 1, Epoch 190: Val Acc: 0.66%
2025-08-15 03:45:01,198 - INFO - Fold 1, Epoch 200: Val Acc: 0.75%
2025-08-15 03:45:03,437 - INFO - Fold 1, Epoch 210: Val Acc: 0.59%
2025-08-15 03:45:05,696 - INFO - Fold 1, Epoch 220: Val Acc: 0.78%
2025-08-15 03:45:07,972 - INFO - Fold 1, Epoch 230: Val Acc: 0.84%
2025-08-15 03:45:13,000 - INFO - Fold 1, Epoch 240: Val Acc: 0.69%
2025-08-15 03:45:15,328 - INFO - Fold 1, Epoch 250: Val Acc: 0.75%
2025-08-15 03:45:17,609 - INFO - Fold 1, Epoch 260: Val Acc: 0.56%
2025-08-15 03:45:19,852 - INFO - Fold 1, Epoch 270: Val Acc: 0.69%
2025-08-15 03:45:22,089 - INFO - Fold 1, Epoch 280: Val Acc: 0.69%
2025-08-15 03:45:24,319 - INFO - Fold 1, Epoch 290: Val Acc: 0.72%
2025-08-15 03:45:26,552 - INFO - Fold 1, Epoch 300: Val Acc: 0.47%
2025-08-15 03:45:28,779 - INFO - Fold 1, Epoch 310: Val Acc: 0.62%
2025-08-15 03:45:30,993 - INFO - Fold 1, Epoch 320: Val Acc: 0.72%
2025-08-15 03:45:33,215 - INFO - Fold 1, Epoch 330: Val Acc: 0.56%
2025-08-15 03:45:34,543 - INFO - Early stopping at epoch 336
2025-08-15 03:45:38,114 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:45:38,117 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:45:38,117 - INFO - Starting training for fold 2/3
2025-08-15 03:45:47,718 - INFO - Fold 2, Epoch 10: Val Acc: 0.62%
2025-08-15 03:45:51,572 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-15 03:45:56,768 - INFO - Fold 2, Epoch 30: Val Acc: 0.81%
2025-08-15 03:45:58,707 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-15 03:46:00,882 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-15 03:46:02,938 - INFO - Fold 2, Epoch 60: Val Acc: 0.56%
2025-08-15 03:46:05,105 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-15 03:46:07,243 - INFO - Fold 2, Epoch 80: Val Acc: 0.81%
2025-08-15 03:46:09,288 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-15 03:46:11,546 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-15 03:46:13,867 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-15 03:46:16,175 - INFO - Fold 2, Epoch 120: Val Acc: 0.66%
2025-08-15 03:46:18,025 - INFO - Early stopping at epoch 128
2025-08-15 03:46:19,061 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:46:19,062 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:46:19,063 - INFO - Starting training for fold 3/3
2025-08-15 03:46:28,290 - INFO - Fold 3, Epoch 10: Val Acc: 0.72%
2025-08-15 03:46:34,834 - INFO - Fold 3, Epoch 20: Val Acc: 0.81%
2025-08-15 03:46:40,147 - INFO - Fold 3, Epoch 30: Val Acc: 0.75%
2025-08-15 03:46:42,368 - INFO - Fold 3, Epoch 40: Val Acc: 0.81%
2025-08-15 03:46:46,079 - INFO - Fold 3, Epoch 50: Val Acc: 0.88%
2025-08-15 03:46:48,303 - INFO - Fold 3, Epoch 60: Val Acc: 0.84%
2025-08-15 03:46:50,507 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-15 03:46:52,554 - INFO - Fold 3, Epoch 80: Val Acc: 0.81%
2025-08-15 03:46:54,764 - INFO - Fold 3, Epoch 90: Val Acc: 0.69%
2025-08-15 03:46:56,981 - INFO - Fold 3, Epoch 100: Val Acc: 0.84%
2025-08-15 03:46:59,020 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-15 03:47:01,250 - INFO - Fold 3, Epoch 120: Val Acc: 0.69%
2025-08-15 03:47:03,477 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-15 03:47:07,291 - INFO - Fold 3, Epoch 140: Val Acc: 0.66%
2025-08-15 03:47:09,519 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-15 03:47:11,741 - INFO - Fold 3, Epoch 160: Val Acc: 0.84%
2025-08-15 03:47:13,970 - INFO - Fold 3, Epoch 170: Val Acc: 0.66%
2025-08-15 03:47:16,277 - INFO - Fold 3, Epoch 180: Val Acc: 0.53%
2025-08-15 03:47:18,601 - INFO - Fold 3, Epoch 190: Val Acc: 0.75%
2025-08-15 03:47:20,801 - INFO - Fold 3, Epoch 200: Val Acc: 0.66%
2025-08-15 03:47:22,612 - INFO - Fold 3, Epoch 210: Val Acc: 0.84%
2025-08-15 03:47:24,424 - INFO - Fold 3, Epoch 220: Val Acc: 0.66%
2025-08-15 03:47:26,232 - INFO - Fold 3, Epoch 230: Val Acc: 0.78%
2025-08-15 03:47:26,954 - INFO - Early stopping at epoch 234
2025-08-15 03:47:27,990 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.8084869384765625), 'std': np.float64(0.17720783288315678)}, 'train_accuracy': {'mean': np.float64(0.8194444444444443), 'std': np.float64(0.043645156562418456)}, 'val_loss': {'mean': np.float64(4.19067923227946), 'std': np.float64(0.04280747413298986)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.02946278254943948)}, 'epoch': {'mean': np.float64(131.66666666666666), 'std': np.float64(84.92087820763251)}}
[I 2025-08-15 03:47:27,998] Trial 181 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0006998587531484279, 'batch_size': 32, 'num_epochs': 853, 'temperature': 0.32572364115629104, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2501342143959346, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07628256376589296, 'crop_size': 0.5304815696101323}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 181 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0006998587531484279, 'batch_size': 32, 'num_epochs': 853, 'temperature': 0.32572364115629104, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2501342143959346, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07628256376589296, 'crop_size': 0.5304815696101323}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:47:28,054 - INFO - Using device: cuda
2025-08-15 03:47:37,725 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:47:37,726 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:47:37,726 - INFO - Starting training for fold 1/3
2025-08-15 03:47:44,425 - INFO - Fold 1, Epoch 10: Val Acc: 0.66%
2025-08-15 03:47:51,287 - INFO - Fold 1, Epoch 20: Val Acc: 0.75%
2025-08-15 03:47:55,638 - INFO - Fold 1, Epoch 30: Val Acc: 0.88%
2025-08-15 03:47:57,906 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-15 03:48:00,206 - INFO - Fold 1, Epoch 50: Val Acc: 0.84%
2025-08-15 03:48:02,520 - INFO - Fold 1, Epoch 60: Val Acc: 0.62%
2025-08-15 03:48:04,822 - INFO - Fold 1, Epoch 70: Val Acc: 0.78%
2025-08-15 03:48:07,127 - INFO - Fold 1, Epoch 80: Val Acc: 0.62%
2025-08-15 03:48:09,436 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-15 03:48:11,668 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-15 03:48:13,885 - INFO - Fold 1, Epoch 110: Val Acc: 0.59%
2025-08-15 03:48:16,099 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-15 03:48:18,030 - INFO - Early stopping at epoch 130
2025-08-15 03:48:21,573 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:48:21,583 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:48:21,583 - INFO - Starting training for fold 2/3
2025-08-15 03:48:26,576 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 03:48:31,332 - INFO - Fold 2, Epoch 20: Val Acc: 0.72%
2025-08-15 03:48:33,475 - INFO - Fold 2, Epoch 30: Val Acc: 0.78%
2025-08-15 03:48:37,119 - INFO - Fold 2, Epoch 40: Val Acc: 0.66%
2025-08-15 03:48:40,954 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-15 03:48:43,075 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-15 03:48:45,321 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-15 03:48:47,549 - INFO - Fold 2, Epoch 80: Val Acc: 0.84%
2025-08-15 03:48:49,638 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-15 03:48:51,565 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-15 03:48:53,585 - INFO - Fold 2, Epoch 110: Val Acc: 0.84%
2025-08-15 03:48:55,813 - INFO - Fold 2, Epoch 120: Val Acc: 0.78%
2025-08-15 03:48:58,042 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-15 03:49:00,266 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-15 03:49:01,376 - INFO - Early stopping at epoch 145
2025-08-15 03:49:04,288 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:49:04,291 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:49:04,291 - INFO - Starting training for fold 3/3
2025-08-15 03:49:10,714 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-15 03:49:14,368 - INFO - Fold 3, Epoch 20: Val Acc: 0.66%
2025-08-15 03:49:17,909 - INFO - Fold 3, Epoch 30: Val Acc: 0.72%
2025-08-15 03:49:21,059 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-15 03:49:24,494 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-15 03:49:26,731 - INFO - Fold 3, Epoch 60: Val Acc: 0.78%
2025-08-15 03:49:28,984 - INFO - Fold 3, Epoch 70: Val Acc: 0.75%
2025-08-15 03:49:31,231 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-15 03:49:33,461 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-15 03:49:35,679 - INFO - Fold 3, Epoch 100: Val Acc: 0.59%
2025-08-15 03:49:37,896 - INFO - Fold 3, Epoch 110: Val Acc: 0.81%
2025-08-15 03:49:40,100 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-15 03:49:42,319 - INFO - Fold 3, Epoch 130: Val Acc: 0.50%
2025-08-15 03:49:44,552 - INFO - Fold 3, Epoch 140: Val Acc: 0.69%
2025-08-15 03:49:45,672 - INFO - Early stopping at epoch 145
2025-08-15 03:49:46,736 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9528512424892845), 'std': np.float64(0.04355354629933913)}, 'train_accuracy': {'mean': np.float64(0.7604166666666666), 'std': np.float64(0.05103103630798288)}, 'val_loss': {'mean': np.float64(4.230189323425293), 'std': np.float64(0.06748214899543767)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(39.0), 'std': np.float64(7.0710678118654755)}}
[I 2025-08-15 03:49:46,742] Trial 182 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0006692205877204013, 'batch_size': 32, 'num_epochs': 859, 'temperature': 0.35396770174430564, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.26786492938651685, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06885637740919791, 'crop_size': 0.525170124923101}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 182 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0006692205877204013, 'batch_size': 32, 'num_epochs': 859, 'temperature': 0.35396770174430564, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.26786492938651685, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06885637740919791, 'crop_size': 0.525170124923101}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:49:46,786 - INFO - Using device: cuda
2025-08-15 03:49:56,365 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:49:56,367 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:49:56,367 - INFO - Starting training for fold 1/3
2025-08-15 03:50:05,439 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-15 03:50:07,466 - INFO - Fold 1, Epoch 20: Val Acc: 0.59%
2025-08-15 03:50:09,329 - INFO - Fold 1, Epoch 30: Val Acc: 0.75%
2025-08-15 03:50:11,194 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-15 03:50:17,169 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-15 03:50:19,143 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-15 03:50:21,256 - INFO - Fold 1, Epoch 70: Val Acc: 0.75%
2025-08-15 03:50:23,385 - INFO - Fold 1, Epoch 80: Val Acc: 0.78%
2025-08-15 03:50:25,465 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-15 03:50:29,998 - INFO - Fold 1, Epoch 100: Val Acc: 0.66%
2025-08-15 03:50:32,240 - INFO - Fold 1, Epoch 110: Val Acc: 0.59%
2025-08-15 03:50:34,479 - INFO - Fold 1, Epoch 120: Val Acc: 0.81%
2025-08-15 03:50:36,569 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-15 03:50:38,717 - INFO - Fold 1, Epoch 140: Val Acc: 0.59%
2025-08-15 03:50:40,948 - INFO - Fold 1, Epoch 150: Val Acc: 0.59%
2025-08-15 03:50:42,979 - INFO - Fold 1, Epoch 160: Val Acc: 0.62%
2025-08-15 03:50:45,223 - INFO - Fold 1, Epoch 170: Val Acc: 0.62%
2025-08-15 03:50:47,340 - INFO - Fold 1, Epoch 180: Val Acc: 0.66%
2025-08-15 03:50:49,585 - INFO - Fold 1, Epoch 190: Val Acc: 0.69%
2025-08-15 03:50:50,939 - INFO - Early stopping at epoch 196
2025-08-15 03:50:54,513 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:50:54,516 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:50:54,516 - INFO - Starting training for fold 2/3
2025-08-15 03:51:03,735 - INFO - Fold 2, Epoch 10: Val Acc: 0.75%
2025-08-15 03:51:08,224 - INFO - Fold 2, Epoch 20: Val Acc: 0.69%
2025-08-15 03:51:09,953 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-15 03:51:13,195 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-15 03:51:16,389 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-15 03:51:18,632 - INFO - Fold 2, Epoch 60: Val Acc: 0.69%
2025-08-15 03:51:20,935 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-15 03:51:23,247 - INFO - Fold 2, Epoch 80: Val Acc: 0.78%
2025-08-15 03:51:26,903 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-15 03:51:28,965 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-15 03:51:30,988 - INFO - Fold 2, Epoch 110: Val Acc: 0.84%
2025-08-15 03:51:33,056 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-15 03:51:35,283 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-15 03:51:37,502 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-15 03:51:39,787 - INFO - Fold 2, Epoch 150: Val Acc: 0.72%
2025-08-15 03:51:42,091 - INFO - Fold 2, Epoch 160: Val Acc: 0.78%
2025-08-15 03:51:44,418 - INFO - Fold 2, Epoch 170: Val Acc: 0.78%
2025-08-15 03:51:46,727 - INFO - Fold 2, Epoch 180: Val Acc: 0.84%
2025-08-15 03:51:47,659 - INFO - Early stopping at epoch 184
2025-08-15 03:51:48,720 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:51:48,723 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:51:48,723 - INFO - Starting training for fold 3/3
2025-08-15 03:51:53,800 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-15 03:51:57,502 - INFO - Fold 3, Epoch 20: Val Acc: 0.66%
2025-08-15 03:52:01,187 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-15 03:52:04,896 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-15 03:52:08,557 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-15 03:52:12,119 - INFO - Fold 3, Epoch 60: Val Acc: 0.78%
2025-08-15 03:52:14,366 - INFO - Fold 3, Epoch 70: Val Acc: 0.84%
2025-08-15 03:52:16,599 - INFO - Fold 3, Epoch 80: Val Acc: 0.81%
2025-08-15 03:52:18,802 - INFO - Fold 3, Epoch 90: Val Acc: 0.62%
2025-08-15 03:52:21,027 - INFO - Fold 3, Epoch 100: Val Acc: 0.62%
2025-08-15 03:52:23,259 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-15 03:52:25,501 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-15 03:52:27,737 - INFO - Fold 3, Epoch 130: Val Acc: 0.78%
2025-08-15 03:52:29,970 - INFO - Fold 3, Epoch 140: Val Acc: 0.81%
2025-08-15 03:52:32,199 - INFO - Fold 3, Epoch 150: Val Acc: 0.81%
2025-08-15 03:52:33,566 - INFO - Early stopping at epoch 156
2025-08-15 03:52:36,469 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.897668308681912), 'std': np.float64(0.03784615826288878)}, 'train_accuracy': {'mean': np.float64(0.75), 'std': np.float64(0.014731391274719766)}, 'val_loss': {'mean': np.float64(4.217871189117432), 'std': np.float64(0.05931498745454322)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(77.66666666666667), 'std': np.float64(16.75974011996871)}}
[I 2025-08-15 03:52:36,480] Trial 183 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0005590716449828175, 'batch_size': 32, 'num_epochs': 821, 'temperature': 0.3185107457961447, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.28498085858033606, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.056972377356407505, 'crop_size': 0.5172184307239748}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 183 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0005590716449828175, 'batch_size': 32, 'num_epochs': 821, 'temperature': 0.3185107457961447, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.28498085858033606, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.056972377356407505, 'crop_size': 0.5172184307239748}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:52:36,575 - INFO - Using device: cuda
2025-08-15 03:52:46,476 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:52:46,486 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:52:46,486 - INFO - Starting training for fold 1/3
2025-08-15 03:52:55,721 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-15 03:53:00,142 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-15 03:53:06,899 - INFO - Fold 1, Epoch 30: Val Acc: 0.72%
2025-08-15 03:53:11,288 - INFO - Fold 1, Epoch 40: Val Acc: 0.59%
2025-08-15 03:53:13,515 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-15 03:53:17,932 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-15 03:53:20,101 - INFO - Fold 1, Epoch 70: Val Acc: 0.62%
2025-08-15 03:53:22,013 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-15 03:53:23,926 - INFO - Fold 1, Epoch 90: Val Acc: 0.66%
2025-08-15 03:53:26,157 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-15 03:53:28,376 - INFO - Fold 1, Epoch 110: Val Acc: 0.75%
2025-08-15 03:53:30,594 - INFO - Fold 1, Epoch 120: Val Acc: 0.72%
2025-08-15 03:53:32,813 - INFO - Fold 1, Epoch 130: Val Acc: 0.66%
2025-08-15 03:53:34,899 - INFO - Fold 1, Epoch 140: Val Acc: 0.66%
2025-08-15 03:53:37,108 - INFO - Fold 1, Epoch 150: Val Acc: 0.56%
2025-08-15 03:53:39,099 - INFO - Early stopping at epoch 159
2025-08-15 03:53:42,640 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:53:42,644 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:53:42,645 - INFO - Starting training for fold 2/3
2025-08-15 03:53:49,245 - INFO - Fold 2, Epoch 10: Val Acc: 0.53%
2025-08-15 03:53:53,968 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-15 03:53:56,188 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-15 03:53:58,357 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-15 03:54:01,858 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-15 03:54:04,076 - INFO - Fold 2, Epoch 60: Val Acc: 0.78%
2025-08-15 03:54:05,826 - INFO - Fold 2, Epoch 70: Val Acc: 0.66%
2025-08-15 03:54:07,539 - INFO - Fold 2, Epoch 80: Val Acc: 0.72%
2025-08-15 03:54:09,580 - INFO - Fold 2, Epoch 90: Val Acc: 0.84%
2025-08-15 03:54:11,722 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-15 03:54:13,960 - INFO - Fold 2, Epoch 110: Val Acc: 0.84%
2025-08-15 03:54:16,198 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-15 03:54:18,437 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-15 03:54:20,684 - INFO - Fold 2, Epoch 140: Val Acc: 0.66%
2025-08-15 03:54:24,299 - INFO - Fold 2, Epoch 150: Val Acc: 0.81%
2025-08-15 03:54:26,519 - INFO - Fold 2, Epoch 160: Val Acc: 0.88%
2025-08-15 03:54:28,762 - INFO - Fold 2, Epoch 170: Val Acc: 0.81%
2025-08-15 03:54:31,009 - INFO - Fold 2, Epoch 180: Val Acc: 0.81%
2025-08-15 03:54:33,243 - INFO - Fold 2, Epoch 190: Val Acc: 0.78%
2025-08-15 03:54:35,465 - INFO - Fold 2, Epoch 200: Val Acc: 0.69%
2025-08-15 03:54:37,699 - INFO - Fold 2, Epoch 210: Val Acc: 0.81%
2025-08-15 03:54:39,927 - INFO - Fold 2, Epoch 220: Val Acc: 0.78%
2025-08-15 03:54:42,150 - INFO - Fold 2, Epoch 230: Val Acc: 0.72%
2025-08-15 03:54:44,375 - INFO - Fold 2, Epoch 240: Val Acc: 0.78%
2025-08-15 03:54:45,928 - INFO - Early stopping at epoch 247
2025-08-15 03:54:48,675 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:54:48,678 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:54:48,679 - INFO - Starting training for fold 3/3
2025-08-15 03:54:55,321 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-15 03:54:59,041 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-15 03:55:02,717 - INFO - Fold 3, Epoch 30: Val Acc: 0.69%
2025-08-15 03:55:06,287 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-15 03:55:09,931 - INFO - Fold 3, Epoch 50: Val Acc: 0.84%
2025-08-15 03:55:14,006 - INFO - Fold 3, Epoch 60: Val Acc: 0.78%
2025-08-15 03:55:16,233 - INFO - Fold 3, Epoch 70: Val Acc: 0.78%
2025-08-15 03:55:18,336 - INFO - Fold 3, Epoch 80: Val Acc: 0.69%
2025-08-15 03:55:20,046 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-15 03:55:22,026 - INFO - Fold 3, Epoch 100: Val Acc: 0.84%
2025-08-15 03:55:24,138 - INFO - Fold 3, Epoch 110: Val Acc: 0.69%
2025-08-15 03:55:25,968 - INFO - Fold 3, Epoch 120: Val Acc: 0.69%
2025-08-15 03:55:27,903 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-15 03:55:30,129 - INFO - Fold 3, Epoch 140: Val Acc: 0.66%
2025-08-15 03:55:32,140 - INFO - Fold 3, Epoch 150: Val Acc: 0.81%
2025-08-15 03:55:34,142 - INFO - Early stopping at epoch 159
2025-08-15 03:55:35,163 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.860471169153849), 'std': np.float64(0.08428024536965636)}, 'train_accuracy': {'mean': np.float64(0.7708333333333334), 'std': np.float64(0.017010345435994324)}, 'val_loss': {'mean': np.float64(4.221214294433594), 'std': np.float64(0.07115239476447996)}, 'val_accuracy': {'mean': np.float64(0.9375), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(87.33333333333333), 'std': np.float64(41.48359782961079)}}
[I 2025-08-15 03:55:35,169] Trial 184 finished with value: -0.9375 and parameters: {'learning_rate': 0.0008073980840094295, 'batch_size': 32, 'num_epochs': 871, 'temperature': 0.4585939926830271, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2519207845282748, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.059610111708607166, 'crop_size': 0.538688252342324}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 184 finished with value: -0.9375 and parameters: {'learning_rate': 0.0008073980840094295, 'batch_size': 32, 'num_epochs': 871, 'temperature': 0.4585939926830271, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2519207845282748, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.059610111708607166, 'crop_size': 0.538688252342324}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:55:35,213 - INFO - Using device: cuda
2025-08-15 03:55:45,030 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:55:45,031 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:55:45,032 - INFO - Starting training for fold 1/3
2025-08-15 03:55:53,891 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-15 03:56:02,761 - INFO - Fold 1, Epoch 20: Val Acc: 0.66%
2025-08-15 03:56:07,047 - INFO - Fold 1, Epoch 30: Val Acc: 0.78%
2025-08-15 03:56:13,724 - INFO - Fold 1, Epoch 40: Val Acc: 0.75%
2025-08-15 03:56:15,936 - INFO - Fold 1, Epoch 50: Val Acc: 0.88%
2025-08-15 03:56:17,767 - INFO - Fold 1, Epoch 60: Val Acc: 0.81%
2025-08-15 03:56:19,483 - INFO - Fold 1, Epoch 70: Val Acc: 0.78%
2025-08-15 03:56:21,461 - INFO - Fold 1, Epoch 80: Val Acc: 0.84%
2025-08-15 03:56:23,367 - INFO - Fold 1, Epoch 90: Val Acc: 0.66%
2025-08-15 03:56:25,239 - INFO - Fold 1, Epoch 100: Val Acc: 0.78%
2025-08-15 03:56:26,954 - INFO - Fold 1, Epoch 110: Val Acc: 0.75%
2025-08-15 03:56:28,757 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-15 03:56:30,980 - INFO - Fold 1, Epoch 130: Val Acc: 0.56%
2025-08-15 03:56:32,978 - INFO - Early stopping at epoch 139
2025-08-15 03:56:36,473 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:56:36,476 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:56:36,476 - INFO - Starting training for fold 2/3
2025-08-15 03:56:44,588 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 03:56:49,743 - INFO - Fold 2, Epoch 20: Val Acc: 0.72%
2025-08-15 03:56:51,778 - INFO - Fold 2, Epoch 30: Val Acc: 0.59%
2025-08-15 03:56:55,351 - INFO - Fold 2, Epoch 40: Val Acc: 0.84%
2025-08-15 03:56:57,574 - INFO - Fold 2, Epoch 50: Val Acc: 0.88%
2025-08-15 03:56:59,485 - INFO - Fold 2, Epoch 60: Val Acc: 0.84%
2025-08-15 03:57:01,708 - INFO - Fold 2, Epoch 70: Val Acc: 0.84%
2025-08-15 03:57:03,935 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-15 03:57:06,169 - INFO - Fold 2, Epoch 90: Val Acc: 0.59%
2025-08-15 03:57:08,404 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-15 03:57:10,634 - INFO - Fold 2, Epoch 110: Val Acc: 0.81%
2025-08-15 03:57:12,864 - INFO - Fold 2, Epoch 120: Val Acc: 0.78%
2025-08-15 03:57:14,668 - INFO - Fold 2, Epoch 130: Val Acc: 0.62%
2025-08-15 03:57:16,063 - INFO - Early stopping at epoch 137
2025-08-15 03:57:17,097 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:57:17,099 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:57:17,100 - INFO - Starting training for fold 3/3
2025-08-15 03:57:25,010 - INFO - Fold 3, Epoch 10: Val Acc: 0.47%
2025-08-15 03:57:26,996 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-15 03:57:30,711 - INFO - Fold 3, Epoch 30: Val Acc: 0.69%
2025-08-15 03:57:32,950 - INFO - Fold 3, Epoch 40: Val Acc: 0.84%
2025-08-15 03:57:35,184 - INFO - Fold 3, Epoch 50: Val Acc: 0.62%
2025-08-15 03:57:37,416 - INFO - Fold 3, Epoch 60: Val Acc: 0.62%
2025-08-15 03:57:41,088 - INFO - Fold 3, Epoch 70: Val Acc: 0.78%
2025-08-15 03:57:43,325 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-15 03:57:45,556 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-15 03:57:47,740 - INFO - Fold 3, Epoch 100: Val Acc: 0.84%
2025-08-15 03:57:49,941 - INFO - Fold 3, Epoch 110: Val Acc: 0.69%
2025-08-15 03:57:52,171 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-15 03:57:54,397 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-15 03:57:56,635 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-15 03:57:58,866 - INFO - Fold 3, Epoch 150: Val Acc: 0.62%
2025-08-15 03:58:01,095 - INFO - Fold 3, Epoch 160: Val Acc: 0.75%
2025-08-15 03:58:01,272 - INFO - Early stopping at epoch 161
2025-08-15 03:58:02,311 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.969249195522732), 'std': np.float64(0.038160069217631744)}, 'train_accuracy': {'mean': np.float64(0.7777777777777778), 'std': np.float64(0.02455231879119953)}, 'val_loss': {'mean': np.float64(4.246293862660726), 'std': np.float64(0.03198356066633279)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(44.666666666666664), 'std': np.float64(10.873004286866726)}}
[I 2025-08-15 03:58:02,319] Trial 185 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0009071413691656857, 'batch_size': 32, 'num_epochs': 898, 'temperature': 0.4492092665159474, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4813470273485472, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06401579485948097, 'crop_size': 0.5520225628568489}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 185 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0009071413691656857, 'batch_size': 32, 'num_epochs': 898, 'temperature': 0.4492092665159474, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.4813470273485472, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06401579485948097, 'crop_size': 0.5520225628568489}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 03:58:02,364 - INFO - Using device: cuda
2025-08-15 03:58:12,447 - INFO - --- Starting Fold 1/3 ---
2025-08-15 03:58:12,449 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:58:12,449 - INFO - Starting training for fold 1/3
2025-08-15 03:58:23,525 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-15 03:58:27,741 - INFO - Fold 1, Epoch 20: Val Acc: 0.78%
2025-08-15 03:58:34,501 - INFO - Fold 1, Epoch 30: Val Acc: 0.81%
2025-08-15 03:58:36,667 - INFO - Fold 1, Epoch 40: Val Acc: 0.56%
2025-08-15 03:58:38,895 - INFO - Fold 1, Epoch 50: Val Acc: 0.84%
2025-08-15 03:58:40,978 - INFO - Fold 1, Epoch 60: Val Acc: 0.81%
2025-08-15 03:58:42,950 - INFO - Fold 1, Epoch 70: Val Acc: 0.75%
2025-08-15 03:58:45,182 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-15 03:58:47,261 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-15 03:58:49,498 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-15 03:58:51,452 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-15 03:58:53,567 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-15 03:58:54,899 - INFO - Early stopping at epoch 126
2025-08-15 03:58:58,607 - INFO - --- Starting Fold 2/3 ---
2025-08-15 03:58:58,610 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:58:58,611 - INFO - Starting training for fold 2/3
2025-08-15 03:59:03,870 - INFO - Fold 2, Epoch 10: Val Acc: 0.69%
2025-08-15 03:59:07,716 - INFO - Fold 2, Epoch 20: Val Acc: 0.75%
2025-08-15 03:59:12,752 - INFO - Fold 2, Epoch 30: Val Acc: 0.81%
2025-08-15 03:59:14,980 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-15 03:59:17,201 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-15 03:59:19,259 - INFO - Fold 2, Epoch 60: Val Acc: 0.69%
2025-08-15 03:59:21,408 - INFO - Fold 2, Epoch 70: Val Acc: 0.69%
2025-08-15 03:59:23,625 - INFO - Fold 2, Epoch 80: Val Acc: 0.72%
2025-08-15 03:59:25,679 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-15 03:59:27,393 - INFO - Fold 2, Epoch 100: Val Acc: 0.69%
2025-08-15 03:59:29,400 - INFO - Fold 2, Epoch 110: Val Acc: 0.84%
2025-08-15 03:59:31,447 - INFO - Fold 2, Epoch 120: Val Acc: 0.81%
2025-08-15 03:59:32,786 - INFO - Early stopping at epoch 127
2025-08-15 03:59:33,805 - INFO - --- Starting Fold 3/3 ---
2025-08-15 03:59:33,807 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 03:59:33,807 - INFO - Starting training for fold 3/3
2025-08-15 03:59:41,938 - INFO - Fold 3, Epoch 10: Val Acc: 0.69%
2025-08-15 03:59:45,560 - INFO - Fold 3, Epoch 20: Val Acc: 0.72%
2025-08-15 03:59:49,228 - INFO - Fold 3, Epoch 30: Val Acc: 0.81%
2025-08-15 03:59:52,740 - INFO - Fold 3, Epoch 40: Val Acc: 0.81%
2025-08-15 03:59:54,968 - INFO - Fold 3, Epoch 50: Val Acc: 0.81%
2025-08-15 03:59:57,195 - INFO - Fold 3, Epoch 60: Val Acc: 0.72%
2025-08-15 03:59:59,426 - INFO - Fold 3, Epoch 70: Val Acc: 0.69%
2025-08-15 04:00:01,665 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-15 04:00:03,897 - INFO - Fold 3, Epoch 90: Val Acc: 0.78%
2025-08-15 04:00:06,122 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-15 04:00:07,984 - INFO - Fold 3, Epoch 110: Val Acc: 0.69%
2025-08-15 04:00:09,688 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-15 04:00:11,564 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-15 04:00:12,758 - INFO - Early stopping at epoch 137
2025-08-15 04:00:13,786 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.947284539540609), 'std': np.float64(0.03319030677611227)}, 'train_accuracy': {'mean': np.float64(0.7256944444444445), 'std': np.float64(0.0177049288666416)}, 'val_loss': {'mean': np.float64(4.220925172170003), 'std': np.float64(0.05462136727708463)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(29.0), 'std': np.float64(4.96655480858378)}}
[I 2025-08-15 04:00:13,792] Trial 186 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0007900226527455622, 'batch_size': 32, 'num_epochs': 877, 'temperature': 0.4573602597778863, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.449165302622857, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07003292471842433, 'crop_size': 0.562702320686159}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 186 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.0007900226527455622, 'batch_size': 32, 'num_epochs': 877, 'temperature': 0.4573602597778863, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.449165302622857, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.07003292471842433, 'crop_size': 0.562702320686159}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 04:00:13,836 - INFO - Using device: cuda
2025-08-15 04:00:23,824 - INFO - --- Starting Fold 1/3 ---
2025-08-15 04:00:23,826 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:00:23,826 - INFO - Starting training for fold 1/3
2025-08-15 04:00:31,523 - INFO - Fold 1, Epoch 10: Val Acc: 0.50%
2025-08-15 04:00:33,345 - INFO - Fold 1, Epoch 20: Val Acc: 0.50%
2025-08-15 04:00:38,944 - INFO - Fold 1, Epoch 30: Val Acc: 0.72%
2025-08-15 04:00:40,943 - INFO - Fold 1, Epoch 40: Val Acc: 0.66%
2025-08-15 04:00:44,765 - INFO - Fold 1, Epoch 50: Val Acc: 0.69%
2025-08-15 04:00:50,148 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-15 04:00:52,161 - INFO - Fold 1, Epoch 70: Val Acc: 0.69%
2025-08-15 04:00:54,171 - INFO - Fold 1, Epoch 80: Val Acc: 0.56%
2025-08-15 04:00:56,182 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-15 04:00:58,162 - INFO - Fold 1, Epoch 100: Val Acc: 0.72%
2025-08-15 04:01:00,172 - INFO - Fold 1, Epoch 110: Val Acc: 0.66%
2025-08-15 04:01:02,176 - INFO - Fold 1, Epoch 120: Val Acc: 0.81%
2025-08-15 04:01:04,179 - INFO - Fold 1, Epoch 130: Val Acc: 0.53%
2025-08-15 04:01:06,191 - INFO - Fold 1, Epoch 140: Val Acc: 0.66%
2025-08-15 04:01:08,197 - INFO - Fold 1, Epoch 150: Val Acc: 0.62%
2025-08-15 04:01:12,153 - INFO - Fold 1, Epoch 160: Val Acc: 0.69%
2025-08-15 04:01:14,145 - INFO - Fold 1, Epoch 170: Val Acc: 0.75%
2025-08-15 04:01:16,137 - INFO - Fold 1, Epoch 180: Val Acc: 0.59%
2025-08-15 04:01:18,127 - INFO - Fold 1, Epoch 190: Val Acc: 0.75%
2025-08-15 04:01:20,136 - INFO - Fold 1, Epoch 200: Val Acc: 0.75%
2025-08-15 04:01:22,152 - INFO - Fold 1, Epoch 210: Val Acc: 0.69%
2025-08-15 04:01:24,157 - INFO - Fold 1, Epoch 220: Val Acc: 0.69%
2025-08-15 04:01:26,145 - INFO - Fold 1, Epoch 230: Val Acc: 0.81%
2025-08-15 04:01:28,156 - INFO - Fold 1, Epoch 240: Val Acc: 0.66%
2025-08-15 04:01:30,174 - INFO - Fold 1, Epoch 250: Val Acc: 0.78%
2025-08-15 04:01:31,185 - INFO - Early stopping at epoch 255
2025-08-15 04:01:34,093 - INFO - --- Starting Fold 2/3 ---
2025-08-15 04:01:34,102 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:01:34,103 - INFO - Starting training for fold 2/3
2025-08-15 04:01:37,360 - INFO - Fold 2, Epoch 10: Val Acc: 0.47%
2025-08-15 04:01:42,804 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-15 04:01:47,094 - INFO - Fold 2, Epoch 30: Val Acc: 0.50%
2025-08-15 04:01:49,123 - INFO - Fold 2, Epoch 40: Val Acc: 0.56%
2025-08-15 04:01:52,176 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-15 04:01:53,895 - INFO - Fold 2, Epoch 60: Val Acc: 0.78%
2025-08-15 04:01:56,694 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-15 04:01:58,327 - INFO - Fold 2, Epoch 80: Val Acc: 0.88%
2025-08-15 04:02:00,229 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-15 04:02:02,227 - INFO - Fold 2, Epoch 100: Val Acc: 0.69%
2025-08-15 04:02:04,223 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-15 04:02:06,213 - INFO - Fold 2, Epoch 120: Val Acc: 0.78%
2025-08-15 04:02:09,005 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-15 04:02:10,868 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-15 04:02:12,422 - INFO - Fold 2, Epoch 150: Val Acc: 0.56%
2025-08-15 04:02:14,427 - INFO - Fold 2, Epoch 160: Val Acc: 0.84%
2025-08-15 04:02:16,410 - INFO - Fold 2, Epoch 170: Val Acc: 0.72%
2025-08-15 04:02:18,409 - INFO - Fold 2, Epoch 180: Val Acc: 0.81%
2025-08-15 04:02:20,400 - INFO - Fold 2, Epoch 190: Val Acc: 0.78%
2025-08-15 04:02:22,407 - INFO - Fold 2, Epoch 200: Val Acc: 0.78%
2025-08-15 04:02:24,304 - INFO - Fold 2, Epoch 210: Val Acc: 0.81%
2025-08-15 04:02:26,268 - INFO - Fold 2, Epoch 220: Val Acc: 0.84%
2025-08-15 04:02:26,668 - INFO - Early stopping at epoch 222
2025-08-15 04:02:27,481 - INFO - --- Starting Fold 3/3 ---
2025-08-15 04:02:27,482 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:02:27,483 - INFO - Starting training for fold 3/3
2025-08-15 04:02:33,360 - INFO - Fold 3, Epoch 10: Val Acc: 0.56%
2025-08-15 04:02:36,400 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-15 04:02:38,332 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-15 04:02:40,247 - INFO - Fold 3, Epoch 40: Val Acc: 0.78%
2025-08-15 04:02:42,252 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-15 04:02:44,258 - INFO - Fold 3, Epoch 60: Val Acc: 0.78%
2025-08-15 04:02:46,273 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-15 04:02:49,418 - INFO - Fold 3, Epoch 80: Val Acc: 0.69%
2025-08-15 04:02:51,443 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-15 04:02:53,455 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-15 04:02:56,582 - INFO - Fold 3, Epoch 110: Val Acc: 0.81%
2025-08-15 04:02:58,158 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-15 04:02:59,809 - INFO - Fold 3, Epoch 130: Val Acc: 0.75%
2025-08-15 04:03:01,820 - INFO - Fold 3, Epoch 140: Val Acc: 0.75%
2025-08-15 04:03:03,790 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-15 04:03:05,345 - INFO - Fold 3, Epoch 160: Val Acc: 0.69%
2025-08-15 04:03:06,901 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-15 04:03:08,580 - INFO - Fold 3, Epoch 180: Val Acc: 0.59%
2025-08-15 04:03:10,580 - INFO - Fold 3, Epoch 190: Val Acc: 0.72%
2025-08-15 04:03:12,290 - INFO - Fold 3, Epoch 200: Val Acc: 0.69%
2025-08-15 04:03:12,445 - INFO - Early stopping at epoch 201
2025-08-15 04:03:13,263 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.8905668523576526), 'std': np.float64(0.02443573356628226)}, 'train_accuracy': {'mean': np.float64(0.7604166666666666), 'std': np.float64(0.05953620902598007)}, 'val_loss': {'mean': np.float64(4.172909100850423), 'std': np.float64(0.03472119599273659)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.0)}, 'epoch': {'mean': np.float64(125.0), 'std': np.float64(22.22611077089287)}}
[I 2025-08-15 04:03:13,270] Trial 187 finished with value: -0.90625 and parameters: {'learning_rate': 0.0004868344435594249, 'batch_size': 32, 'num_epochs': 917, 'temperature': 0.47419515250592476, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.19257989341401344, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.04682726951282211, 'crop_size': 0.5396587955942274}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 187 finished with value: -0.90625 and parameters: {'learning_rate': 0.0004868344435594249, 'batch_size': 32, 'num_epochs': 917, 'temperature': 0.47419515250592476, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.19257989341401344, 'num_layers': 4, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.04682726951282211, 'crop_size': 0.5396587955942274}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 04:03:13,314 - INFO - Using device: cuda
2025-08-15 04:03:23,093 - INFO - --- Starting Fold 1/3 ---
2025-08-15 04:03:23,095 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:03:23,095 - INFO - Starting training for fold 1/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 04:03:30,088 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-15 04:03:36,865 - INFO - Fold 1, Epoch 20: Val Acc: 0.53%
2025-08-15 04:03:43,339 - INFO - Fold 1, Epoch 30: Val Acc: 0.66%
2025-08-15 04:03:45,575 - INFO - Fold 1, Epoch 40: Val Acc: 0.62%
2025-08-15 04:03:50,036 - INFO - Fold 1, Epoch 50: Val Acc: 0.72%
2025-08-15 04:03:52,295 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-15 04:03:54,597 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-15 04:03:56,891 - INFO - Fold 1, Epoch 80: Val Acc: 0.69%
2025-08-15 04:03:58,687 - INFO - Fold 1, Epoch 90: Val Acc: 0.78%
2025-08-15 04:04:00,535 - INFO - Fold 1, Epoch 100: Val Acc: 0.78%
2025-08-15 04:04:02,664 - INFO - Fold 1, Epoch 110: Val Acc: 0.88%
2025-08-15 04:04:04,396 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-15 04:04:06,267 - INFO - Fold 1, Epoch 130: Val Acc: 0.66%
2025-08-15 04:04:08,274 - INFO - Fold 1, Epoch 140: Val Acc: 0.69%
2025-08-15 04:04:09,385 - INFO - Early stopping at epoch 145
2025-08-15 04:04:13,478 - INFO - --- Starting Fold 2/3 ---
2025-08-15 04:04:13,480 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:04:13,481 - INFO - Starting training for fold 2/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 04:04:20,566 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 04:04:22,736 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-15 04:04:26,422 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-15 04:04:29,998 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-15 04:04:32,209 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-15 04:04:33,944 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-15 04:04:35,665 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-15 04:04:39,228 - INFO - Fold 2, Epoch 80: Val Acc: 0.69%
2025-08-15 04:04:41,438 - INFO - Fold 2, Epoch 90: Val Acc: 0.75%
2025-08-15 04:04:43,656 - INFO - Fold 2, Epoch 100: Val Acc: 0.84%
2025-08-15 04:04:45,888 - INFO - Fold 2, Epoch 110: Val Acc: 0.84%
2025-08-15 04:04:48,101 - INFO - Fold 2, Epoch 120: Val Acc: 0.66%
2025-08-15 04:04:50,337 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-15 04:04:52,578 - INFO - Fold 2, Epoch 140: Val Acc: 0.69%
2025-08-15 04:04:54,814 - INFO - Fold 2, Epoch 150: Val Acc: 0.81%
2025-08-15 04:04:57,053 - INFO - Fold 2, Epoch 160: Val Acc: 0.72%
2025-08-15 04:04:59,286 - INFO - Fold 2, Epoch 170: Val Acc: 0.81%
2025-08-15 04:05:00,626 - INFO - Early stopping at epoch 176
2025-08-15 04:05:03,786 - INFO - --- Starting Fold 3/3 ---
2025-08-15 04:05:03,789 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:05:03,790 - INFO - Starting training for fold 3/3
/usr/pkg/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:227: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn(
2025-08-15 04:05:10,284 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-15 04:05:15,750 - INFO - Fold 3, Epoch 20: Val Acc: 0.72%
2025-08-15 04:05:19,387 - INFO - Fold 3, Epoch 30: Val Acc: 0.72%
2025-08-15 04:05:22,730 - INFO - Fold 3, Epoch 40: Val Acc: 0.72%
2025-08-15 04:05:24,756 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-15 04:05:26,967 - INFO - Fold 3, Epoch 60: Val Acc: 0.69%
2025-08-15 04:05:29,194 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-15 04:05:32,549 - INFO - Fold 3, Epoch 80: Val Acc: 0.78%
2025-08-15 04:05:34,794 - INFO - Fold 3, Epoch 90: Val Acc: 0.78%
2025-08-15 04:05:37,006 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-15 04:05:38,978 - INFO - Fold 3, Epoch 110: Val Acc: 0.72%
2025-08-15 04:05:40,936 - INFO - Fold 3, Epoch 120: Val Acc: 0.72%
2025-08-15 04:05:42,883 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-15 04:05:44,820 - INFO - Fold 3, Epoch 140: Val Acc: 0.69%
2025-08-15 04:05:46,816 - INFO - Fold 3, Epoch 150: Val Acc: 0.75%
2025-08-15 04:05:48,816 - INFO - Fold 3, Epoch 160: Val Acc: 0.59%
2025-08-15 04:05:51,035 - INFO - Fold 3, Epoch 170: Val Acc: 0.62%
2025-08-15 04:05:51,548 - INFO - Early stopping at epoch 173
2025-08-15 04:05:52,585 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9309679667154946), 'std': np.float64(0.02592368447874129)}, 'train_accuracy': {'mean': np.float64(0.7743055555555557), 'std': np.float64(0.04983576421669207)}, 'val_loss': {'mean': np.float64(4.251091957092285), 'std': np.float64(0.09030322277541374)}, 'val_accuracy': {'mean': np.float64(0.875), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(63.666666666666664), 'std': np.float64(13.960261060914616)}}
[I 2025-08-15 04:05:52,591] Trial 188 finished with value: -0.875 and parameters: {'learning_rate': 0.0008205625324519101, 'batch_size': 32, 'num_epochs': 935, 'temperature': 0.1651420459530604, 'embedding_dim': 128, 'hidden_dim': 128, 'dropout': 0.4327909249196791, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1792574934580393, 'crop_size': 0.5729692777839531}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 188 finished with value: -0.875 and parameters: {'learning_rate': 0.0008205625324519101, 'batch_size': 32, 'num_epochs': 935, 'temperature': 0.1651420459530604, 'embedding_dim': 128, 'hidden_dim': 128, 'dropout': 0.4327909249196791, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.1792574934580393, 'crop_size': 0.5729692777839531}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 04:05:52,636 - INFO - Using device: cuda
2025-08-15 04:06:02,738 - INFO - --- Starting Fold 1/3 ---
2025-08-15 04:06:02,740 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:06:02,740 - INFO - Starting training for fold 1/3
2025-08-15 04:06:14,022 - INFO - Fold 1, Epoch 10: Val Acc: 0.69%
2025-08-15 04:06:18,116 - INFO - Fold 1, Epoch 20: Val Acc: 0.84%
2025-08-15 04:06:20,233 - INFO - Fold 1, Epoch 30: Val Acc: 0.72%
2025-08-15 04:06:24,526 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-15 04:06:26,631 - INFO - Fold 1, Epoch 50: Val Acc: 0.72%
2025-08-15 04:06:28,734 - INFO - Fold 1, Epoch 60: Val Acc: 0.66%
2025-08-15 04:06:30,844 - INFO - Fold 1, Epoch 70: Val Acc: 0.66%
2025-08-15 04:06:32,955 - INFO - Fold 1, Epoch 80: Val Acc: 0.75%
2025-08-15 04:06:35,069 - INFO - Fold 1, Epoch 90: Val Acc: 0.59%
2025-08-15 04:06:37,189 - INFO - Fold 1, Epoch 100: Val Acc: 0.81%
2025-08-15 04:06:39,298 - INFO - Fold 1, Epoch 110: Val Acc: 0.88%
2025-08-15 04:06:41,375 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-15 04:06:43,169 - INFO - Fold 1, Epoch 130: Val Acc: 0.50%
2025-08-15 04:06:44,687 - INFO - Early stopping at epoch 138
2025-08-15 04:06:48,276 - INFO - --- Starting Fold 2/3 ---
2025-08-15 04:06:48,280 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:06:48,281 - INFO - Starting training for fold 2/3
2025-08-15 04:06:54,740 - INFO - Fold 2, Epoch 10: Val Acc: 0.50%
2025-08-15 04:07:00,759 - INFO - Fold 2, Epoch 20: Val Acc: 0.59%
2025-08-15 04:07:03,904 - INFO - Fold 2, Epoch 30: Val Acc: 0.78%
2025-08-15 04:07:07,409 - INFO - Fold 2, Epoch 40: Val Acc: 0.66%
2025-08-15 04:07:09,524 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-15 04:07:11,630 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-15 04:07:13,743 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-15 04:07:17,209 - INFO - Fold 2, Epoch 80: Val Acc: 0.78%
2025-08-15 04:07:19,293 - INFO - Fold 2, Epoch 90: Val Acc: 0.84%
2025-08-15 04:07:21,399 - INFO - Fold 2, Epoch 100: Val Acc: 0.88%
2025-08-15 04:07:23,287 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-15 04:07:25,398 - INFO - Fold 2, Epoch 120: Val Acc: 0.78%
2025-08-15 04:07:27,506 - INFO - Fold 2, Epoch 130: Val Acc: 0.72%
2025-08-15 04:07:29,613 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-15 04:07:31,716 - INFO - Fold 2, Epoch 150: Val Acc: 0.72%
2025-08-15 04:07:33,822 - INFO - Fold 2, Epoch 160: Val Acc: 0.66%
2025-08-15 04:07:35,922 - INFO - Fold 2, Epoch 170: Val Acc: 0.84%
2025-08-15 04:07:37,392 - INFO - Early stopping at epoch 177
2025-08-15 04:07:40,492 - INFO - --- Starting Fold 3/3 ---
2025-08-15 04:07:40,504 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:07:40,505 - INFO - Starting training for fold 3/3
2025-08-15 04:07:46,868 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-15 04:07:53,194 - INFO - Fold 3, Epoch 20: Val Acc: 0.72%
2025-08-15 04:07:55,296 - INFO - Fold 3, Epoch 30: Val Acc: 0.75%
2025-08-15 04:07:57,406 - INFO - Fold 3, Epoch 40: Val Acc: 0.78%
2025-08-15 04:08:00,907 - INFO - Fold 3, Epoch 50: Val Acc: 0.75%
2025-08-15 04:08:03,016 - INFO - Fold 3, Epoch 60: Val Acc: 0.81%
2025-08-15 04:08:05,110 - INFO - Fold 3, Epoch 70: Val Acc: 0.81%
2025-08-15 04:08:07,210 - INFO - Fold 3, Epoch 80: Val Acc: 0.84%
2025-08-15 04:08:09,307 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-15 04:08:11,402 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-15 04:08:13,499 - INFO - Fold 3, Epoch 110: Val Acc: 0.72%
2025-08-15 04:08:15,594 - INFO - Fold 3, Epoch 120: Val Acc: 0.84%
2025-08-15 04:08:17,699 - INFO - Fold 3, Epoch 130: Val Acc: 0.66%
2025-08-15 04:08:19,801 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-15 04:08:20,638 - INFO - Early stopping at epoch 144
2025-08-15 04:08:21,693 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.95607852935791), 'std': np.float64(0.03664639309634981)}, 'train_accuracy': {'mean': np.float64(0.7916666666666666), 'std': np.float64(0.06421264586426018)}, 'val_loss': {'mean': np.float64(4.161576747894287), 'std': np.float64(0.0605394522207801)}, 'val_accuracy': {'mean': np.float64(0.8854166666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(52.0), 'std': np.float64(17.146428199482248)}}
[I 2025-08-15 04:08:21,700] Trial 189 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0007429967588174635, 'batch_size': 32, 'num_epochs': 838, 'temperature': 0.4118591523823588, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.23326280720718479, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.5453763724904468}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 189 finished with value: -0.8854166666666666 and parameters: {'learning_rate': 0.0007429967588174635, 'batch_size': 32, 'num_epochs': 838, 'temperature': 0.4118591523823588, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.23326280720718479, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': False, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'crop_size': 0.5453763724904468}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 04:08:21,748 - INFO - Using device: cuda
2025-08-15 04:08:31,533 - INFO - --- Starting Fold 1/3 ---
2025-08-15 04:08:31,535 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:08:31,535 - WARNING - Fold 1 has insufficient pairs to form a batch. Skipping.
2025-08-15 04:08:31,535 - INFO - --- Starting Fold 2/3 ---
2025-08-15 04:08:31,537 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:08:31,537 - WARNING - Fold 2 has insufficient pairs to form a batch. Skipping.
2025-08-15 04:08:31,537 - INFO - --- Starting Fold 3/3 ---
2025-08-15 04:08:31,538 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:08:31,538 - WARNING - Fold 3 has insufficient pairs to form a batch. Skipping.
2025-08-15 04:08:31,538 - WARNING - No folds completed successfully to aggregate metrics.
[I 2025-08-15 04:08:31,540] Trial 190 finished with value: inf and parameters: {'learning_rate': 0.0009900865043086788, 'batch_size': 64, 'num_epochs': 758, 'temperature': 0.3781350697166192, 'embedding_dim': 128, 'hidden_dim': 512, 'dropout': 0.46819371725671927, 'num_layers': 4, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0862167991393831, 'crop_size': 0.535677326467042}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 190 finished with value: inf and parameters: {'learning_rate': 0.0009900865043086788, 'batch_size': 64, 'num_epochs': 758, 'temperature': 0.3781350697166192, 'embedding_dim': 128, 'hidden_dim': 512, 'dropout': 0.46819371725671927, 'num_layers': 4, 'num_heads': 2, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0862167991393831, 'crop_size': 0.535677326467042}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 04:08:31,589 - INFO - Using device: cuda
2025-08-15 04:08:41,602 - INFO - --- Starting Fold 1/3 ---
2025-08-15 04:08:41,604 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:08:41,604 - INFO - Starting training for fold 1/3
2025-08-15 04:08:52,897 - INFO - Fold 1, Epoch 10: Val Acc: 0.66%
2025-08-15 04:08:59,931 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-15 04:09:04,244 - INFO - Fold 1, Epoch 30: Val Acc: 0.59%
2025-08-15 04:09:06,244 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-15 04:09:08,199 - INFO - Fold 1, Epoch 50: Val Acc: 0.81%
2025-08-15 04:09:10,117 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-15 04:09:12,068 - INFO - Fold 1, Epoch 70: Val Acc: 0.78%
2025-08-15 04:09:14,038 - INFO - Fold 1, Epoch 80: Val Acc: 0.81%
2025-08-15 04:09:15,984 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-15 04:09:17,972 - INFO - Fold 1, Epoch 100: Val Acc: 0.66%
2025-08-15 04:09:19,934 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-15 04:09:21,880 - INFO - Fold 1, Epoch 120: Val Acc: 0.72%
2025-08-15 04:09:22,439 - INFO - Early stopping at epoch 123
2025-08-15 04:09:25,981 - INFO - --- Starting Fold 2/3 ---
2025-08-15 04:09:25,984 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:09:25,984 - INFO - Starting training for fold 2/3
2025-08-15 04:09:32,664 - INFO - Fold 2, Epoch 10: Val Acc: 0.59%
2025-08-15 04:09:37,820 - INFO - Fold 2, Epoch 20: Val Acc: 0.62%
2025-08-15 04:09:40,116 - INFO - Fold 2, Epoch 30: Val Acc: 0.66%
2025-08-15 04:09:43,837 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-15 04:09:45,948 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-15 04:09:47,952 - INFO - Fold 2, Epoch 60: Val Acc: 0.75%
2025-08-15 04:09:49,824 - INFO - Fold 2, Epoch 70: Val Acc: 0.78%
2025-08-15 04:09:52,145 - INFO - Fold 2, Epoch 80: Val Acc: 0.81%
2025-08-15 04:09:54,451 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-15 04:09:56,769 - INFO - Fold 2, Epoch 100: Val Acc: 0.66%
2025-08-15 04:09:59,094 - INFO - Fold 2, Epoch 110: Val Acc: 0.69%
2025-08-15 04:10:01,404 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-15 04:10:03,716 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-15 04:10:04,395 - INFO - Early stopping at epoch 133
2025-08-15 04:10:07,377 - INFO - --- Starting Fold 3/3 ---
2025-08-15 04:10:07,381 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:10:07,382 - INFO - Starting training for fold 3/3
2025-08-15 04:10:16,952 - INFO - Fold 3, Epoch 10: Val Acc: 0.50%
2025-08-15 04:10:19,259 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-15 04:10:25,809 - INFO - Fold 3, Epoch 30: Val Acc: 0.69%
2025-08-15 04:10:28,078 - INFO - Fold 3, Epoch 40: Val Acc: 0.75%
2025-08-15 04:10:31,903 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-15 04:10:34,187 - INFO - Fold 3, Epoch 60: Val Acc: 0.75%
2025-08-15 04:10:37,694 - INFO - Fold 3, Epoch 70: Val Acc: 0.62%
2025-08-15 04:10:39,995 - INFO - Fold 3, Epoch 80: Val Acc: 0.78%
2025-08-15 04:10:42,255 - INFO - Fold 3, Epoch 90: Val Acc: 0.62%
2025-08-15 04:10:44,482 - INFO - Fold 3, Epoch 100: Val Acc: 0.69%
2025-08-15 04:10:46,703 - INFO - Fold 3, Epoch 110: Val Acc: 0.62%
2025-08-15 04:10:48,951 - INFO - Fold 3, Epoch 120: Val Acc: 0.88%
2025-08-15 04:10:51,174 - INFO - Fold 3, Epoch 130: Val Acc: 0.66%
2025-08-15 04:10:52,970 - INFO - Fold 3, Epoch 140: Val Acc: 0.72%
2025-08-15 04:10:54,681 - INFO - Fold 3, Epoch 150: Val Acc: 0.66%
2025-08-15 04:10:56,391 - INFO - Fold 3, Epoch 160: Val Acc: 0.88%
2025-08-15 04:10:57,246 - INFO - Early stopping at epoch 165
2025-08-15 04:10:58,272 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.004956695768568), 'std': np.float64(0.03917514262925812)}, 'train_accuracy': {'mean': np.float64(0.7777777777777777), 'std': np.float64(0.017704928866641566)}, 'val_loss': {'mean': np.float64(4.22981611887614), 'std': np.float64(0.07250928802671663)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.05103103630798288)}, 'epoch': {'mean': np.float64(39.333333333333336), 'std': np.float64(17.913371790059205)}}
[I 2025-08-15 04:10:58,278] Trial 191 finished with value: -0.90625 and parameters: {'learning_rate': 0.0006909022210274457, 'batch_size': 32, 'num_epochs': 848, 'temperature': 0.33592626895940175, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2666559035893618, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06113743455238313, 'crop_size': 0.5267895730635384}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 191 finished with value: -0.90625 and parameters: {'learning_rate': 0.0006909022210274457, 'batch_size': 32, 'num_epochs': 848, 'temperature': 0.33592626895940175, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2666559035893618, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06113743455238313, 'crop_size': 0.5267895730635384}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 04:10:58,324 - INFO - Using device: cuda
2025-08-15 04:11:08,066 - INFO - --- Starting Fold 1/3 ---
2025-08-15 04:11:08,068 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:11:08,068 - INFO - Starting training for fold 1/3
2025-08-15 04:11:19,895 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-15 04:11:24,060 - INFO - Fold 1, Epoch 20: Val Acc: 0.69%
2025-08-15 04:11:25,832 - INFO - Fold 1, Epoch 30: Val Acc: 0.72%
2025-08-15 04:11:30,345 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-15 04:11:34,764 - INFO - Fold 1, Epoch 50: Val Acc: 0.84%
2025-08-15 04:11:37,001 - INFO - Fold 1, Epoch 60: Val Acc: 0.78%
2025-08-15 04:11:39,245 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-15 04:11:41,489 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-15 04:11:43,717 - INFO - Fold 1, Epoch 90: Val Acc: 0.75%
2025-08-15 04:11:45,791 - INFO - Fold 1, Epoch 100: Val Acc: 0.75%
2025-08-15 04:11:48,021 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-15 04:11:50,252 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-15 04:11:52,489 - INFO - Fold 1, Epoch 130: Val Acc: 0.59%
2025-08-15 04:11:54,721 - INFO - Fold 1, Epoch 140: Val Acc: 0.84%
2025-08-15 04:11:55,391 - INFO - Early stopping at epoch 143
2025-08-15 04:11:59,153 - INFO - --- Starting Fold 2/3 ---
2025-08-15 04:11:59,156 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:11:59,156 - INFO - Starting training for fold 2/3
2025-08-15 04:12:05,812 - INFO - Fold 2, Epoch 10: Val Acc: 0.59%
2025-08-15 04:12:12,039 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-15 04:12:13,878 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-15 04:12:15,705 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-15 04:12:19,290 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-15 04:12:23,026 - INFO - Fold 2, Epoch 60: Val Acc: 0.72%
2025-08-15 04:12:25,339 - INFO - Fold 2, Epoch 70: Val Acc: 0.88%
2025-08-15 04:12:29,876 - INFO - Fold 2, Epoch 80: Val Acc: 0.91%
2025-08-15 04:12:32,060 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-15 04:12:34,190 - INFO - Fold 2, Epoch 100: Val Acc: 0.81%
2025-08-15 04:12:35,904 - INFO - Fold 2, Epoch 110: Val Acc: 0.88%
2025-08-15 04:12:37,620 - INFO - Fold 2, Epoch 120: Val Acc: 0.69%
2025-08-15 04:12:39,429 - INFO - Fold 2, Epoch 130: Val Acc: 0.78%
2025-08-15 04:12:41,655 - INFO - Fold 2, Epoch 140: Val Acc: 0.72%
2025-08-15 04:12:43,877 - INFO - Fold 2, Epoch 150: Val Acc: 0.62%
2025-08-15 04:12:46,099 - INFO - Fold 2, Epoch 160: Val Acc: 0.81%
2025-08-15 04:12:48,324 - INFO - Fold 2, Epoch 170: Val Acc: 0.84%
2025-08-15 04:12:50,555 - INFO - Early stopping at epoch 180
2025-08-15 04:12:51,609 - INFO - --- Starting Fold 3/3 ---
2025-08-15 04:12:51,611 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:12:51,612 - INFO - Starting training for fold 3/3
2025-08-15 04:12:59,619 - INFO - Fold 3, Epoch 10: Val Acc: 0.66%
2025-08-15 04:13:01,414 - INFO - Fold 3, Epoch 20: Val Acc: 0.69%
2025-08-15 04:13:04,883 - INFO - Fold 3, Epoch 30: Val Acc: 0.81%
2025-08-15 04:13:08,629 - INFO - Fold 3, Epoch 40: Val Acc: 0.62%
2025-08-15 04:13:12,070 - INFO - Fold 3, Epoch 50: Val Acc: 0.84%
2025-08-15 04:13:15,729 - INFO - Fold 3, Epoch 60: Val Acc: 0.84%
2025-08-15 04:13:18,071 - INFO - Fold 3, Epoch 70: Val Acc: 0.91%
2025-08-15 04:13:20,502 - INFO - Fold 3, Epoch 80: Val Acc: 0.69%
2025-08-15 04:13:22,928 - INFO - Fold 3, Epoch 90: Val Acc: 0.81%
2025-08-15 04:13:25,366 - INFO - Fold 3, Epoch 100: Val Acc: 0.72%
2025-08-15 04:13:27,693 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-15 04:13:30,017 - INFO - Fold 3, Epoch 120: Val Acc: 0.75%
2025-08-15 04:13:32,319 - INFO - Fold 3, Epoch 130: Val Acc: 0.72%
2025-08-15 04:13:34,723 - INFO - Fold 3, Epoch 140: Val Acc: 0.62%
2025-08-15 04:13:37,097 - INFO - Fold 3, Epoch 150: Val Acc: 0.62%
2025-08-15 04:13:38,736 - INFO - Early stopping at epoch 157
2025-08-15 04:13:39,764 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.991333325703939), 'std': np.float64(0.026538820304301092)}, 'train_accuracy': {'mean': np.float64(0.78125), 'std': np.float64(0.029462782549439428)}, 'val_loss': {'mean': np.float64(4.2135036786397295), 'std': np.float64(0.038995153781408054)}, 'val_accuracy': {'mean': np.float64(0.9166666666666666), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(59.0), 'std': np.float64(15.253414918196734)}}
[I 2025-08-15 04:13:39,772] Trial 192 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0006038107264908329, 'batch_size': 32, 'num_epochs': 869, 'temperature': 0.4947272494446876, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.24566419301132394, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06039295515282384, 'crop_size': 0.5332178209494258}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 192 finished with value: -0.9166666666666666 and parameters: {'learning_rate': 0.0006038107264908329, 'batch_size': 32, 'num_epochs': 869, 'temperature': 0.4947272494446876, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.24566419301132394, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06039295515282384, 'crop_size': 0.5332178209494258}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 04:13:39,828 - INFO - Using device: cuda
2025-08-15 04:13:49,436 - INFO - --- Starting Fold 1/3 ---
2025-08-15 04:13:49,437 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:13:49,437 - INFO - Starting training for fold 1/3
2025-08-15 04:13:54,050 - INFO - Fold 1, Epoch 10: Val Acc: 0.59%
2025-08-15 04:13:58,638 - INFO - Fold 1, Epoch 20: Val Acc: 0.69%
2025-08-15 04:14:00,914 - INFO - Fold 1, Epoch 30: Val Acc: 0.62%
2025-08-15 04:14:03,045 - INFO - Fold 1, Epoch 40: Val Acc: 0.66%
2025-08-15 04:14:05,359 - INFO - Fold 1, Epoch 50: Val Acc: 0.75%
2025-08-15 04:14:07,678 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-15 04:14:10,002 - INFO - Fold 1, Epoch 70: Val Acc: 0.72%
2025-08-15 04:14:12,251 - INFO - Fold 1, Epoch 80: Val Acc: 0.75%
2025-08-15 04:14:14,457 - INFO - Fold 1, Epoch 90: Val Acc: 0.62%
2025-08-15 04:14:16,686 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-15 04:14:18,918 - INFO - Fold 1, Epoch 110: Val Acc: 0.69%
2025-08-15 04:14:19,140 - INFO - Early stopping at epoch 111
2025-08-15 04:14:22,831 - INFO - --- Starting Fold 2/3 ---
2025-08-15 04:14:22,834 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:14:22,835 - INFO - Starting training for fold 2/3
2025-08-15 04:14:30,904 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 04:14:33,127 - INFO - Fold 2, Epoch 20: Val Acc: 0.75%
2025-08-15 04:14:36,719 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-15 04:14:38,942 - INFO - Fold 2, Epoch 40: Val Acc: 0.78%
2025-08-15 04:14:41,162 - INFO - Fold 2, Epoch 50: Val Acc: 0.69%
2025-08-15 04:14:44,922 - INFO - Fold 2, Epoch 60: Val Acc: 0.81%
2025-08-15 04:14:48,595 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-15 04:14:50,615 - INFO - Fold 2, Epoch 80: Val Acc: 0.81%
2025-08-15 04:14:52,849 - INFO - Fold 2, Epoch 90: Val Acc: 0.81%
2025-08-15 04:14:55,069 - INFO - Fold 2, Epoch 100: Val Acc: 0.72%
2025-08-15 04:14:57,064 - INFO - Fold 2, Epoch 110: Val Acc: 0.66%
2025-08-15 04:14:59,296 - INFO - Fold 2, Epoch 120: Val Acc: 0.78%
2025-08-15 04:15:01,259 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-15 04:15:03,193 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-15 04:15:05,390 - INFO - Fold 2, Epoch 150: Val Acc: 0.72%
2025-08-15 04:15:07,618 - INFO - Fold 2, Epoch 160: Val Acc: 0.81%
2025-08-15 04:15:08,280 - INFO - Early stopping at epoch 163
2025-08-15 04:15:12,588 - INFO - --- Starting Fold 3/3 ---
2025-08-15 04:15:12,592 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:15:12,592 - INFO - Starting training for fold 3/3
2025-08-15 04:15:20,702 - INFO - Fold 3, Epoch 10: Val Acc: 0.59%
2025-08-15 04:15:25,650 - INFO - Fold 3, Epoch 20: Val Acc: 0.78%
2025-08-15 04:15:27,506 - INFO - Fold 3, Epoch 30: Val Acc: 0.78%
2025-08-15 04:15:30,812 - INFO - Fold 3, Epoch 40: Val Acc: 0.88%
2025-08-15 04:15:32,806 - INFO - Fold 3, Epoch 50: Val Acc: 0.88%
2025-08-15 04:15:34,885 - INFO - Fold 3, Epoch 60: Val Acc: 0.62%
2025-08-15 04:15:37,101 - INFO - Fold 3, Epoch 70: Val Acc: 0.88%
2025-08-15 04:15:39,311 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-15 04:15:41,528 - INFO - Fold 3, Epoch 90: Val Acc: 0.78%
2025-08-15 04:15:43,748 - INFO - Fold 3, Epoch 100: Val Acc: 0.81%
2025-08-15 04:15:46,000 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-15 04:15:48,271 - INFO - Fold 3, Epoch 120: Val Acc: 0.62%
2025-08-15 04:15:50,498 - INFO - Fold 3, Epoch 130: Val Acc: 0.84%
2025-08-15 04:15:52,269 - INFO - Early stopping at epoch 140
2025-08-15 04:15:53,324 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.964684857262505), 'std': np.float64(0.08438237212310695)}, 'train_accuracy': {'mean': np.float64(0.763888888888889), 'std': np.float64(0.029869184955009107)}, 'val_loss': {'mean': np.float64(4.21916659673055), 'std': np.float64(0.06108198255911119)}, 'val_accuracy': {'mean': np.float64(0.8958333333333334), 'std': np.float64(0.05311478659992484)}, 'epoch': {'mean': np.float64(37.0), 'std': np.float64(21.275964529643932)}}
[I 2025-08-15 04:15:53,330] Trial 193 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.000552367675697511, 'batch_size': 32, 'num_epochs': 896, 'temperature': 0.3716123437029744, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.24788385792268663, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19034933132928616, 'crop_size': 0.7530325906008094}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 193 finished with value: -0.8958333333333334 and parameters: {'learning_rate': 0.000552367675697511, 'batch_size': 32, 'num_epochs': 896, 'temperature': 0.3716123437029744, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.24788385792268663, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19034933132928616, 'crop_size': 0.7530325906008094}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 04:15:53,376 - INFO - Using device: cuda
2025-08-15 04:16:03,235 - INFO - --- Starting Fold 1/3 ---
2025-08-15 04:16:03,237 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:16:03,237 - INFO - Starting training for fold 1/3
2025-08-15 04:16:12,271 - INFO - Fold 1, Epoch 10: Val Acc: 0.66%
2025-08-15 04:16:16,861 - INFO - Fold 1, Epoch 20: Val Acc: 0.69%
2025-08-15 04:16:21,394 - INFO - Fold 1, Epoch 30: Val Acc: 0.75%
2025-08-15 04:16:23,584 - INFO - Fold 1, Epoch 40: Val Acc: 0.78%
2025-08-15 04:16:28,052 - INFO - Fold 1, Epoch 50: Val Acc: 0.84%
2025-08-15 04:16:32,963 - INFO - Fold 1, Epoch 60: Val Acc: 0.69%
2025-08-15 04:16:35,220 - INFO - Fold 1, Epoch 70: Val Acc: 0.84%
2025-08-15 04:16:37,365 - INFO - Fold 1, Epoch 80: Val Acc: 0.69%
2025-08-15 04:16:39,352 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-15 04:16:41,286 - INFO - Fold 1, Epoch 100: Val Acc: 0.56%
2025-08-15 04:16:43,381 - INFO - Fold 1, Epoch 110: Val Acc: 0.62%
2025-08-15 04:16:45,691 - INFO - Fold 1, Epoch 120: Val Acc: 0.81%
2025-08-15 04:16:47,897 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-15 04:16:50,082 - INFO - Fold 1, Epoch 140: Val Acc: 0.78%
2025-08-15 04:16:52,401 - INFO - Fold 1, Epoch 150: Val Acc: 0.62%
2025-08-15 04:16:53,531 - INFO - Early stopping at epoch 155
2025-08-15 04:16:57,193 - INFO - --- Starting Fold 2/3 ---
2025-08-15 04:16:57,195 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:16:57,196 - INFO - Starting training for fold 2/3
2025-08-15 04:17:05,250 - INFO - Fold 2, Epoch 10: Val Acc: 0.47%
2025-08-15 04:17:10,099 - INFO - Fold 2, Epoch 20: Val Acc: 0.69%
2025-08-15 04:17:16,480 - INFO - Fold 2, Epoch 30: Val Acc: 0.84%
2025-08-15 04:17:20,387 - INFO - Fold 2, Epoch 40: Val Acc: 0.72%
2025-08-15 04:17:22,608 - INFO - Fold 2, Epoch 50: Val Acc: 0.78%
2025-08-15 04:17:24,811 - INFO - Fold 2, Epoch 60: Val Acc: 0.69%
2025-08-15 04:17:26,747 - INFO - Fold 2, Epoch 70: Val Acc: 0.62%
2025-08-15 04:17:28,662 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-15 04:17:30,364 - INFO - Fold 2, Epoch 90: Val Acc: 0.69%
2025-08-15 04:17:32,249 - INFO - Fold 2, Epoch 100: Val Acc: 0.78%
2025-08-15 04:17:34,216 - INFO - Fold 2, Epoch 110: Val Acc: 0.78%
2025-08-15 04:17:36,260 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-15 04:17:38,192 - INFO - Fold 2, Epoch 130: Val Acc: 0.66%
2025-08-15 04:17:39,466 - INFO - Early stopping at epoch 136
2025-08-15 04:17:42,328 - INFO - --- Starting Fold 3/3 ---
2025-08-15 04:17:42,332 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:17:42,332 - INFO - Starting training for fold 3/3
2025-08-15 04:17:52,908 - INFO - Fold 3, Epoch 10: Val Acc: 0.69%
2025-08-15 04:17:55,007 - INFO - Fold 3, Epoch 20: Val Acc: 0.66%
2025-08-15 04:18:02,829 - INFO - Fold 3, Epoch 30: Val Acc: 0.66%
2025-08-15 04:18:06,575 - INFO - Fold 3, Epoch 40: Val Acc: 0.81%
2025-08-15 04:18:08,883 - INFO - Fold 3, Epoch 50: Val Acc: 0.62%
2025-08-15 04:18:10,716 - INFO - Fold 3, Epoch 60: Val Acc: 0.84%
2025-08-15 04:18:12,657 - INFO - Fold 3, Epoch 70: Val Acc: 0.72%
2025-08-15 04:18:14,984 - INFO - Fold 3, Epoch 80: Val Acc: 0.72%
2025-08-15 04:18:18,525 - INFO - Fold 3, Epoch 90: Val Acc: 0.88%
2025-08-15 04:18:20,604 - INFO - Fold 3, Epoch 100: Val Acc: 0.78%
2025-08-15 04:18:22,444 - INFO - Fold 3, Epoch 110: Val Acc: 0.72%
2025-08-15 04:18:24,153 - INFO - Fold 3, Epoch 120: Val Acc: 0.66%
2025-08-15 04:18:25,871 - INFO - Fold 3, Epoch 130: Val Acc: 0.75%
2025-08-15 04:18:27,582 - INFO - Fold 3, Epoch 140: Val Acc: 0.81%
2025-08-15 04:18:30,899 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-15 04:18:34,473 - INFO - Fold 3, Epoch 160: Val Acc: 0.78%
2025-08-15 04:18:36,694 - INFO - Fold 3, Epoch 170: Val Acc: 0.78%
2025-08-15 04:18:38,923 - INFO - Fold 3, Epoch 180: Val Acc: 0.56%
2025-08-15 04:18:41,155 - INFO - Fold 3, Epoch 190: Val Acc: 0.75%
2025-08-15 04:18:43,384 - INFO - Fold 3, Epoch 200: Val Acc: 0.81%
2025-08-15 04:18:45,457 - INFO - Fold 3, Epoch 210: Val Acc: 0.72%
2025-08-15 04:18:47,455 - INFO - Fold 3, Epoch 220: Val Acc: 0.75%
2025-08-15 04:18:49,407 - INFO - Fold 3, Epoch 230: Val Acc: 0.62%
2025-08-15 04:18:51,392 - INFO - Fold 3, Epoch 240: Val Acc: 0.84%
2025-08-15 04:18:53,406 - INFO - Fold 3, Epoch 250: Val Acc: 0.72%
2025-08-15 04:18:54,043 - INFO - Early stopping at epoch 253
2025-08-15 04:18:57,013 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9204159842597117), 'std': np.float64(0.12381273101017369)}, 'train_accuracy': {'mean': np.float64(0.7743055555555555), 'std': np.float64(0.057893513890739795)}, 'val_loss': {'mean': np.float64(4.314756552378337), 'std': np.float64(0.07047881505372848)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(80.33333333333333), 'std': np.float64(51.266189854739764)}}
[I 2025-08-15 04:18:57,024] Trial 194 finished with value: -0.90625 and parameters: {'learning_rate': 0.0007135684816995941, 'batch_size': 32, 'num_epochs': 877, 'temperature': 0.2983380520418555, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2302549759343797, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.02601095608589897, 'crop_size': 0.5199992931715913}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 194 finished with value: -0.90625 and parameters: {'learning_rate': 0.0007135684816995941, 'batch_size': 32, 'num_epochs': 877, 'temperature': 0.2983380520418555, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.2302549759343797, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.02601095608589897, 'crop_size': 0.5199992931715913}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 04:18:57,116 - INFO - Using device: cuda
2025-08-15 04:19:07,048 - INFO - --- Starting Fold 1/3 ---
2025-08-15 04:19:07,049 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:19:07,049 - INFO - Starting training for fold 1/3
2025-08-15 04:19:18,074 - INFO - Fold 1, Epoch 10: Val Acc: 0.66%
2025-08-15 04:19:22,523 - INFO - Fold 1, Epoch 20: Val Acc: 0.72%
2025-08-15 04:19:27,132 - INFO - Fold 1, Epoch 30: Val Acc: 0.69%
2025-08-15 04:19:29,445 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-15 04:19:31,746 - INFO - Fold 1, Epoch 50: Val Acc: 0.84%
2025-08-15 04:19:33,962 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-15 04:19:35,881 - INFO - Fold 1, Epoch 70: Val Acc: 0.62%
2025-08-15 04:19:37,979 - INFO - Fold 1, Epoch 80: Val Acc: 0.75%
2025-08-15 04:19:40,208 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-15 04:19:42,457 - INFO - Fold 1, Epoch 100: Val Acc: 0.53%
2025-08-15 04:19:46,656 - INFO - Fold 1, Epoch 110: Val Acc: 0.75%
2025-08-15 04:19:48,472 - INFO - Fold 1, Epoch 120: Val Acc: 0.62%
2025-08-15 04:19:50,563 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-15 04:19:52,871 - INFO - Fold 1, Epoch 140: Val Acc: 0.69%
2025-08-15 04:19:55,179 - INFO - Fold 1, Epoch 150: Val Acc: 0.88%
2025-08-15 04:19:57,497 - INFO - Fold 1, Epoch 160: Val Acc: 0.72%
2025-08-15 04:19:59,319 - INFO - Fold 1, Epoch 170: Val Acc: 0.75%
2025-08-15 04:20:01,538 - INFO - Fold 1, Epoch 180: Val Acc: 0.72%
2025-08-15 04:20:03,839 - INFO - Fold 1, Epoch 190: Val Acc: 0.59%
2025-08-15 04:20:06,067 - INFO - Fold 1, Epoch 200: Val Acc: 0.75%
2025-08-15 04:20:07,627 - INFO - Early stopping at epoch 207
2025-08-15 04:20:11,327 - INFO - --- Starting Fold 2/3 ---
2025-08-15 04:20:11,330 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:20:11,330 - INFO - Starting training for fold 2/3
2025-08-15 04:20:18,372 - INFO - Fold 2, Epoch 10: Val Acc: 0.56%
2025-08-15 04:20:22,011 - INFO - Fold 2, Epoch 20: Val Acc: 0.72%
2025-08-15 04:20:26,914 - INFO - Fold 2, Epoch 30: Val Acc: 0.78%
2025-08-15 04:20:28,958 - INFO - Fold 2, Epoch 40: Val Acc: 0.81%
2025-08-15 04:20:31,051 - INFO - Fold 2, Epoch 50: Val Acc: 0.84%
2025-08-15 04:20:33,377 - INFO - Fold 2, Epoch 60: Val Acc: 0.81%
2025-08-15 04:20:35,692 - INFO - Fold 2, Epoch 70: Val Acc: 0.69%
2025-08-15 04:20:37,974 - INFO - Fold 2, Epoch 80: Val Acc: 0.94%
2025-08-15 04:20:40,253 - INFO - Fold 2, Epoch 90: Val Acc: 0.62%
2025-08-15 04:20:42,480 - INFO - Fold 2, Epoch 100: Val Acc: 0.81%
2025-08-15 04:20:44,684 - INFO - Fold 2, Epoch 110: Val Acc: 0.75%
2025-08-15 04:20:46,479 - INFO - Fold 2, Epoch 120: Val Acc: 0.75%
2025-08-15 04:20:48,468 - INFO - Early stopping at epoch 129
2025-08-15 04:20:51,684 - INFO - --- Starting Fold 3/3 ---
2025-08-15 04:20:51,688 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:20:51,689 - INFO - Starting training for fold 3/3
2025-08-15 04:20:57,055 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-15 04:21:03,498 - INFO - Fold 3, Epoch 20: Val Acc: 0.62%
2025-08-15 04:21:05,639 - INFO - Fold 3, Epoch 30: Val Acc: 0.72%
2025-08-15 04:21:07,866 - INFO - Fold 3, Epoch 40: Val Acc: 0.62%
2025-08-15 04:21:10,097 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-15 04:21:11,891 - INFO - Fold 3, Epoch 60: Val Acc: 0.78%
2025-08-15 04:21:13,716 - INFO - Fold 3, Epoch 70: Val Acc: 0.88%
2025-08-15 04:21:15,420 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-15 04:21:17,137 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-15 04:21:18,842 - INFO - Fold 3, Epoch 100: Val Acc: 0.66%
2025-08-15 04:21:20,706 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-15 04:21:22,483 - INFO - Early stopping at epoch 118
2025-08-15 04:21:23,499 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.981651491589016), 'std': np.float64(0.07526012895454932)}, 'train_accuracy': {'mean': np.float64(0.7152777777777778), 'std': np.float64(0.10769487791160287)}, 'val_loss': {'mean': np.float64(4.19964075088501), 'std': np.float64(0.02670635962816468)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(50.333333333333336), 'std': np.float64(39.617616732402716)}}
[I 2025-08-15 04:21:23,506] Trial 195 finished with value: -0.90625 and parameters: {'learning_rate': 0.0008457235607071409, 'batch_size': 32, 'num_epochs': 801, 'temperature': 0.35514301429260964, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.25543150155605976, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19532822624006632, 'crop_size': 0.5065860927258168}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 195 finished with value: -0.90625 and parameters: {'learning_rate': 0.0008457235607071409, 'batch_size': 32, 'num_epochs': 801, 'temperature': 0.35514301429260964, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.25543150155605976, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.19532822624006632, 'crop_size': 0.5065860927258168}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 04:21:23,554 - INFO - Using device: cuda
2025-08-15 04:21:33,288 - INFO - --- Starting Fold 1/3 ---
2025-08-15 04:21:33,290 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:21:33,290 - INFO - Starting training for fold 1/3
2025-08-15 04:21:48,133 - INFO - Fold 1, Epoch 10: Val Acc: 0.58%
2025-08-15 04:21:54,082 - INFO - Fold 1, Epoch 20: Val Acc: 0.69%
2025-08-15 04:22:02,335 - INFO - Fold 1, Epoch 30: Val Acc: 0.75%
2025-08-15 04:22:08,220 - INFO - Fold 1, Epoch 40: Val Acc: 0.75%
2025-08-15 04:22:11,944 - INFO - Fold 1, Epoch 50: Val Acc: 0.71%
2025-08-15 04:22:15,771 - INFO - Fold 1, Epoch 60: Val Acc: 0.79%
2025-08-15 04:22:21,341 - INFO - Fold 1, Epoch 70: Val Acc: 0.65%
2025-08-15 04:22:24,181 - INFO - Fold 1, Epoch 80: Val Acc: 0.67%
2025-08-15 04:22:27,729 - INFO - Fold 1, Epoch 90: Val Acc: 0.69%
2025-08-15 04:22:31,209 - INFO - Fold 1, Epoch 100: Val Acc: 0.67%
2025-08-15 04:22:36,660 - INFO - Fold 1, Epoch 110: Val Acc: 0.58%
2025-08-15 04:22:40,125 - INFO - Fold 1, Epoch 120: Val Acc: 0.69%
2025-08-15 04:22:43,936 - INFO - Fold 1, Epoch 130: Val Acc: 0.67%
2025-08-15 04:22:47,659 - INFO - Fold 1, Epoch 140: Val Acc: 0.75%
2025-08-15 04:22:51,513 - INFO - Fold 1, Epoch 150: Val Acc: 0.71%
2025-08-15 04:22:55,311 - INFO - Fold 1, Epoch 160: Val Acc: 0.60%
2025-08-15 04:22:58,646 - INFO - Fold 1, Epoch 170: Val Acc: 0.81%
2025-08-15 04:23:02,138 - INFO - Fold 1, Epoch 180: Val Acc: 0.67%
2025-08-15 04:23:05,576 - INFO - Fold 1, Epoch 190: Val Acc: 0.77%
2025-08-15 04:23:09,387 - INFO - Fold 1, Epoch 200: Val Acc: 0.73%
2025-08-15 04:23:11,345 - INFO - Early stopping at epoch 205
2025-08-15 04:23:14,834 - INFO - --- Starting Fold 2/3 ---
2025-08-15 04:23:14,837 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:23:14,837 - INFO - Starting training for fold 2/3
2025-08-15 04:23:24,525 - INFO - Fold 2, Epoch 10: Val Acc: 0.58%
2025-08-15 04:23:32,034 - INFO - Fold 2, Epoch 20: Val Acc: 0.75%
2025-08-15 04:23:38,759 - INFO - Fold 2, Epoch 30: Val Acc: 0.79%
2025-08-15 04:23:42,373 - INFO - Fold 2, Epoch 40: Val Acc: 0.77%
2025-08-15 04:23:46,177 - INFO - Fold 2, Epoch 50: Val Acc: 0.81%
2025-08-15 04:23:51,481 - INFO - Fold 2, Epoch 60: Val Acc: 0.73%
2025-08-15 04:23:55,291 - INFO - Fold 2, Epoch 70: Val Acc: 0.73%
2025-08-15 04:23:59,113 - INFO - Fold 2, Epoch 80: Val Acc: 0.79%
2025-08-15 04:24:02,665 - INFO - Fold 2, Epoch 90: Val Acc: 0.65%
2025-08-15 04:24:06,477 - INFO - Fold 2, Epoch 100: Val Acc: 0.75%
2025-08-15 04:24:09,992 - INFO - Fold 2, Epoch 110: Val Acc: 0.71%
2025-08-15 04:24:13,793 - INFO - Fold 2, Epoch 120: Val Acc: 0.83%
2025-08-15 04:24:17,582 - INFO - Fold 2, Epoch 130: Val Acc: 0.83%
2025-08-15 04:24:21,496 - INFO - Fold 2, Epoch 140: Val Acc: 0.77%
2025-08-15 04:24:25,461 - INFO - Fold 2, Epoch 150: Val Acc: 0.79%
2025-08-15 04:24:26,251 - INFO - Early stopping at epoch 152
2025-08-15 04:24:29,150 - INFO - --- Starting Fold 3/3 ---
2025-08-15 04:24:29,153 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:24:29,153 - INFO - Starting training for fold 3/3
2025-08-15 04:24:39,093 - INFO - Fold 3, Epoch 10: Val Acc: 0.67%
2025-08-15 04:24:47,363 - INFO - Fold 3, Epoch 20: Val Acc: 0.81%
2025-08-15 04:24:52,276 - INFO - Fold 3, Epoch 30: Val Acc: 0.75%
2025-08-15 04:24:56,866 - INFO - Fold 3, Epoch 40: Val Acc: 0.83%
2025-08-15 04:25:00,661 - INFO - Fold 3, Epoch 50: Val Acc: 0.69%
2025-08-15 04:25:05,777 - INFO - Fold 3, Epoch 60: Val Acc: 0.81%
2025-08-15 04:25:09,577 - INFO - Fold 3, Epoch 70: Val Acc: 0.73%
2025-08-15 04:25:13,384 - INFO - Fold 3, Epoch 80: Val Acc: 0.77%
2025-08-15 04:25:17,187 - INFO - Fold 3, Epoch 90: Val Acc: 0.75%
2025-08-15 04:25:20,975 - INFO - Fold 3, Epoch 100: Val Acc: 0.71%
2025-08-15 04:25:24,615 - INFO - Fold 3, Epoch 110: Val Acc: 0.73%
2025-08-15 04:25:27,932 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-15 04:25:31,196 - INFO - Fold 3, Epoch 130: Val Acc: 0.85%
2025-08-15 04:25:34,477 - INFO - Fold 3, Epoch 140: Val Acc: 0.79%
2025-08-15 04:25:37,766 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-15 04:25:40,994 - INFO - Early stopping at epoch 159
2025-08-15 04:25:42,085 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.173732572131687), 'std': np.float64(0.07108714572516632)}, 'train_accuracy': {'mean': np.float64(0.767361111111111), 'std': np.float64(0.061527934537046323)}, 'val_loss': {'mean': np.float64(3.5040136178334556), 'std': np.float64(0.011827419006693934)}, 'val_accuracy': {'mean': np.float64(0.8819444444444443), 'std': np.float64(0.009820927516479791)}, 'epoch': {'mean': np.float64(71.0), 'std': np.float64(23.50886357667394)}}
[I 2025-08-15 04:25:42,092] Trial 196 finished with value: -0.8819444444444443 and parameters: {'learning_rate': 0.0006393692263641252, 'batch_size': 16, 'num_epochs': 840, 'temperature': 0.4256750428637816, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.48696548265662176, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0779189482371505, 'crop_size': 0.5414029021197966}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 196 finished with value: -0.8819444444444443 and parameters: {'learning_rate': 0.0006393692263641252, 'batch_size': 16, 'num_epochs': 840, 'temperature': 0.4256750428637816, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.48696548265662176, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.0779189482371505, 'crop_size': 0.5414029021197966}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 04:25:42,136 - INFO - Using device: cuda
2025-08-15 04:25:51,914 - INFO - --- Starting Fold 1/3 ---
2025-08-15 04:25:51,915 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:25:51,915 - INFO - Starting training for fold 1/3
2025-08-15 04:26:03,271 - INFO - Fold 1, Epoch 10: Val Acc: 0.47%
2025-08-15 04:26:05,490 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-15 04:26:12,232 - INFO - Fold 1, Epoch 30: Val Acc: 0.81%
2025-08-15 04:26:14,388 - INFO - Fold 1, Epoch 40: Val Acc: 0.69%
2025-08-15 04:26:16,617 - INFO - Fold 1, Epoch 50: Val Acc: 0.56%
2025-08-15 04:26:18,836 - INFO - Fold 1, Epoch 60: Val Acc: 0.84%
2025-08-15 04:26:25,497 - INFO - Fold 1, Epoch 70: Val Acc: 0.53%
2025-08-15 04:26:27,719 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-15 04:26:29,944 - INFO - Fold 1, Epoch 90: Val Acc: 0.72%
2025-08-15 04:26:32,163 - INFO - Fold 1, Epoch 100: Val Acc: 0.66%
2025-08-15 04:26:34,377 - INFO - Fold 1, Epoch 110: Val Acc: 0.72%
2025-08-15 04:26:36,595 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-15 04:26:38,883 - INFO - Fold 1, Epoch 130: Val Acc: 0.72%
2025-08-15 04:26:41,102 - INFO - Fold 1, Epoch 140: Val Acc: 0.59%
2025-08-15 04:26:43,073 - INFO - Fold 1, Epoch 150: Val Acc: 0.56%
2025-08-15 04:26:45,323 - INFO - Fold 1, Epoch 160: Val Acc: 0.56%
2025-08-15 04:26:47,172 - INFO - Early stopping at epoch 168
2025-08-15 04:26:50,680 - INFO - --- Starting Fold 2/3 ---
2025-08-15 04:26:50,691 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:26:50,692 - INFO - Starting training for fold 2/3
2025-08-15 04:26:57,414 - INFO - Fold 2, Epoch 10: Val Acc: 0.66%
2025-08-15 04:27:00,936 - INFO - Fold 2, Epoch 20: Val Acc: 0.66%
2025-08-15 04:27:06,061 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-15 04:27:08,291 - INFO - Fold 2, Epoch 40: Val Acc: 0.69%
2025-08-15 04:27:12,108 - INFO - Fold 2, Epoch 50: Val Acc: 0.66%
2025-08-15 04:27:14,385 - INFO - Fold 2, Epoch 60: Val Acc: 0.81%
2025-08-15 04:27:16,598 - INFO - Fold 2, Epoch 70: Val Acc: 0.62%
2025-08-15 04:27:18,701 - INFO - Fold 2, Epoch 80: Val Acc: 0.75%
2025-08-15 04:27:22,159 - INFO - Fold 2, Epoch 90: Val Acc: 0.78%
2025-08-15 04:27:24,401 - INFO - Fold 2, Epoch 100: Val Acc: 0.81%
2025-08-15 04:27:26,737 - INFO - Fold 2, Epoch 110: Val Acc: 0.66%
2025-08-15 04:27:28,961 - INFO - Fold 2, Epoch 120: Val Acc: 0.88%
2025-08-15 04:27:31,195 - INFO - Fold 2, Epoch 130: Val Acc: 0.81%
2025-08-15 04:27:33,463 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-15 04:27:35,620 - INFO - Fold 2, Epoch 150: Val Acc: 0.84%
2025-08-15 04:27:37,597 - INFO - Fold 2, Epoch 160: Val Acc: 0.78%
2025-08-15 04:27:39,595 - INFO - Fold 2, Epoch 170: Val Acc: 0.75%
2025-08-15 04:27:41,544 - INFO - Fold 2, Epoch 180: Val Acc: 0.78%
2025-08-15 04:27:42,349 - INFO - Early stopping at epoch 184
2025-08-15 04:27:43,379 - INFO - --- Starting Fold 3/3 ---
2025-08-15 04:27:43,388 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:27:43,388 - INFO - Starting training for fold 3/3
2025-08-15 04:27:51,167 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-15 04:27:54,833 - INFO - Fold 3, Epoch 20: Val Acc: 0.53%
2025-08-15 04:27:58,665 - INFO - Fold 3, Epoch 30: Val Acc: 0.81%
2025-08-15 04:28:00,903 - INFO - Fold 3, Epoch 40: Val Acc: 0.66%
2025-08-15 04:28:02,761 - INFO - Fold 3, Epoch 50: Val Acc: 0.72%
2025-08-15 04:28:07,980 - INFO - Fold 3, Epoch 60: Val Acc: 0.66%
2025-08-15 04:28:10,138 - INFO - Fold 3, Epoch 70: Val Acc: 0.84%
2025-08-15 04:28:12,301 - INFO - Fold 3, Epoch 80: Val Acc: 0.66%
2025-08-15 04:28:14,528 - INFO - Fold 3, Epoch 90: Val Acc: 0.72%
2025-08-15 04:28:16,672 - INFO - Fold 3, Epoch 100: Val Acc: 0.81%
2025-08-15 04:28:18,893 - INFO - Fold 3, Epoch 110: Val Acc: 0.78%
2025-08-15 04:28:21,107 - INFO - Fold 3, Epoch 120: Val Acc: 0.78%
2025-08-15 04:28:23,331 - INFO - Fold 3, Epoch 130: Val Acc: 0.81%
2025-08-15 04:28:25,555 - INFO - Fold 3, Epoch 140: Val Acc: 0.84%
2025-08-15 04:28:27,778 - INFO - Fold 3, Epoch 150: Val Acc: 0.81%
2025-08-15 04:28:29,566 - INFO - Early stopping at epoch 158
2025-08-15 04:28:30,631 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.92453047964308), 'std': np.float64(0.01634871770450377)}, 'train_accuracy': {'mean': np.float64(0.6840277777777778), 'std': np.float64(0.03437324630767938)}, 'val_loss': {'mean': np.float64(4.192778428395589), 'std': np.float64(0.022491945369958452)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.0)}, 'epoch': {'mean': np.float64(69.0), 'std': np.float64(10.708252269472673)}}
[I 2025-08-15 04:28:30,637] Trial 197 finished with value: -0.90625 and parameters: {'learning_rate': 0.00046476260705011907, 'batch_size': 32, 'num_epochs': 280, 'temperature': 0.32689865177772637, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.2155711923276067, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06783335279400336, 'crop_size': 0.5544267595965289}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 197 finished with value: -0.90625 and parameters: {'learning_rate': 0.00046476260705011907, 'batch_size': 32, 'num_epochs': 280, 'temperature': 0.32689865177772637, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.2155711923276067, 'num_layers': 5, 'num_heads': 4, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.06783335279400336, 'crop_size': 0.5544267595965289}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 04:28:30,683 - INFO - Using device: cuda
2025-08-15 04:28:40,630 - INFO - --- Starting Fold 1/3 ---
2025-08-15 04:28:40,641 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:28:40,641 - INFO - Starting training for fold 1/3
2025-08-15 04:28:51,757 - INFO - Fold 1, Epoch 10: Val Acc: 0.44%
2025-08-15 04:28:53,935 - INFO - Fold 1, Epoch 20: Val Acc: 0.62%
2025-08-15 04:28:58,477 - INFO - Fold 1, Epoch 30: Val Acc: 0.50%
2025-08-15 04:29:00,535 - INFO - Fold 1, Epoch 40: Val Acc: 0.38%
2025-08-15 04:29:02,919 - INFO - Fold 1, Epoch 50: Val Acc: 0.53%
2025-08-15 04:29:05,282 - INFO - Fold 1, Epoch 60: Val Acc: 0.47%
2025-08-15 04:29:09,971 - INFO - Fold 1, Epoch 70: Val Acc: 0.56%
2025-08-15 04:29:12,303 - INFO - Fold 1, Epoch 80: Val Acc: 0.44%
2025-08-15 04:29:14,725 - INFO - Fold 1, Epoch 90: Val Acc: 0.53%
2025-08-15 04:29:17,062 - INFO - Fold 1, Epoch 100: Val Acc: 0.44%
2025-08-15 04:29:19,182 - INFO - Fold 1, Epoch 110: Val Acc: 0.47%
2025-08-15 04:29:21,516 - INFO - Fold 1, Epoch 120: Val Acc: 0.47%
2025-08-15 04:29:23,829 - INFO - Fold 1, Epoch 130: Val Acc: 0.53%
2025-08-15 04:29:26,097 - INFO - Fold 1, Epoch 140: Val Acc: 0.59%
2025-08-15 04:29:28,414 - INFO - Fold 1, Epoch 150: Val Acc: 0.50%
2025-08-15 04:29:30,808 - INFO - Fold 1, Epoch 160: Val Acc: 0.56%
2025-08-15 04:29:32,657 - INFO - Early stopping at epoch 168
2025-08-15 04:29:36,093 - INFO - --- Starting Fold 2/3 ---
2025-08-15 04:29:36,096 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:29:36,096 - INFO - Starting training for fold 2/3
2025-08-15 04:29:42,872 - INFO - Fold 2, Epoch 10: Val Acc: 0.44%
2025-08-15 04:29:46,640 - INFO - Fold 2, Epoch 20: Val Acc: 0.50%
2025-08-15 04:29:49,028 - INFO - Fold 2, Epoch 30: Val Acc: 0.50%
2025-08-15 04:29:51,028 - INFO - Fold 2, Epoch 40: Val Acc: 0.56%
2025-08-15 04:29:53,040 - INFO - Fold 2, Epoch 50: Val Acc: 0.50%
2025-08-15 04:29:56,606 - INFO - Fold 2, Epoch 60: Val Acc: 0.56%
2025-08-15 04:29:58,677 - INFO - Fold 2, Epoch 70: Val Acc: 0.53%
2025-08-15 04:30:00,994 - INFO - Fold 2, Epoch 80: Val Acc: 0.44%
2025-08-15 04:30:03,315 - INFO - Fold 2, Epoch 90: Val Acc: 0.53%
2025-08-15 04:30:05,630 - INFO - Fold 2, Epoch 100: Val Acc: 0.31%
2025-08-15 04:30:07,935 - INFO - Fold 2, Epoch 110: Val Acc: 0.53%
2025-08-15 04:30:10,229 - INFO - Fold 2, Epoch 120: Val Acc: 0.44%
2025-08-15 04:30:13,841 - INFO - Fold 2, Epoch 130: Val Acc: 0.56%
2025-08-15 04:30:15,937 - INFO - Fold 2, Epoch 140: Val Acc: 0.50%
2025-08-15 04:30:17,995 - INFO - Fold 2, Epoch 150: Val Acc: 0.53%
2025-08-15 04:30:20,055 - INFO - Fold 2, Epoch 160: Val Acc: 0.47%
2025-08-15 04:30:22,068 - INFO - Fold 2, Epoch 170: Val Acc: 0.50%
2025-08-15 04:30:24,080 - INFO - Fold 2, Epoch 180: Val Acc: 0.50%
2025-08-15 04:30:26,135 - INFO - Fold 2, Epoch 190: Val Acc: 0.62%
2025-08-15 04:30:28,187 - INFO - Fold 2, Epoch 200: Val Acc: 0.50%
2025-08-15 04:30:30,218 - INFO - Fold 2, Epoch 210: Val Acc: 0.50%
2025-08-15 04:30:32,494 - INFO - Fold 2, Epoch 220: Val Acc: 0.50%
2025-08-15 04:30:33,417 - INFO - Early stopping at epoch 224
2025-08-15 04:30:34,416 - INFO - --- Starting Fold 3/3 ---
2025-08-15 04:30:34,418 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:30:34,418 - INFO - Starting training for fold 3/3
2025-08-15 04:30:39,841 - INFO - Fold 3, Epoch 10: Val Acc: 0.53%
2025-08-15 04:30:43,614 - INFO - Fold 3, Epoch 20: Val Acc: 0.34%
2025-08-15 04:30:45,917 - INFO - Fold 3, Epoch 30: Val Acc: 0.53%
2025-08-15 04:30:48,185 - INFO - Fold 3, Epoch 40: Val Acc: 0.50%
2025-08-15 04:30:50,485 - INFO - Fold 3, Epoch 50: Val Acc: 0.47%
2025-08-15 04:30:52,789 - INFO - Fold 3, Epoch 60: Val Acc: 0.53%
2025-08-15 04:30:55,100 - INFO - Fold 3, Epoch 70: Val Acc: 0.50%
2025-08-15 04:30:58,758 - INFO - Fold 3, Epoch 80: Val Acc: 0.59%
2025-08-15 04:31:01,104 - INFO - Fold 3, Epoch 90: Val Acc: 0.41%
2025-08-15 04:31:03,416 - INFO - Fold 3, Epoch 100: Val Acc: 0.44%
2025-08-15 04:31:05,782 - INFO - Fold 3, Epoch 110: Val Acc: 0.59%
2025-08-15 04:31:08,177 - INFO - Fold 3, Epoch 120: Val Acc: 0.53%
2025-08-15 04:31:10,546 - INFO - Fold 3, Epoch 130: Val Acc: 0.50%
2025-08-15 04:31:12,746 - INFO - Fold 3, Epoch 140: Val Acc: 0.44%
2025-08-15 04:31:15,052 - INFO - Fold 3, Epoch 150: Val Acc: 0.56%
2025-08-15 04:31:17,363 - INFO - Fold 3, Epoch 160: Val Acc: 0.53%
2025-08-15 04:31:19,677 - INFO - Fold 3, Epoch 170: Val Acc: 0.50%
2025-08-15 04:31:21,754 - INFO - Early stopping at epoch 179
2025-08-15 04:31:22,760 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(4.139955467647976), 'std': np.float64(0.011291314776512771)}, 'train_accuracy': {'mean': np.float64(0.5520833333333334), 'std': np.float64(0.014731391274719792)}, 'val_loss': {'mean': np.float64(4.160422960917155), 'std': np.float64(0.01955177576723844)}, 'val_accuracy': {'mean': np.float64(0.7083333333333334), 'std': np.float64(0.01473139127471974)}, 'epoch': {'mean': np.float64(89.33333333333333), 'std': np.float64(24.225789747475496)}}
[I 2025-08-15 04:31:22,767] Trial 198 finished with value: -0.7083333333333334 and parameters: {'learning_rate': 0.0005197966289856394, 'batch_size': 32, 'num_epochs': 299, 'temperature': 0.39347307218663297, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.45646663486811756, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.037113812818986555, 'crop_size': 0.5313083525639778}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 198 finished with value: -0.7083333333333334 and parameters: {'learning_rate': 0.0005197966289856394, 'batch_size': 32, 'num_epochs': 299, 'temperature': 0.39347307218663297, 'embedding_dim': 256, 'hidden_dim': 256, 'dropout': 0.45646663486811756, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': False, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': True, 'noise_level': 0.037113812818986555, 'crop_size': 0.5313083525639778}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 04:31:22,813 - INFO - Using device: cuda
2025-08-15 04:31:32,487 - INFO - --- Starting Fold 1/3 ---
2025-08-15 04:31:32,489 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:31:32,489 - INFO - Starting training for fold 1/3
2025-08-15 04:31:36,703 - INFO - Fold 1, Epoch 10: Val Acc: 0.53%
2025-08-15 04:31:40,866 - INFO - Fold 1, Epoch 20: Val Acc: 0.47%
2025-08-15 04:31:45,362 - INFO - Fold 1, Epoch 30: Val Acc: 0.75%
2025-08-15 04:31:47,771 - INFO - Fold 1, Epoch 40: Val Acc: 0.72%
2025-08-15 04:31:52,091 - INFO - Fold 1, Epoch 50: Val Acc: 0.69%
2025-08-15 04:31:56,488 - INFO - Fold 1, Epoch 60: Val Acc: 0.59%
2025-08-15 04:32:00,785 - INFO - Fold 1, Epoch 70: Val Acc: 0.56%
2025-08-15 04:32:03,001 - INFO - Fold 1, Epoch 80: Val Acc: 0.66%
2025-08-15 04:32:05,217 - INFO - Fold 1, Epoch 90: Val Acc: 0.88%
2025-08-15 04:32:07,429 - INFO - Fold 1, Epoch 100: Val Acc: 0.59%
2025-08-15 04:32:09,668 - INFO - Fold 1, Epoch 110: Val Acc: 0.84%
2025-08-15 04:32:11,914 - INFO - Fold 1, Epoch 120: Val Acc: 0.75%
2025-08-15 04:32:14,148 - INFO - Fold 1, Epoch 130: Val Acc: 0.69%
2025-08-15 04:32:16,395 - INFO - Fold 1, Epoch 140: Val Acc: 0.72%
2025-08-15 04:32:18,648 - INFO - Fold 1, Epoch 150: Val Acc: 0.62%
2025-08-15 04:32:20,895 - INFO - Fold 1, Epoch 160: Val Acc: 0.69%
2025-08-15 04:32:22,468 - INFO - Early stopping at epoch 167
2025-08-15 04:32:27,369 - INFO - --- Starting Fold 2/3 ---
2025-08-15 04:32:27,371 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:32:27,372 - INFO - Starting training for fold 2/3
2025-08-15 04:32:33,962 - INFO - Fold 2, Epoch 10: Val Acc: 0.53%
2025-08-15 04:32:37,090 - INFO - Fold 2, Epoch 20: Val Acc: 0.69%
2025-08-15 04:32:39,056 - INFO - Fold 2, Epoch 30: Val Acc: 0.69%
2025-08-15 04:32:44,292 - INFO - Fold 2, Epoch 40: Val Acc: 0.66%
2025-08-15 04:32:47,948 - INFO - Fold 2, Epoch 50: Val Acc: 0.66%
2025-08-15 04:32:50,283 - INFO - Fold 2, Epoch 60: Val Acc: 0.69%
2025-08-15 04:32:52,196 - INFO - Fold 2, Epoch 70: Val Acc: 0.72%
2025-08-15 04:32:54,248 - INFO - Fold 2, Epoch 80: Val Acc: 0.62%
2025-08-15 04:32:57,787 - INFO - Fold 2, Epoch 90: Val Acc: 0.72%
2025-08-15 04:33:01,368 - INFO - Fold 2, Epoch 100: Val Acc: 0.72%
2025-08-15 04:33:03,612 - INFO - Fold 2, Epoch 110: Val Acc: 0.81%
2025-08-15 04:33:05,858 - INFO - Fold 2, Epoch 120: Val Acc: 0.88%
2025-08-15 04:33:08,091 - INFO - Fold 2, Epoch 130: Val Acc: 0.62%
2025-08-15 04:33:10,341 - INFO - Fold 2, Epoch 140: Val Acc: 0.75%
2025-08-15 04:33:12,629 - INFO - Fold 2, Epoch 150: Val Acc: 0.88%
2025-08-15 04:33:14,866 - INFO - Fold 2, Epoch 160: Val Acc: 0.72%
2025-08-15 04:33:17,171 - INFO - Fold 2, Epoch 170: Val Acc: 0.84%
2025-08-15 04:33:19,509 - INFO - Fold 2, Epoch 180: Val Acc: 0.75%
2025-08-15 04:33:22,795 - INFO - Fold 2, Epoch 190: Val Acc: 0.75%
2025-08-15 04:33:24,519 - INFO - Fold 2, Epoch 200: Val Acc: 0.75%
2025-08-15 04:33:26,239 - INFO - Fold 2, Epoch 210: Val Acc: 0.56%
2025-08-15 04:33:27,965 - INFO - Fold 2, Epoch 220: Val Acc: 0.78%
2025-08-15 04:33:30,177 - INFO - Fold 2, Epoch 230: Val Acc: 0.75%
2025-08-15 04:33:32,325 - INFO - Fold 2, Epoch 240: Val Acc: 0.69%
2025-08-15 04:33:34,633 - INFO - Fold 2, Epoch 250: Val Acc: 0.56%
2025-08-15 04:33:36,929 - INFO - Fold 2, Epoch 260: Val Acc: 0.78%
2025-08-15 04:33:39,166 - INFO - Fold 2, Epoch 270: Val Acc: 0.81%
2025-08-15 04:33:41,412 - INFO - Fold 2, Epoch 280: Val Acc: 0.72%
2025-08-15 04:33:42,078 - INFO - Early stopping at epoch 283
2025-08-15 04:33:45,004 - INFO - --- Starting Fold 3/3 ---
2025-08-15 04:33:45,007 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:33:45,007 - INFO - Starting training for fold 3/3
2025-08-15 04:33:53,154 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-15 04:33:54,883 - INFO - Fold 3, Epoch 20: Val Acc: 0.59%
2025-08-15 04:33:56,607 - INFO - Fold 3, Epoch 30: Val Acc: 0.53%
2025-08-15 04:34:01,589 - INFO - Fold 3, Epoch 40: Val Acc: 0.69%
2025-08-15 04:34:03,632 - INFO - Fold 3, Epoch 50: Val Acc: 0.75%
2025-08-15 04:34:07,009 - INFO - Fold 3, Epoch 60: Val Acc: 0.78%
2025-08-15 04:34:08,998 - INFO - Fold 3, Epoch 70: Val Acc: 0.59%
2025-08-15 04:34:11,021 - INFO - Fold 3, Epoch 80: Val Acc: 0.66%
2025-08-15 04:34:13,149 - INFO - Fold 3, Epoch 90: Val Acc: 0.78%
2025-08-15 04:34:15,355 - INFO - Fold 3, Epoch 100: Val Acc: 0.88%
2025-08-15 04:34:17,518 - INFO - Fold 3, Epoch 110: Val Acc: 0.66%
2025-08-15 04:34:19,746 - INFO - Fold 3, Epoch 120: Val Acc: 0.69%
2025-08-15 04:34:22,002 - INFO - Fold 3, Epoch 130: Val Acc: 0.69%
2025-08-15 04:34:24,254 - INFO - Fold 3, Epoch 140: Val Acc: 0.66%
2025-08-15 04:34:26,471 - INFO - Fold 3, Epoch 150: Val Acc: 0.69%
2025-08-15 04:34:27,628 - INFO - Early stopping at epoch 155
2025-08-15 04:34:28,668 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.9951252937316895), 'std': np.float64(0.06583616614801388)}, 'train_accuracy': {'mean': np.float64(0.7638888888888888), 'std': np.float64(0.03437324630767936)}, 'val_loss': {'mean': np.float64(4.253461043039958), 'std': np.float64(0.09595751283505961)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.02551551815399144)}, 'epoch': {'mean': np.float64(100.66666666666667), 'std': np.float64(57.71962885843564)}}
[I 2025-08-15 04:34:28,674] Trial 199 finished with value: -0.90625 and parameters: {'learning_rate': 0.00036190125912536773, 'batch_size': 32, 'num_epochs': 904, 'temperature': 0.310406405183619, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4388771928479224, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18700342774212964, 'crop_size': 0.5482406145794901}. Best is trial 92 with value: -0.9479166666666666.
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
Trial 199 finished with value: -0.90625 and parameters: {'learning_rate': 0.00036190125912536773, 'batch_size': 32, 'num_epochs': 904, 'temperature': 0.310406405183619, 'embedding_dim': 128, 'hidden_dim': 256, 'dropout': 0.4388771928479224, 'num_layers': 5, 'num_heads': 8, 'noise_enabled': True, 'shift_enabled': False, 'scale_enabled': True, 'crop_enabled': True, 'flip_enabled': False, 'permutation_enabled': False, 'noise_level': 0.18700342774212964, 'crop_size': 0.5482406145794901}. Best is trial 92 with value: -0.9479166666666666.
2025-08-15 04:34:28,674 - INFO - Using device: cuda
2025-08-15 04:34:38,930 - INFO - --- Starting Fold 1/3 ---
2025-08-15 04:34:38,931 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:34:38,932 - INFO - Starting training for fold 1/3
2025-08-15 04:34:49,913 - INFO - Fold 1, Epoch 10: Val Acc: 0.69%
2025-08-15 04:34:54,202 - INFO - Fold 1, Epoch 20: Val Acc: 0.56%
2025-08-15 04:34:56,447 - INFO - Fold 1, Epoch 30: Val Acc: 0.72%
2025-08-15 04:35:03,112 - INFO - Fold 1, Epoch 40: Val Acc: 0.75%
2025-08-15 04:35:05,316 - INFO - Fold 1, Epoch 50: Val Acc: 0.53%
2025-08-15 04:35:07,612 - INFO - Fold 1, Epoch 60: Val Acc: 0.72%
2025-08-15 04:35:09,924 - INFO - Fold 1, Epoch 70: Val Acc: 0.69%
2025-08-15 04:35:12,242 - INFO - Fold 1, Epoch 80: Val Acc: 0.72%
2025-08-15 04:35:14,185 - INFO - Fold 1, Epoch 90: Val Acc: 0.66%
2025-08-15 04:35:15,994 - INFO - Fold 1, Epoch 100: Val Acc: 0.69%
2025-08-15 04:35:17,807 - INFO - Fold 1, Epoch 110: Val Acc: 0.50%
2025-08-15 04:35:19,876 - INFO - Fold 1, Epoch 120: Val Acc: 0.84%
2025-08-15 04:35:22,157 - INFO - Fold 1, Epoch 130: Val Acc: 0.62%
2025-08-15 04:35:24,189 - INFO - Early stopping at epoch 139
2025-08-15 04:35:27,790 - INFO - --- Starting Fold 2/3 ---
2025-08-15 04:35:27,792 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:35:27,793 - INFO - Starting training for fold 2/3
2025-08-15 04:35:34,447 - INFO - Fold 2, Epoch 10: Val Acc: 0.62%
2025-08-15 04:35:37,967 - INFO - Fold 2, Epoch 20: Val Acc: 0.81%
2025-08-15 04:35:41,707 - INFO - Fold 2, Epoch 30: Val Acc: 0.72%
2025-08-15 04:35:43,722 - INFO - Fold 2, Epoch 40: Val Acc: 0.75%
2025-08-15 04:35:47,271 - INFO - Fold 2, Epoch 50: Val Acc: 0.75%
2025-08-15 04:35:50,817 - INFO - Fold 2, Epoch 60: Val Acc: 0.66%
2025-08-15 04:35:53,131 - INFO - Fold 2, Epoch 70: Val Acc: 0.75%
2025-08-15 04:35:55,414 - INFO - Fold 2, Epoch 80: Val Acc: 0.47%
2025-08-15 04:35:57,672 - INFO - Fold 2, Epoch 90: Val Acc: 0.62%
2025-08-15 04:35:59,973 - INFO - Fold 2, Epoch 100: Val Acc: 0.59%
2025-08-15 04:36:02,281 - INFO - Fold 2, Epoch 110: Val Acc: 0.72%
2025-08-15 04:36:04,568 - INFO - Fold 2, Epoch 120: Val Acc: 0.72%
2025-08-15 04:36:06,844 - INFO - Fold 2, Epoch 130: Val Acc: 0.75%
2025-08-15 04:36:09,079 - INFO - Fold 2, Epoch 140: Val Acc: 0.78%
2025-08-15 04:36:11,329 - INFO - Fold 2, Epoch 150: Val Acc: 0.88%
2025-08-15 04:36:12,261 - INFO - Early stopping at epoch 154
2025-08-15 04:36:13,268 - INFO - --- Starting Fold 3/3 ---
2025-08-15 04:36:13,270 - INFO - Generated pairs. Train: 1128 (Positive: 48). Val: 276 (Positive: 24)
2025-08-15 04:36:13,271 - INFO - Starting training for fold 3/3
2025-08-15 04:36:21,586 - INFO - Fold 3, Epoch 10: Val Acc: 0.62%
2025-08-15 04:36:29,406 - INFO - Fold 3, Epoch 20: Val Acc: 0.88%
2025-08-15 04:36:31,613 - INFO - Fold 3, Epoch 30: Val Acc: 0.72%
2025-08-15 04:36:33,501 - INFO - Fold 3, Epoch 40: Val Acc: 0.78%
2025-08-15 04:36:35,814 - INFO - Fold 3, Epoch 50: Val Acc: 0.78%
2025-08-15 04:36:38,116 - INFO - Fold 3, Epoch 60: Val Acc: 0.69%
2025-08-15 04:36:40,365 - INFO - Fold 3, Epoch 70: Val Acc: 0.75%
2025-08-15 04:36:44,064 - INFO - Fold 3, Epoch 80: Val Acc: 0.75%
2025-08-15 04:36:46,267 - INFO - Fold 3, Epoch 90: Val Acc: 0.88%
2025-08-15 04:36:48,482 - INFO - Fold 3, Epoch 100: Val Acc: 0.75%
2025-08-15 04:36:50,702 - INFO - Fold 3, Epoch 110: Val Acc: 0.53%
2025-08-15 04:36:52,789 - INFO - Fold 3, Epoch 120: Val Acc: 0.81%
2025-08-15 04:36:54,924 - INFO - Fold 3, Epoch 130: Val Acc: 0.50%
2025-08-15 04:36:57,187 - INFO - Fold 3, Epoch 140: Val Acc: 0.81%
2025-08-15 04:36:59,428 - INFO - Fold 3, Epoch 150: Val Acc: 0.72%
2025-08-15 04:37:01,667 - INFO - Fold 3, Epoch 160: Val Acc: 0.59%
2025-08-15 04:37:03,890 - INFO - Fold 3, Epoch 170: Val Acc: 0.72%
2025-08-15 04:37:04,072 - INFO - Early stopping at epoch 171
2025-08-15 04:37:05,070 - INFO - Cross-validation statistics for transformer: {'train_loss': {'mean': np.float64(3.938292211956448), 'std': np.float64(0.059125924811156014)}, 'train_accuracy': {'mean': np.float64(0.7256944444444445), 'std': np.float64(0.01964185503295969)}, 'val_loss': {'mean': np.float64(4.21902322769165), 'std': np.float64(0.029301118939132037)}, 'val_accuracy': {'mean': np.float64(0.90625), 'std': np.float64(0.0)}, 'epoch': {'mean': np.float64(53.666666666666664), 'std': np.float64(13.072447700751718)}}
2025-08-15 04:37:05,081 - INFO - Best hyperparameters for transformer saved to optuna_logs_contrastive/transformer.config
2025-08-15 04:37:05,083 - INFO - Final statistics for transformer saved to results/stats_simclr_transformer.json

Optimization for transformer finished.
Best trial:
  Value (negative val_accuracy): -0.9479166666666666
  Params: 
    learning_rate: 0.0005679322945498316
    batch_size: 32
    num_epochs: 375
    temperature: 0.29063452579262367
    embedding_dim: 256
    hidden_dim: 256
    dropout: 0.48991175948539684
    num_layers: 5
    num_heads: 8
    noise_enabled: True
    shift_enabled: False
    scale_enabled: False
    crop_enabled: True
    flip_enabled: False
    permutation_enabled: False
    noise_level: 0.0984100262799093
    crop_size: 0.537691257614809
Actual device being used: cuda
Attempting to load data from: /vol/ecrg-solar/woodj4/fishy-business/data/REIMS.xlsx
