<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Literature Review &mdash; fish 0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=d45e8c67"></script>
        <script src="_static/doctools.js?v=9a2dae69"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Notes" href="notes.html" />
    <link rel="prev" title="Minutes" href="minutes.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            fish
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="about.html">About</a></li>
<li class="toctree-l1"><a class="reference internal" href="papers.html">Papers</a></li>
<li class="toctree-l1"><a class="reference internal" href="minutes.html">Minutes</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Literature Review</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#abdi2010principal">abdi2010principal</a></li>
<li class="toctree-l2"><a class="reference internal" href="#adebayo2018sanity">adebayo2018sanity</a></li>
<li class="toctree-l2"><a class="reference internal" href="#agarwal2011building">agarwal2011building</a></li>
<li class="toctree-l2"><a class="reference internal" href="#aizerman1964theoretical">aizerman1964theoretical</a></li>
<li class="toctree-l2"><a class="reference internal" href="#akkaya2019solving">akkaya2019solving</a></li>
<li class="toctree-l2"><a class="reference internal" href="#al2019survey">al2019survey</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ba2016layer">ba2016layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#balas1969machine">balas1969machine</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bao2022estimating">bao2022estimating</a></li>
<li class="toctree-l2"><a class="reference internal" href="#batstone1999new">batstone1999new</a></li>
<li class="toctree-l2"><a class="reference internal" href="#banzhaf2006artificial">banzhaf2006artificial</a></li>
<li class="toctree-l2"><a class="reference internal" href="#banzhaf2009genetic">banzhaf2009genetic</a></li>
<li class="toctree-l2"><a class="reference internal" href="#behmo2010towards">behmo2010towards</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bengio2017consciousness">bengio2017consciousness</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bi2020gc">bi2020gc</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bifet2007learning">bifet2007learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#black2017real">black2017real</a></li>
<li class="toctree-l2"><a class="reference internal" href="#black2019rapid">black2019rapid</a></li>
<li class="toctree-l2"><a class="reference internal" href="#blattmann2023align">blattmann2023align</a></li>
<li class="toctree-l2"><a class="reference internal" href="#boccard2013consensus">boccard2013consensus</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bongiovanni2019electric">bongiovanni2019electric</a></li>
<li class="toctree-l2"><a class="reference internal" href="#boser1992training">boser1992training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bourque2018ten">bourque2018ten</a></li>
<li class="toctree-l2"><a class="reference internal" href="#breiman2017classification">breiman2017classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#brewer2006brown">brewer2006brown</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bridle1989training">bridle1989training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#brochu2010tutorial">brochu2010tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bromley1993signatured">bromley1993signatured</a></li>
<li class="toctree-l2"><a class="reference internal" href="#brosnan2003monkeys">brosnan2003monkeys</a></li>
<li class="toctree-l2"><a class="reference internal" href="#brown2012conditional">brown2012conditional</a></li>
<li class="toctree-l2"><a class="reference internal" href="#brown2018superhuman">brown2018superhuman</a></li>
<li class="toctree-l2"><a class="reference internal" href="#brown2019superhuman">brown2019superhuman</a></li>
<li class="toctree-l2"><a class="reference internal" href="#brown2020language">brown2020language</a></li>
<li class="toctree-l2"><a class="reference internal" href="#brown2022human">brown2022human</a></li>
<li class="toctree-l2"><a class="reference internal" href="#brownlee2016gentle">brownlee2016gentle</a></li>
<li class="toctree-l2"><a class="reference internal" href="#brudigam2021gaussian">brudigam2021gaussian</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cai2020high">cai2020high</a></li>
<li class="toctree-l2"><a class="reference internal" href="#chase1973perception">chase1973perception</a></li>
<li class="toctree-l2"><a class="reference internal" href="#chen2019deep">chen2019deep</a></li>
<li class="toctree-l2"><a class="reference internal" href="#chen2020deep">chen2020deep</a></li>
<li class="toctree-l2"><a class="reference internal" href="#chen2019looks">chen2019looks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#chen2021evaluating">chen2021evaluating</a></li>
<li class="toctree-l2"><a class="reference internal" href="#chen2022deep">chen2022deep</a></li>
<li class="toctree-l2"><a class="reference internal" href="#chevalier2018babyai">chevalier2018babyai</a></li>
<li class="toctree-l2"><a class="reference internal" href="#codevilla2018end">codevilla2018end</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cortes1995support">cortes1995support</a></li>
<li class="toctree-l2"><a class="reference internal" href="#couillet2022submerged">couillet2022submerged</a></li>
<li class="toctree-l2"><a class="reference internal" href="#crall2013hotspotter">crall2013hotspotter</a></li>
<li class="toctree-l2"><a class="reference internal" href="#craik1972levels">craik1972levels</a></li>
<li class="toctree-l2"><a class="reference internal" href="#craik1975depth">craik1975depth</a></li>
<li class="toctree-l2"><a class="reference internal" href="#da2018evolutionary">da2018evolutionary</a></li>
<li class="toctree-l2"><a class="reference internal" href="#dawkins1995evolved">dawkins1995evolved</a></li>
<li class="toctree-l2"><a class="reference internal" href="#devlin2018bert">devlin2018bert</a></li>
<li class="toctree-l2"><a class="reference internal" href="#di2019survey">di2019survey</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ding2005minimum">ding2005minimum</a></li>
<li class="toctree-l2"><a class="reference internal" href="#do2008expectation">do2008expectation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#domingos2015master">domingos2015master</a></li>
<li class="toctree-l2"><a class="reference internal" href="#dong2022survey">dong2022survey</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ecoffet2021first">ecoffet2021first</a></li>
<li class="toctree-l2"><a class="reference internal" href="#eder1995gas">eder1995gas</a></li>
<li class="toctree-l2"><a class="reference internal" href="#eiben2015evolutionary">eiben2015evolutionary</a></li>
<li class="toctree-l2"><a class="reference internal" href="#eich1975state">eich1975state</a></li>
<li class="toctree-l2"><a class="reference internal" href="#emrah2022imbalance">emrah2022imbalance</a></li>
<li class="toctree-l2"><a class="reference internal" href="#espeholt2022deep">espeholt2022deep</a></li>
<li class="toctree-l2"><a class="reference internal" href="#eyesenck1980effects">eyesenck1980effects</a></li>
<li class="toctree-l2"><a class="reference internal" href="#fawzi2022discovering">fawzi2022discovering</a></li>
<li class="toctree-l2"><a class="reference internal" href="#fahy2009update">fahy2009update</a></li>
<li class="toctree-l2"><a class="reference internal" href="#fix1989discriminatory">fix1989discriminatory</a></li>
<li class="toctree-l2"><a class="reference internal" href="#fukushima1982neocognitron">fukushima1982neocognitron</a></li>
<li class="toctree-l2"><a class="reference internal" href="#galanakis2019saving">galanakis2019saving</a></li>
<li class="toctree-l2"><a class="reference internal" href="#garnelo2018conditional">garnelo2018conditional</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gencoglu2019hark">gencoglu2019hark</a></li>
<li class="toctree-l2"><a class="reference internal" href="#glorot2010understanding">glorot2010understanding</a></li>
<li class="toctree-l2"><a class="reference internal" href="#girshick2014rich">girshick2014rich</a></li>
<li class="toctree-l2"><a class="reference internal" href="#godden1975context">godden1975context</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gomes2020ensemble">gomes2020ensemble</a></li>
<li class="toctree-l2"><a class="reference internal" href="#gonick2012cartoon">gonick2012cartoon</a></li>
<li class="toctree-l2"><a class="reference internal" href="#goodfellow2016deep">goodfellow2016deep</a></li>
<li class="toctree-l2"><a class="reference internal" href="#goodfellow2014generative">goodfellow2014generative</a></li>
<li class="toctree-l2"><a class="reference internal" href="#goodman2020weighting">goodman2020weighting</a></li>
<li class="toctree-l2"><a class="reference internal" href="#grcic2021densly">grcic2021densly</a></li>
<li class="toctree-l2"><a class="reference internal" href="#grover2016node2vec">grover2016node2vec</a></li>
<li class="toctree-l2"><a class="reference internal" href="#handa2006robust">handa2006robust</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hand2001idiot">hand2001idiot</a></li>
<li class="toctree-l2"><a class="reference internal" href="#haralick1973textual">haralick1973textual</a></li>
<li class="toctree-l2"><a class="reference internal" href="#he2015delving">he2015delving</a></li>
<li class="toctree-l2"><a class="reference internal" href="#he2016deep">he2016deep</a></li>
<li class="toctree-l2"><a class="reference internal" href="#he2020bayesian">he2020bayesian</a></li>
<li class="toctree-l2"><a class="reference internal" href="#he2020momentum">he2020momentum</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hengzhe2021evolutionary">hengzhe2021evolutionary</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hendrycks2016gaussian">hendrycks2016gaussian</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hildebrandt2010towards">hildebrandt2010towards</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hinton2012improving">hinton2012improving</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ho1995random">ho1995random</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ho2020denoising">ho2020denoising</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hof2016industrial">hof2016industrial</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hofstadter1979godel">Hofstadter1979godel</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hou2019deep">hou2019deep</a></li>
<li class="toctree-l2"><a class="reference internal" href="#howard2017mobilenets">howard2017mobilenets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#huang2017densely">huang2017densely</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hung2019optimizing">hung2019optimizing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#hussain2016food">hussain2016food</a></li>
<li class="toctree-l2"><a class="reference internal" href="#huszar2022algorithmic">huszar2022algorithmic</a></li>
<li class="toctree-l2"><a class="reference internal" href="#li2022language">li2022language</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ioffe2015batch">ioffe2015batch</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ingalalli2014multi">ingalalli2014multi</a></li>
<li class="toctree-l2"><a class="reference internal" href="#jacot2018neural">jacot2018neural</a></li>
<li class="toctree-l2"><a class="reference internal" href="#jaegle2021perceiver">jaegle2021perceiver</a></li>
<li class="toctree-l2"><a class="reference internal" href="#jha2015rapid">jha2015rapid</a></li>
<li class="toctree-l2"><a class="reference internal" href="#jiang2019degenerate">jiang2019degenerate</a></li>
<li class="toctree-l2"><a class="reference internal" href="#jing2020learning">jing2020learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#jing2022masked">jing2022masked</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kajiya1993get">kajiya1993get</a></li>
<li class="toctree-l2"><a class="reference internal" href="#karras2020analyzing">karras2020analyzing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#karras2022elucidating">karras2022elucidating</a></li>
<li class="toctree-l2"><a class="reference internal" href="#karpathy2023lets">karpathy2023lets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#katharopoulos2020transformers">katharopoulos2020transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ke2018sparse">ke2018sparse</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kennedy1995particle">kennedy1995particle</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kennedy1997discrete">kennedy1997discrete</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kerber1992chimerge">kerber1992chimerge</a></li>
<li class="toctree-l2"><a class="reference internal" href="#khakimov2015trends">khakimov2015trends</a></li>
<li class="toctree-l2"><a class="reference internal" href="#killeen2017fast">killeen2017fast</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kingma2014adam">kingma2014adam</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kira1992practical">kira1992practical</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kishore2021fixed">kishore2021fixed</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kitaev2020reformer">kitaev2020reformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kobyzev2020normalizing">kobyzev2020normalizing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">kobyzev2020normalizing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kononenko1994estimating">kononenko1994estimating</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kool2018attention">kool2018attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="#koppen2000curse">koppen2000curse</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kulasekara2014transposon">kulasekara2014transposon</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kumar2019multi">kumar2019multi</a></li>
<li class="toctree-l2"><a class="reference internal" href="#krizhevsky2012imagenet">krizhevsky2012imagenet</a></li>
<li class="toctree-l2"><a class="reference internal" href="#krizhevsky2017imagenet">krizhevsky2017imagenet</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kullback1951information">kullback1951information</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lecun1989backpropagation">lecun1989backpropagation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lecun1989generalization">lecun1989generalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lecun1989handwritten">lecun1989handwritten</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lecun1998gradient">lecun1998gradient</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lee2019wide">lee2019wide</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lehman2020surprising">lehman2020surprising</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lensen2017new">lensen2017new</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lex2022noam">lex2022noam</a></li>
<li class="toctree-l2"><a class="reference internal" href="#li2002novel">li2002novel</a></li>
<li class="toctree-l2"><a class="reference internal" href="#li2004evolutionary">li2004evolutionary</a></li>
<li class="toctree-l2"><a class="reference internal" href="#li2017feature">li2017feature</a></li>
<li class="toctree-l2"><a class="reference internal" href="#li2021learnable">li2021learnable</a></li>
<li class="toctree-l2"><a class="reference internal" href="#li2023blip">li2023blip</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lin2017feature">lin2017feature</a></li>
<li class="toctree-l2"><a class="reference internal" href="#linnainmaa1970representation">linnainmaa1970representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#liu1995chi2">liu1995chi2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#liu2018darts">liu2018darts</a></li>
<li class="toctree-l2"><a class="reference internal" href="#liu2023instaflow">liu2023instaflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lock2007new">lock2007new</a></li>
<li class="toctree-l2"><a class="reference internal" href="#loh2011classification">loh2011classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="#loshchilov2017decoupled">loshchilov2017decoupled</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mantyla1998cuelensen2017new">mantyla1998cuelensen2017new</a></li>
<li class="toctree-l2"><a class="reference internal" href="#marhsall2022cybermarine">marhsall2022cybermarine</a></li>
<li class="toctree-l2"><a class="reference internal" href="#marine2020tackling">marine2020tackling</a></li>
<li class="toctree-l2"><a class="reference internal" href="#matyushin2020gas">matyushin2020gas</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mccann2012local">mccann2012local</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mcconnell1986method">mcconnell1986method</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mclean2005differences">mclean2005differences</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mikolov2013efficient">mikolov2013efficient</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mikolov2013linguistic">mikolov2013linguistic</a></li>
<li class="toctree-l2"><a class="reference internal" href="#miles1998state">miles1998state</a></li>
<li class="toctree-l2"><a class="reference internal" href="#miller1994exploiting">miller1994exploiting</a></li>
<li class="toctree-l2"><a class="reference internal" href="#miller2017explainable">miller2017explainable</a></li>
<li class="toctree-l2"><a class="reference internal" href="#miller2019explanation">miller2019explanation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#miller2021contrastive">miller2021contrastive</a></li>
<li class="toctree-l2"><a class="reference internal" href="#morgan1989generalization">morgan1989generalization</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mnih2013playing">mnih2013playing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#moraglio2012geometric">moraglio2012geometric</a></li>
<li class="toctree-l2"><a class="reference internal" href="#moravvcik2017deepstack">moravvcik2017deepstack</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mouret2015illuminating">mouret2015illuminating</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mouss2004test">mouss2004test</a></li>
<li class="toctree-l2"><a class="reference internal" href="#muller2021transformers">muller2021transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="#munoz2015m3gp">munoz2015m3gp</a></li>
<li class="toctree-l2"><a class="reference internal" href="#nickerson2022creating">nickerson2022creating</a></li>
<li class="toctree-l2"><a class="reference internal" href="#nielsen2020survae">nielsen2020survae</a></li>
<li class="toctree-l2"><a class="reference internal" href="#nguyen2014filtermccann2012local">nguyen2014filtermccann2012local</a></li>
<li class="toctree-l2"><a class="reference internal" href="#olah2018building">olah2018building</a></li>
<li class="toctree-l2"><a class="reference internal" href="#pardo2016misdescription">pardo2016misdescription</a></li>
<li class="toctree-l2"><a class="reference internal" href="#pascual2022fullband">pascual2022fullband</a></li>
<li class="toctree-l2"><a class="reference internal" href="#pearce2021empirical">pearce2021empirical</a></li>
<li class="toctree-l2"><a class="reference internal" href="#peng2022prenastvec">peng2022prenastvec</a></li>
<li class="toctree-l2"><a class="reference internal" href="#peng2021prenasgecco">Peng2021prenasgecco</a></li>
<li class="toctree-l2"><a class="reference internal" href="#peng2023rwkv">peng2023rwkv</a></li>
<li class="toctree-l2"><a class="reference internal" href="#perez2019analysis">perez2019analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="#podell2023sdxl">podell2023sdxl</a></li>
<li class="toctree-l2"><a class="reference internal" href="#qin2021one">qin2021one</a></li>
<li class="toctree-l2"><a class="reference internal" href="#radford2018improving">radford2018improving</a></li>
<li class="toctree-l2"><a class="reference internal" href="#radford2021learning">radford2021learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#radford2021zero">radford2021zero</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rajpurkar2017chexnet">rajpurkar2017chexnet</a></li>
<li class="toctree-l2"><a class="reference internal" href="#raine1997brain">raine1997brain</a></li>
<li class="toctree-l2"><a class="reference internal" href="#raissi2019physics">raissi2019physics</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ramesh2022hierarchical">ramesh2022hierarchical</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rampal2022high">rampal2022high</a></li>
<li class="toctree-l2"><a class="reference internal" href="#rasmussen2003gaussian">rasmussen2003gaussian</a></li>
<li class="toctree-l2"><a class="reference internal" href="#restek2018high">restek2018high</a></li>
<li class="toctree-l2"><a class="reference internal" href="#riad2022learning">riad2022learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#riccardo2009field">riccardo2009field</a></li>
<li class="toctree-l2"><a class="reference internal" href="#robinson2020genetic">robinson2020genetic</a></li>
<li class="toctree-l2"><a class="reference internal" href="#robnik2003theoretical">robnik2003theoretical</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ronneberger2015u">ronneberger2015u</a></li>
<li class="toctree-l2"><a class="reference internal" href="#runarsson2000stochastic">runarsson2000stochastic</a></li>
<li class="toctree-l2"><a class="reference internal" href="#russell2010artificial">russell2010artificial</a></li>
<li class="toctree-l2"><a class="reference internal" href="#saxe2013exact">saxe2013exact</a></li>
<li class="toctree-l2"><a class="reference internal" href="#shahriari2015taking">shahriari2015taking</a></li>
<li class="toctree-l2"><a class="reference internal" href="#schnier2004digital">schnier2004digital</a></li>
<li class="toctree-l2"><a class="reference internal" href="#scholkopf2000new">scholkopf2000new</a></li>
<li class="toctree-l2"><a class="reference internal" href="#shaukat2022state">shaukat2022state</a></li>
<li class="toctree-l2"><a class="reference internal" href="#schulman2017proximal">schulman2017proximal</a></li>
<li class="toctree-l2"><a class="reference internal" href="#simonyan2014very">simonyan2014very</a></li>
<li class="toctree-l2"><a class="reference internal" href="#smart2005using">smart2005using</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sobel1990isotropic">sobel1990isotropic</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sobel2014history">sobel2014history</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sobieczky1999parametric">sobieczky1999parametric</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sohl2015deep">sohl2015deep</a></li>
<li class="toctree-l2"><a class="reference internal" href="#song2020denoising">song2020denoising</a></li>
<li class="toctree-l2"><a class="reference internal" href="#song2023consistency">song2023consistency</a></li>
<li class="toctree-l2"><a class="reference internal" href="#stewart2022quarry">stewart2022quarry</a></li>
<li class="toctree-l2"><a class="reference internal" href="#srivastava2014dropout">srivastava2014dropout</a></li>
<li class="toctree-l2"><a class="reference internal" href="#sun2022soknl">sun2022soknl</a></li>
<li class="toctree-l2"><a class="reference internal" href="#szegedy2013intriguing">szegedy2013intriguing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#szegedy2015going">szegedy2015going</a></li>
<li class="toctree-l2"><a class="reference internal" href="#szegedy2016rethinking">szegedy2016rethinking</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tran2019genetic">tran2019genetic</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tegmark2020aifeynman">tegmark2020aifeynman</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tegmark2020aifeynman2">tegmark2020aifeynman2</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tegmark2021aipoincare">tegmark2021aipoincare</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tegmark2022poisson">tegmark2022poisson</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tomasi2004correlation">tomasi2004correlation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tran2018variable">tran2018variable</a></li>
<li class="toctree-l2"><a class="reference internal" href="#van2008visualizing">van2008visualizing</a></li>
<li class="toctree-l2"><a class="reference internal" href="#vaswani2017attention">vaswani2017attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="#vincent2011connection">vincent2011connection</a></li>
<li class="toctree-l2"><a class="reference internal" href="#volz2018evolving">volz2018evolving</a></li>
<li class="toctree-l2"><a class="reference internal" href="#von1986decision">von1986decision</a></li>
<li class="toctree-l2"><a class="reference internal" href="#wang2018evolving">wang2018evolving</a></li>
<li class="toctree-l2"><a class="reference internal" href="#wang2020linformer">wang2020linformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#watkins1992q">watkins1992q</a></li>
<li class="toctree-l2"><a class="reference internal" href="#wayne2018unsupervised">wayne2018unsupervised</a></li>
<li class="toctree-l2"><a class="reference internal" href="#weinstein2022hunter">weinstein2022hunter</a></li>
<li class="toctree-l2"><a class="reference internal" href="#white2023neural">white2023neural</a></li>
<li class="toctree-l2"><a class="reference internal" href="#wood2022automated">wood2022automated</a></li>
<li class="toctree-l2"><a class="reference internal" href="#wolpert1997no">wolpert1997no</a></li>
<li class="toctree-l2"><a class="reference internal" href="#xie2022physics">xie2022physics</a></li>
<li class="toctree-l2"><a class="reference internal" href="#xiong2020layer">xiong2020layer</a></li>
<li class="toctree-l2"><a class="reference internal" href="#xie2017aggregated">xie2017aggregated</a></li>
<li class="toctree-l2"><a class="reference internal" href="#xin2022current">xin2022current</a></li>
<li class="toctree-l2"><a class="reference internal" href="#xue2014particle">xue2014particle</a></li>
<li class="toctree-l2"><a class="reference internal" href="#xue2015survey">xue2015survey</a></li>
<li class="toctree-l2"><a class="reference internal" href="#yang2022noise">yang2022noise</a></li>
<li class="toctree-l2"><a class="reference internal" href="#yu2019adapting">yu2019adapting</a></li>
<li class="toctree-l2"><a class="reference internal" href="#zemmal2016adaptative">zemmal2016adaptative</a></li>
<li class="toctree-l2"><a class="reference internal" href="#zhai2021attention">zhai2021attention</a></li>
<li class="toctree-l2"><a class="reference internal" href="#zhang2008two">zhang2008two</a></li>
<li class="toctree-l2"><a class="reference internal" href="#zhang2021evolutionary">zhang2021evolutionary</a></li>
<li class="toctree-l2"><a class="reference internal" href="#zhang2023adding">zhang2023adding</a></li>
<li class="toctree-l2"><a class="reference internal" href="#zhao2017pyramid">zhao2017pyramid</a></li>
<li class="toctree-l2"><a class="reference internal" href="#zhao2019maximum">zhao2019maximum</a></li>
<li class="toctree-l2"><a class="reference internal" href="#zhu2022few">zhu2022few</a></li>
<li class="toctree-l2"><a class="reference internal" href="#zoph2016neural">zoph2016neural</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="notes.html">Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="thoughts.html">Thoughts</a></li>
<li class="toctree-l1"><a class="reference internal" href="contact.html">Contact</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">fish</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Literature Review</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/literature.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="literature-review">
<span id="id1"></span><h1>Literature Review<a class="headerlink" href="#literature-review" title="Link to this heading"></a></h1>
<section id="abdi2010principal">
<h2>abdi2010principal<a class="headerlink" href="#abdi2010principal" title="Link to this heading"></a></h2>
<p>Principal component analysis</p>
<p>(Abdi 2010) propose Principal Component Analysis (PCA) for dimensionality reduction.</p>
<dl class="simple">
<dt>Method:</dt><dd><ul class="simple">
<li><p>Project data along the principal components, the axis of maximum variance in descending order.</p></li>
<li><p>The first principal component is the axis of maximum variance, the second principal component is orthogonal to the first and has the second largest variance, and so on.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#black2019rapid"><span class="std std-ref">(Black 2019)</span></a> uses PCA for preprocessing.</p></li>
<li><p><a class="reference internal" href="#goodfellow2016deep"><span class="std std-ref">(Goodfellow 2016)</span></a> gives dervation using Linear Algebra.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="adebayo2018sanity">
<h2>adebayo2018sanity<a class="headerlink" href="#adebayo2018sanity" title="Link to this heading"></a></h2>
<p>Sanity checks for saliency maps</p>
<p>(Adebayo 2018) suggests salience maps are glorified edge detectors.</p>
</section>
<section id="agarwal2011building">
<h2>agarwal2011building<a class="headerlink" href="#agarwal2011building" title="Link to this heading"></a></h2>
<p>Building rome in a day</p>
<dl class="simple">
<dt>TODO:</dt><dd><ul class="simple">
<li><p>READ <a class="reference external" href="https://dl.acm.org/doi/abs/10.1145/2001269.2001293">https://dl.acm.org/doi/abs/10.1145/2001269.2001293</a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="aizerman1964theoretical">
<h2>aizerman1964theoretical<a class="headerlink" href="#aizerman1964theoretical" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>The original hyperplane algorithm used a linear kernel.</p></li>
</ul>
</div></blockquote>
</section>
<section id="akkaya2019solving">
<h2>akkaya2019solving<a class="headerlink" href="#akkaya2019solving" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Akkaya et al. propose a robotic hand that “single-handedly” solved a Rubiks cube cite{akkaya2019solving}.</p></li>
<li><p>They use Automatic Domain Randomization (ADR) and simulation to impute data for physics-based problems.</p></li>
<li><p>This technique was used to solve a Rubiks cube “single-handedly” by simulation.</p></li>
<li><p>It can be difficult to model an accurate physics engine.</p></li>
<li><p>Instead, ADR solves all possible sets of physics environments within given constraints for the Rubiks cube.</p></li>
<li><p>Through simulation, they create a model that generalizes well, with very little real-world experimentation needed.</p></li>
</ul>
</div></blockquote>
</section>
<section id="al2019survey">
<h2>al2019survey<a class="headerlink" href="#al2019survey" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Survey of evolutionary machine learning - Vuw staff.</p></li>
<li><p><strong>TODO</strong> read</p></li>
</ul>
</div></blockquote>
</section>
<section id="ba2016layer">
<h2>ba2016layer<a class="headerlink" href="#ba2016layer" title="Link to this heading"></a></h2>
<p>Layer Normalization</p>
<p>(Ba 2016) propose Layer Normalization, a regularization technique for deep learning.</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/1607.06450">https://arxiv.org/abs/1607.06450</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Transformer <a class="reference internal" href="#vaswani2017attention"><span class="std std-ref">(Vaswani 2017)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="balas1969machine">
<h2>balas1969machine<a class="headerlink" href="#balas1969machine" title="Link to this heading"></a></h2>
<p>Machine Sequencing Via Disjunctive Graphs: An Implicit Enumeration Algorithm</p>
<p>(Balas 1969) proposes a disjunctive graph for machine sequencing.</p>
<p>Available: <a class="reference external" href="https://pubsonline.informs.org/doi/abs/10.1287/opre.17.6.941">https://pubsonline.informs.org/doi/abs/10.1287/opre.17.6.941</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Mentioned in <a class="reference internal" href="minutes.html#id149"><span class="std std-ref">2023-10-06 - ECRG</span></a></p></li>
<li><p>Vehicle routing with transformers <a class="reference internal" href="#kool2018attention"><span class="std std-ref">(Kool 2018)</span></a></p></li>
<li><p>node2vec <a class="reference internal" href="#grover2016node2vec"><span class="std std-ref">(Grover 2016)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="bao2022estimating">
<h2>bao2022estimating<a class="headerlink" href="#bao2022estimating" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Estimating the Optimal Covariance with Imperfect Mean in Diffusion Probabilistic Models</p></li>
<li><p>Diffusion Probabilistic Models (DPM) are special Markov Models with Gaussian Transitions.</p></li>
<li><p>Paper shows how to go from noisy-to-clean with a deterministic process.</p></li>
<li><p>A new approach to diffusion based models.</p></li>
</ul>
</div></blockquote>
</section>
<section id="batstone1999new">
<h2>batstone1999new<a class="headerlink" href="#batstone1999new" title="Link to this heading"></a></h2>
<p>New Zealand’s quota management system: the first ten years</p>
<p>(Batstone 1999) describes the first 10 years of the New Zealand Quota Management System (QMS) for fisheries management.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#lock2007new"><span class="std std-ref">(lock2007new)</span></a> gives a history of NZ QMS for first 20 years.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="banzhaf2006artificial">
<h2>banzhaf2006artificial<a class="headerlink" href="#banzhaf2006artificial" title="Link to this heading"></a></h2>
<p>From artificial evolution to computational evolution: a research agenda</p>
<p>(Banzahf 2006) proposes a research agenda for evolutional computataion, published in nature magazine. Available <a class="reference external" href="https://www.nature.com/articles/nrg1921">https://www.nature.com/articles/nrg1921</a></p>
<p>TODO [ ] Read this paper!</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See ECRG - 2022-10-28</p></li>
</ul>
</dd>
</dl>
</section>
<section id="banzhaf2009genetic">
<h2>banzhaf2009genetic<a class="headerlink" href="#banzhaf2009genetic" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Genetic Programming: An Introduction On The Automatic Evolution Of Computer Programs And Its Applications</p></li>
<li><p>TODO [ ] must read book for foundations of GP. (buy?)</p></li>
</ul>
</div></blockquote>
</section>
<section id="behmo2010towards">
<h2>behmo2010towards<a class="headerlink" href="#behmo2010towards" title="Link to this heading"></a></h2>
<p>Towards optimal naive bayes nearest neighborhood</p>
<p><cite>(Behmo 2010) &lt;https://link.springer.com/chapter/10.1007/978-3-642-15561-1_13&gt;</cite> proposes a Naive Bayes Nearest Neighbour (NBNN) classifier.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#crall2013hotspotter"><span class="std std-ref">(Crall 2013)</span></a> uses LBNN for instance recognition.</p></li>
<li><p><a class="reference internal" href="#mccann2012local"><span class="std std-ref">(McCann 2012)</span></a> proposed Local Naive Bayes Nearest Neighbour (LNBNN).</p></li>
</ul>
</dd>
</dl>
</section>
<section id="bengio2017consciousness">
<h2>bengio2017consciousness<a class="headerlink" href="#bengio2017consciousness" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>The consciousness prior</p></li>
</ul>
</div></blockquote>
</section>
<section id="bi2020gc">
<h2>bi2020gc<a class="headerlink" href="#bi2020gc" title="Link to this heading"></a></h2>
<p>GC-MS Fingerprints Profiling Using Machine Learning Models for Food Flavor Prediction</p>
<p>(Bi 2022) proposed a CNN model that incorporated GC-MS data fusion for food science.</p>
<dl class="simple">
<dt>Data:</dt><dd><ul class="simple">
<li><p>Food flavour quality evaluation is interesting, but lacks evaluation techniques.</p></li>
<li><p>Olfactometry, an instrument used to detect and measure odor dilution, is unreliable due to user error or systematic laboratroy effect.</p></li>
<li><p>Existing technique for analysis was intractable large scale.</p></li>
<li><p>Evaluated on existing Gas Chromatography - Mass Spectrometry (GC-MS) measurements on peanut oil data.</p></li>
</ul>
</dd>
<dt>Method:</dt><dd><ul class="simple">
<li><p>A novel fingerprint modelling and profilling process</p></li>
<li><p>Dataset expansion</p></li>
</ul>
</dd>
<dt>Results:</dt><dd><ul class="simple">
<li><p>Their work classified the flavour quality of peanut oil with 93% accuracy.</p></li>
<li><p>Dataset expansion: the fusion of existing datasets improved the efficacy of their model.</p></li>
</ul>
</dd>
<dt>Why it matters?</dt><dd><ul class="simple">
<li><p>CNN can make accurate predictions on high-dimensional GC-MS data.</p></li>
<li><p>Proposes method can automate aroma analysis, reducing human labour, and improving accuracy.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#eder1995gas"><span class="std std-ref">(Eder 1995)</span></a> is the original gas chromatrogaphy (GC) paper.</p></li>
<li><p><a class="reference internal" href="#zhang2008two"><span class="std std-ref">(Zhang 2008)</span></a> preprocssing method for aligning gas chromatography (GC).</p></li>
<li><p><a class="reference internal" href="#wood2022automated"><span class="std std-ref">(Wood 2022)</span></a> performs classification / feature selection on gas chromatography data.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="bifet2007learning">
<h2>bifet2007learning<a class="headerlink" href="#bifet2007learning" title="Link to this heading"></a></h2>
<p>Learning from time-changing data with adaptive windowing</p>
<p>(Bifet 2007) propsoed the ADWIN method for detecting concept drift in data streams.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See (<a class="reference internal" href="#gomes2020ensemble"><span class="std std-ref">Gomes 2020</span></a>) for paper that cites.</p></li>
<li><p>See <a class="reference internal" href="minutes.html#id131"><span class="std std-ref">2023-02-16 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="black2017real">
<h2>black2017real<a class="headerlink" href="#black2017real" title="Link to this heading"></a></h2>
<p>A real time metabolomic profiling approach to detecting fish fraud using rapid evaporative ionisation mass spectrometry</p>
<p>(Black 2017) prose REIMS for fish fraud detection.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>TODO [ ] Read this paper</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#black2019rapid"><span class="std std-ref">(Black 2019)</span></a> propose REIMS for rapid and specific identification of foffal cuts within minced beef samples.</p></li>
<li><p><a class="reference internal" href="#wood2022automated"><span class="std std-ref">(Wood 2022)</span></a> performs classification / feature selection on gas chromatography data on fish data.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="black2019rapid">
<h2>black2019rapid<a class="headerlink" href="#black2019rapid" title="Link to this heading"></a></h2>
<p>Rapid detection and specific identification of offals within minced beef samples utilising ambient mass spectrometry</p>
<p>(Black 2019) propose REIMS for rapid and specific identification of foffal cuts within minced beef samples.</p>
<dl class="simple">
<dt>Background:</dt><dd><ul class="simple">
<li><p>Criminals add stuff to meat products (adulteration) for economic gains.</p></li>
<li><p>Meat adulteration in non-meat products of &lt;1% expected (and allowed) as it is considered cross-contaminiation, and not for economic gains.</p></li>
<li><p>Adulterations levels from (15%-20%) are considered criminal as they are likely for economic gains.</p></li>
<li><p>2013 European Horsemeat scandal is an example of this.</p></li>
<li><p>In repsonse, European Union (EU) decalared that non-meat opffcal cuts must be declared on product labels.</p></li>
<li><p>Recent study (BBC 2018) in the UK (n=665), found &gt;1/5 of samples contained non-declared meat species.</p></li>
<li><p>E.g., for 2013 European horsemeat scandal, REIMS could detect the adulteration, and identify that adulterant as horse.</p></li>
<li><p>Rapid evaportive ionization mass spectrometry (REIMS)</p></li>
<li><p>Minced beef products are often ready-to-go, and pre-cooked, so a method is needed that works on raw/cooked meat products.</p></li>
</ul>
</dd>
<dt>Motivation:</dt><dd><ul class="simple">
<li><p>DNA sequencing can only differentiate between different species, not offal adulteration from the same species.</p></li>
<li><p>Virbration spectroscopy cand etect adulteration, but not the specific offal present.</p></li>
<li><p>Both DNA methodologies and vibrational spectroscopy are ineffective at detecting these adulterations.</p></li>
<li><p>Traditional chromatroagprahy/mass spectromety hasn’t been tried, due to time to prepare/analyze samples.</p></li>
<li><p>Ambient Mass Spectromerty (AMS) has potential to identify unique/signficiant metabolites. GC-MS cannot do this!</p></li>
<li><p>Significant Markers (or important variables) are ions that are unique to a specific offal cut, and present in all samples.</p></li>
<li><p>Looking for a reliable, accurate and rapid method that can be deployed in a food processing plant for quality assurance.</p></li>
<li><p>Looking for a model that can detect adulteration levels for criminal activity adulteration for economic gains.</p></li>
</ul>
</dd>
<dt>Data:</dt><dd><ul class="simple">
<li><p>Cheap offal products can be addded to beef tissues when they are minced in food processing to cut corners and increase profits.</p></li>
<li><p>Minced beef (1 class) with alteration from beef brain, heart, kidney, large intestine and liver tissues (5 classes).</p></li>
<li><p>Outliers are hybrid spectra - a homogenous mix of beef and adulteration - at a given adulteration level (i.e. 20%, 10%, 5%, 1%).</p></li>
<li><dl class="simple">
<dt>Pre-processing (before PCA-LDA):</dt><dd><ol class="arabic simple">
<li><p>Prototpye abstract model builder</p></li>
<li><p>Masslynx pre-processing algorithms</p></li>
<li><p>Background subtracted</p></li>
<li><p>Lockmass corrected</p></li>
<li><p>Normalized by TIC (total ion count)</p></li>
</ol>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Post-processing (after PCA-LDA):</dt><dd><ol class="arabic simple">
<li><p>Mean-centered</p></li>
<li><p>Pareto scaled</p></li>
<li><p>Grouped by class</p></li>
</ol>
</dd>
</dl>
</li>
<li><p>Method facilitates real-time classification, with classification output prodived every second.</p></li>
<li><p>METLIN metabolies databas, and LIPID MAPS can proved annotated lables for spectra.</p></li>
</ul>
</dd>
<dt>Method:</dt><dd><ul class="simple">
<li><p>They propose REIMS for detecting beef adulteration.</p></li>
<li><dl class="simple">
<dt>Metrics:</dt><dd><ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(R^2\)</span> measures the variation in samples.</p></li>
<li><p><span class="math notranslate nohighlight">\(Q^2\)</span> measures the accuracy of classification of class.</p></li>
<li><p>RMSE-CV measure cross validated root means squared error.</p></li>
</ol>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Feature Selection:</dt><dd><ul>
<li><p>Variable Importance Projection (VIP)</p></li>
<li><p>S-plots?</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Chemometric analysis (VIP + S-plots) of REIMS could detect unique/significant markers.</p></li>
<li><p>Prinicapl component anaylsis linear discriminat anaylsis (PCA-LDA) (Abdi 2010) using orthogonal partial least squares discriminant analysis (OPLS-DA) (Boccard 2013).</p></li>
<li><p>PCA-LCA used for dimensionality reduction - classification, respectively.</p></li>
<li><p>Detect outliers based on standard deviation outside 20 <span class="math notranslate nohighlight">\(\sigma\)</span> of the mean for any class.</p></li>
<li><p>They provide a very detailed description of their method from the chemistry side, including instruments and their settings. Good for reproducability and understanding.</p></li>
</ul>
</dd>
<dt>Results:</dt><dd><ul class="simple">
<li><p>PCA/LDA (with manual hyper-parameter tuining) can effecitvely detect adulteration - i.e. cluster different classes within adulteration levels (i.e. 15-20%).</p></li>
<li><p>The adulteration levels were measured on raw/boiled minced beefs.</p></li>
<li><p>Raw: brain (5%), heart (1-10%), kidney (1-5%), large intestincce (1-10%), liver (5-10%).</p></li>
<li><p>Beef and large intestine were too similar to detect outliers with PCA-LDA. Perhaps very similar tissue composition.</p></li>
<li><p>Within adulteration levels (i.e. 15-20%), their model can predict adulteration with perfect precision <span class="math notranslate nohighlight">\(P(C|\hat{C}) = 1\)</span>, i.e., all predicted alduterations were correct.</p></li>
<li><p>Boiled: brain (5-10%), heart (1-10%), kidney (1-5%), large intestine (1-10%), live (5-10%).</p></li>
<li><p>Boiled samples are harder to classify. More principle components were needed to correctly identify adularation for boiled samples.</p></li>
</ul>
</dd>
<dt>Why it matters?</dt><dd><ul class="simple">
<li><p>REIMS is a cheap and rapid method for detecting adulteration in minced beef in a factory setting.</p></li>
<li><p>REIMS can detect both adulterations, and the specific adulteration present, superior to other methods.</p></li>
<li><p>Many meat products are pre-cooked, REIMS detects adulteration (at criminal levels) in raw/boiled meat.</p></li>
<li><p>REIMS can provide a paradigm shift across many authenticity applications.</p></li>
<li><p>(Black 2017) shows can be successfully applied to fish REIMS data.</p></li>
</ul>
</dd>
<dt>Limitations:</dt><dd><ul class="simple">
<li><p>Basic dimensioanlity reduction techniques (PCA) were used. Future work should consider t-SNE.</p></li>
<li><p>Basic sueprvised statistical models were (LDA, OPLS-DA) were used for classification. Future work should consider GANs, VAEs, Diffusion, CNNs.</p></li>
<li><p>Potential for transfer learning (encorporate previously existing data) to improve performance for few-shot classification tasks.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#black2017real"><span class="std std-ref">(Black 2017)</span></a> use REIMS for fish fraud detection.</p></li>
<li><p>(BBC 2018) Recent study in the UK (n-665), found &gt;1/5 of samples contained non-declared meat species. <a class="reference external" href="https://www.bbc.com/news/uk-45371852">https://www.bbc.com/news/uk-45371852</a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="blattmann2023align">
<h2>blattmann2023align<a class="headerlink" href="#blattmann2023align" title="Link to this heading"></a></h2>
<p>Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>NVIDIA Paper on text-to-video synthesis.</p></li>
<li><p>[Available] <a class="reference external" href="https://arxiv.org/abs/2304.08818">https://arxiv.org/abs/2304.08818</a></p></li>
<li><p>TODO [ ] Read</p></li>
</ul>
</dd>
</dl>
<p>Background:</p>
<p>Motivations:</p>
<p>Data:</p>
<p>Method:</p>
<p>Results:</p>
<p>Why it matters?</p>
<p>Limitations:</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>DDPM <a class="reference internal" href="#ho2020denoising"><span class="std std-ref">(Ho 2020)</span></a> was the original Denoising diffusion probabilistic models (DDPM)</p></li>
<li><p>DDIM <a class="reference internal" href="#song2020denoising"><span class="std std-ref">(Song 2020)</span></a> Denoising diffusion implicit models (DDIM), improved DDPM</p></li>
<li><p>Elucidating <a class="reference internal" href="#karras2022elucidating"><span class="std std-ref">(Karras 2022)</span></a> provided a concrete design space for LDM architectures.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="boccard2013consensus">
<h2>boccard2013consensus<a class="headerlink" href="#boccard2013consensus" title="Link to this heading"></a></h2>
<p>A consensus orthogonal partial least squares discriminant analysis (OPLS-DA) strategy for multiblock Omics data fusion</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>TODO [ ] Read</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#black2019rapid"><span class="std std-ref">(Black 2019)</span></a> use OPLS-DA for adulteration detection in minced beef.</p></li>
<li><p><a class="reference internal" href="#black2017real"><span class="std std-ref">(Black 2017)</span></a> uses OPLS-DA for fish fraud detection.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="bongiovanni2019electric">
<h2>bongiovanni2019electric<a class="headerlink" href="#bongiovanni2019electric" title="Link to this heading"></a></h2>
<p>The electric autonomous dial-a-ride problem</p>
<p>(Bongiovanni) introduces the Electric Autonomous Dial-A-Ride Problem (EA-DARP)</p>
<p>Available: <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0191261517309669">https://www.sciencedirect.com/science/article/pii/S0191261517309669</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed by Guenther in <span class="xref std std-ref">2024-03-22 - ECRG</span></p></li>
</ul>
</dd>
</dl>
</section>
<section id="boser1992training">
<h2>boser1992training<a class="headerlink" href="#boser1992training" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Kernal trick for SVM.</p></li>
<li><p>These employ the kernel trick.</p></li>
</ul>
</div></blockquote>
</section>
<section id="bourque2018ten">
<h2>bourque2018ten<a class="headerlink" href="#bourque2018ten" title="Link to this heading"></a></h2>
<p>Ten things you should know about transposable elements</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Julie discussed this at ECRG - 2022-10-14</p></li>
<li><p><a class="reference internal" href="#hof2016industrial"><span class="std std-ref">(Hof 2016)</span></a> gives an example of tranposons affecting moths.</p></li>
<li><p><a class="reference internal" href="#kulasekara2014transposon"><span class="std std-ref">(Kulasekara 2014)</span></a> says changes passed to offspring.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="breiman2017classification">
<h2>breiman2017classification<a class="headerlink" href="#breiman2017classification" title="Link to this heading"></a></h2>
<p>Classification and Regression Trees</p>
<p>(Breiman 2017) is the book on CART.</p>
<p>Available: <a class="reference external" href="https://www.taylorfrancis.com/books/mono/10.1201/9781315139470/classification-regression-trees-leo-breiman-jerome-friedman-olshen-charles-stone">https://www.taylorfrancis.com/books/mono/10.1201/9781315139470/classification-regression-trees-leo-breiman-jerome-friedman-olshen-charles-stone</a></p>
<dl>
<dt>Background:</dt><dd><ul class="simple">
<li><p>Book orginally published in 1984</p></li>
<li><p>decision trees are an algorithm that only contains conditional control statements, i.e. if-else statements.</p></li>
<li><p>The acronym is Classification and Regression Trees (CART).</p></li>
<li><p>In 1984, Breiman et al cite{breiman2017classification} proposed .</p></li>
</ul>
<p>The classification task predicts the class label an instance is most likely to belong to.</p>
</dd>
<dt>Representation:</dt><dd><ul class="simple">
<li><p>CART uses a tree-based structure of both nodes, branches and leaves.</p></li>
<li><p>The nodes are where decisions are made, branches give the outcome of those decisions, and leaves give the predicted class label.</p></li>
</ul>
</dd>
<dt>Method:</dt><dd><ul class="simple">
<li><p>The algorithm uses a greedy approach to build the tree.</p></li>
<li><p>It evaluates all possible splits and selects the one that best reduces the impurity of the resulting subsets.</p></li>
<li><p>It splits at the feature that is the best splitting point.</p></li>
<li><p>CART continues to split until a stopping rule is met, or no further best splits are available.</p></li>
<li><p>For classification, Gini impurity is the splitting criterion.</p></li>
<li><p>The lower the Gini impurity, the more pure a subset is.</p></li>
<li><p>For regression, the residual reduction is the splitting criterion.</p></li>
<li><p>The lower the residual reduction, the better fit the model is to the data.</p></li>
<li><p>Pruning: to prevent overfitting of the data, pruning can remove branches that do not improve the model’s performance.</p></li>
<li><p>Cost complexity and information gain pruning are two popular techniques.</p></li>
</ul>
</dd>
</dl>
<p>Applications:
.. epigraph:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">In</span> <span class="mi">1977</span><span class="o">-</span><span class="mi">1978</span> <span class="ow">and</span> <span class="n">again</span> <span class="ow">in</span> <span class="mi">1981</span><span class="p">,</span> <span class="n">the</span> <span class="n">EPA</span> <span class="n">funded</span> <span class="n">projects</span> <span class="k">for</span> <span class="n">the</span> <span class="n">construction</span> <span class="n">of</span> <span class="n">classification</span> <span class="n">trees</span> <span class="n">to</span> <span class="n">recognize</span> <span class="n">the</span> <span class="n">presence</span> <span class="n">of</span> <span class="n">certain</span> <span class="n">elements</span> <span class="ow">in</span> <span class="n">compounds</span> <span class="n">through</span> <span class="n">the</span> <span class="n">examination</span> <span class="n">of</span> <span class="n">their</span> <span class="n">mass</span> <span class="n">spectra</span><span class="o">.</span> <span class="n">The</span> <span class="n">EPA</span><span class="p">,</span> <span class="k">as</span> <span class="n">part</span> <span class="n">of</span> <span class="n">its</span> <span class="n">regulatory</span> <span class="n">function</span><span class="p">,</span> <span class="n">collects</span> <span class="n">numerous</span> <span class="n">samples</span> <span class="n">of</span> <span class="n">air</span> <span class="ow">and</span> <span class="n">water</span> <span class="n">containing</span> <span class="n">unknown</span> <span class="n">cdompounds</span> <span class="ow">and</span> <span class="n">tries</span> <span class="n">to</span> <span class="n">determine</span> <span class="n">the</span> <span class="n">presence</span> <span class="n">of</span> <span class="n">toxic</span> <span class="n">substances</span><span class="o">.</span> <span class="n">According</span> <span class="n">to</span> <span class="n">McLafferty</span><span class="p">:</span> <span class="s2">&quot;The fragment ions indicate the pieces of which the molecule is composed, and the interpreter attempts to deduce how these pieces fit together in the original molecular structure. In such correlations have been achieved for the spectra of a variety of complex molecules.&quot;</span> <span class="n">The</span> <span class="n">critical</span> <span class="n">element</span> <span class="n">of</span> <span class="n">the</span> <span class="n">bromine</span> <span class="n">tree</span> <span class="n">was</span> <span class="n">the</span> <span class="n">construction</span> <span class="n">of</span> <span class="n">a</span> <span class="nb">set</span> <span class="n">of</span> <span class="n">questions</span> <span class="n">designed</span> <span class="n">to</span> <span class="n">recognize</span> <span class="n">bromine</span> <span class="n">hallmarks</span><span class="o">.</span> <span class="n">If</span> <span class="n">bromine</span> <span class="n">occurs</span> <span class="ow">in</span> <span class="n">combination</span> <span class="k">with</span> <span class="n">chlorine</span><span class="p">,</span> <span class="n">then</span> <span class="n">since</span> <span class="n">chlorine</span> <span class="p">(</span><span class="n">weight</span> <span class="mi">35</span><span class="p">)</span> <span class="n">has</span> <span class="n">an</span> <span class="n">isotope</span> <span class="n">of</span> <span class="n">weight</span> <span class="mi">37</span> <span class="n">that</span> <span class="n">occurs</span> <span class="mf">24.5</span> <span class="n">percent</span> <span class="n">of</span> <span class="n">the</span> <span class="n">time</span><span class="p">,</span> <span class="n">there</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">different</span> <span class="n">theoretical</span> <span class="n">ratio</span> <span class="n">vector</span><span class="o">.</span>

<span class="o">--</span> <span class="n">Mass</span> <span class="n">Spectra</span> <span class="n">Classification</span>
</pre></div>
</div>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#von1986decision"><span class="std std-ref">(Von 1986)</span></a> is another decision tree paper from the 80s.</p></li>
<li><p>Geeks for Geeks <a class="reference external" href="https://www.geeksforgeeks.org/cart-classification-and-regression-tree-in-machine-learning/">https://www.geeksforgeeks.org/cart-classification-and-regression-tree-in-machine-learning/</a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="brewer2006brown">
<h2>brewer2006brown<a class="headerlink" href="#brewer2006brown" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Flashbuld memories - recollections that seem vivid and clear, so we take them to be accurate.</p></li>
<li><p>Most likely occur for distinct stronly positive or negative emotional events.</p></li>
<li><p>Weddings, Funerals, Deaths, Tragedy, Violence.</p></li>
<li><p>We are more likely to be confident these are correct.</p></li>
<li><p>But our memory is shit, so we often re-write and incorrectly recall these events.</p></li>
<li><p>The distinictness of flashbulb memories, does help recall them longer, but does not guarantee correctness.</p></li>
</ul>
</div></blockquote>
</section>
<section id="bridle1989training">
<h2>bridle1989training<a class="headerlink" href="#bridle1989training" title="Link to this heading"></a></h2>
<p>Training stochastic model recognition algorithms as networks can lead to maximum mutual information estimation of parameters</p>
<p>(Bridle 1989) is the first paper to mention “softmax” in neural networks.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>According to StackExchange, this is the original “softmax” paper for neural networks <a class="reference external" href="https://ai.stackexchange.com/questions/22426/which-paper-introduced-the-term-softmax">https://ai.stackexchange.com/questions/22426/which-paper-introduced-the-term-softmax</a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="brochu2010tutorial">
<h2>brochu2010tutorial<a class="headerlink" href="#brochu2010tutorial" title="Link to this heading"></a></h2>
<p>A Tutorial on Bayesian Optimization of Expensive Cost Functions, with Application to Active User Modeling and Hierarchical Reinforcement Learning</p>
<p>(Brochu 2010) is useful for Gaussian Processes, predictions with confidence intervals, or uncertainty thresholds.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>A Tutorial on Bayesian Optimization of Expensive Cost Functions</p></li>
<li><dl class="simple">
<dt>Application:</dt><dd><ol class="arabic simple">
<li><p>Active User Modeling</p></li>
<li><p>Hierarchical Reinforcement Learning</p></li>
</ol>
</dd>
</dl>
</li>
<li><p>Covers the theory and intuition behind Bayesian optimization</p></li>
</ul>
</dd>
</dl>
</section>
<section id="bromley1993signatured">
<h2>bromley1993signatured<a class="headerlink" href="#bromley1993signatured" title="Link to this heading"></a></h2>
<p>Signature verification using a” siamese” time delay neural network</p>
<p>(Bromley 1993), from LeCun’s lab, proposes Siamese Neural Networks, a contrastive learning technique, for signature verification.</p>
<dl class="simple">
<dt>Task:</dt><dd><ul class="simple">
<li><p>Signature verification</p></li>
<li><p>Pair-wise comparison of signatures.</p></li>
<li><dl class="simple">
<dt>Given:</dt><dd><ul>
<li><p>Reference - a genuine signature</p></li>
<li><p>Query - a signature to be verified.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Determine if query is a genuine signature</p></li>
</ul>
</dd>
<dt>Data:</dt><dd><ul class="simple">
<li><p>Signature verification.</p></li>
<li><p>Eliminate redundancies - forgeries must attempt to copy a genuine signature.</p></li>
<li><p>Genuine signatures have between 80% to 120% of the original strokes of the reference signature.</p></li>
<li><p>Note: 120% implies a signature with a few more strokes than the reference is still considered genuine.</p></li>
<li><p>219 people signed between 10 and 20 signatures each, 145 signed genuines, 74 signed forgeries.</p></li>
<li><p>Few-shot learning - A person must have signed at least 6 genuine signatures or forgeries.</p></li>
</ul>
</dd>
<dt>Method:</dt><dd><ul class="simple">
<li><p>Siamese network - two identical networks, with shared weights.</p></li>
<li><p>The two networks are fed the reference and query signatures.</p></li>
<li><p>Euclidean distance between the two networks is used to determine if the query is genuine.</p></li>
<li><p>A form of contrastive learning.</p></li>
</ul>
</dd>
<dt>Results:</dt><dd><ul class="simple">
<li><p>Best performance was obtained with Network 4. With the threshold set to detect 80% of forgeries, 95.5% of genuine signatures were detected (24 signatures rejected).</p></li>
<li><p>Performance could be improved to 97.0% genuine signatures detected (13 rejected) by removing all first and second signature from the test set 2.</p></li>
<li><p>For 9 of the remaining 13 rejected signatures pen up trajectories differed from the person’s typical signature.</p></li>
</ul>
</dd>
<dt>Why it matters?</dt><dd><ul class="simple">
<li><p>Siamese networks are a form of contrastive learning.</p></li>
<li><p>Contrastive learning is a form of self-supervised learning.</p></li>
<li><p>Contastrive learning is an efficient technique for few-shot learning.</p></li>
</ul>
</dd>
<dt>Limitations:</dt><dd><ul class="simple">
<li><p>“Another cause of error came from a few people who seemed unable to sign consistently and would miss out letters or add new strokes to their signature.”</p></li>
<li><p>The authors note that the performance of the system is limited by the quality of the signatures.</p></li>
</ul>
</dd>
<dt>Applications:</dt><dd><ul class="simple">
<li><p>(Bromley 1993) was a proof-of-concept for the signature verification system.</p></li>
<li><p>It worked equally well for American, European and Chinese signatures.</p></li>
<li><p>A field trial needed before it could be deployed in a real-world setting.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><span class="xref std std-ref">(Zhu 2020)</span> uses Siamese networks for malware detection.</p></li>
<li><p><a class="reference internal" href="#jing2022masked"><span class="std std-ref">(Jing 2020)</span></a> propose masked siamese networks.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="brosnan2003monkeys">
<h2>brosnan2003monkeys<a class="headerlink" href="#brosnan2003monkeys" title="Link to this heading"></a></h2>
<p>Monkeys reject unequal pay</p>
<p>(Brosnan 2003), in parntership with Frans de Waal, show that monkeys reject unequal pay.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Monkeys are given a simple task with a reward.</p></li>
<li><p>One monkey is given plain cucumbers, the other is given grapes.</p></li>
<li><p>The monkey that is given cucumbers goes bananas over the inequity.</p></li>
<li><p>Repeat experiments where both monkeys are given cucumbers, show no reaction.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#lex2022noam"><span class="std std-ref">(Lex 2022)</span></a> fairness lead to self-destructive behaviour for retribution in the game of diplomacy.</p></li>
<li><p><a class="reference internal" href="#brown2022human"><span class="std std-ref">(Brown 2022)</span></a> shows that AI can beat humans at diplomacy.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="brown2012conditional">
<h2>brown2012conditional<a class="headerlink" href="#brown2012conditional" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Conditional likelihood maximisation: a unifying framework for information theoretic feature selection</p></li>
<li><p>Generalized model for information based feature selection methods.</p></li>
<li><p>These models generazlize to iterative maximizers of conditional likelihood.</p></li>
</ul>
</div></blockquote>
</section>
<section id="brown2018superhuman">
<h2>brown2018superhuman<a class="headerlink" href="#brown2018superhuman" title="Link to this heading"></a></h2>
<p>Superhuman AI for heads-up no-limit poker: Libratus beats top professionals</p>
<p>(Brown 2018) shows that AI can beat humans at poker.</p>
<p>Libratus: Brown was also a lead researcher on the Libratus project, which developed an AI system that was able to consistently beat human professionals at two-player no-limit Texas hold ‘em poker.</p>
<p>The research paper describing Libratus was published in the journal Science in 2017 and can be found here: <a class="reference external" href="https://www.science.org/doi/full/10.1126/science.aao1733">https://www.science.org/doi/full/10.1126/science.aao1733</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#lex2022noam"><span class="std std-ref">(Lex 2022)</span></a> interviews Noam Brown, the author of this paper.</p></li>
<li><p><a class="reference internal" href="#brown2019superhuman"><span class="std std-ref">(Brown 2019)</span></a> shows that AI can beat humans at poker.</p></li>
<li><p><a class="reference internal" href="#brown2022human"><span class="std std-ref">(Brown 2022)</span></a> shows that AI can beat humans at diplomacy.</p></li>
<li><p><a class="reference internal" href="#moravvcik2017deepstack"><span class="std std-ref">(Morvavvcik 2017)</span></a> DeepStack beats humans at heads-up no-limit Texas hold ‘em poker.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="brown2019superhuman">
<h2>brown2019superhuman<a class="headerlink" href="#brown2019superhuman" title="Link to this heading"></a></h2>
<p>Superhuman AI for multiplayer poker</p>
<p>(Brown 2019) shows that AI can beat humans at poker.</p>
<p>Brown was one of the lead researchers on the Pluribus project, which developed a new type of AI system that was able to consistently beat human professionals at six-player no-limit Texas hold ‘em poker.</p>
<p>The research paper describing Pluribus was published in the journal Science in 2019 and can be found here: <a class="reference external" href="https://www.science.org/doi/full/10.1126/science.aay2400">https://www.science.org/doi/full/10.1126/science.aay2400</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#lex2022noam"><span class="std std-ref">(Lex 2022)</span></a> interviews Noam Brown, the author of this paper.</p></li>
<li><p><a class="reference internal" href="#brown2018superhuman"><span class="std std-ref">(Brown 2018)</span></a> shows that AI can beat humans at poker.</p></li>
<li><p><a class="reference internal" href="#brown2022human"><span class="std std-ref">(Brown 2022)</span></a> shows that AI can beat humans at diplomacy.</p></li>
<li><p><a class="reference internal" href="#moravvcik2017deepstack"><span class="std std-ref">(Morvavvcik 2017)</span></a> DeepStack beats humans at heads-up no-limit Texas hold ‘em poker.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="brown2020language">
<h2>brown2020language<a class="headerlink" href="#brown2020language" title="Link to this heading"></a></h2>
<p>Language Models are Few-Shot Learners</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Scaling up language models greatly improves task-agnostic, few-shot performance</p></li>
<li><p>tasks: NLP datasets, including translation, question-answering, and cloze tasks</p></li>
<li><p>tasks with on-the-fly reasoning or domain adaptation: unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic.</p></li>
<li><p>GPT can produce convincing fake news articles that humans struggle to spot.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#dong2022survey"><span class="std std-ref">(Dong 2022)</span></a> suvery paper on ICL</p></li>
<li><p><span class="xref std std-ref">2023-02-22 - Deep Learning</span> discusses this.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="brown2022human">
<h2>brown2022human<a class="headerlink" href="#brown2022human" title="Link to this heading"></a></h2>
<p>Human-level play in the game of Diplomacy by combining language models with strategic reasoning.</p>
<p>(Brown 2022) shows that AI can beat humans at diplomacy.</p>
<p>Cicero: Brown co-created an AI system that can strategically out-negotiate humans using natural language in a popular board game called diplomacy which is a war game that emphasizes negotiation.</p>
<p>The research paper describing Pluribus was published in the journal Science in 2019 and can be found here: <a class="reference external" href="https://www.science.org/doi/10.1126/science.ade9097">https://www.science.org/doi/10.1126/science.ade9097</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#lex2022noam"><span class="std std-ref">(Lex 2022)</span></a> interviews Noam Brown, the author of this paper.</p></li>
<li><p><a class="reference internal" href="#brown2018superhuman"><span class="std std-ref">(Brown 2018)</span></a> shows that AI can beat humans at poker.</p></li>
<li><p><a class="reference internal" href="#brown2019superhuman"><span class="std std-ref">(Brown 2019)</span></a> shows that AI can beat humans at poker.</p></li>
<li><p><a class="reference internal" href="#brosnan2003monkeys"><span class="std std-ref">(Brosnan 2003)</span></a> shows monkeys reject unequal pay.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="brownlee2016gentle">
<h2>brownlee2016gentle<a class="headerlink" href="#brownlee2016gentle" title="Link to this heading"></a></h2>
<p>Gentle Introduction to the Bias-Variance Trade-Off in Machine Learning</p>
<p>(Brownlee 2016) shows “[s]upervised learning can be best understood through the lens of the bias-variance tradeoff.”</p>
<p>Available here <a class="reference external" href="https://machinelearningmastery.com/gentle-introduction-to-the-bias-variance-trade-off-in-machine-learning/">https://machinelearningmastery.com/gentle-introduction-to-the-bias-variance-trade-off-in-machine-learning/</a></p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>The goal of supervised learning is to find the best estimate function (<span class="math notranslate nohighlight">\(f\)</span>) for the output variable (<span class="math notranslate nohighlight">\(y\)</span>) given the input data (<span class="math notranslate nohighlight">\(x\)</span>) - often referred to as the target function.</p></li>
<li><p>Bias are simplfying assumtions made by the model to make the target function easier to learn.</p></li>
<li><dl class="simple">
<dt>Bias E.g.</dt><dd><ul>
<li><p>Low-bias: DT, KNN, SVM</p></li>
<li><p>High-bias: LDA, Linear/Logistic Regression</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Variance is the amount that the estiamte of the target function will change if different training data were used.</p></li>
<li><dl class="simple">
<dt>Variance E.g.</dt><dd><ul>
<li><p>Low-variance: LDA, Linear/Logistic Regression</p></li>
<li><p>High-variance: DT, KNN, SVM</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Trend (often):</dt><dd><ul>
<li><p>Linear models will have high-bias low-variance</p></li>
<li><p>Non-linear models will have low-bias high-variance</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Trade-off E.g.</dt><dd><ul>
<li><p>The KNN has low-bais high-variance, tradeoff can be changed by increasing <span class="math notranslate nohighlight">\(k\)</span> (which increases the number of neighbors that contribute t the prediction), increases the bias of the model.</p></li>
<li><p>The SVM has low-bias high-variance, increasing C parameter (influences the number of violations of the margin allowed) increases bias, but decreases variance</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>The parameterisation of ML algorithms is often a battle to balnce out bias and variance.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="#cortes1995support"><span class="std std-ref">(Cortes 1995)</span></a> for SVM.</p></li>
<li><p>See <a class="reference internal" href="#fix1989discriminatory"><span class="std std-ref">(Fix 1989)</span></a> for KNN.</p></li>
<li><p>See <a class="reference internal" href="#loh2011classification"><span class="std std-ref">(Loh 2011)</span></a> for DT.</p></li>
<li><p>See (<a class="reference internal" href="#black2017real"><span class="std std-ref">Black 2017</span></a>, <a class="reference internal" href="#black2019rapid"><span class="std std-ref">Black 2019</span></a>, <a class="reference internal" href="#boccard2013consensus"><span class="std std-ref">Boccard 2013</span></a>) that use LDA.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="brudigam2021gaussian">
<h2>brudigam2021gaussian<a class="headerlink" href="#brudigam2021gaussian" title="Link to this heading"></a></h2>
<p>Gaussian Process-based Stochastic Model Predictive Control for Overtaking in Autonomous Racing</p>
<p>(Brudigam) uses Gaussain Processes in Reinforcement Learning to design controllers for race cars to overtake.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="minutes.html#id51"><span class="std std-ref">2022-07-20 - Deep Learning</span></a> where Hayden Dyne discusses this paper.</p></li>
<li><p>See <a class="reference internal" href="#codevilla2018end"><span class="std std-ref">(Codevilla 2018)</span></a>, another racing paper, for RL drifiting controller.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="cai2020high">
<h2>cai2020high<a class="headerlink" href="#cai2020high" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>End-to-end driving via conditional imitation learning.</p></li>
<li><p>Model-free reinforcement learning - does not rely on human understanding of world and design controllers.</p></li>
<li><p>Human driver is the trajectory with is the goal, uses a professional driver playing the game with a steering wheel.</p></li>
<li><p>Model performs on different track difficulties.</p></li>
<li><p>Reward function is scaled by velocity, so faster lap times are rewarded.</p></li>
<li><p>Works for 4 different kinds of vehicles, although the truck struggles to achieve same performance as lighter ones.</p></li>
</ul>
</div></blockquote>
</section>
<section id="chase1973perception">
<h2>chase1973perception<a class="headerlink" href="#chase1973perception" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Domain expertise allows people to build meaningful schema to represent patterns.</p></li>
<li><p>Expert chess players recall 16 pieces, intermeidate 8, novice 4 when arranged in meaninful positions.</p></li>
<li><p>Recall was consistant for levels of expertise on nonsense chess boards.</p></li>
<li><p>Our mental schemas for encoding patterns break on noise (unseen data).</p></li>
</ul>
</div></blockquote>
</section>
<section id="chen2019deep">
<h2>chen2019deep<a class="headerlink" href="#chen2019deep" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Deep reasoning networks: Thinking fast and slow</p></li>
<li><p>System 1 and System 2 thinking.</p></li>
</ul>
</div></blockquote>
</section>
<section id="chen2020deep">
<h2>chen2020deep<a class="headerlink" href="#chen2020deep" title="Link to this heading"></a></h2>
<p>A deep learning method for bearing fault diagnosis based on cyclic spectral coherence and convolutional neural networks</p>
<p>(Chen 2022) propose a Cyclic Spectral Coherence (CsCoh) + Convolutional Neural Networks (CNNs) for rolling element fault diagnosis.</p>
<dl class="simple">
<dt>Data:</dt><dd><ul class="simple">
<li><p>The domain is rolling element fault diagnosis - i.e. ball bearings in a factory setting.</p></li>
<li><p>A rotating bearing will modulate (go up and down) in ptich in a non-periodic manner, this is a telltale sign of a faulty ball bearing.</p></li>
</ul>
</dd>
<dt>Method:</dt><dd><ul class="simple">
<li><p>Combine CsCoh + CNNs for fault diagnosis of rotating elements in a factory.</p></li>
<li><p>Cyclic Speherical Coherence (CsCoh) is used to preprocess virbation signals, estimated by the fourier transform of Cyclic ACF (see paper for derivation).</p></li>
<li><p>Group Normalization (GN) is developed to reduce the internal covariant shift by data distribution discrepency, extends applications of the algorithm to real industrial environments.</p></li>
</ul>
</dd>
<dt>Results:</dt><dd><ul class="simple">
<li><p>Their proposed method improves classification performance, &gt;95% accuracy needed for use in real-world.</p></li>
<li><p>CsCoh proivde superior dsciminate feature representations for bearing health statuses under varying conditions.</p></li>
<li><p>Group Normalization increases robustness for data from differenet domains (with different data distributions).</p></li>
</ul>
</dd>
<dt>Why it matters?</dt><dd><ul class="simple">
<li><p>Garbage-in-garbage out - Preprocessing can dramatically improve the performance of a CNN.</p></li>
<li><p>Group Normalization makes the method robust, and applicable to out-of-distribution data from unseen domains.</p></li>
<li><p>Detecting faults in ball bearings is crucial for safety, automation, and efficiency in factories.</p></li>
</ul>
</dd>
<dt>Related :</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="minutes.html#id94"><span class="std std-ref">2022-10-12 - Deep Learning</span></a> for more.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="chen2019looks">
<h2>chen2019looks<a class="headerlink" href="#chen2019looks" title="Link to this heading"></a></h2>
<p>This looks like that: deep learning for interpretable image recognition</p>
<p>(Chen 2019) forces a deep neural network to use a reasoning process in a human-understandable way.</p>
<dl class="simple">
<dt>Method:</dt><dd><ul class="simple">
<li><p>(Chen 2019) forces a deep neural network to use a reasoning process in a human-understandable way.</p></li>
<li><p>But while the model’s predictions can be explained easily to humans, the parameters of that model remain black-box, an utter mystery.</p></li>
<li><p>Add a prototype layer to neural networks to for interpretable models for black-box nets.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="chen2021evaluating">
<h2>chen2021evaluating<a class="headerlink" href="#chen2021evaluating" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>70% accuracy for basic DSA problems.</p></li>
<li><p>Can’t solve more difficult problems - doesn’t optimize solutions for performance.</p></li>
<li><p>CoPilot outperforms other state-of-the-art NLP code generation models.</p></li>
<li><p>Requires “fine-tuning”, supervised human intervention to hint towards correct answer.</p></li>
</ul>
</div></blockquote>
</section>
<section id="chen2022deep">
<h2>chen2022deep<a class="headerlink" href="#chen2022deep" title="Link to this heading"></a></h2>
<p>A deep reinforcement learning framework based on an attention mechanism and disjunctive graph embedding for the job-shop scheduling problem</p>
<p>(Chen 2022) propose Disjunctive Graph Embedded Recurrent Decoding Transformer (DGERD).</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/1301.3781">https://arxiv.org/abs/1301.3781</a></p>
<dl class="simple">
<dt>Task:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>Job shop scheduling:</dt><dd><ul>
<li><p>Job shop sechduling refers to the allocation of resrouces, such as machines and operators, subject to certrain constraints.</p></li>
<li><p>It  inovles determing order and timing of a set of jobs to be processed.</p></li>
<li><p>Goal of optimizing one (or more) objective(s), such as minimizing completion time, minimzing delays, or maximizing resource utilization.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Limitations:</dt><dd><ul class="simple">
<li><p>Human designed heuristics rely on domain exerptise, and are often sub-optimal. They are static, and cannot adapt to changing conditions.</p></li>
<li><p>Traditional deep reinforcement learning (DRL) have fixed input size, and fixed parameterization (architecture) that do not generalize well to other problems.</p></li>
</ul>
</dd>
<dt>Method:</dt><dd><ul class="simple">
<li><p>The job shop scheduling problem can be represneted as a disjunctive graph <a class="reference internal" href="#balas1969machine"><span class="std std-ref">(Balas 1969)</span></a>.</p></li>
<li><p>Routing problems can be solved with attention-based representations <a class="reference internal" href="#kool2018attention"><span class="std std-ref">(Kool 2018)</span></a>.</p></li>
<li><p>Node2vec <a class="reference internal" href="#grover2016node2vec"><span class="std std-ref">(Grover 2016)</span></a> is a technique for learning low-dimensional representations of nodes in a graph.</p></li>
<li><p>Word2vec <a class="reference internal" href="#mikolov2013efficient"><span class="std std-ref">(Mikolov 2013)</span></a> is a technique for learning low-dimensional representations of words in a corpus.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>Presented at <a class="reference internal" href="minutes.html#id149"><span class="std std-ref">2023-10-06 - ECRG</span></a></p></li>
<li><p>node2vec <a class="reference internal" href="#grover2016node2vec"><span class="std std-ref">(Grover 2016)</span></a></p></li>
<li><p>Attention for routing problems <a class="reference internal" href="#kool2018attention"><span class="std std-ref">(Kool 2018)</span></a></p></li>
<li><p>Disjunctive graphs <a class="reference internal" href="#balas1969machine"><span class="std std-ref">(Balas 1969)</span></a></p></li>
<li><p>Attention mechanisms <a class="reference internal" href="#vaswani2017attention"><span class="std std-ref">(Vaswani 2017)</span></a></p></li>
<li><p>Word2vec <a class="reference internal" href="#mikolov2013efficient"><span class="std std-ref">(Mikolov 2013)</span></a></p></li>
</ul>
</dd>
<dt>Results:</dt><dd><ul class="simple">
<li><p>Performs worse than state-of-the-art methods for smaller problems.</p></li>
<li><p>Outperforms state-of-the-art methods on on larger problems.</p></li>
<li><p>Requires re-training for each new problem.</p></li>
<li><p>GP approaches are competitive with DRL approaches.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="chevalier2018babyai">
<h2>chevalier2018babyai<a class="headerlink" href="#chevalier2018babyai" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Babyai: A platform to study the sample efficiency of grounded language learning</p></li>
</ul>
</div></blockquote>
</section>
<section id="codevilla2018end">
<h2>codevilla2018end<a class="headerlink" href="#codevilla2018end" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>High-speed autonomous drifting with deep reinforcement learning.</p></li>
<li><p>Far easier to use real-world data on driving that has already been collected than generate simulation data.</p></li>
<li><p>Data augmentation used to help network generalize to new scenarios and edge cases not in the training data.</p></li>
</ul>
</div></blockquote>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="#brudigam2021gaussian"><span class="std std-ref">(Brudigam 2021)</span></a>, another racing paper, for RL overtaking controller.</p></li>
<li><p>See <a class="reference internal" href="minutes.html#id51"><span class="std std-ref">2022-07-20 - Deep Learning</span></a> where Hayden Dyne discusses this paper.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="cortes1995support">
<h2>cortes1995support<a class="headerlink" href="#cortes1995support" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Cortes and Vapnik proposed the Support Vector Machine (SVM).</p></li>
<li><p>This model creates a hyperplane that can draw distinct class boundaries between classes.</p></li>
<li><p>We call these class boundaries the support vectors.</p></li>
<li><p>We are performing multi-class classification, so it used a one-vs-all approach cite{sklearn2021feature}.</p></li>
<li><p>This creates a divide between one class and the rest, then repeats for the other classes.</p></li>
</ul>
</div></blockquote>
</section>
<section id="couillet2022submerged">
<h2>couillet2022submerged<a class="headerlink" href="#couillet2022submerged" title="Link to this heading"></a></h2>
<p>The submerged part of the AI-Ceberg [Perspectives]</p>
<p>(Couillet 2022) provide a critize of AI based on its sustainability and environmental impacts on the planet.</p>
<p>TODO [ ] Read this paper.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="minutes.html#id106"><span class="std std-ref">2022-11-09 - Deep Learning</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="crall2013hotspotter">
<h2>crall2013hotspotter<a class="headerlink" href="#crall2013hotspotter" title="Link to this heading"></a></h2>
<p>HotSpotter — Patterned species instance recognition</p>
<p><a href="#id3"><span class="problematic" id="id4">`(Crall 2013)&lt;https://ieeexplore.ieee.org/abstract/document/6475023&gt;`__</span></a> is an instance recognition computer vision paper.</p>
<dl class="simple">
<dt>Purpose:</dt><dd><p>HotSpotter a model to recognize instances based on their unique spots.</p>
</dd>
<dt>Dataset:</dt><dd><ul class="simple">
<li><p>This is a species invariant model, that differentiates between dissimilar species, e.g. zebras, giraffes, leopards, and lionfish. Fish and mammals are dissimilar but share spots.</p></li>
</ul>
</dd>
<dt>Method:</dt><dd><ul class="simple">
<li><p>Local Naive Bayes Nearest Neighbours (:BNN)</p></li>
</ul>
</dd>
<dt>Limitations:</dt><dd><ul class="simple">
<li><p>relatively dated paper, 2012 paper cite{mccann2012local} that proposed acrfull{LNBNN},</p></li>
<li><p>an extension of acrfull{NBNN} cite{behmo2010towards}.</p></li>
<li><p>where “only the classes represented in the local neighborhood of a descriptor contribute significantly and reliabl to their posterior probability estimates”.</p></li>
<li><p>The authors admit {LNBNN, did not beat state-of-the-art methods such as feature pyramid networks <a class="reference internal" href="#lin2017feature"><span class="std std-ref">(Lin 2017)</span></a>, which rely on local soft assignment and max pooling operators. Convolutions and max-pooling are utilized in CNNs cite{lecun1989backpropagation}, a powerful model for computer vision-related tasks. Which with advancements in hardware, and the lifting of the AI winter, are efficient to train at scale using GPUs. Since then, a a plethor of CNN-based architectures dominate computer-vision tasks:</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>While images are far from rapid mass spectrometry data, this research aims to perform a similar task, by providing a species-invariant model that differentiates between dissimilar species of fish, e.g. whitefish and oily fish, based on their unique chemical compositions.</p></li>
<li><p>See <a class="reference internal" href="#lecun1989backpropagation"><span class="std std-ref">(Lecun 1989)</span></a> for original CNN paper.</p></li>
<li><p>Local Naive Bayes Nearest Neighrbour (LNBNN) <a class="reference internal" href="#behmo2010towards"><span class="std std-ref">(Behmo 2010)</span></a></p></li>
<li><p>Naive Bayes Nearest Neighbour (NBNN) <a class="reference internal" href="#mccann2012local"><span class="std std-ref">(McCann 2012)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="craik1972levels">
<h2>craik1972levels<a class="headerlink" href="#craik1972levels" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Levels of processing: A framework for memory research.</p></li>
<li><p>Elaborative rehearsal requires deeper processing than maintainence rehearsal.</p></li>
</ul>
</div></blockquote>
</section>
<section id="craik1975depth">
<h2>craik1975depth<a class="headerlink" href="#craik1975depth" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Deeper processing, semantic over structural or phonetic, better.</p></li>
<li><p>Depth processing increased later recognition of words in a list.</p></li>
<li><p>Annecodte, study: skim-read vs. thoughtful reading.</p></li>
</ul>
</div></blockquote>
</section>
<section id="da2018evolutionary">
<h2>da2018evolutionary<a class="headerlink" href="#da2018evolutionary" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Evolutionary Computation Approaches to Web Service Composition.</p></li>
<li><p>Service composition is an NP-hard combinatorial problem - local search via heuristic is needed.</p></li>
<li><p>Optimizes fitness as multi-objective function of correctness and exectution time.</p></li>
<li><p>Graph building algorithm that uses evolutionary techniques, mutation and crossover.</p></li>
<li><p>Don’t reinvet the wheel, encourage reuse of existing services.</p></li>
</ul>
</div></blockquote>
</section>
<section id="dawkins1995evolved">
<h2>dawkins1995evolved<a class="headerlink" href="#dawkins1995evolved" title="Link to this heading"></a></h2>
<p>The Evolved Imagination: Animals as models of their world</p>
<p>(Dawkins 1995) proposed animals are models of their world.</p>
<p>Available <a class="reference external" href="https://richarddawkins.net/1995/09/the-evolved-imagination-animals-as-models-of-their-world-2/">https://richarddawkins.net/1995/09/the-evolved-imagination-animals-as-models-of-their-world-2/</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See Wolfgang’s talk at 2022-10-28 - ECRG , GP as a model of a discrete fitness landscape.</p></li>
<li><p>See 12:18 from “Psychedlics, Consciosness, and AI | Richard Dawkins | #256” <a class="reference external" href="https://youtu.be/HbGoUwmqIEQ?t=738">https://youtu.be/HbGoUwmqIEQ?t=738</a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="devlin2018bert">
<h2>devlin2018bert<a class="headerlink" href="#devlin2018bert" title="Link to this heading"></a></h2>
<p>Bert: Pre-training of deep bidirectional transformers for language understanding</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/1810.04805">https://arxiv.org/abs/1810.04805</a></p>
<p>BERT is a bidrectionanal transformer model proposed by google.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><span class="xref std std-ref">2023-02-22 - Deep Learning</span> discussed here.</p></li>
<li><p><a class="reference internal" href="#vaswani2017attention"><span class="std std-ref">(Vaswani 2017)</span></a> attention paper</p></li>
</ul>
</dd>
</dl>
</section>
<section id="di2019survey">
<h2>di2019survey<a class="headerlink" href="#di2019survey" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>A survey on gans for anomaly detection</p></li>
<li><p>Generative Adversarial Networks (GANs) can be used for anomoly detection.</p></li>
<li><p>We build an latent representation of the expected data from nominal samples.</p></li>
<li><p>Then measure the reconstruction error between the latent representation and the anomoly.</p></li>
<li><p>If the reconstruction error is unusually high, then the anomoly is detected.</p></li>
<li><p>If the reconstruction error is low, then it is likely a nominal sample.</p></li>
<li><p>Compute the error between the model’s original input and output. The sample represents an anomoly if the error exceeds a predefined threshold (Bnomial 2022).</p></li>
<li><p>Medium article <a class="reference external" href="https://medium.com/analytics-vidhya/anomaly-detection-using-generative-adversarial-networks-gan-ca433f2ac287">https://medium.com/analytics-vidhya/anomaly-detection-using-generative-adversarial-networks-gan-ca433f2ac287</a></p></li>
<li><p>TODO [ ] - READ</p></li>
</ul>
</div></blockquote>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#goodfellow2014generative"><span class="std std-ref">(Goodfellow 2014)</span></a> proposed Generative Adversarial Networks (GANs).</p></li>
<li><p>See (Goodfellow 2016) Chapter 20, pg. 690, 20.10.4 Generative Adversarial Networks <a class="reference external" href="https://www.deeplearningbook.org/contents/generative_models.html">https://www.deeplearningbook.org/contents/generative_models.html</a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="ding2005minimum">
<h2>ding2005minimum<a class="headerlink" href="#ding2005minimum" title="Link to this heading"></a></h2>
<p>Minimum Redudancy Featyre Selection from MicroArray Gene Expression Data.</p>
<p>(Ding 2005) is the original Minimum Redundancy - Maximum Relevance (MRMR) paper.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="#zhao2019maximum"><span class="std std-ref">(Zhao 2019)</span></a> for more recent Uber paper.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="do2008expectation">
<h2>do2008expectation<a class="headerlink" href="#do2008expectation" title="Link to this heading"></a></h2>
<p>What is the expectation maximization algorithm?</p>
<p>(Do 2008) is a nature paper that explains the EM algorithm.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See 2023-02-03 - ECRG where Jiabin uses EM.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="domingos2015master">
<h2>domingos2015master<a class="headerlink" href="#domingos2015master" title="Link to this heading"></a></h2>
<p>The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World</p>
<p>(Domingos 2015) gives a broad introduction for beginners to Artificial Intelligence.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="minutes.html#id125"><span class="std std-ref">2023-02-02 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="dong2022survey">
<h2>dong2022survey<a class="headerlink" href="#dong2022survey" title="Link to this heading"></a></h2>
<p>A survey for in-context learning</p>
<p>Available: <a class="reference external" href="https://arxiv.org/pdf/2301.00234.pdf">https://arxiv.org/pdf/2301.00234.pdf</a></p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Mechanisms for in-context learning (ICL) are unclear</p></li>
<li><p>Paradigm for training-free learning.</p></li>
<li><p>In-context, learn a new task when presented with a demonstration, without any further optimiztion.</p></li>
<li><p>Few-shot ICL is possible with a large enough corpus of text and sufficient model complexity.</p></li>
<li><p>ICL is where a language model can learn a task from a few examples without any further fine-tuning.</p></li>
<li><p>Tasks are often specified in the text, e.g. a textbook may contain word problems with answers.</p></li>
<li><p>A task-specific language model can be conditioned to perform a certain task, for example answering word problems.</p></li>
<li><p>Arbitrary tasks could be learnt by scaling up models and training on a very large corpus - more data and parameters improves task-agnostic performance.</p></li>
<li><p>While the mechanisms of in context-learning <cite>(Dong 2022) &lt;dong2022survey&gt;</cite> are a mystery, <a class="reference internal" href="#brown2020language"><span class="std std-ref">(Brown 2020)</span></a> shows that scaling up language models improves task-agnostic few-shot performance.</p></li>
<li><p>ICL is an “emergent property” of LLMs (airquotes as term is controversial)</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>OpenAI GPT-3</p></li>
<li><p><a class="reference internal" href="#brown2020language"><span class="std std-ref">(Brown 2020)</span></a> LLMs are few shot learners papers</p></li>
</ul>
</dd>
</dl>
</section>
<section id="ecoffet2021first">
<h2>ecoffet2021first<a class="headerlink" href="#ecoffet2021first" title="Link to this heading"></a></h2>
<p>First return, then explore</p>
<p>(Ecoffet 2021) propose an RL agent that remembers promising states and returning to such states before intentionally exploring.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See 2022-12-05 - AJCAI #01</p></li>
</ul>
</dd>
</dl>
</section>
<section id="eder1995gas">
<h2>eder1995gas<a class="headerlink" href="#eder1995gas" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Gas chromatography (GC) is a method that can identify chemicial structures in these fish oils.</p></li>
<li><p>This produces high-dimensional low sample size data from the fish oils.</p></li>
<li><p>Chemists compare a given sample to a reference sample to determine what chemicals are present.</p></li>
<li><p>The existing analytical techniques to perform these tasks are time-consuming and laborious.</p></li>
</ul>
</div></blockquote>
</section>
<section id="eiben2015evolutionary">
<h2>eiben2015evolutionary<a class="headerlink" href="#eiben2015evolutionary" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>From evolutionary computation to the evolution of things - Nature review article.</p></li>
<li><dl class="simple">
<dt>X-band antenneas for NASA Space Technology 5 (ST5) spacecraft</dt><dd><ul>
<li><p>Evolutionary-algorithm based aaporach discovered effective antennea esigns.</p></li>
<li><p>Also could adjust designs quckly when requirements changed .</p></li>
<li><p>One of these antennas was deployed, the first computer evolved hardware in space.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>EC has an advantage over manual design.</p></li>
<li><p>Similar to model-free in reinforcement learning (Cai 2020 - cai2020high, Codevilla 2018 - codevilla2018end)</p></li>
<li><dl class="simple">
<dt>State-of-the-art protein structure prediction</dt><dd><ul>
<li><p>Design an algorithm do develop complex energy functions with genetic programming.</p></li>
<li><p>EC great at exploring intractibly large combinatorial search spaces with high evaluation cost.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>EC have seperation of concerns, phenotype seperate from fitness, good modularity.</p></li>
<li><p>EC makes no implicit assumptions about the problem.</p></li>
<li><dl class="simple">
<dt>Trends</dt><dd><ul>
<li><p>Automated design and tuning of evolutionary algorithms.</p></li>
<li><p>Using surrogate models.</p></li>
<li><p>Handiling many objectives</p></li>
<li><p>Generative and developmental representations.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Crazy futurist ideas for this field, evolutionary factories, artificial bio-silica life, etc…</p></li>
</ul>
</div></blockquote>
</section>
<section id="eich1975state">
<h2>eich1975state<a class="headerlink" href="#eich1975state" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>State-dependent accessibility of retrieval cues in retneion of categorized list.</p></li>
<li><p>Subjects are asked to recall a list of words with and without the influence of marajuana.</p></li>
<li><p>Subjects who learn something high, are more likely to retrieve that information high.</p></li>
<li><p>People can not recall their drug-induced experience easily when they sober up.</p></li>
</ul>
</div></blockquote>
</section>
<section id="emrah2022imbalance">
<h2>emrah2022imbalance<a class="headerlink" href="#emrah2022imbalance" title="Link to this heading"></a></h2>
<p>An imbalance-aware nuclei segmentation methodology for H&amp;E stained histopathology images</p>
<p>(Emrah 2022) proposes a novel nuclei segmentation method for cancer diagnosis in histopathology images.</p>
<p>Available: <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S1746809423001532">https://www.sciencedirect.com/science/article/pii/S1746809423001532</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Author discussed in FASLIP at <a class="reference internal" href="minutes.html#id161"><span class="std std-ref">2023-11-30 FASLIP</span></a></p></li>
<li><p>Nuclei segmentation dataset <a class="reference internal" href="#kumar2019multi"><span class="std std-ref">(Kumar 2019)</span></a>’</p></li>
<li><p>Dice pixel classification layer <a class="reference internal" href="#shaukat2022state"><span class="std std-ref">(Shaukat 2022)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="espeholt2022deep">
<h2>espeholt2022deep<a class="headerlink" href="#espeholt2022deep" title="Link to this heading"></a></h2>
<p>Deep learning for twelve hour precipitation forecasts</p>
<p>(Espeholt 2022) prepose MetNet-2 that can outperform SOTA for 12 hour precipitation forecasts.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>TODO read</p></li>
</ul>
</dd>
</dl>
</section>
<section id="eyesenck1980effects">
<h2>eyesenck1980effects<a class="headerlink" href="#eyesenck1980effects" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Effects of processing depth, distinctiveness, and word frequency on retention.</p></li>
<li><p>In general distinct stimuli are better remembered than non-distinct ones.</p></li>
<li><p>We are more likely to remember things that are out of the blue, or that have a personal connection to us.</p></li>
</ul>
</div></blockquote>
</section>
<section id="fawzi2022discovering">
<h2>fawzi2022discovering<a class="headerlink" href="#fawzi2022discovering" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Discovering faster matrix multiplication algorithms with reinforcement learning</p></li>
<li><p>Deep Mind - AlphaTensor</p></li>
<li><p>Improves Strassman’s algorithm for 4x4 matrix multiplication for first time in 50 years.</p></li>
<li><p>Matrix multiplication is the bedrock of deep learning.</p></li>
<li><p>Fast matrix multplication can lead to exponential speedups in deep learning.</p></li>
<li><p>TODO [ ] - Read this paper</p></li>
</ul>
</div></blockquote>
</section>
<section id="fahy2009update">
<h2>fahy2009update<a class="headerlink" href="#fahy2009update" title="Link to this heading"></a></h2>
<p>Update of the LIPID MAPS comprehensive classification system for lipids1</p>
<dl class="simple">
<dt>Def. lipidomics</dt><dd><p>Lipidomics is the study of reaction pathways involved in lipid metabolism within biological systems. The lipidome consists of the lipid profile of a particular sample such as cell, tissue or organism, which can be integrated as a metabolome sub-set</p>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See Propsoal, lipidomics definition used in glossary.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="fix1989discriminatory">
<h2>fix1989discriminatory<a class="headerlink" href="#fix1989discriminatory" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>K-nearest neighbours (KNN).</p></li>
</ul>
</div></blockquote>
</section>
<section id="fukushima1982neocognitron">
<h2>fukushima1982neocognitron<a class="headerlink" href="#fukushima1982neocognitron" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Rectified Linear Unit (ReLu) paper.</p></li>
<li><p>Activation function for neural networks.</p></li>
<li><p>Shares nice properties of linear function. chen2019looks</p></li>
<li><p>But allows for non-linearities to be captured.</p></li>
</ul>
</div></blockquote>
</section>
<section id="galanakis2019saving">
<h2>galanakis2019saving<a class="headerlink" href="#galanakis2019saving" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Saving Food, 2019, has a chapter on Fish Waste.</p></li>
<li><p>60% of treated fish biomass is discarded as waste.</p></li>
<li><p>This can be repuprosed as fish oil (e.g. Omega 3), or fish meal (e.g. animal feed).</p></li>
<li><p>Their are a range of other products, such as Geltain, Petpitides, Proteins.</p></li>
<li><p>Sustainable fish processing would repurpose the fish waste.</p></li>
</ul>
</div></blockquote>
</section>
<section id="garnelo2018conditional">
<h2>garnelo2018conditional<a class="headerlink" href="#garnelo2018conditional" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Conditional Neural Processes.</p></li>
<li><p>Combine Bayesian optimizationa and Neural Networks.</p></li>
<li><p>Use Gaussian Processes (GP) to approximate functions within reasonable confidence.</p></li>
<li><p>Neural network, encoder-decoder GAN-like architecture to perform ML tasks.</p></li>
</ul>
</div></blockquote>
</section>
<section id="gencoglu2019hark">
<h2>gencoglu2019hark<a class="headerlink" href="#gencoglu2019hark" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>HARK Side of Deep Learning–From Grad Student Descent to Automated Machine Learning</p></li>
<li><p>Grad Student Descent</p></li>
<li><p><strong>TODO</strong> read this!</p></li>
</ul>
</div></blockquote>
</section>
<section id="glorot2010understanding">
<h2>glorot2010understanding<a class="headerlink" href="#glorot2010understanding" title="Link to this heading"></a></h2>
<p>Understanding the difficulty of training deep feedforward neural networks</p>
<p>(Glorot 2010) is the original paper on Xavier initialization.</p>
<p>Available: <a class="reference external" href="http://proceedings.mlr.press/v9/glorot10a">http://proceedings.mlr.press/v9/glorot10a</a></p>
<dl class="simple">
<dt>Related: it pu</dt><dd><ul class="simple">
<li><p>Pytorch: <a class="reference external" href="https://pytorch.org/cppdocs/api/function_namespacetorch_1_1nn_1_1init_1ace282f75916a862c9678343dfd4d5ffe.html">https://pytorch.org/cppdocs/api/function_namespacetorch_1_1nn_1_1init_1ace282f75916a862c9678343dfd4d5ffe.html</a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="girshick2014rich">
<h2>girshick2014rich<a class="headerlink" href="#girshick2014rich" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Rich feature hierarchies for accurate object detection and semantic segmentation</p></li>
<li><p>R-CNNs, Region-based Convolutional Neural Networks.</p></li>
<li><p>Combine region proposals and CNNs.</p></li>
<li><p>See <span class="xref std std-ref">2022-10-06 - FASLIP</span> for more details.</p></li>
</ul>
</div></blockquote>
</section>
<section id="godden1975context">
<h2>godden1975context<a class="headerlink" href="#godden1975context" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Context-dependent memory in two natural environments: On land and underwater.</p></li>
<li><p>Scuba divers who learn lists of words underwater, best recalled them underwater.</p></li>
<li><p>Same true for words learnt on land.</p></li>
<li><p>Recall accuracy depends on similarity of context in sensory information.</p></li>
</ul>
</div></blockquote>
</section>
<section id="gomes2020ensemble">
<h2>gomes2020ensemble<a class="headerlink" href="#gomes2020ensemble" title="Link to this heading"></a></h2>
<p>On ensemble techniques for data stream regression</p>
<p>(Gomes 2020) talks about ADR-Reg in data stream mining</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See (<a class="reference internal" href="#mouss2004test"><span class="std std-ref">Mouss 2004</span></a>) for Page-Hinkley method for drift detection.</p></li>
<li><p>See (<a class="reference internal" href="#bifet2007learning"><span class="std std-ref">Bifet 2007</span></a>) for ADWIN drift detection algorithm.</p></li>
<li><p>See <a class="reference internal" href="minutes.html#id131"><span class="std std-ref">2023-02-16 - FASLIP</span></a> where ADR-Reg is mentioned.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="gonick2012cartoon">
<h2>gonick2012cartoon<a class="headerlink" href="#gonick2012cartoon" title="Link to this heading"></a></h2>
<p>The cartoon guide to calculus</p>
<p>(Gonick 2012) is a great book for learning calculus with heaps of pictures.</p>
<p>“Any equation that caontains derivities […] is called a differential equation.”</p>
<dl>
<dt>Notes:</dt><dd><ul class="simple">
<li><p>A differential equation is an queation that contains a derivite.</p></li>
<li><p>Examples of differential equations include Newton’s second law, hookes law (or the spring equation).</p></li>
<li><p>Newton’s second law states that a froce is equal to the mass of an object multiplied by its acceleration, <span class="math notranslate nohighlight">\(F = ma\)</span></p></li>
<li><p>We can express accelaration as the first-order derivite of velocity <span class="math notranslate nohighlight">\(\frac{d}{dt}(v)\)</span>.</p></li>
<li><p>Therefore we can give Newton’s second as, <span class="math notranslate nohighlight">\(f = \frac{d}{dt}(mv)\)</span>.</p></li>
<li><p>This is an example of a differential equation (DE).</p></li>
<li><p>Hookes law, which can be derived from newtons first law (describing inertia) can be given as,</p></li>
</ul>
<p><span class="math notranslate nohighlight">\(x''(t)=\frac{k}{m} x(t)\)</span>
or
<span class="math notranslate nohighlight">\(F = kx\)</span>
* That is the second-order derivitive can be expressed as a function of itself multiplied by a constant.</p>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See 2022-10-31 - Guest Speaker</p></li>
</ul>
</dd>
</dl>
</section>
<section id="goodfellow2016deep">
<h2>goodfellow2016deep<a class="headerlink" href="#goodfellow2016deep" title="Link to this heading"></a></h2>
<p>Deep Learning</p>
<p>(Goodfellow 2016) is a textbook on deep learning.</p>
<p>Available: <a class="reference external" href="https://www.deeplearningbook.org/">https://www.deeplearningbook.org/</a></p>
</section>
<section id="goodfellow2014generative">
<h2>goodfellow2014generative<a class="headerlink" href="#goodfellow2014generative" title="Link to this heading"></a></h2>
<p>Generative adversarial networks</p>
<p>(Goodfellow 2014) is the original paper on GANs, a deep learning technique for generating new data, based of a game theoretic approach with discriminator and generator networks.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See 2022-10-26 Deep Learning</p></li>
<li><p><a class="reference internal" href="#di2019survey"><span class="std std-ref">(Di 2019)</span></a> for a survey on GANs for anomaly detection.</p></li>
<li><p>See <a class="reference internal" href="#goodfellow2016deep"><span class="std std-ref">(Goodfellow 2016)</span></a> Chapter 20, pg. 690, 20.10.4 Generative Adversarial Networks <a class="reference external" href="https://www.deeplearningbook.org/contents/generative_models.html">https://www.deeplearningbook.org/contents/generative_models.html</a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="goodman2020weighting">
<h2>goodman2020weighting<a class="headerlink" href="#goodman2020weighting" title="Link to this heading"></a></h2>
<p>Weighting NTBEA for game AI optimisation</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#volz2018evolving"><span class="std std-ref">(Volz 2018)</span></a> same author evolves mario levels using EAs on GAN latent spaces.</p></li>
<li><p><a class="reference internal" href="#perez2019analysis"><span class="std std-ref">(Perez 2019)</span></a> same author uses RHEA to design Game AI for ponnerman.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="grcic2021densly">
<h2>grcic2021densly<a class="headerlink" href="#grcic2021densly" title="Link to this heading"></a></h2>
<p>Densely connected normalizing flows</p>
<dl class="simple">
<dt>Available:</dt><dd><ul class="simple">
<li><p><a class="reference external" href="https://proceedings.neurips.cc/paper/2021/hash/c950cde9b3f83f41721788e3315a14a3-Abstract.html">https://proceedings.neurips.cc/paper/2021/hash/c950cde9b3f83f41721788e3315a14a3-Abstract.html</a></p></li>
</ul>
</dd>
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Normalizing flows are bijective mappings between input and latent representations with a fully factoritzed distribution.</p></li>
<li><p>Normalizing flows (NF) are attrictive due to exact likelihood evaluation and efficient sampling.</p></li>
<li><p>However their effective capacity is often insuffiencet since bijectivity constraints limit the model width.</p></li>
<li><p>The proposed method addresses this limitation by incrementally padding intermediate representations with noise. Precondition noise in accordance with previous invertible units, coined “cross-unit coupling”.</p></li>
<li><p>Their invertible glow0like, modules increase the expressivity by fusing a densely connected block with NYstron self-attention.</p></li>
<li><p>They refer to their proposed achitecture as DenseFlwo, since both cross-unit and intra-module couplings rely on dense connectivity.</p></li>
<li><p>Experiments show significant improvements due to prposed contributions and reveal state-of-the-art density estimation under moderate computing budgets.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="grover2016node2vec">
<h2>grover2016node2vec<a class="headerlink" href="#grover2016node2vec" title="Link to this heading"></a></h2>
<p>node2vec: Scalable Feature Learning for Networks</p>
<p>(Grover 2016) is a paper on node2vec, a method for learning low-dimensional representations of nodes in a graph.</p>
<p>Available: <a class="reference external" href="https://dl.acm.org/doi/abs/10.1145/2939672.2939754">https://dl.acm.org/doi/abs/10.1145/2939672.2939754</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Mentioned in <a class="reference internal" href="minutes.html#id149"><span class="std std-ref">2023-10-06 - ECRG</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="handa2006robust">
<h2>handa2006robust<a class="headerlink" href="#handa2006robust" title="Link to this heading"></a></h2>
<p>Robust route optimization for gritting/salting trucks: A CERCIA experience</p>
<p>(Hand 2006) use evolutionary computation for route optimization for gritting trucks.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#li2002novel"><span class="std std-ref">(Li 2002)</span></a> use evolutionary computation to solve differentiral equations for deriving physics laws.</p></li>
<li><p><a class="reference internal" href="#li2002novel"><span class="std std-ref">(Li 2002)</span></a> is another paper by same author, with EC for solving DE in materials science.</p></li>
<li><p><a class="reference internal" href="#runarsson2000stochastic"><span class="std std-ref">(Runarsson 2000)</span></a> used stocastic ranking (bubblesort variant) for constrained optimization with Evolutionary Computaiton.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="hand2001idiot">
<h2>hand2001idiot<a class="headerlink" href="#hand2001idiot" title="Link to this heading"></a></h2>
<p>Idiot’s Bayes—Not So Stupid After All?</p>
<p>(Hand 2001) is a paper that discusses the Naive Bayes classifier.</p>
<p>Available: <a class="reference external" href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1751-5823.2001.tb00465.x">https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1751-5823.2001.tb00465.x</a></p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Despite the assumption of independence, Naive Bayes is a powerful classifier.</p></li>
<li><p>Naive bayes assumption is that the features are conditionally independent given the class.</p></li>
<li><p>This assumption is not always true, but the model still performs well in practice.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="haralick1973textual">
<h2>haralick1973textual<a class="headerlink" href="#haralick1973textual" title="Link to this heading"></a></h2>
<p>Textural Features for Image Classification</p>
<p>(Haralick 1973) propose grey-level co-occurence matrix for image analysis.</p>
<p>Available: <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/4309314">https://ieeexplore.ieee.org/abstract/document/4309314</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <span class="xref std std-ref">2023-08-10 - FASLIP</span></p></li>
<li><p>Sklearn documentation and code available: <a class="reference external" href="https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_glcm.html">https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_glcm.html</a></p></li>
<li><p>Naive bayes.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="he2015delving">
<h2>he2015delving<a class="headerlink" href="#he2015delving" title="Link to this heading"></a></h2>
<p>Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</p>
<p>(He 2015) proposes Kaiming weight initialization.</p>
<p>Available: <a class="reference external" href="http://openaccess.thecvf.com/content_iccv_2015/html/He_Delving_Deep_into_ICCV_2015_paper.html">http://openaccess.thecvf.com/content_iccv_2015/html/He_Delving_Deep_into_ICCV_2015_paper.html</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Pytorch <a class="reference external" href="https://pytorch.org/cppdocs/api/function_namespacetorch_1_1nn_1_1init_1a5e807af188fc8542c487d50d81cb1aa1.html#exhale-function-namespacetorch-1-1nn-1-1init-1a5e807af188fc8542c487d50d81cb1aa1">https://pytorch.org/cppdocs/api/function_namespacetorch_1_1nn_1_1init_1a5e807af188fc8542c487d50d81cb1aa1.html#exhale-function-namespacetorch-1-1nn-1-1init-1a5e807af188fc8542c487d50d81cb1aa1</a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="he2016deep">
<h2>he2016deep<a class="headerlink" href="#he2016deep" title="Link to this heading"></a></h2>
<p>Deep residual learning for image recognition</p>
<p>(He 2016) is the original paper on ResNet.</p>
<p>Available: <a class="reference external" href="http://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html">http://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html</a></p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>A residual neural network (He 2016) is a deep learning model in which the weight layers learn redidual functions with reference to the layer inputs.</p></li>
<li><p>Defn. a network with skip connectionts that perform identity mappings, merged with layer outputs by addition.</p></li>
<li><p>(He 2016) proposed ResNet for imace Recognition, the original Resnet paper that won the ILSVRC 2015 classification task. Residual neurons, or skip connetions between layers.</p></li>
<li><p>Skip connections provide shortcuts for information flow between layers of a nerual network. Skip connections allow a network to better propogage information between layers, which inproves performance overall. * A residual neural network (He 2016) is a deep learning model in which the weight layers learn redidual functions with reference to the layer inputs.</p></li>
<li><p>Defn. a network with skip connectionts that perform identity mappings, merged with layer outputs by addition.</p></li>
<li><p>(He 2016) proposed ResNet for imace Recognition, the original Resnet paper that won the ILSVRC 2015 classification task. Residual neurons, or skip connetions between layers.</p></li>
<li><p>Skip connections provide shortcuts for information flow between layers of a nerual network. Skip connections allow a network to better propogage information between layers, which inproves performance overall.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>Dicussed in <a class="reference internal" href="minutes.html#id138"><span class="std std-ref">2023-05-25 - FASLIP</span></a></p></li>
<li><p>See <a class="reference internal" href="#lecun1989backpropagation"><span class="std std-ref">(Lecun 1989)</span></a> for LeNet.</p></li>
<li><p>See <a class="reference internal" href="#krizhevsky2012imagenet"><span class="std std-ref">(Krizhevsky 2012)</span></a> for AlexNet.</p></li>
<li><p>See <a class="reference internal" href="#simonyan2014very"><span class="std std-ref">(Simonyan 2014)</span></a> for VGGNet.</p></li>
<li><p>See <a class="reference internal" href="#szegedy2015going"><span class="std std-ref">(Szegedy 2015)</span></a> for GoogLeNet.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="he2020bayesian">
<h2>he2020bayesian<a class="headerlink" href="#he2020bayesian" title="Link to this heading"></a></h2>
<p>Bayesian Deep Ensembles via the Neural Tangent Kernel</p>
<dl class="simple">
<dt>TODO:</dt><dd><ul class="simple">
<li><p>read <a class="reference external" href="https://proceedings.neurips.cc/paper/2020/hash/0b1ec366924b26fc98fa7b71a9c249cf-Abstract.html">https://proceedings.neurips.cc/paper/2020/hash/0b1ec366924b26fc98fa7b71a9c249cf-Abstract.html</a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="he2020momentum">
<h2>he2020momentum<a class="headerlink" href="#he2020momentum" title="Link to this heading"></a></h2>
<p>Momentum contrast for unsupervised visual representation learning</p>
<p>Available: <a class="reference external" href="https://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html">https://openaccess.thecvf.com/content_CVPR_2020/html/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.html</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Mentioned in <a class="reference internal" href="minutes.html#id191"><span class="std std-ref">2024-04-18 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="hengzhe2021evolutionary">
<h2>hengzhe2021evolutionary<a class="headerlink" href="#hengzhe2021evolutionary" title="Link to this heading"></a></h2>
<p>An Evolutionary Forest for regression</p>
<p>(Hengzhe 2021) is a TVEC paper for Evolutionary Forest.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="minutes.html#id125"><span class="std std-ref">2023-02-02 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="hendrycks2016gaussian">
<h2>hendrycks2016gaussian<a class="headerlink" href="#hendrycks2016gaussian" title="Link to this heading"></a></h2>
<p>Gaussian error linear units (gelus)</p>
<p>(Hendrycks 2016) is the original paper on Gaussian error linear units (GELUs).</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/1606.08415">https://arxiv.org/abs/1606.08415</a></p>
<p><span class="math notranslate nohighlight">\(GELU(x) = 0.5 * x * (1 + Tanh(\sqrt{2/\pi} * (x + 0.044715 * x^3)))\)</span></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>pytorch <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.GELU.html">https://pytorch.org/docs/stable/generated/torch.nn.GELU.html</a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="hildebrandt2010towards">
<h2>hildebrandt2010towards<a class="headerlink" href="#hildebrandt2010towards" title="Link to this heading"></a></h2>
<p>Towards improved dispatching rules for complex shop floor scenarios: a genetic programming approach</p>
<p>(Hildebrandt 2010) use genetic programming for dispatching rules in complex shop floor scenarios.</p>
<p>Available: <a class="reference external" href="https://dl.acm.org/doi/abs/10.1145/1830483.1830530">https://dl.acm.org/doi/abs/10.1145/1830483.1830530</a></p>
</section>
<section id="hinton2012improving">
<h2>hinton2012improving<a class="headerlink" href="#hinton2012improving" title="Link to this heading"></a></h2>
<p>Improving neural networks by preventing co-adaptation of feature detector</p>
<p>Available <a class="reference external" href="https://arxiv.org/abs/1207.0580">https://arxiv.org/abs/1207.0580</a></p>
<dl class="simple">
<dt>Notes:</dt><dd><p>“This “overfitting” is greatly reduced by randomly omitting half of the feature detectors on each training case” - abstract</p>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>Dropout paper <a class="reference internal" href="#srivastava2014dropout"><span class="std std-ref">(Srivastava 2014)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="ho1995random">
<h2>ho1995random<a class="headerlink" href="#ho1995random" title="Link to this heading"></a></h2>
<p>Random decision forests</p>
<p>(Ho 1995) is the original paper on random forests.</p>
<p>Available: <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/598994/">https://ieeexplore.ieee.org/abstract/document/598994/</a></p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Random forest.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="ho2020denoising">
<h2>ho2020denoising<a class="headerlink" href="#ho2020denoising" title="Link to this heading"></a></h2>
<p>Denoising diffusion probabilistic models</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#song2020denoising"><span class="std std-ref">(Song 2020)</span></a> proposed DDIM, a generalized DDPM that is faster.</p></li>
<li><p>Stable Diffusion <a class="reference external" href="https://github.com/CompVis/stable-diffusion">https://github.com/CompVis/stable-diffusion</a></p></li>
<li><p>Deforum Notebook <a class="reference external" href="https://t.co/mWNkzWtPsK">https://t.co/mWNkzWtPsK</a></p></li>
<li><p>See <a class="reference internal" href="minutes.html#id134"><span class="std std-ref">2023-05-03 - Deep Learning</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="hof2016industrial">
<h2>hof2016industrial<a class="headerlink" href="#hof2016industrial" title="Link to this heading"></a></h2>
<p>The industrial melanism mutation in British peppered moths is a transposable element</p>
<p>(Hof 2016) moth that changes colour of its wings due to transposons.</p>
<ul class="simple">
<li><p>TODO [ ] Read this paper.</p></li>
<li><p>Nature article</p></li>
</ul>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Julie ECRG - 2022-10-14 mentioned this.</p></li>
<li><p><a class="reference internal" href="#bourque2018ten"><span class="std std-ref">(Bourque 2018)</span></a> explains transposons in detail.</p></li>
<li><p><a class="reference internal" href="#kulasekara2014transposon"><span class="std std-ref">(Kulasekara 2014)</span></a> says changes passed to offspring.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="hofstadter1979godel">
<h2>Hofstadter1979godel<a class="headerlink" href="#hofstadter1979godel" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Godel Escher Bach</p></li>
<li><p>The hand that draws itself.</p></li>
</ul>
</div></blockquote>
</section>
<section id="hou2019deep">
<h2>hou2019deep<a class="headerlink" href="#hou2019deep" title="Link to this heading"></a></h2>
<p>Deep multimodal multilinear fusion with high-order polynomial pooling</p>
<p>Available: <a class="reference external" href="https://proceedings.neurips.cc/paper_files/paper/2019/hash/f56d8183992b6c54c92c16a8519a6e2b-Abstract.html">https://proceedings.neurips.cc/paper_files/paper/2019/hash/f56d8183992b6c54c92c16a8519a6e2b-Abstract.html</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Mentioned in <a class="reference internal" href="minutes.html#id191"><span class="std std-ref">2024-04-18 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="howard2017mobilenets">
<h2>howard2017mobilenets<a class="headerlink" href="#howard2017mobilenets" title="Link to this heading"></a></h2>
<p>Mobilenets: Efficient convolutional neural networks for mobile vision applications</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/1704.04861">https://arxiv.org/abs/1704.04861</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <a class="reference internal" href="minutes.html#id145"><span class="std std-ref">2023-09-21 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="huang2017densely">
<h2>huang2017densely<a class="headerlink" href="#huang2017densely" title="Link to this heading"></a></h2>
<p>Densely connected convolutional networks</p>
<p>(Huang 2017) is the original paper on DenseNet, a deep learning technique for image classification.</p>
<p>Available: <a class="reference external" href="https://openaccess.thecvf.com/content_cvpr_2017/html/Huang_Densely_Connected_Convolutional_CVPR_2017_paper.html">https://openaccess.thecvf.com/content_cvpr_2017/html/Huang_Densely_Connected_Convolutional_CVPR_2017_paper.html</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <a class="reference internal" href="minutes.html#id145"><span class="std std-ref">2023-09-21 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="hung2019optimizing">
<h2>hung2019optimizing<a class="headerlink" href="#hung2019optimizing" title="Link to this heading"></a></h2>
<p>Optimizing agent behavior over long time scales by transporting value</p>
<p>(Hung 2019) deal with naviagation with distraction, a model that requires semantic control.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See 2022-12-05 - AJCAI #01</p></li>
</ul>
</dd>
</dl>
</section>
<section id="hussain2016food">
<h2>hussain2016food<a class="headerlink" href="#hussain2016food" title="Link to this heading"></a></h2>
<p>Food contamination: major challenges of the future</p>
<dl class="simple">
<dt>Def. Food contamination:</dt><dd><p>Food contamination is generally defined as foods that are spoiled or tainted because they either contain microorganisms, such as bacteria or parasites, or toxic substances that make them unfit for consumption. A food contaminant can be biological, chemical or physical in nature, with the former being more common. These contaminants have several routes throughout the supply chain (farm to fork) to enter and make a food product unfit for consumption.</p>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See proposal, fish contamination deteciton.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="huszar2022algorithmic">
<h2>huszar2022algorithmic<a class="headerlink" href="#huszar2022algorithmic" title="Link to this heading"></a></h2>
<p>Algorithmic amplification of politics on Twitter</p>
<p>(Huszar 2022), study by former Twitter employees, reveal amplification of political content on Twitter.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in Deep Learning - 2022-11-30</p></li>
</ul>
</dd>
</dl>
</section>
<section id="li2022language">
<h2>li2022language<a class="headerlink" href="#li2022language" title="Link to this heading"></a></h2>
<p>Language-driven semantic segmentation</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/2201.03546">https://arxiv.org/abs/2201.03546</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Mentioned at <a class="reference internal" href="minutes.html#id191"><span class="std std-ref">2024-04-18 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="ioffe2015batch">
<h2>ioffe2015batch<a class="headerlink" href="#ioffe2015batch" title="Link to this heading"></a></h2>
<p>Batch normalization: Accelerating deep network training by reducing internal covariate shift</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/1502.03167">https://arxiv.org/abs/1502.03167</a></p>
<p><span class="math notranslate nohighlight">\(y = \frac{x - E[x]}{\sqrt{Var[x] + \epsilon}} * \gamma + \beta\)</span></p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Batch Normalization is a popular technique used to train deep neural networks. It normalizes the input to a layer during every training iteration using a mini-batch of data. It smooths and simplifies the optimization function leading to a more stable and faster training.</p></li>
<li><p>Batch Normalization works by scaling its input—the previous layer’s output—to a mean of zero and a standard deviation of one per mini-batch.</p></li>
<li><p>Although correctly initializing a network can significantly impact convergence, the stability offered by Batch Normalization makes training deep neural networks less sensitive to a specific weight initialization scheme. Since Batch Normalization normalizes values, it reduces the likelihood of running into vanishing or exploding gradients.</p></li>
<li><p>Batch Normalization does require extra computations, making individual iterations slower. However, it will dramatically reduce the number of iterations needed to achieve convergence, making the training process much faster.</p></li>
<li><p>However, at initialization, batch normalization in fact induces severe gradient explosion in deep networks. Practically, this means deep batchnorm networks are untrainable.</p></li>
<li><p>This is only relieved by skip connections in the fashion of residual networks <a class="reference internal" href="#he2016deep"><span class="std std-ref">(He 2016)</span></a></p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#he2016deep"><span class="std std-ref">(He 2016)</span></a> ResNet fixes gradient explosion in deep networks with batchnorm.</p></li>
<li><p><a class="reference internal" href="#szegedy2015going"><span class="std std-ref">(Szegedy 2015)</span></a> GoogLeNet - same author.</p></li>
<li><p><a class="reference internal" href="#szegedy2013intriguing"><span class="std std-ref">(Szegedy 2013)</span></a> same author.</p></li>
<li><p>Pytorch 1D <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html">https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html</a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="ingalalli2014multi">
<h2>ingalalli2014multi<a class="headerlink" href="#ingalalli2014multi" title="Link to this heading"></a></h2>
<p>A multi-dimensional genetic programming approach for multi-class classification problems</p>
<p>(Ingalalli 2014) propose M2GP, for feature construction for mutli-class classification tasks.</p>
<p>Available: <a class="reference external" href="https://link.springer.com/chapter/10.1007/978-3-662-44303-3_5">https://link.springer.com/chapter/10.1007/978-3-662-44303-3_5</a></p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>M2GP is a multi-dimensional genetic programming approach for multi-class classification problems.</p></li>
<li><p>Fixed number of dimensions <span class="math notranslate nohighlight">\(d\)</span></p></li>
<li><p>Predecessor to M3GP 2023-10-06 - ECRG</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in FASLIP <a class="reference internal" href="minutes.html#id147"><span class="std std-ref">2023-09-28 - FASLIP</span></a>.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="jacot2018neural">
<h2>jacot2018neural<a class="headerlink" href="#jacot2018neural" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Neural tangent kernel: Convergence and generalization in neural networks</p></li>
</ul>
</div></blockquote>
</section>
<section id="jaegle2021perceiver">
<h2>jaegle2021perceiver<a class="headerlink" href="#jaegle2021perceiver" title="Link to this heading"></a></h2>
<p>Perceiver: General perception with iterative attention</p>
<p>(Jaegle 2021) is a DeepMind paper on a multi-modal perceptron with attention.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <span class="xref std std-ref">2023-03-01 - Deep Learning</span> for discussion on this paper.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="jha2015rapid">
<h2>jha2015rapid<a class="headerlink" href="#jha2015rapid" title="Link to this heading"></a></h2>
<p>Rapid detection of food adulterants and contaminants: theory and practice</p>
<dl class="simple">
<dt>Def. adulteration:</dt><dd><p>Food adulteration is the act of intentionally debasing the quality of food offered for sale either by the admixture or substitution of inferior substances or by the removal of some valuable ingredient</p>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><span class="xref std std-ref">(Black 2019)</span> uses REIMS to detect beef adulteration.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="jiang2019degenerate">
<h2>jiang2019degenerate<a class="headerlink" href="#jiang2019degenerate" title="Link to this heading"></a></h2>
<p>Degenerate Feedback Loops in Recommender Systems</p>
<p>(Jiang 2019) is a deep mind paper on degeneracy in positive feedback loops on social media.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See Deep Learning - 2022-11-30 for discussion on this paper.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="jing2020learning">
<h2>jing2020learning<a class="headerlink" href="#jing2020learning" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Graph nerual Networks can be used for protien folding.</p></li>
<li><p>Equivariance to rotations - if the networks thinks the same instance rotates is a completely different structure, this is very inefficient.</p></li>
<li><p>Instead we want rotation invariant representations for things like protiens. (Like we wan’t time invariant representations for gas chromatography).</p></li>
<li><p>Voxels are 3D pixels, these can be used to make a 3D representation of an instance, which then applies a 3D Convolutional Neural Network.</p></li>
<li><p>We think that (1) message passing and (2) spatial convolution, are both well suited for different types of reasoning.</p></li>
<li><p>In protein folding, their are chemical propoerties of protiens that simplify the combinatorial search space for the graphical neural network.</p></li>
<li><p>This is similar to how the AI Feynman (Tegmark 2020) used properties of physics equations to simplify symbolic regression.</p></li>
</ul>
</div></blockquote>
</section>
<section id="jing2022masked">
<h2>jing2022masked<a class="headerlink" href="#jing2022masked" title="Link to this heading"></a></h2>
<p>Masked siamese convnets</p>
<dl class="simple">
<dt>Task:</dt><dd><ul class="simple">
<li><p>low-shot image classification and outperforms previous methods on object detection benchmarks</p></li>
</ul>
</dd>
<dt>Data:</dt><dd><ul class="simple">
<li><p>object detection benchmarks</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><span class="xref std std-ref">(Bromley 1993)</span> is the original siamese network paper.</p></li>
<li><p><span class="xref std std-ref">(Zhu 2020)</span> propose siamese networks for ransomware detection.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="kajiya1993get">
<h2>kajiya1993get<a class="headerlink" href="#kajiya1993get" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>How to get your SIGGRAPH paper rejected</p></li>
<li><p>TODO [ ] Read this</p></li>
</ul>
</div></blockquote>
</section>
<section id="karras2020analyzing">
<h2>karras2020analyzing<a class="headerlink" href="#karras2020analyzing" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>StyleGAN</p></li>
<li><p>Latent layer representation.</p></li>
<li><p>Manipulating latent layer gives a sense of semantically meaninful feature space.</p></li>
<li><p>We can see the change in style that sampling latent layer gives.</p></li>
</ul>
</div></blockquote>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="#karras2022elucidating"><span class="std std-ref">(Karras 2022)</span></a> for LDM design space paper from same author.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="karras2022elucidating">
<h2>karras2022elucidating<a class="headerlink" href="#karras2022elucidating" title="Link to this heading"></a></h2>
<p>Elucidating the design space of diffusion-based generative models</p>
<p>(Karras 2022) provides a clear explanation of the design of generative models.</p>
<dl class="simple">
<dt>Background:</dt><dd><ul class="simple">
<li><p>Diffusion-based generative models were unnecessarily convoluted.</p></li>
</ul>
</dd>
<dt>Motivation:</dt><dd><ul class="simple">
<li><p>Simplify Latent Diffusion Model (LDM) architecture, decouple architecture,</p></li>
<li><p>Provide a clear explanation of the design space of generative models.</p></li>
</ul>
</dd>
</dl>
<p>Data:</p>
<p>Method:</p>
<p>Results:</p>
<dl class="simple">
<dt>Why it matters?</dt><dd><ul class="simple">
<li><p>NeurIPS 2022 paper for LDMs, provided code that EVERYBODY uses (steals!)</p></li>
</ul>
</dd>
<dt>Limitations:</dt><dd><ul class="simple">
<li><p>No video, consistency across time, recurrence needed.</p></li>
</ul>
</dd>
<dt>Applications:</dt><dd><ul class="simple">
<li><p>(Wood 2022) Glimpse of Us - Joji (AI Generated Music Video) <a class="reference external" href="https://youtu.be/IzhWOuCzzzs">https://youtu.be/IzhWOuCzzzs</a></p></li>
<li><p>Deforum Art - Twitter profile <a class="reference external" href="https://twitter.com/deforum_art">https://twitter.com/deforum_art</a></p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="#karras2020analyzing"><span class="std std-ref">(Karras 2020)</span></a> for StyleGAN paper from same author.</p></li>
<li><p>See <a class="reference internal" href="minutes.html#id134"><span class="std std-ref">2023-05-03 - Deep Learning</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="karpathy2023lets">
<h2>karpathy2023lets<a class="headerlink" href="#karpathy2023lets" title="Link to this heading"></a></h2>
<p>Let’s build GPT: from scratch, in code, spelled out.</p>
<p>(Karpathy 2023) builds GPT from scratch</p>
<p>YouTube <a class="reference external" href="https://youtu.be/kCc8FmEb1nY?si=1vM4DhyqsGKUSAdV">https://youtu.be/kCc8FmEb1nY?si=1vM4DhyqsGKUSAdV</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Transformer <a class="reference internal" href="#vaswani2017attention"><span class="std std-ref">(Vaswani 2017)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="katharopoulos2020transformers">
<h2>katharopoulos2020transformers<a class="headerlink" href="#katharopoulos2020transformers" title="Link to this heading"></a></h2>
<p>Transformers are rnns: Fast autoregressive transformers with linear attention</p>
<p><a class="reference external" href="https://proceedings.mlr.press/v119/katharopoulos20a.html">(katharopoulos 2020)</a> propose <span class="math notranslate nohighlight">\(O(n)\)</span> transformers with self-attention as a linear dot-product of kernel feature maps.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Transformers achieve remarkable performance in several tasks but due to their quadratic complexity, with respect to the input’s length, they are prohibitively slow for very long sequences.</p></li>
<li><p>To address this limitation, we express the self-attention as a linear dot-product of kernel feature maps and make use of the associativity property of matrix products to reduce the complexity from <span class="math notranslate nohighlight">\(O(n^2)\)</span> to <span class="math notranslate nohighlight">\(O(n)\)</span>, where N is the sequence length.</p></li>
<li><p>We show that this formulation permits an iterative implementation that dramatically accelerates autoregressive transformers and reveals their relationship to recurrent neural networks.</p></li>
<li><p>Linear Transformers achieve similar performance to vanilla Transformers and they are up to 4000x faster on autoregressive prediction of very long sequences.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <a class="reference internal" href="minutes.html#id136"><span class="std std-ref">2023-05-10 - Deep Learning</span></a></p></li>
<li><p>See <a class="reference internal" href="#zhai2021attention"><span class="std std-ref">(Zhai 2021)</span></a> for Attention Free Transformer (AFT)</p></li>
<li><p>See <a class="reference internal" href="#peng2023rwkv"><span class="std std-ref">(Peng 2023)</span></a> for RWKV - transformers + RNNs.</p></li>
<li><p>See <a class="reference internal" href="#wang2020linformer"><span class="std std-ref">(Wang 2020)</span></a> for Linformer paper.</p></li>
<li><p>See <a class="reference internal" href="#kitaev2020reformer"><span class="std std-ref">(Kitaev 2020)</span></a> for Reformer paper.</p></li>
<li><p>See <a class="reference internal" href="#vaswani2017attention"><span class="std std-ref">(Vaswani 2017)</span></a> for transformer paper.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="ke2018sparse">
<h2>ke2018sparse<a class="headerlink" href="#ke2018sparse" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Sparse attentive backtracking: Temporal credit assignment through reminding</p></li>
</ul>
</div></blockquote>
</section>
<section id="kennedy1995particle">
<h2>kennedy1995particle<a class="headerlink" href="#kennedy1995particle" title="Link to this heading"></a></h2>
<p>Particle Swarm Optimisation (PSO).</p>
<dl class="simple">
<dt>Purpose:</dt><dd><ul class="simple">
<li><p>PSO optimizes non-linear functions with particle swarn methedology.</p></li>
<li><p>PSO was discovered through simulation of a simpleified social behaviour model. Then taken from a social behaviour model, and turned into an optimizer.</p></li>
</ul>
</dd>
<dt>Background:</dt><dd><ul class="simple">
<li><p>The synchonicit was though of as a function of the bird trying to maintain an optimal distance between itself and its neighbours.</p></li>
<li><p>All birds in the flock know the global best position, the roost.</p></li>
<li><dl class="simple">
<dt>(Millonas 1995) developed 5 basic principles of swarm intelligence.</dt><dd><ol class="arabic simple">
<li><p>Prxomity - perform space/time computations.</p></li>
<li><p>Quality - respond to quality features in the environment</p></li>
<li><p>Diversity - not commit to narrow channels.</p></li>
<li><p>Stablity - Don’t change mode behaviour each iteration.</p></li>
<li><p>Adaptability - Change behaviour if it is worth it.</p></li>
</ol>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Paradigms:</dt><dd><ol class="arabic simple">
<li><p>Artificial life - i.e. fish schooling, birds flocking,</p></li>
<li><p>Genetic algorithms / evotionary programming.</p></li>
</ol>
</dd>
</dl>
</li>
<li><p>Train ANN weights, Model Schaffers f6 function a GA from (Davis 1991).</p></li>
<li><p>School of Fish <a class="reference external" href="https://youtu.be/15B8qN9dre4">https://youtu.be/15B8qN9dre4</a></p></li>
<li><p>(Heppner 1990) had simulations which introduced a “roost”, a global maximum, or home the birds, that they all know.</p></li>
<li><p>But, how do birds find food? I.e. a new bird feeder is found within hours.</p></li>
<li><p>Agents move towards their best know value - the cornfield, in search of food.</p></li>
<li><p>Birds store their local maxima, the cornfield vector (I know there is food here!).</p></li>
<li><p>Model is very simple, requires a few lines of code, primitive mathematics operators, both effecient in memory and speed.</p></li>
<li><p>(Reynolds 1987) was intrigued by the aesthetics of bird flocking, the choreography, synchonocity. He wanted to understand the mechanics of bird flocking - as set of simple rules that governed the behaviour.</p></li>
<li><p>With the assumption, like Conway’s Game of Life for cellular automata, that a simple set of rules, my underpin the unpredictable and complex group dynamics of bird social behaviour.</p></li>
</ul>
</dd>
<dt>Motivations:</dt><dd><ul class="simple">
<li><p>Motivation for simulation: to model human behaviour. Humans are more complex, we don’t just update our velocity/direction as animals flocking do, we update our beliefs/views to conform to our peers around us - i.e. social desirability bias, cultural homogenuity.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Method:</dt><dd><ul class="simple">
<li><p>Explorers and settlers model, explorers overrun target, settlers more precise, had little improvement, Occam’s razor removed the complex model.</p></li>
<li><p>Initial approach: a nearest neighbour method to synchonocity that matched velocity resulted in unifrom unchanging direction.</p></li>
<li><p>Stochasity, randomness, “craziness” was required to add variation to the flocks direciton. Enough stochacity to give the illusion of aritificial life.</p></li>
<li><p>Simulation behaviour: a high p/g increment had violent fast behaviour, an approximately equal p/g increment had synchronocity, low p/g increment had no convergence.</p></li>
<li><p>Improvements: removed craziness, removed nearest neighbour (NN), without NN collisions were enabled, the flock was now a swarm. A swarm not a flock, because we have collisions.</p></li>
<li><p>g/p increment values had to be chosen carefully.</p></li>
<li><p>Social anaologies: <span class="math notranslate nohighlight">\(pbest\)</span> is autiobiographical memory, <span class="math notranslate nohighlight">\(\nabla pbest\)</span> is simple nostalgia. <span class="math notranslate nohighlight">\(gbest\)</span> is public knowledge, <span class="math notranslate nohighlight">\(\nabla gbest\)</span> is social conformity.</p></li>
<li><p>Appxomiations, PSO could solve the XOR problem on a 2-3-1 ANN with 13 parameters.</p></li>
<li><p>Improvement: velocities were adjusted according to their difference, per dimension, this added momementum, a memory of previous motion. p/g increment was a nuisance parameter, and was such removed.</p></li>
<li><p>Stochastic factor, which amplifieid the randomness, was set to 2. This makes the agents “overfly” or overshoot the target about half of the time. Tuned with black magic, a more formal derivation could be done in future work.</p></li>
<li><p>Tried a model with one midpoint between <span class="math notranslate nohighlight">\(gbest\)</span> and pbest, but it converged at the midpoint.</p></li>
<li><p>The stochasity was necesarry for good results.</p></li>
<li><p>Version without momentum, had no knowledge of previous motion, and failed to find the global optima.</p></li>
</ul>
</dd>
<dt>Results:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>PSO met all 5 of (Millonas 1995) swarm intelligence principles:</dt><dd><ol class="arabic simple">
<li><p>n-d space calucaltions computed over a series of time setps.</p></li>
<li><p>Responds to quality factors <span class="math notranslate nohighlight">\(gbest\)</span> and pbest.</p></li>
<li><p>Moves between <span class="math notranslate nohighlight">\(gbest\)</span> and pbest, encourging diversity.</p></li>
<li><p>Mode behaviour only changes when <span class="math notranslate nohighlight">\(gbest\)</span> does.</p></li>
<li><p>Mode behaviour does change when <span class="math notranslate nohighlight">\(gbest\)</span> does.</p></li>
</ol>
</dd>
</dl>
</li>
<li><p>Term particle chosen as birds have velocity and acceleration, similar to elementary particles in phusocs. (Reeves 1983) also dicussed particle systems and primitive particles as models of diffucse objects, like a cloud of smoke. So we can refer to the representation as a particle swarm.</p></li>
<li><p>PSO sometimes find ANN weights better than those found via gradient descent.</p></li>
<li><p>PSO is a form of Evolutionary Computation, somewhere between genetic algorithms and evolutionary programming.</p></li>
<li><p><span class="math notranslate nohighlight">\(gbest\)</span> / <span class="math notranslate nohighlight">\(pbest\)</span> is similar to crossover operator, it also has a fitness function, both from evolutionary computation (EC).</p></li>
<li><p>The momentum of the swarm flying towards better solutions, and often overshooting, is a strength. IT allows the swarm to explore unkown regions in the problem domain.</p></li>
</ul>
</dd>
<dt>Applications:</dt><dd><ol class="arabic simple">
<li><p>non-linear function optimization,</p></li>
<li><p>neural network training.</p></li>
</ol>
</dd>
<dt>Philosophy (some beautiful philosophical musings from the end of the paper):</dt><dd><ul class="simple">
<li><p>Perhaps these same rules govern social behaviour in humans. Social sharing of infomration amoung members of the same species (cospeciates) offers an evolutionary advantage (Wilson 1975).</p></li>
<li><p>In abstract multi-dimenisional space, our psychological space, we allow colluions within a population - i.e. two individuals may share the same beliefs. Thus our model allows collisions, e.g. “collision-proof birds”.</p></li>
<li><p>Aristotle spoke of Qualitative and quantitative movement.</p></li>
<li><p>PSO walks a fine line between order (known) and chaos (unknown).</p></li>
<li><p>Allows wisom to emerge rather than impose it.</p></li>
<li><p>Emulates nature rather than trying to control it.</p></li>
<li><p>Makes things simpler than more complex.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#kennedy1997discrete"><span class="std std-ref">(Kennedy 1997)</span></a> Discrete PSO, for feature selection.</p></li>
<li><p><a class="reference internal" href="#wood2022automated"><span class="std std-ref">(Wood 2022)</span></a> uses PSO for feature selection in GC-MS data.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="kennedy1997discrete">
<h2>kennedy1997discrete<a class="headerlink" href="#kennedy1997discrete" title="Link to this heading"></a></h2>
<p>PSO for feature selection.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>TODO [ ] Read this paper.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#kennedy1995particle"><span class="std std-ref">(Kennedy 1995)</span></a> original PSO paper.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="kerber1992chimerge">
<h2>kerber1992chimerge<a class="headerlink" href="#kerber1992chimerge" title="Link to this heading"></a></h2>
<p>Chimerge: Discretization of numeric attributes</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Predecessor to Chi2 (Liu 1995, liu1995chi2)</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#liu1995chi2"><span class="std std-ref">(Liu 1995)</span></a> the successor to Chimerge.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="khakimov2015trends">
<h2>khakimov2015trends<a class="headerlink" href="#khakimov2015trends" title="Link to this heading"></a></h2>
<p>Trends in the application of chemometrics to foodomics studies</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>TODO [ ] READ THIS !!!</p></li>
</ul>
</dd>
<dt>Daniel email:</dt><dd><ul class="simple">
<li><p>Re: using the 4800x500 image, would it be possible to use a three dimensional ‘data cube’ instead of a 2D image? i.e. time x peak intensity x mass spectrometry (See image below I took from the attached paper)? When we started the work on the GC data, that was the kind of format I hoped to use.</p></li>
</ul>
</dd>
<dt>Why it matter?</dt><dd><ul class="simple">
<li><p>Data cube, a useful representation of GS-MS data.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#bi2020gc"><span class="std std-ref">(Bi 2022)</span></a> proposed a CNN model that incorporated GC-MS data fusion for food science.</p></li>
<li><p><a class="reference internal" href="#zhang2008two"><span class="std std-ref">(Zhang 2008)</span></a> proposed a 2-D COW algorithm for aligning gas chromatography and mass spectrometry.</p></li>
<li><p><a class="reference internal" href="#eder1995gas"><span class="std std-ref">(Eder 1995)</span></a> The original paper on gas chromatrography (GC).</p></li>
</ul>
</dd>
</dl>
</section>
<section id="killeen2017fast">
<h2>killeen2017fast<a class="headerlink" href="#killeen2017fast" title="Link to this heading"></a></h2>
<p>Fast sampling, analyses and chemometrics for plant breeding: bitter acids, xanthohumol and terpenes in lupulin glands of hops (Humulus lupulus)</p>
<p>(Killeen 2017) addressed rapid chemical analysis techniques for hops.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See 2023-02-08 - Callaghan Innovation Workshop, for Daniels talk on this paper.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="kingma2014adam">
<h2>kingma2014adam<a class="headerlink" href="#kingma2014adam" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Adam optimizer for neural networks.</p></li>
</ul>
</div></blockquote>
</section>
<section id="kira1992practical">
<h2>kira1992practical<a class="headerlink" href="#kira1992practical" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>A practical approach to feature selection,</p></li>
<li><p>Relief feature selection method, predecessor to ReliefF (Kononeko 1994, kononenko1994estimating)</p></li>
<li><p>Authors suggest: splitting into a sereis of 2-class problems to handle multi-class problems.</p></li>
</ul>
</div></blockquote>
</section>
<section id="kishore2021fixed">
<h2>kishore2021fixed<a class="headerlink" href="#kishore2021fixed" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Hide messages in adversarial neural network.</p></li>
<li><p>Pre-trained stenograph, results in non-zero error, we need perfect reconstruction for encryption.</p></li>
<li><p>Face anonymization, post a persons face online, then regenerate the face, but encrypt the private face.</p></li>
<li><p>This lets friends anonmyously share images with their face online, without revealing their identity.</p></li>
</ul>
</div></blockquote>
</section>
<section id="kitaev2020reformer">
<h2>kitaev2020reformer<a class="headerlink" href="#kitaev2020reformer" title="Link to this heading"></a></h2>
<p>Reformer: The efficient transformer</p>
<p><a class="reference external" href="https://arxiv.org/abs/2001.04451">(Kitaev 2020)</a> propose the Reformer, an <span class="math notranslate nohighlight">\(O(L\log L)\)</span> efficient transformer.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from <span class="math notranslate nohighlight">\(O(L^2)\)</span> to <span class="math notranslate nohighlight">\(O(L\log L)\)</span>, where <span class="math notranslate nohighlight">\(L\)</span> is the length of the sequence</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <a class="reference internal" href="minutes.html#id136"><span class="std std-ref">2023-05-10 - Deep Learning</span></a></p></li>
<li><p>See <a class="reference internal" href="#wang2020linformer"><span class="std std-ref">(Wang 2020)</span></a> for linformer.</p></li>
<li><p>See <a class="reference internal" href="#peng2023rwkv"><span class="std std-ref">(Peng 2023)</span></a> for RWKV transformer + RNNs paper.</p></li>
<li><p>See <a class="reference internal" href="#zhai2021attention"><span class="std std-ref">(Zhai 2021)</span></a> for attention free transformer (AFT paper).</p></li>
<li><p>See <a class="reference internal" href="#wang2020linformer"><span class="std std-ref">(Wang 2020)</span></a> for Linformer paper.</p></li>
<li><p>See <a class="reference internal" href="#katharopoulos2020transformers"><span class="std std-ref">(Katharopoulos 2020)</span></a> for linear transformers.</p></li>
<li><p>See <a class="reference internal" href="#vaswani2017attention"><span class="std std-ref">(Vaswani 2017)</span></a> for transformer paper.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="kobyzev2020normalizing">
<h2>kobyzev2020normalizing<a class="headerlink" href="#kobyzev2020normalizing" title="Link to this heading"></a></h2>
<p>Normalizing flows: An introduction and review of current methods</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="minutes.html#id102"><span class="std std-ref">2022-10-26 - Deep Learning</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="id2">
<h2>kobyzev2020normalizing<a class="headerlink" href="#id2" title="Link to this heading"></a></h2>
<p>Attention, Learn to Solve Routing Problems!</p>
<p>(Kobyzev 2020) propose a transformer for solving routing problems.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="minutes.html#id149"><span class="std std-ref">2023-10-06 - ECRG</span></a></p></li>
<li><p>See <a class="reference internal" href="#grover2016node2vec"><span class="std std-ref">(Grover 2016)</span></a> for node2vec.</p></li>
<li><p>See <a class="reference internal" href="#balas1969machine"><span class="std std-ref">(Balas 1969)</span></a> for disjunctive graph.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="kononenko1994estimating">
<h2>kononenko1994estimating<a class="headerlink" href="#kononenko1994estimating" title="Link to this heading"></a></h2>
<p>Estimating attributes: Analysis and extensions of Relief.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>ReliefF paper</p></li>
<li><p>ReliefF feature selection method.</p></li>
<li><p>Original Relief method (Kira 1992), could not handle multi-class problems.</p></li>
<li><dl class="simple">
<dt>Contributions: extend Relief (Kira 1992) to ReliefF (Kononeko 1994) to handle</dt><dd><ul>
<li><p>noisy,</p></li>
<li><p>missing features, and,</p></li>
<li><p>multiclass problems.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Motivation: Heuristics needed to identify features woth strong depednenceies due to combinatorial explosion in high-dimensional data.</p></li>
<li><p>Information gain and mutual information are equivalent, MI is used for MRMR.</p></li>
<li><p>Key idea: estimate atttributes according to how well their values distinguish amoung instances that are near eachother.</p></li>
<li><p>Relief Searches for 2 closest neighbours, one of same class (hit), one of different (miss). Then compares attributes ability to seperate the hit and miss.</p></li>
<li><p>Rationale: a goof attribute can differentiate instances from different classes. And should have the same value for nearest neighbour of the same class.</p></li>
<li><p>Extensions to handle: noise, incomplete data, and multi-class problems.</p></li>
<li><p>Diff calculates distance from <span class="math notranslate nohighlight">\(V\)</span> to the hit and miss.</p></li>
<li><p>The algorithm is an approximation of the distance metric: <span class="math notranslate nohighlight">\(W[A]=P(different value of A | miss) - P(different value of A | hit)\)</span>.</p></li>
<li><dl class="simple">
<dt>Limitations of Relief (Kira 1992):</dt><dd><ul>
<li><p>Noisy/redundant features will strongly affect selection of nearest neighbours.</p></li>
<li><p>Estimiation of attributes <span class="math notranslate nohighlight">\(W[A]\)</span> becomes unreliable on noise data.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Fix: Take K nearest neighbours for hit/miss, to increase the reliability og probablity apporximiation, and average (A) the result, hence Relief-A.</p></li>
<li><p><span class="math notranslate nohighlight">\(m\)</span> is a normalization constant, <span class="math notranslate nohighlight">\(m\)</span> caanot exceed the number of training instances, <span class="math notranslate nohighlight">\(m \ge |T|\)</span>, where <span class="math notranslate nohighlight">\(T\)</span> is the training set, and <span class="math notranslate nohighlight">\(|T|\)</span> is its size.</p></li>
<li><p><span class="math notranslate nohighlight">\(m\)</span> is derieved iteratiely, with <span class="math notranslate nohighlight">\(m=|T|\)</span> as an upper bound. Similar to how the first phase of chi2 (Liu 1995) determines a good <span class="math notranslate nohighlight">\(\chi^2\)</span> threshold.</p></li>
<li><p>Synthetic dataset with noisy features, these have no/noisy relation to the class variable. Three datasets of increasing order complexity of dependent relationships.</p></li>
<li><p>First dataset: 5 noise variables, 5 independent/informative, both in decreasing <span class="math notranslate nohighlight">\(P(.)\)</span> so some are more important than others.</p></li>
<li><p>Second dataset: XOR operator, introduces parity relation of the second order. It introduces a non-linearity, it will have zero covariance, but are not independent. Instead, one attribute that determines the redundancy of two others.</p></li>
<li><p>Third dataset: a parity relationship of the third order.</p></li>
<li><p>Information gain / mutual info is not equivalent to intended information gain.</p></li>
<li><p>Increasing the number of nearest neighbours <span class="math notranslate nohighlight">\(n\)</span> has a drastic effect on handling noise in the dataset.</p></li>
<li><p>Monothously, enitirely non-decreasing or non-increasing. “Line goes up!”.</p></li>
<li><p>Relief-A performs well on first two datasets, poorly on third.</p></li>
<li><p>As <span class="math notranslate nohighlight">\(n\)</span> increased, the estimaotr of attributes becomes vanishingly similar to the gini index. See (Kononeko 1994) for derivation/proof.</p></li>
<li><p>Gini index is an impurity function that is highly corelated with infomration gain/mutual info.</p></li>
<li><p>Relief A, as <span class="math notranslate nohighlight">\(n\)</span> increases approaches high correlation with gini index and mutual info.</p></li>
<li><p>There is a limit for <span class="math notranslate nohighlight">\(n\)</span> neighbours, accuracy collapses when <span class="math notranslate nohighlight">\(n\)</span> can no longer capture clusters of the same class in the distribution space.</p></li>
<li><p>Noise has a drastic effect on data with fully independnet vvariables. Less so for depedend attributes from second/third datasets - perhaps because their are less incorrecly labelled instances in those.</p></li>
<li><p>Relief-A,B,C etend Relief in different ways to deal with incomplete datasets. All done through changing the diff function.</p></li>
<li><p>Relief-C ignores missing values, and normalizes afterwards - with enough data, it should converge to the right estimate.</p></li>
<li><p>Conditional probabilities are approximated using relative frequency in the training set.</p></li>
<li><p>Relief-A,B,C had little accuracy difference for datasets without missing values.</p></li>
<li><p>Relief-D performed best for all datasets with missing values.</p></li>
<li><p>Relief-D calculates the probablity that two given instances have a different value for a given attribute.</p></li>
<li><p>Authors (Kira 1992) suggest: splitting into a sereis of 2-class problems to handle multi-class problems.</p></li>
<li><p>Relief-E,F extend Relief-D to deal with multi-class problems.</p></li>
<li><p>Relief-E, nearest miss becomes nearest neighbour for a different classes. A simple and straightforward extension.</p></li>
<li><p>Relief-F, takes weighted average of near miss from each class, rather than just one class, as in Relief-E.</p></li>
<li><p>Algorithm can seperate each pair of classes regardless of which two classes were closest. Robust to all classes becayse of weighted average.</p></li>
<li><p>Relief-F outperforms Relief-E for all synthetic datasets. Both with/without noise.</p></li>
<li><p>Most important contribution: allow Relief-F to deal with multi-class problems.</p></li>
<li><p>Tumour dataset is a real-world dataset with independent variables (verified by domain experts - phycisians).</p></li>
<li><p><span class="math notranslate nohighlight">\(W[A]\)</span> is an approxmiation of the information gain of attributes, higher correlation means this approximiationj is closer to the true mutual information.</p></li>
<li><p>Issues with Relief-F: it can not handle multi-valued attributes.</p></li>
<li><p>Other methods overestimate with mutual infomraiton according to domain experts.</p></li>
<li><p>Relief-F and normalized mutual infomration estimates important features for the tumour dataset correctly.</p></li>
<li><p>Myopy - narrow-minded/focussed on a single idea.</p></li>
<li><p>Calls out reviewer in the acknowledgements section.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>Mutual information can be given for a discrete and continuos by a double sum and integral respectively. See <a class="reference internal" href="#goodfellow2016deep"><span class="std std-ref">(Goodfellow 2016)</span></a> chapter 3 pg. 72 for a derivation of Kullback-Leibler divergence.</p></li>
<li><p><a class="reference internal" href="#kira1992practical"><span class="std std-ref">(Kira 1992)</span></a> an extension of Relief</p></li>
<li><p><a class="reference internal" href="#wood2022automated"><span class="std std-ref">(Wood 2022)</span></a> used Relief-F for feature selection benchmark.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="kool2018attention">
<h2>kool2018attention<a class="headerlink" href="#kool2018attention" title="Link to this heading"></a></h2>
<p>Attention, learn to solve routing problems!</p>
<p>(Kool 2018) propose a transformer for solving routing problems.</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/1803.08475">https://arxiv.org/abs/1803.08475</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discused in <a class="reference internal" href="minutes.html#id149"><span class="std std-ref">2023-10-06 - ECRG</span></a></p></li>
<li><p>Transformers for job shop scheduling <a class="reference internal" href="#chen2022deep"><span class="std std-ref">(Chen 2022)</span></a></p></li>
<li><p>node2vec <a class="reference internal" href="#grover2016node2vec"><span class="std std-ref">(Grover 2016)</span></a></p></li>
<li><p>Disjunctive graphs <a class="reference internal" href="#balas1969machine"><span class="std std-ref">(Balas 1969)</span></a></p></li>
<li><p>Attention mechanisms <a class="reference internal" href="#vaswani2017attention"><span class="std std-ref">(Vaswani 2017)</span></a></p></li>
<li><p>Word2vec <a class="reference internal" href="#mikolov2013efficient"><span class="std std-ref">(Mikolov 2013)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="koppen2000curse">
<h2>koppen2000curse<a class="headerlink" href="#koppen2000curse" title="Link to this heading"></a></h2>
<p>Curse of dimensionality.</p>
<p>(Koppen 2000) discussed the curse of dimensionality.</p>
<p>Available: <a class="reference external" href="https://www.class-specific.com/csf/papers/hidim.pdf">https://www.class-specific.com/csf/papers/hidim.pdf</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed by Ruwang in <a class="reference internal" href="minutes.html#id165"><span class="std std-ref">2023-12-08 - ECRG</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="kulasekara2014transposon">
<h2>kulasekara2014transposon<a class="headerlink" href="#kulasekara2014transposon" title="Link to this heading"></a></h2>
<p>Transposon mutagenesis</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Transposons effects are passed on to offsrping, because their effects are encorporated into the genome.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#hof2016industrial"><span class="std std-ref">(Hof 2016)</span></a> discussed tranposons affect on Moths.</p></li>
<li><p><a class="reference internal" href="#bourque2018ten"><span class="std std-ref">(Bourque 2018)</span></a> discussed transposons in general.</p></li>
<li><p>Julie discussed this in 2022-10-14 - ECRG</p></li>
</ul>
</dd>
</dl>
</section>
<section id="kumar2019multi">
<h2>kumar2019multi<a class="headerlink" href="#kumar2019multi" title="Link to this heading"></a></h2>
<p>A multi-organ nucleus segmentation challenge</p>
<p>Available: <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/8880654">https://ieeexplore.ieee.org/abstract/document/8880654</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <a class="reference internal" href="minutes.html#id161"><span class="std std-ref">2023-11-30 FASLIP</span></a></p></li>
<li><p>Mentioned in <a class="reference internal" href="#emrah2022imbalance"><span class="std std-ref">Emrah 2022</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="krizhevsky2012imagenet">
<h2>krizhevsky2012imagenet<a class="headerlink" href="#krizhevsky2012imagenet" title="Link to this heading"></a></h2>
<p>Imagenet classification with deep convolutional neural networks</p>
<p>(Krizhevsky 2012) proposed AlexNet.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#krizhevsky2017imagenet"><span class="std std-ref">(Krizhevsky 2017)</span></a> further AlexNet paper.</p></li>
<li><p><a class="reference internal" href="#lecun1989backpropagation"><span class="std std-ref">(Lecun 1989)</span></a> proposed LeNet, the original CNN.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="krizhevsky2017imagenet">
<h2>krizhevsky2017imagenet<a class="headerlink" href="#krizhevsky2017imagenet" title="Link to this heading"></a></h2>
<p>Imagenet classification with deep convolutional neural networks</p>
<p>(Krizhevsky 2012) improved AlexNet</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#lecun1989backpropagation"><span class="std std-ref">(Lecun 1989)</span></a> proposed the original form of LeNet</p></li>
</ul>
</dd>
</dl>
</section>
<section id="kullback1951information">
<h2>kullback1951information<a class="headerlink" href="#kullback1951information" title="Link to this heading"></a></h2>
<p>On information and sufficiency</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Kullback-Leibler (KL) divergence.</p></li>
<li><p>Measures distance between two probability distributions.</p></li>
<li><p>Most common loss function for deep learning with stochastic gradient descent.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#goodfellow2016deep"><span class="std std-ref">(Goodfellow 2016)</span></a> chapter 3 pg. 72 for a derivation of Kullback-Leibler divergence.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="lecun1989backpropagation">
<h2>lecun1989backpropagation<a class="headerlink" href="#lecun1989backpropagation" title="Link to this heading"></a></h2>
<p>Backpropagation applied to handwritten zip code recognition</p>
<p>(Lecun 1989) proposed the original form of LeNet</p>
<dl class="simple">
<dt>Motivations:</dt><dd><ul class="simple">
<li><p>CNNs are a special case of multilayer perceptrons (MLPs).</p></li>
<li><p>MLPs are not translation invariant.</p></li>
<li><p>MLPs are not robust to distortions in the input.</p></li>
</ul>
</dd>
<dt>Dataset:</dt><dd><ul class="simple">
<li><p>MNIST handwritten digits dataset.</p></li>
<li><p>60,000 training images, 10,000 test images.</p></li>
</ul>
</dd>
<dt>Method:</dt><dd><ul class="simple">
<li><p>Architecture is called the LeNet-5.</p></li>
<li><p>Model consists of: Convolutional layers, Pooling layers, MLP layers.</p></li>
<li><p>Convolution and pooling layers perform automatic feature extraction.</p></li>
<li><p>Fully connected layers learn to perform classification based on the extracted features.</p></li>
<li><dl class="simple">
<dt>LeNet-5 Architrecture:</dt><dd><ol class="arabic simple">
<li><p>Input layer: The input layer takes in the 28x28 pixel grayscale images of handwritten digits from the MNIST dataset.</p></li>
<li><p>Convolutional layers: The first convolutional layer applies six filters to the input image, each filter being 5x5 pixels in size. The second convolutional layer applies 16 filters to the output of the first layer.</p></li>
<li><p>Subsampling layers: The subsampling layers perform down-sampling on the output of the convolutional layers, reducing the dimensions of the output. The subsampling is done using a max-pooling operation with a 2x2 window.</p></li>
<li><p>Fully connected layers: The output of the subsampling layers is then passed through three fully connected layers, with 120, 84, and 10 neurons, respectively. The final layer has 10 neurons, each representing a possible digit from 0 to 9.</p></li>
</ol>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Results:</dt><dd><ul class="simple">
<li><p>99.2% accuracy on MNIST test set.</p></li>
<li><p>0.8% error rate on MNIST test set.</p></li>
</ul>
</dd>
<dt>Why it matters?</dt><dd><ul class="simple">
<li><p>CNNs are a powerful architecture for computer vision tasks.</p></li>
<li><p>CNNs recognique local connectivity in data that is spatially related (e.g. images).</p></li>
<li><p>CNNs are translation invariant.</p></li>
</ul>
</dd>
<dt>Limitations:</dt><dd><ul class="simple">
<li><p>CNNs are not rotation invariant.</p></li>
<li><p>CNNs are not scale invariant.</p></li>
<li><p>CNNs are not robust to distortions in the input.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#lecun1998gradient"><span class="std std-ref">(Lecun 1998)</span></a> describres practical applications for CNNs.</p></li>
<li><p><a class="reference internal" href="#lecun1989generalization"><span class="std std-ref">(Lecun 1989)</span></a> describes the generalization ability of CNNs.</p></li>
<li><p><a class="reference internal" href="#lecun1989handwritten"><span class="std std-ref">(Lecun 1989)</span></a> describes practical applications of CNNs for handwritten digit recognition (MNIST).</p></li>
<li><p><a class="reference internal" href="#lecun1998gradient"><span class="std std-ref">(Lecun 1998)</span></a> describes practical applications for CNNs.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="lecun1989generalization">
<h2>lecun1989generalization<a class="headerlink" href="#lecun1989generalization" title="Link to this heading"></a></h2>
<p>Handwritten digit recognition with a back-propagation network</p>
<p>Yann LeCun (Lecun 1989) proves that minimizing the number of free parameters in neural networks can enhance the generalization ability of neural networks.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#lecun1989backpropagation"><span class="std std-ref">(Lecun 1989)</span></a> is the original CNN paper.</p></li>
<li><p><a class="reference internal" href="#lecun1989handwritten"><span class="std std-ref">(Lecun 1989)</span></a> describes practical applications of CNNs for handwritten digit recognition (MNIST).</p></li>
<li><p><a class="reference internal" href="#lecun1998gradient"><span class="std std-ref">(Lecun 1998)</span></a> describres practical applications for CNNs.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="lecun1989handwritten">
<h2>lecun1989handwritten<a class="headerlink" href="#lecun1989handwritten" title="Link to this heading"></a></h2>
<p>Handwritten digit recognition with a back-propagation network</p>
<p>(Lecun 1989) describes the application of backpropagation networks in handwritten digit recognition once again.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><span class="xref std std-ref">(Lecun 1989)</span> is the original CNN paper.</p></li>
<li><p><a class="reference internal" href="#lecun1989generalization"><span class="std std-ref">(Lecun 1989)</span></a> describes the generalization ability of CNNs.</p></li>
<li><p><a class="reference internal" href="#lecun1998gradient"><span class="std std-ref">(Lecun 1998)</span></a> practical applications of LeNet.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="lecun1998gradient">
<h2>lecun1998gradient<a class="headerlink" href="#lecun1998gradient" title="Link to this heading"></a></h2>
<p>Gradient-based learning applied to document recognition</p>
<p>(Lecun 1998) shows the practical applications of LeNet for document recognition.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#lecun1989backpropagation"><span class="std std-ref">(Lecun 1989)</span></a> is the original CNN paper.</p></li>
<li><p><a class="reference internal" href="#lecun1989generalization"><span class="std std-ref">(Lecun 1989)</span></a> describes the generalization ability of CNNs.</p></li>
<li><p><a class="reference internal" href="#lecun1989handwritten"><span class="std std-ref">(Lecun 1989)</span></a> describes practical applications of CNNs for handwritten digit recognition (MNIST).</p></li>
</ul>
</dd>
</dl>
</section>
<section id="lee2019wide">
<h2>lee2019wide<a class="headerlink" href="#lee2019wide" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Wide neural networks of any depth evolve as linear models under gradient descent</p></li>
</ul>
</div></blockquote>
</section>
<section id="lehman2020surprising">
<h2>lehman2020surprising<a class="headerlink" href="#lehman2020surprising" title="Link to this heading"></a></h2>
<p>The surprising creativity of digital evolution: A collection of anecdotes from the evolutionary computation and artificial life research communities</p>
<p>(Lehman 2020) give annecdotes from researchs in EC about their algorithms demonstrating bizzare interesting behaviour.</p>
</section>
<section id="lensen2017new">
<h2>lensen2017new<a class="headerlink" href="#lensen2017new" title="Link to this heading"></a></h2>
<p>New representations in genetic programming for feature construction in k-means clustering</p>
<p>(Lensen 2017)</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <a class="reference internal" href="minutes.html#id147"><span class="std std-ref">2023-09-28 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="lex2022noam">
<h2>lex2022noam<a class="headerlink" href="#lex2022noam" title="Link to this heading"></a></h2>
<p>Noam Brown: AI vs Humans in Poker and Games of Strategic Negotiation | Lex Fridman Podcast #344</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Counter-factural regret minimization (CFR) <a class="reference external" href="https://youtu.be/2oHH4aClJQs?t=951">https://youtu.be/2oHH4aClJQs?t=951</a></p></li>
<li><p>Imperfect information games, e.g. poker, rock-paper-scissors, etc.</p></li>
<li><p>Litratus - latin for balance - how often to play each action.</p></li>
<li><p>Elo rating system - <a class="reference external" href="https://en.wikipedia.org/wiki/Elo_rating_system">https://en.wikipedia.org/wiki/Elo_rating_system</a></p></li>
<li><p>Top chess players have an Elo around 3,600.</p></li>
<li><p>Strongest version of AlphaZero is around 52,000 Elo.</p></li>
<li><p>If you remove search, forward-planning, Elo drops to 3,000.</p></li>
<li><p>Niether Libratus/Pluribus use neural nets, instead constrain the state-space search in a clever way!</p></li>
<li><p>Diplomacy - natural lanaguage game that is similar to Civilisation.</p></li>
<li><p>Action-state is near infinite.</p></li>
<li><p>Set in pre-war Europe, need to form alliances, goal to conquer the entire map (Europe).</p></li>
<li><p>Human-like, turing test - as humans gang up on bots when they find them (in-group preference?), implied that human-like behaviour is needed to win.</p></li>
<li><p>Fairness, humans kill teammates to seek retribution for unfiarness, even at the cost of winning, bots don’t do this.</p></li>
<li><p>Very similar behaviour to Monkeys <a class="reference internal" href="#brosnan2003monkeys"><span class="std std-ref">(Brosnan 2003)</span></a>.</p></li>
</ul>
</dd>
</dl>
<p>Available: <a class="reference external" href="https://youtu.be/2oHH4aClJQs">https://youtu.be/2oHH4aClJQs</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#brown2019superhuman"><span class="std std-ref">(Brown 2019)</span></a> Pluribus beats humans at 6 person no-limit Texas hold ‘em poker</p></li>
<li><p><a class="reference internal" href="#brown2018superhuman"><span class="std std-ref">(Brown 2018)</span></a> Libratus beats humans at heads-up no-limit Texas hold ‘em poker.</p></li>
<li><p><a class="reference internal" href="#brown2022human"><span class="std std-ref">(Brown 2022)</span></a> shows that AI can beat humans at diplomacy.</p></li>
<li><p><a class="reference internal" href="#moravvcik2017deepstack"><span class="std std-ref">(Morvavvcik 2017)</span></a> DeepStack beats humans at heads-up no-limit Texas hold ‘em poker.</p></li>
<li><p><a class="reference internal" href="#brosnan2003monkeys"><span class="std std-ref">(Brosnan 2003)</span></a> monkeys reject unequal pay.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="li2002novel">
<h2>li2002novel<a class="headerlink" href="#li2002novel" title="Link to this heading"></a></h2>
<p>A novel evolutionary algorithm for determining unified creep damage constitutive equations</p>
<p>(Li 2002) use evolutionary computation to solve differentiral equations for deriving physics laws.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Creep behaviours of different materials are often described by physically based unified creep damage constitutive equations.</p></li>
<li><p>Such equations are extremely complex.</p></li>
<li><p>They often contain undecided constants (parameters).</p></li>
<li><p>Traditional approaches are unable to find good near optima for these parameters.</p></li>
<li><p>Evolutionary algorithms (EAs) have been shown to be very effective.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="minutes.html#id107"><span class="std std-ref">2022-11-10 - FASLIP</span></a> where author Xin Yao discussed this paper.</p></li>
<li><p><a class="reference internal" href="#li2004evolutionary"><span class="std std-ref">(Li 2004)</span></a>, by  Xin Yao same author, with EC for solving DE in astrophysics.</p></li>
<li><p><a class="reference internal" href="#runarsson2000stochastic"><span class="std std-ref">(Runarsson 2000)</span></a> used stocastic ranking (bubblesort variant) for constrained optimization with Evolutionary Computaiton.</p></li>
<li><p><a class="reference internal" href="#handa2006robust"><span class="std std-ref">(Handa 2006)</span></a>, by Xin Yao same author, use evolutionary computation for route optimization for gritting trucks.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="li2004evolutionary">
<h2>li2004evolutionary<a class="headerlink" href="#li2004evolutionary" title="Link to this heading"></a></h2>
<p>An evolutionary approach to modeling radial brightness distributions in elliptical galaxies</p>
<p>(Li 2004) use evolutionary computation to find models that fit observational data in astrophysics.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Empirical laws are widely used in astrophysics.</p></li>
<li><p>However, as the observational data increase, some of these laws do not seem to describe the data very well.</p></li>
<li><p>Can we discover new empirical laws that describe the data better?</p></li>
<li><dl class="simple">
<dt>Previous approach:</dt><dd><ul>
<li><p>Select a functional form in advance</p></li>
<li><p>Drawbacks: ad hoc, difficult to determine and may only suit a smaller number of profiles</p></li>
<li><p>Apply fitting algorithms to find suitable parameters for the function. Usually adopt the non-linear reduced c2 minimization</p></li>
<li><p>Drawbacks: difficult to set initial values and easily trapped in local minima</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Proposed (Li 2004) evolutionary approach:</dt><dd><ol class="arabic simple">
<li><dl class="simple">
<dt>Find functional forms using GP (Genetic Programming) :</dt><dd><ul>
<li><p>A data-driven process without assuming a functional form in advance</p></li>
<li><p>A bottom up process which suits modelling a large number of galaxy profiles without any prior knowledge of them</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Fit parameters in the form found using FEP (Fast Evolutionary Programming):</dt><dd><ul>
<li><p>Not sensitive to initial setting values</p></li>
<li><p>More likely to find global minima</p></li>
</ul>
</dd>
</dl>
</li>
</ol>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="minutes.html#id107"><span class="std std-ref">2022-11-10 - FASLIP</span></a> where author Xin Yao discussed this paper.</p></li>
<li><p><a class="reference internal" href="#li2002novel"><span class="std std-ref">(Li 2002)</span></a>, Xin Yao same author, with EC for solving DE in materials science.</p></li>
<li><p><a class="reference internal" href="#runarsson2000stochastic"><span class="std std-ref">(Runarsson 2000)</span></a>, Xin Yao same author, used stocastic ranking (bubblesort variant) for constrained optimization with Evolutionary Computaiton.</p></li>
<li><p><a class="reference internal" href="#handa2006robust"><span class="std std-ref">(Handa 2006)</span></a>, by Xin Yao same author, use evolutionary computation for route optimization for gritting trucks.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="li2017feature">
<h2>li2017feature<a class="headerlink" href="#li2017feature" title="Link to this heading"></a></h2>
<p>Feature selection: A data perspective</p>
<p>(Li 2017) is a literature survey of feature selection algorithms.</p>
<p>Available: <a class="reference external" href="https://dl.acm.org/doi/abs/10.1145/3136625">https://dl.acm.org/doi/abs/10.1145/3136625</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed by Ruwang in <a class="reference internal" href="minutes.html#id165"><span class="std std-ref">2023-12-08 - ECRG</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="li2021learnable">
<h2>li2021learnable<a class="headerlink" href="#li2021learnable" title="Link to this heading"></a></h2>
<p>Learnable fourier features for multi-dimensional spatial positional encoding</p>
<p>(Li 2021) propose a spatial encoding that works for multi-dimensional data, such as multi-modal input.</p>
<dl class="simple">
<dt>Background:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt><a class="reference internal" href="#vaswani2017attention"><span class="std std-ref">(Vaswani 2017)</span></a> originally proposed sinosoidal positional encodings for 1D data.</dt><dd><ul>
<li><p>This was the original transformers paper, with catchy title, “Attention is all you need”.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Sinosoidal positional encodings are not suited for multi-dimensional or multi-modal data.</p></li>
<li><p>Previous methods rely on hard-coding each position as a token or a vector.</p></li>
</ul>
</dd>
<dt>Data:</dt><dd><ul class="simple">
<li><p>High volume structured data, such as video, images, audio, etc…</p></li>
<li><p>Multi-modal - inputs from different modalities, such as video, audio, text, etc…</p></li>
</ul>
</dd>
<dt>Method:</dt><dd><ul class="simple">
<li><p>They propose positional encodings that use Learnable Fourier features</p></li>
<li><dl class="simple">
<dt>we represent each position:</dt><dd><ul>
<li><p>which can be multi-dimensional,</p></li>
<li><p>as a trainable encoding based on learnable Fourier feature mapping,</p></li>
<li><p>modulated with a multi-layer perceptron</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Why it matters?</dt><dd><ul class="simple">
<li><p>Use positional encodings for multi-modal / multi-dimensional data.</p></li>
<li><p>Useful for semi-supervised learning applications.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="#vaswani2017attention"><span class="std std-ref">(Vaswani 2017)</span></a> proposed sinosoidal positional encodings for 1D data.</p></li>
<li><p>See <a class="reference internal" href="#jaegle2021perceiver"><span class="std std-ref">(Jaegle 2021)</span></a> for Perciever paper that uses these encodings.</p></li>
<li><p>See <a class="reference internal" href="#peng2023rwkv"><span class="std std-ref">(Peng 2023)</span></a> for RWKV paper that builds on this.</p></li>
<li><p>See <a class="reference internal" href="#zhai2021attention"><span class="std std-ref">(Zhai 2021)</span></a> for attention free transformer (AFT paper).</p></li>
<li><p>See <a class="reference internal" href="#wang2020linformer"><span class="std std-ref">(Wang 2020)</span></a> for Linformer paper.</p></li>
<li><p>See <a class="reference internal" href="#kitaev2020reformer"><span class="std std-ref">(Kitaev 2020)</span></a> for Reformer paper.</p></li>
<li><p>See <a class="reference internal" href="#katharopoulos2020transformers"><span class="std std-ref">(Katharopoulos 2020)</span></a> for linear transformers.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="li2023blip">
<h2>li2023blip<a class="headerlink" href="#li2023blip" title="Link to this heading"></a></h2>
<p>Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models</p>
<p>(Li 2023) propose Blip-2 for multimodal pre-training</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/2301.12597">https://arxiv.org/abs/2301.12597</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <a class="reference internal" href="minutes.html#id179"><span class="std std-ref">2024-02-29 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="lin2017feature">
<h2>lin2017feature<a class="headerlink" href="#lin2017feature" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Feature pyramid networks for object detection.</p></li>
<li><p>Feature Pyramid Network (FPN)</p></li>
<li><p>See <span class="xref std std-ref">2022-10-06 - FASLIP</span>-  for more details.</p></li>
</ul>
</div></blockquote>
</section>
<section id="linnainmaa1970representation">
<h2>linnainmaa1970representation<a class="headerlink" href="#linnainmaa1970representation" title="Link to this heading"></a></h2>
<p>The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors</p>
<p>(Linnainmaa 1970) proposed automatic differentiation (AD).</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Backpropagation is a special case of reverse mode automatic differentiation.</p></li>
<li><p>Reverse mode automatic differentiation is more efficient than forward mode automatic differentiation.</p></li>
<li><p>Requires on foward and one reverse pass to propogate error and adjusrt the weights through the network.</p></li>
<li><p>However, it requires more memory than forward mode automatic differentiation, as it needs to store the intermediate values of the forward pass.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>Everything that uses backpropagation.</p></li>
<li><p>All of deep learning.</p></li>
<li><p><a class="reference internal" href="#lecun1989backpropagation"><span class="std std-ref">(LeCun 1989)</span></a> is the original CNN paper.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="liu1995chi2">
<h2>liu1995chi2<a class="headerlink" href="#liu1995chi2" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Chi2: feature selection and discretization of numeric attributes</p></li>
<li><p>Discretization bins continuous values into discrete ones.</p></li>
<li><p>Feature selection via discretization - ideal for numeric data.</p></li>
<li><p>Motivation: (1) (can) improve performance, (2) efficiency (time/space), (3) simplify models.</p></li>
<li><p>Chi2 discretizes and performs FS - useful as many algorithms perform better with discrete/binary data.</p></li>
<li><p>Under discretization would return the original continuous attribute unchanged.</p></li>
<li><p>Over-discretization is when inconsistencies are introduced to the data - the data loses fidelity.</p></li>
<li><p>Previous work, ChiMerge (Kerber 1992, kerber1992chimerge) with hyper-parameter <span class="math notranslate nohighlight">\(\alpha\)</span> the significance level that had to be manually set.</p></li>
<li><p><span class="math notranslate nohighlight">\(\alpha\)</span> is nuisance variable that requires black magic approach to tune.</p></li>
<li><p>Difficult to find ideal <span class="math notranslate nohighlight">\(\alpha\)</span> without domain knowledge or extensive trial and error.</p></li>
<li><p>New approach Chi2 lets data determine value of <span class="math notranslate nohighlight">\(\alpha\)</span>, perform discretization until over-discretization - a stopping criterion.</p></li>
<li><p>Chi2 is a two-phase method, a generalized version of ChiMege that automatically determines a good <span class="math notranslate nohighlight">\(\chi^2\)</span> threshold that fits the data.</p></li>
<li><p>The formula for calcutaling the $chi^2$ statistic is given by, <span class="math notranslate nohighlight">\(\chi^2 = \sum_{i=1}^2 \sum_{j=1}^k \frac{(A_{ij} - E_{ij})^2}{E_{ij}}\)</span>.</p></li>
<li><p>Phase 1: Extends ChiMerge to be an automated one, to select an ideal value for <span class="math notranslate nohighlight">\(\alpha\)</span> based on the data.</p></li>
<li><p>Phase 2: Each feature is assigned signfnicance level and merged in a round robin fashion - until stopping criterion met.</p></li>
<li><p>Attributes only merged to one value are elminianted as part of feature selection.</p></li>
<li><p>Degrees of freedomlensen2017new: the maximum number of logically independent values, which are values that have the freedom to vary, <span class="math notranslate nohighlight">\(D_F = N - 1\)</span>, where <span class="math notranslate nohighlight">\(N =\)</span> samples, <span class="math notranslate nohighlight">\(D_F =\)</span> degrees of freedom.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(R_i\)</span> or <span class="math notranslate nohighlight">\(C_i\)</span> is zero, set to 0.1. Similar to zero frequency problem from Naive Bayes. I.e. Multiplication by zero is always 0, so all other information is lost.</p></li>
<li><p>Experiments: DT (C4.5), Data with Noise, and Synthetic data.</p></li>
<li><p>Datasets: Iris (continious), Breat (discrete), Heart (mixed).</p></li>
<li><p>C4.5, a DT classification algorithm, is run on its default setting.</p></li>
<li><p>Results show predictive accuracy and size, same or improved for all datasets where Chi2 was applied.</p></li>
<li><p>Chi2 was able to remove noise (irrelvant features) from synthetic and real world data.</p></li>
</ul>
</div></blockquote>
</section>
<section id="liu2018darts">
<h2>liu2018darts<a class="headerlink" href="#liu2018darts" title="Link to this heading"></a></h2>
<p>DARTS: Differentiable Architecture Search</p>
<p>(Liu 2018) propose DARTS, a differentiable architecture search algorithm.</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/1806.09055">https://arxiv.org/abs/1806.09055</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <a class="reference internal" href="minutes.html#id176"><span class="std std-ref">2024-02-22 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="liu2023instaflow">
<h2>liu2023instaflow<a class="headerlink" href="#liu2023instaflow" title="Link to this heading"></a></h2>
<p>InstaFlow: One Step is Enough for High-Quality Diffusion-Based Text-to-Image Generation</p>
<p>(Liu 2023) propose InstaFlow as a faster/cheaper one-step diffusion model for text-to-image generation.</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/2309.06380">https://arxiv.org/abs/2309.06380</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <a class="reference internal" href="minutes.html#id150"><span class="std std-ref">2023-08-11 - Deep Learning</span></a></p></li>
<li><p>DDPM <a class="reference internal" href="#ho2020denoising"><span class="std std-ref">(Ho 2020)</span></a></p></li>
<li><p>DDIM <a class="reference internal" href="#song2020denoising"><span class="std std-ref">(Song 2020)</span></a></p></li>
<li><p>Consistency models <a class="reference internal" href="#song2023consistency"><span class="std std-ref">(Song 2023)</span></a></p></li>
<li><p>Diffusion borrows concepts from thermodyamics <span class="xref std std-ref">(Sohl 2015)</span></p></li>
<li><p>Uses SDXL to improve resolution of generated output  <a class="reference internal" href="#podell2023sdxl"><span class="std std-ref">(Podel 2023)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="lock2007new">
<h2>lock2007new<a class="headerlink" href="#lock2007new" title="Link to this heading"></a></h2>
<p>New Zealand’s quota management system: a history of the first 20 years</p>
<p>(Lock 2007) gives a history of the New Zealand Quota Management System (QMS) for the first 20 years.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#batstone1999new"><span class="std std-ref">(batstone 1999)</span></a> give history of QMS in NZ for 10 years.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="loh2011classification">
<h2>loh2011classification<a class="headerlink" href="#loh2011classification" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Decision tree.</p></li>
</ul>
</div></blockquote>
</section>
<section id="loshchilov2017decoupled">
<h2>loshchilov2017decoupled<a class="headerlink" href="#loshchilov2017decoupled" title="Link to this heading"></a></h2>
<p>Decoupled weight decay regularization</p>
<p>(Loshchilov 2017) propose AdamW</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/1711.05101">https://arxiv.org/abs/1711.05101</a></p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>“decoupling weight decay from the learning rate.” - Christian Raymond</p></li>
</ul>
</dd>
</dl>
</section>
<section id="mantyla1998cuelensen2017new">
<h2>mantyla1998cuelensen2017new<a class="headerlink" href="#mantyla1998cuelensen2017new" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Cue distinctiveness and forgetting: Effectiveness of self-generated retrieval cues in delayed recall.</p></li>
<li><p>Students were given a word list, and asked to make 1 or 3 retrieval cues.</p></li>
<li><p>Students with who used their own multiple retrieval cues had better recall.</p></li>
<li><p>Recall was terrible when using another students own personal retrieval cues.</p></li>
<li><p>Multiple self-generated retrieval cues is the most effective approach to maximising recall.</p></li>
</ul>
</div></blockquote>
</section>
<section id="marhsall2022cybermarine">
<h2>marhsall2022cybermarine<a class="headerlink" href="#marhsall2022cybermarine" title="Link to this heading"></a></h2>
<p>Cyber-marine: 100 percent utilisation, maximised value</p>
<p>(Marshall 2022) from Cyber-marine gives an overview of their research aims on pg. 49 of Seafood New Zealand - Issue #226.</p>
<p>TODO [ ] READ THIS</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Cybermarine research magazine aims.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#wood2022automated"><span class="std std-ref">(Wood 2016)</span></a> was colab between Cybermarine and VUW.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="marine2020tackling">
<h2>marine2020tackling<a class="headerlink" href="#marine2020tackling" title="Link to this heading"></a></h2>
<p>Tackling Seafood Fraud</p>
<p>(Marine 2020) is an article from the Marine Steward Council (MSC) on seafood fraud in New Zealand.</p>
<p>TODO [ ] READ THIS!!!</p>
<dl class="simple">
<dt>Def. fish fraud:</dt><dd><p>Food fraud, simply put, is the selling of food products with a misleading label, description or promise.</p>
</dd>
<dt>Links:</dt><dd><ul class="simple">
<li><p>Available: <a class="reference external" href="https://www.msc.org/media-centre/news-opinion/news/2020/02/25/tackling-seafood-fraud">https://www.msc.org/media-centre/news-opinion/news/2020/02/25/tackling-seafood-fraud</a></p></li>
<li><p>Cool video: <a class="reference external" href="https://www.youtube.com/watch?v=Kac1cqkjX1U">https://www.youtube.com/watch?v=Kac1cqkjX1U</a></p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#pardo2016misdescription"><span class="std std-ref">(Pardo 2016)</span></a> 30% of seafood is mislabelled.</p></li>
<li><p><a class="reference internal" href="#black2017real"><span class="std std-ref">(Black 2017)</span></a> REIMS for fish fraud detection.</p></li>
<li><p><a class="reference internal" href="#wood2022automated"><span class="std std-ref">(Wood 2022)</span></a> fish speciation with Gas Chromatography.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="matyushin2020gas">
<h2>matyushin2020gas<a class="headerlink" href="#matyushin2020gas" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Matyshuin et al. proposed a stacking model for analysis of gas-chromatograph data.</p></li>
<li><p>It stacked the results of 1DConv, 2DConv, Deep Residual MLP and XGBoost.</p></li>
<li><p>Their model predicted the retention index for samples.</p></li>
<li><p>A retention index is a standardized value that only depends on the chemical structure of a compound.</p></li>
<li><p>Once identified the retention index can be used for further identification.</p></li>
<li><p>GC-MS data has underlying patterns that correspond to chemical compounds.</p></li>
</ul>
</div></blockquote>
</section>
<section id="mccann2012local">
<h2>mccann2012local<a class="headerlink" href="#mccann2012local" title="Link to this heading"></a></h2>
<p>Local naive bayes nearest neighbor for image classification</p>
<p><cite>(McCann 2012) &lt;https://ieeexplore.ieee.org/abstract/document/6248111&gt;</cite> propose a local naive bayes nearest neighbor (LNBNN) classifier.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#crall2013hotspotter"><span class="std std-ref">(Crall 2013)</span></a> uses LNBNN for instance recognition.</p></li>
<li><p><a class="reference internal" href="#behmo2010towards"><span class="std std-ref">(Behmo 2010)</span></a> proposed Naive Bayes Nearest Neighbor (NBNN).</p></li>
</ul>
</dd>
</dl>
</section>
<section id="mcconnell1986method">
<h2>mcconnell1986method<a class="headerlink" href="#mcconnell1986method" title="Link to this heading"></a></h2>
<p>Method of and apparatus for pattern recognition</p>
<p>(McConnell 1986) proposed Histograms of Oriented Gradients (HOG) for pattern recognition.</p>
<p>Available: <a class="reference external" href="https://www.osti.gov/biblio/6007283">https://www.osti.gov/biblio/6007283</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <span class="xref std std-ref">2023-10-12 FASLIP</span></p></li>
</ul>
</dd>
</dl>
</section>
<section id="mclean2005differences">
<h2>mclean2005differences<a class="headerlink" href="#mclean2005differences" title="Link to this heading"></a></h2>
<p>Differences in lipid profile of New Zealand marine species over four seasons</p>
<p>(Mclean 2005) describes the seasonal-variation for lipids in Hoki fish when spawning.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#sun2022soknl"><span class="std std-ref">(Sun 2022)</span></a> for concept drift from data steam mining.</p></li>
<li><p>See <a class="reference internal" href="minutes.html#id131"><span class="std std-ref">(2023-02-16 - FASLIP)</span></a> for talk from (Sun 2022) author.</p></li>
<li><p><a class="reference internal" href="#gomes2020ensemble"><span class="std std-ref">(Gomes 2022)</span></a> for concept drift from data stream mining.</p></li>
<li><p>See (Wood 2023), my proposal, which references Hoki seasonal variation.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="mikolov2013efficient">
<h2>mikolov2013efficient<a class="headerlink" href="#mikolov2013efficient" title="Link to this heading"></a></h2>
<p>Efficient Estimation of Word Representations in Vector Space</p>
<p>(Mikolov 2013) proposed word2vec.</p>
<dl class="simple">
<dt>Related;</dt><dd><ul class="simple">
<li><p>Cited in <a class="reference internal" href="minutes.html#id149"><span class="std std-ref">2023-10-06 - ECRG</span></a></p></li>
<li><p>Same author of <a class="reference internal" href="#mikolov2013linguistic"><span class="std std-ref">(Mikolov 2013)</span></a>.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="mikolov2013linguistic">
<h2>mikolov2013linguistic<a class="headerlink" href="#mikolov2013linguistic" title="Link to this heading"></a></h2>
<p>Linguistic Regularities in Continuous Space Word Representations</p>
<p>(Mikolov 2013) found semantically meaningful feature embeddings for natural language, e.g. “King” - “Man” + “Woman” = “Queen”</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Mikolov et al. found the word embeddings used in NLP were semantically meaningful cite{mikolov2013linguistic}.</p></li>
<li><p>They showed arithmetic could be applied to these word vectors that were interpretable.</p></li>
<li><p>For example “King” - “Man” + “Woman” = “Queen”.</p></li>
<li><p>The feature space was semantically meaningful, which serves as a powerful representation, that we intuitively reason with.</p></li>
<li><p>Similar thought has been applied to computer vision cite{olah2018building, karras2020analyzing}.</p></li>
<li><p>Semantically meaningful feature spaces allow for intuition about the behaviour of complex models, be it through visualisation or arithmetic.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>Related to node2vec (Grover 2016) for graph embeddings.</p></li>
<li><p>Related to (Olah 2018) for feature visualisation.</p></li>
<li><p>Same author as <a class="reference internal" href="#mikolov2013efficient"><span class="std std-ref">(Mikolov 2013)</span></a>.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="miles1998state">
<h2>miles1998state<a class="headerlink" href="#miles1998state" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>State-dependent memory produced by aeorobic exercise.</p></li>
<li><p>Students studies while exercising on a treadmil.</p></li>
<li><p>Material learnt on the treadmill was better recalled on the treadmill.</p></li>
<li><p>Greater information retrieval when the state (i.e. aerobic exercise) is similar.</p></li>
</ul>
</div></blockquote>
</section>
<section id="miller1994exploiting">
<h2>miller1994exploiting<a class="headerlink" href="#miller1994exploiting" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Complement natural selection with sexual selection.</p></li>
<li><p>Biological theory behind sexual selection.</p></li>
<li><p>Sexual selections influences culture around metrics for fitness/fertility.</p></li>
<li><p>Gendered candidate solutions.</p></li>
<li><p>Mate choice / mate preference.</p></li>
<li><p><strong>TODO</strong> read</p></li>
</ul>
</div></blockquote>
</section>
<section id="miller2017explainable">
<h2>miller2017explainable<a class="headerlink" href="#miller2017explainable" title="Link to this heading"></a></h2>
<p>Explainable AI: Beware of inmates running the asylum or: How I learnt to stop worrying and love the social and behavioural sciences},</p>
<p>(Miller 2017) talks about the pitfalls of academics defining XAI.</p>
<dl class="simple">
<dt>Related: lensen2017new</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#miller2021contrastive"><span class="std std-ref">(Miller 2021)</span></a> contrastive explanation.</p></li>
<li><p><a class="reference internal" href="#miller2019explanation"><span class="std std-ref">(Miller 2019)</span></a> explanation in AI.</p></li>
<li><p><a class="reference internal" href="minutes.html#ajcai"><span class="std std-ref">2022-12-07 - AJCAI</span></a> for talk from author.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="miller2019explanation">
<h2>miller2019explanation<a class="headerlink" href="#miller2019explanation" title="Link to this heading"></a></h2>
<p>Explanation in artificial intelligence: Insights from the social sciences},</p>
<p>(Millier 2019) addresses the disconnect between XAI and social sciences.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#miller2021contrastive"><span class="std std-ref">(Miller 2021)</span></a> contrastive explanation.</p></li>
<li><p><a class="reference internal" href="#miller2017explainable"><span class="std std-ref">(Miller 2017)</span></a> explainable AI.</p></li>
<li><p><a class="reference internal" href="minutes.html#ajcai"><span class="std std-ref">2022-12-07 - AJCAI</span></a> for talk from author.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="miller2021contrastive">
<h2>miller2021contrastive<a class="headerlink" href="#miller2021contrastive" title="Link to this heading"></a></h2>
<p>Contrastive explanation: A structural-model approach</p>
<p>(Miller 2021) proposes a new approach to explainable AI, called contrastive explanation.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#miller2017explainable"><span class="std std-ref">(Miller 2017)</span></a> explainable AI.</p></li>
<li><p><a class="reference internal" href="#miller2019explanation"><span class="std std-ref">(Miller 2019)</span></a> explanation in AI.</p></li>
<li><p><a class="reference internal" href="minutes.html#ajcai"><span class="std std-ref">2022-12-07 - AJCAI</span></a> for talk from author.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="morgan1989generalization">
<h2>morgan1989generalization<a class="headerlink" href="#morgan1989generalization" title="Link to this heading"></a></h2>
<p>Generalization and parameter estimation in feedforward nets: Some experiments</p>
<p>(Morgan 1989) propose early stopping for neural networks.</p>
<p>Available: <a class="reference external" href="https://proceedings.neurips.cc/paper_files/paper/1989/hash/63923f49e5241343aa7acb6a06a751e7-Abstract.html">https://proceedings.neurips.cc/paper_files/paper/1989/hash/63923f49e5241343aa7acb6a06a751e7-Abstract.html</a></p>
</section>
<section id="mnih2013playing">
<h2>mnih2013playing<a class="headerlink" href="#mnih2013playing" title="Link to this heading"></a></h2>
<p>Playing atari with deep reinforcement learning</p>
<p>(Mnih 2013) from Deep Mind propose deep q-learning for Atari games.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>2022-12-05 - AJCAI #01</p></li>
</ul>
</dd>
</dl>
</section>
<section id="moraglio2012geometric">
<h2>moraglio2012geometric<a class="headerlink" href="#moraglio2012geometric" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Genetic semantic genetic programming.</p></li>
<li><p><strong>TODO</strong> read - related to Qi Chen talk on 2022-03-18 ECRG.</p></li>
<li><p>Unimodal fitness landscape, one global optima, but semantic search is intractable.</p></li>
<li><p>We approximate semantic search through geometric genetic programming methods.</p></li>
</ul>
</div></blockquote>
</section>
<section id="moravvcik2017deepstack">
<h2>moravvcik2017deepstack<a class="headerlink" href="#moravvcik2017deepstack" title="Link to this heading"></a></h2>
<p>Deepstack: Expert-level artificial intelligence in heads-up no-limit poker</p>
<p>(Moravcik 2017) shows that AI can beat human professionals at two-player no-limit Texas hold ‘em poker.</p>
<p>DeepStack: DeepStack, an AI system that was able to consistently beat human professionals at two-player no-limit Texas hold ‘em poker.</p>
<p>The research paper describing DeepStack was published in the journal Science in 2016 and can be found here: <a class="reference external" href="https://www.science.org/doi/full/10.1126/science.aam6960">https://www.science.org/doi/full/10.1126/science.aam6960</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#brown2019superhuman"><span class="std std-ref">(Brown 2019)</span></a> Pluribus beats humans at 6 person no-limit Texas hold ‘em poker</p></li>
<li><p><a class="reference internal" href="#brown2018superhuman"><span class="std std-ref">(Brown 2018)</span></a> Libratus beats humans at heads-up no-limit Texas hold ‘em poker.</p></li>
<li><p><a class="reference internal" href="#moravvcik2017deepstack"><span class="std std-ref">(Morvavvcik 2017)</span></a> DeepStack beats humans at heads-up no-limit Texas hold ‘em poker.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="mouret2015illuminating">
<h2>mouret2015illuminating<a class="headerlink" href="#mouret2015illuminating" title="Link to this heading"></a></h2>
<p>Illuminating search spaces by mapping elites</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>(Hengzhe 2023) his GECCO 2023 paper uses MAP-elites in the semantic space.</p></li>
<li><p>See 2023-02-10 - ECRG where Hengzhe discussed this paper, and his work above.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="mouss2004test">
<h2>mouss2004test<a class="headerlink" href="#mouss2004test" title="Link to this heading"></a></h2>
<p>Test of page-hinckley, an approach for fault detection in an agro-alimentary production system</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See (<a class="reference internal" href="#gomes2020ensemble"><span class="std std-ref">Gomes 2020</span></a>) for a paper that cites this.</p></li>
<li><p>See <a class="reference internal" href="minutes.html#id131"><span class="std std-ref">2023-02-16 - FASLIP</span></a> where this method is mentioned.</p></li>
<li><p>See (<a class="reference internal" href="#sun2022soknl"><span class="std std-ref">Sun 2022</span></a>) for paper on data stream mining.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="muller2021transformers">
<h2>muller2021transformers<a class="headerlink" href="#muller2021transformers" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Transformers Can Do Bayesian Inference</p></li>
<li><p><strong>TODO</strong> read</p></li>
<li><p>Transformers can do Bayesian inference, The propose prior-data fitted networks (PFNs). PFNs leverage large-scale machine learning techniques to approximate a larget set of posteriors (Muller 2021, muller2021transformers).</p></li>
<li><p>Requires the ability to sample from a prior distribution over supverised learning tasks (or functions).</p></li>
<li><p>Their method restates the objective prosterior apprimixation as a supervised classification problem with set valued input: it repeatedly draws a task (or function) from the prior, draws a set of data points and their labels from it, marks on of the labels and learns to make probabilistic predictions for it based on the set-valued input of the rest of the data points.</p></li>
<li><p>PFNs can nearly perfectly mimic Gaussian Processes and also enable efficient Bayesian Inference for intractable problems, with 200-fold speedups in networks evaluated.</p></li>
<li><p>PFNs perofrm well in GP regression, Bayesian NNs, classification on tabular data, few-shot iamge classification - there applications demonstrate generality of PFNs.</p></li>
</ul>
</div></blockquote>
</section>
<section id="munoz2015m3gp">
<h2>munoz2015m3gp<a class="headerlink" href="#munoz2015m3gp" title="Link to this heading"></a></h2>
<p>M3GP – Multiclass Classification with GP</p>
<p>Available: <a class="reference external" href="https://link.springer.com/chapter/10.1007/978-3-319-16501-1_7">https://link.springer.com/chapter/10.1007/978-3-319-16501-1_7</a></p>
<p>Notes:</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <a class="reference internal" href="minutes.html#id147"><span class="std std-ref">2023-09-28 - FASLIP</span></a></p></li>
<li><p>Variation of M2GP from <a class="reference internal" href="#ingalalli2014multi"><span class="std std-ref">(Ingalalli 2014)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="nickerson2022creating">
<h2>nickerson2022creating<a class="headerlink" href="#nickerson2022creating" title="Link to this heading"></a></h2>
<p>Creating Diverse Ensembles for Classification with Genetic Programming and Neuro-MAP-Elites</p>
<ul class="simple">
<li><p>TODO [ ] - READ</p></li>
</ul>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Hengzhe is working on MAP-Elites in GP. See <a class="reference internal" href="minutes.html#id96"><span class="std std-ref">2022-10-13 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="nielsen2020survae">
<h2>nielsen2020survae<a class="headerlink" href="#nielsen2020survae" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>SurVAE Flows: Surjections to Bridge the Gap between VAEs and Flows</p></li>
<li><p>TODO [ ] read</p></li>
</ul>
</div></blockquote>
</section>
<section id="nguyen2014filtermccann2012local">
<h2>nguyen2014filtermccann2012local<a class="headerlink" href="#nguyen2014filtermccann2012local" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Nguyen et al. proposed a wrapper based PSO technique for feature selection in classification.</p></li>
<li><p>The algorithm uses a wrapper based fitness function of the classification error rate.</p></li>
<li><p>The local search only considers the global best using a filter based method.</p></li>
<li><p>It draws from the strengths of filter and wrapper based feature selection.</p></li>
<li><p>This proposed method outperformed three state-of-the-art and two traditional feature selection methods.</p></li>
</ul>
</div></blockquote>
</section>
<section id="olah2018building">
<h2>olah2018building<a class="headerlink" href="#olah2018building" title="Link to this heading"></a></h2>
<p>The Building Blocks of Interpretability</p>
<p>(Olah 2018) from Distill shows how to visualise semantically meaningful features in computer vision.</p>
<p>Available: <a class="reference external" href="https://distill.pub/2018/building-blocks/?translate=1&amp;translate=1&amp;translate=1&amp;translate=1&amp;student&amp;student&amp;student&amp;student">https://distill.pub/2018/building-blocks/?translate=1&amp;translate=1&amp;translate=1&amp;translate=1&amp;student&amp;student&amp;student&amp;student</a></p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Semantically meaningful features in computer vision.</p></li>
<li><p>Distill <a class="reference external" href="https://distill.pub/2018/building-blocks/">https://distill.pub/2018/building-blocks/</a></p></li>
<li><p>Visualization techniques are powerful for understanding black-box systems.</p></li>
<li><p>Gain intution for semantically meaninful features in complex models.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>Original CNN paper <a class="reference internal" href="#lecun1989backpropagation"><span class="std std-ref">(Lecun 1989)</span></a></p></li>
<li><p>word2vec, semantically meaningful feature embeddings for natural language <a class="reference internal" href="#mikolov2013linguistic"><span class="std std-ref">(Mikolov 2013)</span></a></p></li>
<li><p>node2vec, feature embeddings for graphs <a class="reference internal" href="#grover2016node2vec"><span class="std std-ref">(Grover 2016)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="pardo2016misdescription">
<h2>pardo2016misdescription<a class="headerlink" href="#pardo2016misdescription" title="Link to this heading"></a></h2>
<p>Misdescription incidents in seafood sector</p>
<p>Highlights:
* The average percentage of reported misdescription is 30%.
* Misdescription incidents are significantly greater in restaurants than retailers.
* Gadoids, flatfish and salmonids comprise almost the 60% of the total.
* Future surveys should be focused on other commercial species.</p>
<dl class="simple">
<dt>Method:</dt><dd><ul class="simple">
<li><p>DNA testing, good for species identification</p></li>
<li><p>compares 51 studies with total n=4,500 seafood samples.</p></li>
</ul>
</dd>
<dt>Results:</dt><dd><ul class="simple">
<li><p>found an average mislabelling rate of 30%</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#black2017real"><span class="std std-ref">(Black 2017)</span></a> REIMS for fish fraud detection.</p></li>
<li><p><a class="reference internal" href="#marine2020tackling"><span class="std std-ref">(Marine 2020)</span></a> for fish fraud definition.</p></li>
<li><p><a class="reference internal" href="#black2019rapid"><span class="std std-ref">(Black 2019)</span></a> discusses DNA methods for speciation.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="pascual2022fullband">
<h2>pascual2022fullband<a class="headerlink" href="#pascual2022fullband" title="Link to this heading"></a></h2>
<p>Full-band General Audio Synthesis with Score-based Diffusion</p>
<dl class="simple">
<dt>Linked:</dt><dd><ul class="simple">
<li><p>Website <a class="reference external" href="https://diffusionaudiosynthesis.github.io/">https://diffusionaudiosynthesis.github.io/</a></p></li>
<li><p>ArVix <a class="reference external" href="https://arxiv.org/abs/2210.14661">https://arxiv.org/abs/2210.14661</a></p></li>
<li><p>Video <a class="reference external" href="https://twitter.com/_akhaliq/status/1585431732916027392">https://twitter.com/_akhaliq/status/1585431732916027392</a></p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#song2020denoising"><span class="std std-ref">(Song 2020)</span></a> DDPM.</p></li>
<li><p><a class="reference internal" href="#ho2020denoising"><span class="std std-ref">(Ho 2020)</span></a> DDIM.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="pearce2021empirical">
<h2>pearce2021empirical<a class="headerlink" href="#pearce2021empirical" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>70% accuracy for basic DSA problems.</p></li>
<li><p>Can’t solve more difficult problems - doesn’t optimize solutions for performance.</p></li>
<li><p>CoPilot outperforms other state-of-the-art NLP code generation models.</p></li>
<li><p>Requires “fine-tuning”, supervised human intervention to hint towards correct answer.</p></li>
</ul>
</div></blockquote>
</section>
<section id="peng2022prenastvec">
<h2>peng2022prenastvec<a class="headerlink" href="#peng2022prenastvec" title="Link to this heading"></a></h2>
<p>PRE-NAS: Evolutionary Neural Architecture Search with Predictor. IEEE Transactions on Evolutionary Computation.</p>
<p>(Peng 2022) is a IEEE TVEC paper on Pre-NAS (first paper).</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See ECRG - 2023-01-20 for talk from author.</p></li>
<li><p>See <a class="reference internal" href="#peng2022prenastvec"><span class="std std-ref">(Peng 2022)</span></a> for GECCO paper, published later.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="peng2021prenasgecco">
<h2>Peng2021prenasgecco<a class="headerlink" href="#peng2021prenasgecco" title="Link to this heading"></a></h2>
<p>PRE-NAS: Evolutionary Neural Architecture Search with Predictor. IEEE Transactions on Evolutionary Computation.</p>
<p>(Peng 2022) is a GECCO paper on Pre-NAS (second paper).</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See ECRG - 2023-01-20 for talk from author.</p></li>
<li><p>See <a class="reference internal" href="#peng2022prenastvec"><span class="std std-ref">(Peng 2022)</span></a> for TVEC paper, published earlier.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="peng2023rwkv">
<h2>peng2023rwkv<a class="headerlink" href="#peng2023rwkv" title="Link to this heading"></a></h2>
<p>RWKV: Reinventing RNNs for the Transformer Era</p>
<p><a class="reference external" href="https://arxiv.org/abs/2305.13048">(Peng 2023)</a> propose Receptance Weighted Key Value (RWKV).</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>A hybrid model of transformers and RNNs.</p></li>
<li><p>More efficient inference than regular GPT-based transformers.</p></li>
<li><p>Don’t need GPU clusters to fine-tune - works on commodity hardware.</p></li>
</ul>
</dd>
<dt>Background:</dt><dd><ul class="simple">
<li><p>The computation graph of a transformer is setup in a way that isi is very efficient to be computed in parallel on GPU clusters.</p></li>
<li><p>(Zhai 2021) proposed the Attention Free Transformer (AFT), the predecessor to today’s paper, the Receptance Weighted Key Value (RWKV) transformer.</p></li>
</ul>
</dd>
<dt>Method:</dt><dd><ul class="simple">
<li><p>devlin 2018 bert</p></li>
<li><p>RWKV Raven 14B Demo - Hugging Face <a class="reference external" href="https://huggingface.co/spaces/BlinkDL/ChatRWKV-gradio">https://huggingface.co/spaces/BlinkDL/ChatRWKV-gradio</a></p></li>
<li><p>Github <a class="reference external" href="https://github.com/BlinkDL/RWKV-LM">https://github.com/BlinkDL/RWKV-LM</a></p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="minutes.html#id136"><span class="std std-ref">2023-05-10 - Deep Learning</span></a> where paper was dicussed.</p></li>
<li><p>See <a class="reference internal" href="#zhai2021attention"><span class="std std-ref">(Zhai 2021)</span></a> for Attention Free Transformer (AFT).</p></li>
<li><p>See <a class="reference internal" href="#wang2020linformer"><span class="std std-ref">(Wang 2020)</span></a> for Linformer paper.</p></li>
<li><p>See <a class="reference internal" href="#kitaev2020reformer"><span class="std std-ref">(Kitaev 2020)</span></a> for Reformer paper.</p></li>
<li><p>See <a class="reference internal" href="#katharopoulos2020transformers"><span class="std std-ref">(Katharopoulos 2020)</span></a> for linear transformers.</p></li>
<li><p>See <a class="reference internal" href="#vaswani2017attention"><span class="std std-ref">(Vaswani 2017)</span></a> for transformer paper.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="perez2019analysis">
<h2>perez2019analysis<a class="headerlink" href="#perez2019analysis" title="Link to this heading"></a></h2>
<p>Analysis of statistical forward planning methods in Pommerman</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#volz2018evolving"><span class="std std-ref">(Volz 2018)</span></a> same author evolves Mario levels using EAs on GAN latent spaces.</p></li>
<li><p><a class="reference internal" href="#goodman2020weighting"><span class="std std-ref">(Goodman 2020)</span></a> same user uses NBTEA to choose hyperparameters for balancing gamemplay.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="podell2023sdxl">
<h2>podell2023sdxl<a class="headerlink" href="#podell2023sdxl" title="Link to this heading"></a></h2>
<p>Sdxl: Improving latent diffusion models for high-resolution image synthesis</p>
<p>(Podel 2023) propose SDXL for scaling up images to high resolution.</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/2307.01952">https://arxiv.org/abs/2307.01952</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <span class="xref std std-ref">2023-08-11 Deep Learning</span></p></li>
<li><p>Used in InstaFlow <span class="xref std std-ref">(Liu 2023)</span></p></li>
<li><p>Diffusion process based on thermodyamics <span class="xref std std-ref">(Sohl-Diskstein 2015)</span></p></li>
</ul>
</dd>
</dl>
</section>
<section id="qin2021one">
<h2>qin2021one<a class="headerlink" href="#qin2021one" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>From One Hand to Multiple Hands: Imitation Learning for Dexterous Manipulation from Single-Camera Teleoperation.</p></li>
<li><p>TODO read</p></li>
<li><p>This paper shows single-camera teleoperation capabilities for SCARA.</p></li>
<li><p>This could be used to allow for remote intervention in edge cases for our SCARA.</p></li>
</ul>
</div></blockquote>
</section>
<section id="radford2018improving">
<h2>radford2018improving<a class="headerlink" href="#radford2018improving" title="Link to this heading"></a></h2>
<p>Improving language understanding by generative pre-training</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Generative pre-training (GPT) paper from OpenAI.</p></li>
</ul>
</dd>
</dl>
<p>Available: <a class="reference external" href="https://www.mikecaptain.com/resources/pdf/GPT-1.pdf">https://www.mikecaptain.com/resources/pdf/GPT-1.pdf</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="minutes.html#id133"><span class="std std-ref">2023-02-22 - Deep Learning</span></a> describes this paper.</p></li>
<li><p>Same author, CLIP - <a class="reference internal" href="#radford2021learning"><span class="std std-ref">(Radford 2021)</span></a></p></li>
<li><p>Same author, CLIP - <a class="reference internal" href="#radford2021zero"><span class="std std-ref">(Radford 2021)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="radford2021learning">
<h2>radford2021learning<a class="headerlink" href="#radford2021learning" title="Link to this heading"></a></h2>
<p>Learning Transferable Visual Models From Natural Language Supervision</p>
<p>(Radford 2021) propose CLIP a representational model for text-to-image feature embeddings.</p>
<p>Available: <a class="reference external" href="http://proceedings.mlr.press/v139/radford21a">http://proceedings.mlr.press/v139/radford21a</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Same author, same model, same year <a class="reference internal" href="#radford2021zero"><span class="std std-ref">(Radford 2021)</span></a></p></li>
<li><p>Same author <a class="reference internal" href="#radford2018improving"><span class="std std-ref">(Radford 2028)</span></a></p></li>
<li><p>Mentioned in <a class="reference internal" href="minutes.html#id191"><span class="std std-ref">2024-04-18 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="radford2021zero">
<h2>radford2021zero<a class="headerlink" href="#radford2021zero" title="Link to this heading"></a></h2>
<p>Zero-Shot Text-to-Image Generation</p>
<p>(Radford 2021) propose CLIP a representational model for text-to-image feature embeddings.</p>
<p>Available: <a class="reference external" href="https://proceedings.mlr.press/v139/ramesh21a.html?ref=journey-matters">https://proceedings.mlr.press/v139/ramesh21a.html?ref=journey-matters</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Same author, same model, same year <a class="reference internal" href="#radford2021learning"><span class="std std-ref">(Radford 2021)</span></a></p></li>
<li><p>Same author <a class="reference internal" href="#radford2018improving"><span class="std std-ref">(Radford 2028)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="rajpurkar2017chexnet">
<h2>rajpurkar2017chexnet<a class="headerlink" href="#rajpurkar2017chexnet" title="Link to this heading"></a></h2>
<p>Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning</p>
<p>(Rajpurkar 2017) demonstrate leaky validation in medical x-ray images for computer vision.</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/1711.05225">https://arxiv.org/abs/1711.05225</a></p>
<dl class="simple">
<dt>Background:</dt><dd><ul class="simple">
<li><p>In 2017, Andrew Ng’s team published a paper on Deep Learning for pneumonia detection on chest X-rays.</p></li>
</ul>
</dd>
<dt>Dataset:</dt><dd><ul class="simple">
<li><p>They used a dataset with 112,120 images belonging to 30,805 unique patients. They automatically labelled every sample with 14 different pathologies and randomly split the dataset into 80% training and 20% validation. Their process downscaled images to 224x224 pixels before inputting them into a neural network.</p></li>
</ul>
</dd>
<dt>Limitations:</dt><dd><ul class="simple">
<li><p>After publishing the paper and listening to the community’s feedback, they had to redo their experiments.</p></li>
<li><p>The samples in the team’s dataset are not independent. Different X-Ray images from the same patient will have similarities that a neural network could use to make a prediction.</p></li>
<li><p>For example, a patient might have a scar from a previous surgery or a specific bone density or structure. These clues will help the model make a prediction, so having X-rays from the same patient in the training and validation sets will create a leaky validation strategy. Here is an excerpt from The Kaggle Book:</p></li>
<li><p>“In a leaky validation strategy, the problem is that you have arranged your validation strategy in a way that favours better validation scores because some information leaks from the training data.” (Kaggle)</p></li>
</ul>
</dd>
<dt>Method:</dt><dd><ul class="simple">
<li><p>The team fixed the experiment in the third version of their paper. Here is what they did:</p></li>
<li><p>“For the pneumonia detection task, we randomly split the dataset into training (28744 patients, 98637 images), validation (1672 patients, 6351 images), and test (389 patients, 420 images). There is no patient overlap between the sets.” (Kaggle)</p></li>
<li><p>Notice how they ensured that there was no overlap between sets.</p></li>
</ul>
</dd>
<dt>Conclusion:</dt><dd><ul class="simple">
<li><p>Leaky validation is an issue with identifiable instances, leaking information from train to validation, that artificially inflate validation accuracy.</p></li>
<li><p>Leaky validation is a unique form of data leakage, datasets with identifiable features, such as medical/chemical/biological, are vulnerable to validation leakage.</p></li>
</ul>
</dd>
<dt>Why it matters?</dt><dd><ul class="simple">
<li><p>For my research objectives of Identification, Contamination, and Traceability - the same fish in train and validation, is leaky validation.</p></li>
<li><p>Leaky validation explains why my CNN train/validation performance is 100%, but the test is 60%.</p></li>
<li><p>Lesson: stratify samples to avoid identifiable instances being leaked between train/validation/test datasets.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>The Kaggle Book <a class="reference external" href="https://www.amazon.com/Data-Analysis-Machine-Learning-Kaggle/dp/1801817472?crid=2ZSVOUZJCXMO5&amp;keywords=kaggle+book&amp;qid=1650818962&amp;sprefix=kaggle+book,aps,72&amp;sr=8-3&amp;linkCode=sl1&amp;tag=bnomial-20&amp;linkId=6cf9fd66daf5893153a64f03302971f7&amp;language=en_US&amp;ref_=as_li_ss_tl">https://www.amazon.com/Data-Analysis-Machine-Learning-Kaggle/dp/1801817472?crid=2ZSVOUZJCXMO5&amp;keywords=kaggle+book&amp;qid=1650818962&amp;sprefix=kaggle+book,aps,72&amp;sr=8-3&amp;linkCode=sl1&amp;tag=bnomial-20&amp;linkId=6cf9fd66daf5893153a64f03302971f7&amp;language=en_US&amp;ref_=as_li_ss_tl</a></p></li>
<li><p>“Target Leakage in Machine Learning” is a YouTube presentation that covers leakage, including during the partitioning of a dataset. <a class="reference external" href="https://www.youtube.com/watch?v=dWhdWxgt5SU">https://www.youtube.com/watch?v=dWhdWxgt5SU</a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="raine1997brain">
<h2>raine1997brain<a class="headerlink" href="#raine1997brain" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Murderers pleading not guilty by reason of insanity (NGRI).</p></li>
<li><p>Pre-disposition to less activity in their pre-frontal cortex.</p></li>
<li><p>Pre-frontal cortex associated with goal-directed planning and delayed gratification.</p></li>
<li><p>Different brain chemistry meant more likely to perform violent impulsive behaviour.</p></li>
<li><p>Justification for a lobotomy - electrocution of pre-frontal cortex - now replaced by antipsychotics.</p></li>
</ul>
</div></blockquote>
</section>
<section id="raissi2019physics">
<h2>raissi2019physics<a class="headerlink" href="#raissi2019physics" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations</p></li>
<li><p>Discussed by Bastiaan from <a class="reference internal" href="minutes.html#id78"><span class="std std-ref">2022-09-14 - Deep Learning</span></a></p></li>
</ul>
</div></blockquote>
</section>
<section id="ramesh2022hierarchical">
<h2>ramesh2022hierarchical<a class="headerlink" href="#ramesh2022hierarchical" title="Link to this heading"></a></h2>
<p>Hierarchical Text-Conditional Image Generation with CLIP Latents.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>a.k.a. Dalle 2 and Very popular on the internet.</p></li>
<li><p>Original was a d-VAE (discrete), Dalle 2 is a diffusion based model that uses CLIP.</p></li>
<li><p>CLIP trains an auto-enocder to have minimize the distance between image and text embeddings in the latent space.</p></li>
<li><p>Those image embeddings are fed to an autoregressive or diffusion prior to generate image embeddings.</p></li>
<li><p>Then this embedding is used to condition a diffusion decoder which produces an image.</p></li>
<li><p>The model is trained on 250 Million images, and has 3.5 billion parameters.</p></li>
<li><p>We can use CLIP to interpolate between two images in the latent space.</p></li>
<li><p>As we increase the dimensionality of the latent space we can represent more complex hierarchical structures.</p></li>
<li><p>CLIP fails at producing text, and reconstruction can mix up objects and their attributes.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>Available to the public on their website <a class="reference external" href="https://openai.com/dall-e-2/">https://openai.com/dall-e-2/</a></p></li>
<li><p>See <a class="reference internal" href="#ho2020denoising"><span class="std std-ref">(Ho 2022)</span></a> for Denoising Diffusion Probabilistic Models (DDPM), canonical diffusion paper.</p></li>
<li><p>See <a class="reference internal" href="#song2020denoising"><span class="std std-ref">(Song 2020)</span></a> for Denoising Diffusion Implicit Models (DDIM), faster diffusion process.</p></li>
<li><p>See <span class="xref std std-ref">2022-07-06 - Deep Learning</span></p></li>
<li><p>See <a class="reference internal" href="minutes.html#id98"><span class="std std-ref">2022-10-19 - Deep Learning</span></a></p></li>
<li><p>See <a class="reference internal" href="minutes.html#id134"><span class="std std-ref">2023-05-03 - Deep Learning</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="rampal2022high">
<h2>rampal2022high<a class="headerlink" href="#rampal2022high" title="Link to this heading"></a></h2>
<p>High-resolution downscaling with interpretable deep learning: Rainfall extremes over New Zealand</p>
<p>(Rampal 2020) propose CNN rainfall downscaling for prediction of extreme rainfall.</p>
<p>Available <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S2212094722001049">https://www.sciencedirect.com/science/article/pii/S2212094722001049</a></p>
<dl class="simple">
<dt>Data:</dt><dd><ul class="simple">
<li><p>Daily gridded accymlated ranfall from the Viritual Climatete Station network (VCSN), was used here as the predicted rainfall in statistical downscaling, and as the ground truth in out-of-sample testing period.</p></li>
<li><p>VCSN data covers the New Zealand regoion on a 0.05 degree grid, derived from sufrace interpolation of station weather data.</p></li>
<li><p>Precipitation biases are likely to occur in regions where station density is particularly low, namely across rugged and remote terrian like the Southern Alps.</p></li>
</ul>
</dd>
<dt>Method:</dt><dd><ul class="simple">
<li><p>The model trains predictor fields, the variables represent both dynamical and thermodynamical drivers of rainfall.</p></li>
<li><p>Loss functions of Mean Squared Error (MSE) and log-likelihood of Bernoilli-gamma distribution.</p></li>
<li><dl class="simple">
<dt>5 deep learning achrictures were evaluated</dt><dd><ol class="arabic simple">
<li><p>Non-linear CNN (Gamma)</p></li>
<li><p>Linear CNN</p></li>
<li><p>Non-linear Gamma</p></li>
<li><p>Linear Gamma</p></li>
<li><p>Linear Dense</p></li>
</ol>
</dd>
</dl>
</li>
<li><p>Explainabile AI, deep learning models are often referred to as black box models.</p></li>
<li><p>Gradient-weighted class-activation maps (Grad-Cam)</p></li>
<li><dl class="simple">
<dt>Alternative methods, salience maps and layerwise relevance propogation were considered.</dt><dd><ul>
<li><dl class="simple">
<dt>Saliency maps:</dt><dd><ul>
<li><p>but don’t necessarily imply importance. Instead, they show how the output changes when a set of predicotr values are slightly perturbed.</p></li>
<li><p>Saliency maps also tend to focus on local gradients in the input spoace whereas a more global view if odten required.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Layerwise relevance propogation (LRP):</dt><dd><ul>
<li><p>LRP is only available for a relatively small set of neural entwrok architectures.</p></li>
<li><p>Grad-CAM can be applied more widely.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Results:</dt><dd><ul class="simple">
<li><p>When spatially aggregates across the region, the fraciton of explained vaiation on wet days increased from 0.35 to 0.52. The existing dry bais for rainfall extremes decreased from approximately 40% to 15%.</p></li>
<li><p>Largest benefits came from implementing a probablistic loss function. Further improvements come from convolutional layers and non-linear activations.</p></li>
<li><p>Non-linear CNN is capable of outperforming existing statistical approaches, both in terms of variance and mean predictions for extreme rainfall.</p></li>
<li><p>The trained CNN could target the most relevant meteorological features. Suggests the model is capable of learning complex and physically plausible relationships.</p></li>
<li><p>Increasing the domain size over which predictor fields are sampled and increasing the number of training samples generally improves out-of-sample donwscaling performance. The domain size had less effect on linear models (i.e. low variance), sugggesting linear CNNs are better suited for extracting complex information across an extended domain.</p></li>
</ul>
</dd>
<dt>Why it matters?</dt><dd><ul class="simple">
<li><p>Simple CNN models can easily outperform statistical models on high-dimensional data.</p></li>
<li><p>Deep learning can be analyzed post-hoc, to build trust in the prediction, or may even lead to new insights.</p></li>
<li><p>Interpretable models are important bo build trust in their predictions. Also for troubleshooting/diagnosi, as in <a class="reference internal" href="#zhao2019maximum"><span class="std std-ref">(Zhao 2019</span></a>.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#lecun1989generalization"><span class="std std-ref">(Lecun 1989)</span></a> propsoed the original CNN as a shared weight network.</p></li>
<li><p><a class="reference internal" href="#wang2018evolving"><span class="std std-ref">(Wang 2018)</span></a> proposed EvoCNN, uses variable length PSO to perform neural architecture search.</p></li>
<li><p><a class="reference internal" href="#girshick2014rich"><span class="std std-ref">(Girsich 2014)</span></a> proposed R-CNN, a CNN with region proposals.</p></li>
<li><p><a class="reference internal" href="#bi2020gc"><span class="std std-ref">(Bi 2020)</span></a> used CNN to predict food flavor from GS-MS datasets.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="rasmussen2003gaussian">
<h2>rasmussen2003gaussian<a class="headerlink" href="#rasmussen2003gaussian" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Gaussian Processes in machine learning.</p></li>
</ul>
</div></blockquote>
</section>
<section id="restek2018high">
<h2>restek2018high<a class="headerlink" href="#restek2018high" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Explanation of gas-chromatraphy in food science for FAMEs.</p></li>
</ul>
</div></blockquote>
</section>
<section id="riad2022learning">
<h2>riad2022learning<a class="headerlink" href="#riad2022learning" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Learning strides in convolutional neural networks</p></li>
</ul>
</div></blockquote>
</section>
<section id="riccardo2009field">
<h2>riccardo2009field<a class="headerlink" href="#riccardo2009field" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>A Field Guide to Genetic Programming</p></li>
<li><p>A free resource for GP research available online.</p></li>
</ul>
</div></blockquote>
</section>
<section id="robinson2020genetic">
<h2>robinson2020genetic<a class="headerlink" href="#robinson2020genetic" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Demelza et al. proposed a feature and latent variable selection method for regression models in food science.</p></li>
<li><p>The vibrational spectroscopy dataset shared similarities in its high dimensionality and food science domain.</p></li>
<li><p>The purposes GA-PLSR generalized better and produced fewer complex models.</p></li>
<li><p>The study showed that Genetic Algorithms are powerful tools for feature selection in food science.</p></li>
</ul>
</div></blockquote>
</section>
<section id="robnik2003theoretical">
<h2>robnik2003theoretical<a class="headerlink" href="#robnik2003theoretical" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>releifF classifier.</p></li>
</ul>
</div></blockquote>
</section>
<section id="ronneberger2015u">
<h2>ronneberger2015u<a class="headerlink" href="#ronneberger2015u" title="Link to this heading"></a></h2>
<p>U-net: Convolutional networks for biomedical image segmentation</p>
<p>(Ronneberger 2015) propose U-Net <a class="reference internal" href="#ronneberger2015u"><span class="std std-ref">(Ronneberger 2015)</span></a></p>
<p>Available: <a class="reference external" href="https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28">https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <a class="reference internal" href="minutes.html#id187"><span class="std std-ref">2024-04-04 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="runarsson2000stochastic">
<h2>runarsson2000stochastic<a class="headerlink" href="#runarsson2000stochastic" title="Link to this heading"></a></h2>
<p>Stochastic ranking for constrained evolutionary optimization</p>
<p>(Runarsson 2000) used stocastic ranking (bubblesort variant) for constrained optimization with Evolutionary Computaiton.</p>
<dl>
<dt>Notes:</dt><dd><ul>
<li><p>Real-world problem has many constraints, e.g., linear, nonlinear, equality, inequality, …</p></li>
<li><dl>
<dt>It works better than other methods because</dt><dd><ul class="simple">
<li><p>More effective;</p></li>
<li><p>Good at dealing with non-differentiable</p></li>
</ul>
<p>and nonlinear problems;
* Avoid unnecessary and unrealistic
assumptions.</p>
</dd>
</dl>
</li>
<li><dl>
<dt>Stochastic Ranking</dt><dd><ul class="simple">
<li><p>It is a simple yet effective constraint</p></li>
</ul>
<p>handling method.
* It exploits the characteristics of
evolutionary algorithms.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#li2002novel"><span class="std std-ref">(Li 2002)</span></a>, by Xin Yao same author, use evolutionary computation to solve differentiral equations for deriving physics laws.</p></li>
<li><p><a class="reference internal" href="#li2002novel"><span class="std std-ref">(Li 2002)</span></a>, by Xin Yao same author, with EC for solving DE in materials science.</p></li>
<li><p><a class="reference internal" href="#handa2006robust"><span class="std std-ref">(Handa 2006)</span></a>, by Xin Yao same author, use evolutionary computation for route optimization for gritting trucks.</p></li>
<li><p><a class="reference internal" href="#schnier2004digital"><span class="std std-ref">(Schnier 2004)</span></a>, by Xin Yao same author, use evolutionary computation for multi-objective optimisation in computer hardware.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="russell2010artificial">
<h2>russell2010artificial<a class="headerlink" href="#russell2010artificial" title="Link to this heading"></a></h2>
<p>Artificial intelligence a modern approach</p>
<p>(Russell 2010) is the phat textbook I own on AI.</p>
</section>
<section id="saxe2013exact">
<h2>saxe2013exact<a class="headerlink" href="#saxe2013exact" title="Link to this heading"></a></h2>
<p>Exact solutions to the nonlinear dynamics of learning in deep linear neural networks</p>
<p>(Saxe 2013) proposes orthongal weight initialization.</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/1312.6120">https://arxiv.org/abs/1312.6120</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Pytorch <a class="reference external" href="https://pytorch.org/cppdocs/api/function_namespacetorch_1_1nn_1_1init_1a5978fcc257460475f635b5960e892a8e.html#exhale-function-namespacetorch-1-1nn-1-1init-1a5978fcc257460475f635b5960e892a8e">https://pytorch.org/cppdocs/api/function_namespacetorch_1_1nn_1_1init_1a5978fcc257460475f635b5960e892a8e.html#exhale-function-namespacetorch-1-1nn-1-1init-1a5978fcc257460475f635b5960e892a8e</a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="shahriari2015taking">
<h2>shahriari2015taking<a class="headerlink" href="#shahriari2015taking" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Taking the Human Out of theLoop: A Review of Bayesian Optimization.</p></li>
<li><p>Recommended reading from the <span class="xref std std-ref">2023-03-24 - FASLIP</span> on Bayesian Optimization</p></li>
<li><p><strong>TODO</strong> read this.</p></li>
</ul>
</div></blockquote>
</section>
<section id="schnier2004digital">
<h2>schnier2004digital<a class="headerlink" href="#schnier2004digital" title="Link to this heading"></a></h2>
<p>Digital filter design using multiple pareto fronts</p>
<p>(Schnier 2004) use evolutionary computation for multi-objective optimisation in computer hardware.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#li2002novel"><span class="std std-ref">(Li 2002)</span></a>, by Xin Yao same author, use evolutionary computation to solve differentiral equations for deriving physics laws.</p></li>
<li><p><a class="reference internal" href="#li2002novel"><span class="std std-ref">(Li 2002)</span></a>, by Xin Yao same author is another paper by same author, with EC for solving DE in materials science.</p></li>
<li><p><a class="reference internal" href="#runarsson2000stochastic"><span class="std std-ref">(Runarsson 2000)</span></a>, by Xin Yao same author, used stocastic ranking (bubblesort variant) for constrained optimization with Evolutionary Computaiton.</p></li>
<li><p><a class="reference internal" href="#handa2006robust"><span class="std std-ref">(Handa 2006)</span></a>, by Xin Yao same author, use evolutionary computation for route optimization for gritting trucks.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="scholkopf2000new">
<h2>scholkopf2000new<a class="headerlink" href="#scholkopf2000new" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Nu-SVC classifier.</p></li>
<li><p>Setting the number of support vectors is a hyper-parameter.</p></li>
<li><p>Usually this is learned by the system.</p></li>
</ul>
</div></blockquote>
</section>
<section id="shaukat2022state">
<h2>shaukat2022state<a class="headerlink" href="#shaukat2022state" title="Link to this heading"></a></h2>
<p>A state-of-the-art technique to perform cloud-based semantic segmentation using deep learning 3D U-Net architecture</p>
<p>(Shaukat 2022) use Dice pixel classification layer, a loss function for imbalanced datasets.</p>
<p>Available: <a class="reference external" href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-022-04794-9">https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-022-04794-9</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="minutes.html#id161"><span class="std std-ref">2023-11-30 FASLIP</span></a></p></li>
<li><p>Auhtor of <a class="reference internal" href="#emrah2022imbalance"><span class="std std-ref">(Emrah 2022)</span></a> uses Dice loss for imbalanced data.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="schulman2017proximal">
<h2>schulman2017proximal<a class="headerlink" href="#schulman2017proximal" title="Link to this heading"></a></h2>
<p>Proximal Policy Optimization Algorithms</p>
<p>(Schulman 2017) propose Proximal Policy Optimization (PPO) for reinforcement learning.</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/1707.06347">https://arxiv.org/abs/1707.06347</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="minutes.html#id148"><span class="std std-ref">2023-09-04 - Deep Learning</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="simonyan2014very">
<h2>simonyan2014very<a class="headerlink" href="#simonyan2014very" title="Link to this heading"></a></h2>
<p>Very deep convolutional networks for large-scale image recognition</p>
<p>(Simonyan 2014) is the original VGG paper.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#lecun1989backpropagation"><span class="std std-ref">(Lecun 1989)</span></a> proposed LeNet, the original CNN.</p></li>
<li><p><a class="reference internal" href="#krizhevsky2012imagenet"><span class="std std-ref">(Krizhevsky 2012)</span></a> proposed AlexNet, the first CNN to win ImageNet.</p></li>
<li><p><a class="reference internal" href="#he2016deep"><span class="std std-ref">(He 2016)</span></a> proposed ResNet, a CNN with residual connections.</p></li>
<li><p><a class="reference internal" href="#szegedy2015going"><span class="std std-ref">(Szegedy 2015)</span></a> proposed GoogLeNet, a CNN with inception modules.</p></li>
<li><p><a class="reference internal" href="#huang2017densely"><span class="std std-ref">(Huang 2017)</span></a> proposed DenseNet, a CNN with dense connections.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="smart2005using">
<h2>smart2005using<a class="headerlink" href="#smart2005using" title="Link to this heading"></a></h2>
<p>Genetic programming for multiclass object classification.</p>
<p>(Smart 2005) describe classification maps as a method for mutli-class classification using GP.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Using genetic programming for multiclass classification by simultaneously solving component binary classification problems</p></li>
<li><p>Multi-class classification with Genetic Programs using a Classification Map (CM).</p></li>
<li><p>Maps a float to a classification label using a classification map.</p></li>
<li><p>Create class boundaries sequentially on a floating point number line.</p></li>
<li><p>If program output is within a class boundary, it belongs to that class.</p></li>
<li><p>For multi-class classification, their is an identical interval of 1.0.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See proposal for preliminary work section, where classification maps are used.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="sobel1990isotropic">
<h2>sobel1990isotropic<a class="headerlink" href="#sobel1990isotropic" title="Link to this heading"></a></h2>
<p>An Isotropic 3x3 Image Gradient Operator</p>
<p>Available: <a class="reference external" href="https://www.researchgate.net/publication/239398674_An_Isotropic_3x3_Image_Gradient_Operator">https://www.researchgate.net/publication/239398674_An_Isotropic_3x3_Image_Gradient_Operator</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <a class="reference internal" href="minutes.html#id152"><span class="std std-ref">2023-10-12 - FASLIP</span></a></p></li>
<li><p>See history of Sobel operator <a class="reference internal" href="#sobel2014history"><span class="std std-ref">(Sobel 2014)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="sobel2014history">
<h2>sobel2014history<a class="headerlink" href="#sobel2014history" title="Link to this heading"></a></h2>
<p>History and Definition of the so-called “Sobel Operator”,more appropriately named th eSobel-Feldman Operator</p>
<p>Available: <a class="reference external" href="https://www.researchgate.net/publication/239398674_An_Isotropic_3x3_Image_Gradient_Operator">https://www.researchgate.net/publication/239398674_An_Isotropic_3x3_Image_Gradient_Operator</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <a class="reference internal" href="minutes.html#id152"><span class="std std-ref">2023-10-12 - FASLIP</span></a></p></li>
<li><p>See history of Sobel operator <a class="reference internal" href="#sobel2014history"><span class="std std-ref">(Sobel 2014)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="sobieczky1999parametric">
<h2>sobieczky1999parametric<a class="headerlink" href="#sobieczky1999parametric" title="Link to this heading"></a></h2>
<p>Parametric Airfoils and Wings</p>
<p>(Sobieczky 1999) propose the PARSEC parametric airfoil and wing design system.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Parameteric model that uses 11 or 12 parameters to repreent major structural sectional features of an airfoil.</p></li>
<li><dl class="simple">
<dt>Including:</dt><dd><ul>
<li><p>leading edge radii,</p></li>
<li><p>upper and lower crest location,</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Constructs an airfoil using a sixth-order polynomial.</p></li>
</ul>
</dd>
</dl>
<p>Available: <a class="reference external" href="https://link.springer.com/chapter/10.1007/978-3-322-89952-1_4">https://link.springer.com/chapter/10.1007/978-3-322-89952-1_4</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>This real-world task is discussed in <a class="reference internal" href="minutes.html#id143"><span class="std std-ref">2023-09-07 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="sohl2015deep">
<h2>sohl2015deep<a class="headerlink" href="#sohl2015deep" title="Link to this heading"></a></h2>
<p>Deep unsupervised learning using nonequilibrium thermodynamics</p>
<p>(Sohl 2015) borrow ideas from thermodynamics denoising autoencoders.</p>
<p>Available: <a class="reference external" href="http://proceedings.mlr.press/v37/sohl-dickstein15.html">http://proceedings.mlr.press/v37/sohl-dickstein15.html</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <a class="reference internal" href="minutes.html#id150"><span class="std std-ref">2023-08-11 - Deep Learning</span></a></p></li>
<li><p>Used in InstaFlow <span class="xref std std-ref">(Liu 2023)</span></p></li>
<li><p>DDPM <a class="reference internal" href="#ho2020denoising"><span class="std std-ref">(Ho 2022)</span></a></p></li>
<li><p>DDIM <a class="reference internal" href="#song2020denoising"><span class="std std-ref">(Song 2020)</span></a></p></li>
<li><p>Consistency models <a class="reference internal" href="#song2023consistency"><span class="std std-ref">(Song 2023)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="song2020denoising">
<h2>song2020denoising<a class="headerlink" href="#song2020denoising" title="Link to this heading"></a></h2>
<p>Denoising diffusion implicit models.</p>
<p>(Song 2020) propose Denoising Diffusion Implicit Models (DDIM) a generalized DDPM that is faster and deterministic.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>TODO [ ] Read this paper!</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="#ho2020denoising"><span class="std std-ref">(Ho 2022)</span></a> for original DDPM paper.</p></li>
<li><p>See <span class="xref std std-ref">2022-07-06 - Deep Learning</span></p></li>
<li><p>See <a class="reference internal" href="minutes.html#id98"><span class="std std-ref">2022-10-19 - Deep Learning</span></a></p></li>
<li><p>Stable Diffusion <a class="reference external" href="https://github.com/CompVis/stable-diffusion">https://github.com/CompVis/stable-diffusion</a></p></li>
<li><p>Deforum Notebook <a class="reference external" href="https://t.co/mWNkzWtPsK">https://t.co/mWNkzWtPsK</a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="song2023consistency">
<h2>song2023consistency<a class="headerlink" href="#song2023consistency" title="Link to this heading"></a></h2>
<p>Consistency Models</p>
<p><a class="reference external" href="https://arxiv.org/abs/2303.01469">(Song 2023)</a> proposes consistency models, a faster alternative to diffusion. [Available] <a class="reference external" href="https://arxiv.org/abs/2303.01469">https://arxiv.org/abs/2303.01469</a></p>
<dl class="simple">
<dt>Background:</dt><dd><ul class="simple">
<li><p>OpenAI paper, so it’s a big deal.</p></li>
<li><p>OpenAI, ChatGPT, GPT-3/4/5, Bing, DALLE-2</p></li>
</ul>
</dd>
<dt>Motivations:</dt><dd><ul class="simple">
<li><p>inpainting, colorization, and super-resolution</p></li>
<li><p>inpainting: remove objects, fill in missing pixels</p></li>
<li><p>photograph-to-drawing (and vice versa)</p></li>
</ul>
</dd>
<dt>Data:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>Trained as either:</dt><dd><ol class="arabic simple">
<li><p>distilling an existing pre-trained DM</p></li>
<li><p>standalone generative models</p></li>
</ol>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Method:</dt><dd><ul class="simple">
<li><p>The math in figure 1 &amp; 2 <a class="reference external" href="https://twitter.com/jrhwood/status/1653620236145528833?s=20">https://twitter.com/jrhwood/status/1653620236145528833?s=20</a></p></li>
<li><p>Artificial noise is added to pictures.</p></li>
<li><p>Consistency models learn to map and reverse that noise process,</p></li>
<li><p>track the ODE trajectory back to its origin,</p></li>
<li><p>i.e. the denoised original input image.</p></li>
</ul>
</dd>
<dt>Results:</dt><dd><ul class="simple">
<li><p>See figure 12 <a class="reference external" href="https://twitter.com/jrhwood/status/1653625255238459394?s=20">https://twitter.com/jrhwood/status/1653625255238459394?s=20</a></p></li>
<li><p>(top) the same input image with different levels of noise, and,</p></li>
<li><p>(bottom) the output of the consistency model.</p></li>
<li><p>The model <em>consistently</em> denoised very similar images, that closely resemble the original input image, and each other.</p></li>
</ul>
</dd>
<dt>Why it matters?</dt><dd><ul class="simple">
<li><p>Consistency models are based on diffusion, but cheaper for inference and at least as good as SOTA.</p></li>
<li><p>Explicit fast one-step generation by design.</p></li>
<li><p>(Optional) few-step sampling, improves quality with more compute needed.</p></li>
<li><p>Zero-shot editing without explicit training.</p></li>
</ul>
</dd>
<dt>Limitations:</dt><dd><ul class="simple">
<li><p>Text information is not encoded in the embedding space.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="#ho2020denoising"><span class="std std-ref">(Ho 2022)</span></a> for original DDPM paper.</p></li>
<li><p>See <span class="xref std std-ref">2022-07-06 - Deep Learning</span></p></li>
<li><p>See <a class="reference internal" href="minutes.html#id98"><span class="std std-ref">2022-10-19 - Deep Learning</span></a></p></li>
<li><p>Stable Diffusion <a class="reference external" href="https://github.com/CompVis/stable-diffusion">https://github.com/CompVis/stable-diffusion</a></p></li>
<li><p>Deforum Notebook <a class="reference external" href="https://t.co/mWNkzWtPsK">https://t.co/mWNkzWtPsK</a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="stewart2022quarry">
<h2>stewart2022quarry<a class="headerlink" href="#stewart2022quarry" title="Link to this heading"></a></h2>
<p>QUARRY: A Graph Model for Queryable Association Rules</p>
<p>(Stewart 2022) propose QUARRY a model for association rule mining from short technical text in maintenance data.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See 2022-12-05 - AJCAI #01, author gave workshop on knowledge graphs.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="srivastava2014dropout">
<h2>srivastava2014dropout<a class="headerlink" href="#srivastava2014dropout" title="Link to this heading"></a></h2>
<p>Dropout: a simple way to prevent neural networks from overfitting</p>
<p>(Srivastava 2014) propose dropout for regularization in neural networks.</p>
<p>Available: <a class="reference external" href="https://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf">https://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Also about regularization <a class="reference internal" href="#hinton2012improving"><span class="std std-ref">(Hinton 2012)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="sun2022soknl">
<h2>sun2022soknl<a class="headerlink" href="#sun2022soknl" title="Link to this heading"></a></h2>
<p>SOKNL: A novel way of integrating K-nearest neighbours with adaptive random forest regression for data streams</p>
<p>(Sun 2022) proposes self optimizing k-nearest neighbours (SOKNL) for data stream mining.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="minutes.html#id131"><span class="std std-ref">2023-02-16 - FASLIP</span></a> where author gave talk on this paper.</p></li>
<li><p>Another author discussed this paper on <a class="reference internal" href="minutes.html#id175"><span class="std std-ref">2024-02-13 - ECRG</span></a>.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="szegedy2013intriguing">
<h2>szegedy2013intriguing<a class="headerlink" href="#szegedy2013intriguing" title="Link to this heading"></a></h2>
<p>Intriguing properties of neural networks.</p>
<p>(Szegedy 2013) uses adversarial attacks on neural networks to find exploits.</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/1312.6199">https://arxiv.org/abs/1312.6199</a></p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Adversarial attacks on neural networks.</p></li>
<li><p>Trick neural nets into making the wrong prediction on purpose.</p></li>
<li><p>Long tail problem of AI.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>Same author, GoogLeNet <a class="reference internal" href="#szegedy2015going"><span class="std std-ref">(Szegedy 2015)</span></a></p></li>
<li><p>Same author, label smoothing <a class="reference internal" href="#szegedy2016rethinking"><span class="std std-ref">(Szegedy 2016)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="szegedy2015going">
<h2>szegedy2015going<a class="headerlink" href="#szegedy2015going" title="Link to this heading"></a></h2>
<p>Going deeper with convolutions</p>
<p>(Szegedy 2015) propose GoogLeNet, a CNN with inception modules.</p>
<p>Available: <a class="reference external" href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Szegedy_Going_Deeper_With_2015_CVPR_paper.html">https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Szegedy_Going_Deeper_With_2015_CVPR_paper.html</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Same author, label smoothing <a class="reference internal" href="#szegedy2016rethinking"><span class="std std-ref">(Szegedy 2016)</span></a></p></li>
<li><p>Same author, adversarial attacks on NNs <a class="reference internal" href="#szegedy2013intriguing"><span class="std std-ref">(Szegedy 2013)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="szegedy2016rethinking">
<h2>szegedy2016rethinking<a class="headerlink" href="#szegedy2016rethinking" title="Link to this heading"></a></h2>
<p>Rethinking the inception architecture for computer vision</p>
<p>(Szegedy 2016) proposed label smoothing for deep neural networks.</p>
<p>Available: <a class="reference external" href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.html">https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.html</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Medium article: <a class="reference external" href="https://medium.com/&#64;nainaakash012/when-does-label-smoothing-help-89654ec75326">https://medium.com/&#64;nainaakash012/when-does-label-smoothing-help-89654ec75326</a></p></li>
<li><p>Papers with code: <a class="reference external" href="https://paperswithcode.com/method/label-smoothing">https://paperswithcode.com/method/label-smoothing</a></p></li>
<li><p>Same author, GoogLeNet <a class="reference internal" href="#szegedy2015going"><span class="std std-ref">(Szegedy 2015)</span></a></p></li>
<li><p>Same author, GoogLeNet <a class="reference internal" href="#szegedy2015going"><span class="std std-ref">(Szegedy 2015)</span></a></p></li>
<li><p>Same author, adversarial attacks on NNs <a class="reference internal" href="#szegedy2013intriguing"><span class="std std-ref">(Szegedy 2013)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="tran2019genetic">
<h2>tran2019genetic<a class="headerlink" href="#tran2019genetic" title="Link to this heading"></a></h2>
<p>Genetic programming for multiple-feature construction on high-dimensional classification.</p>
<p>(Tran 2019) propose multiple multi-tree GP methods for multi-class classification problems, including multi class-indepdent feature construction (MCIFC).</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Genetic programming for multiple-feature construction on high-dimensional Classification Data</p></li>
<li><p>This paper includes an example of Multi-tree GP.</p></li>
<li><p>I have apply Multi-tree GP for a one-vs-all multi-class classification problem.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See proposal for preliminary work section, MCIFC is used.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="tegmark2020aifeynman">
<h2>tegmark2020aifeynman<a class="headerlink" href="#tegmark2020aifeynman" title="Link to this heading"></a></h2>
<p>AI Feynman: A physics-inspired method for symbolic regression</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Tegmark et al. developed they AI Feynman cite{udrescu2020ai}.</p></li>
<li><p>This algorithm can derive physics equations from data using symbolic regression.</p></li>
<li><p>Symbolic regression is a difficult task, but by simplifying properties exhibited by physics equations (i.e symmetry, composability, separability), the problem can be reduced.</p></li>
<li><p>Their work uses blackbox neural networks, to derive interpretable models that can easily be verified by humans.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="#tegmark2020aifeynman2"><span class="std std-ref">(Tegmark 2022)</span></a> for the second iteration.</p></li>
<li><p>Banzahf discussed the Feynman AI benchmark dataset at 2022-10-28 - ECRG.</p></li>
<li><p>He employed correlation + linear scaling to exploit the shape of the data, a global measure, to find the best fit and reduce the search space.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="tegmark2020aifeynman2">
<h2>tegmark2020aifeynman2<a class="headerlink" href="#tegmark2020aifeynman2" title="Link to this heading"></a></h2>
<p>AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>2nd iteration for the AI Feynman 2.0.</p></li>
<li><p>More robust towards noise and bad data.</p></li>
<li><p>Can discover more formulas that previous method.</p></li>
<li><p>Implements Normalizaing flows.</p></li>
<li><p>Method for generalized symmetries (abitrary modularity in the compuational graph formula)</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="#tegmark2020aifeynman"><span class="std std-ref">(Tegmark 2020)</span></a> for the original AI Feynman.</p></li>
<li><p>Banzahf discussed the Feynman AI benchmark dataset at 2022-10-28 - ECRG.</p></li>
<li><p>He employed correlation + linear scaling to exploit the shape of the data, a global measure, to find the best fit and reduce the search space.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="tegmark2021aipoincare">
<h2>tegmark2021aipoincare<a class="headerlink" href="#tegmark2021aipoincare" title="Link to this heading"></a></h2>
<p>AI Poincaré 2.0: Machine Learning Conservation Laws from Differential Equations</p>
<p>(Temark 2021) use deep learning to model conservation laws from physics.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>TODO [ ] READ</p></li>
</ul>
</dd>
</dl>
</section>
<section id="tegmark2022poisson">
<h2>tegmark2022poisson<a class="headerlink" href="#tegmark2022poisson" title="Link to this heading"></a></h2>
<p>Poisson Flow Generative Models</p>
<p>(Tegmark 2022) propose Poisson Flow Generative Models (PFGM)&lt; which map a uniform distribution on a high-diemsnaioal hemisphere into any data distriubtion.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>TODO [ ] READ</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="minutes.html#id102"><span class="std std-ref">2022-10-26 - Deep Learning</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="tomasi2004correlation">
<h2>tomasi2004correlation<a class="headerlink" href="#tomasi2004correlation" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Tomasi et al. investigated correlation optimisation warping (COW) and dynamic time warping (DT) for preprocessing chromatography data.</p></li>
<li><p>Unconstrained dynamic time warping was found to be too flexible.</p></li>
<li><p>The algorithm overcompensated when trying to fix the alignment in the data.</p></li>
</ul>
</div></blockquote>
</section>
<section id="tran2018variable">
<h2>tran2018variable<a class="headerlink" href="#tran2018variable" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Tran et al. propose a Variable-Length PSO.</p></li>
<li><p>Traditional PSO methods for feature selection are limited in the fixed length of their representation.</p></li>
<li><p>This leads to both high memory usage and computational cost.</p></li>
<li><p>The proposed algorithm allows particles to have shorter and different variable lengths.</p></li>
<li><p>Their length changing mechanism allows PSO to escape local optima.</p></li>
<li><p>Results across several high dimensional datasets showed improved performance in terms of computational time, fewer features selected and classification accuracy.</p></li>
</ul>
</div></blockquote>
</section>
<section id="van2008visualizing">
<h2>van2008visualizing<a class="headerlink" href="#van2008visualizing" title="Link to this heading"></a></h2>
<p>Visualizing data using t-SNE.</p>
<p>(Van 2008) prose t-distributed stochastic neighbor embedding (t-SNE) for visualizing high-dimensional data.</p>
<dl>
<dt>Method:</dt><dd><ul class="simple">
<li><p>The t-SNE algorithm comprises two main stages.</p></li>
</ul>
<ol class="arabic simple">
<li><p>First, t-SNE constructs a probability distribution over pairs of high-dimensional objects in such a way that similar objects are assigned a higher probability while dissimilar points are assigned a lower probability.</p></li>
<li><p>Second, t-SNE defines a similar probability distribution over the points in the low-dimensional map, and it minimizes the Kullback-Leibler divergence (KL divergence) between the two distributions with respect to the locations of the points in the map.</p></li>
</ol>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="#goodfellow2016deep"><span class="std std-ref">(Goodfellow 2016)</span></a> chapter 3 pg. 72 for a derivation of Kullback-Leibler divergence.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="vaswani2017attention">
<h2>vaswani2017attention<a class="headerlink" href="#vaswani2017attention" title="Link to this heading"></a></h2>
<p>Attention is all you need</p>
</section>
<section id="vincent2011connection">
<h2>vincent2011connection<a class="headerlink" href="#vincent2011connection" title="Link to this heading"></a></h2>
<p>A connection between score matching and denoising autoencoders</p>
<p>(Vincent 2011) propose a connection between score matching and denoising autoencoders.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Denoising score matcher</p></li>
<li><p>Shows a simple denoising autoencoder training criterion is equivalent to matvching the score (with respect to the data) of a specific energy-based model to that of a nonparametric Pazen density estimator of the data.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="#goodfellow2016deep"><span class="std std-ref">(Goodfellow 2016)</span></a> chapter 16, page 567, [Available] <a class="reference external" href="https://www.deeplearningbook.org/contents/graphical_models.html">https://www.deeplearningbook.org/contents/graphical_models.html</a></p></li>
<li><p>See <a class="reference internal" href="minutes.html#id134"><span class="std std-ref">2023-05-03 - Deep Learning</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="volz2018evolving">
<h2>volz2018evolving<a class="headerlink" href="#volz2018evolving" title="Link to this heading"></a></h2>
<p>Evolving mario levels in the latent space of a deep convolutional generative adversarial network</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#perez2019analysis"><span class="std std-ref">(Perez 2019)</span></a> same author uses RHEA to design Game AI for ponnerman.</p></li>
<li><p><a class="reference internal" href="#goodman2020weighting"><span class="std std-ref">(Goodman 2020)</span></a> same user uses NBTEA to choose hyperparameters for balancing gamemplay.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="von1986decision">
<h2>von1986decision<a class="headerlink" href="#von1986decision" title="Link to this heading"></a></h2>
<p>“Decision trees”. Decision Analysis and Behavioral Research.</p>
<p>(Von 1986) is cited on wikipedia for decision trees.</p>
<p>Available: <a class="reference external" href="https://cir.nii.ac.jp/crid/1130000795953711872">https://cir.nii.ac.jp/crid/1130000795953711872</a></p>
<dl class="simple">
<dt>notes:</dt><dd><ul class="simple">
<li><p>see pp. 63-89, an excerpt from the book, Decision Analysis and Behavioural Research,</p></li>
<li><p>decision trees are an algorithm that only contains conditional control statements, i.e. if-else statements.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#breiman2017classification"><span class="std std-ref">(Breiman 1984)</span></a> proposed the original CART algorithm for decision trees.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="wang2018evolving">
<h2>wang2018evolving<a class="headerlink" href="#wang2018evolving" title="Link to this heading"></a></h2>
<p>Evolving deep convolutional neural networks by variable-length particle swarm optimization for image classification</p>
<p>(Wang 2018) propose EvoCNN to automatically search for optimal CNN architecture without any manual work involved.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="minutes.html#id104"><span class="std std-ref">2022-10-27 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="wang2020linformer">
<h2>wang2020linformer<a class="headerlink" href="#wang2020linformer" title="Link to this heading"></a></h2>
<p>Linformer: Self-attention with linear complexity},</p>
<p><cite>(Wang 2020) &lt;https://arxiv.org/abs/2006.04768&gt;</cite> propose Linformer an <span class="math notranslate nohighlight">\(O(n)\)</span> appromimation of self-attention.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Self-attention mechanism can be approximated with a low rank matrix.</p></li>
<li><p>Reduces space and time complexity from <span class="math notranslate nohighlight">\(O(n^2)\)</span> to <span class="math notranslate nohighlight">\(O(n)\)</span>.</p></li>
<li><p>Performance on par with standard transformer models, whilst being much more memory and time efficient.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="#peng2023rwkv"><span class="std std-ref">(Peng 2023)</span></a> is inspired by Linformer.</p></li>
<li><p>See <a class="reference internal" href="#zhai2021attention"><span class="std std-ref">(Zhai 2021)</span></a> for Attention Free Transformer (AFT).</p></li>
<li><p>See <a class="reference internal" href="#wang2020linformer"><span class="std std-ref">(Wang 2020)</span></a> for Linformer paper.</p></li>
<li><p>See <a class="reference internal" href="#kitaev2020reformer"><span class="std std-ref">(Kitaev 2020)</span></a> for Reformer paper.</p></li>
<li><p>See <a class="reference internal" href="#katharopoulos2020transformers"><span class="std std-ref">(Katharopoulos 2020)</span></a> for linear transformers.</p></li>
<li><p>See <a class="reference internal" href="#vaswani2017attention"><span class="std std-ref">(Vaswani 2017)</span></a> for transformer paper.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="watkins1992q">
<h2>watkins1992q<a class="headerlink" href="#watkins1992q" title="Link to this heading"></a></h2>
<p>Q-learning</p>
<p>(Watkins 1992) proposed q-learning, the foundation of reinforcment learning.</p>
<dl class="simple">
<dt>Related :</dt><dd><ul class="simple">
<li><p>See 2022-12-05 - AJCAI #01</p></li>
</ul>
</dd>
</dl>
</section>
<section id="wayne2018unsupervised">
<h2>wayne2018unsupervised<a class="headerlink" href="#wayne2018unsupervised" title="Link to this heading"></a></h2>
<p>Unsupervised Predictive Memory in a Goal-Directed Agent</p>
<p>(Wayne 2018) propose the Memory, RL, and Inference Network (MERLIN), in which memory formation is guided by a process of predictive modeling.</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See 2022-12-05 - AJCAI #01</p></li>
</ul>
</dd>
</dl>
</section>
<section id="weinstein2022hunter">
<h2>weinstein2022hunter<a class="headerlink" href="#weinstein2022hunter" title="Link to this heading"></a></h2>
<p>A Hunter Gatherer’s Guide to the 21st Century (Book).</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>pg. 229 “Evolutionary stable strategy - A strategy incapable of invasion by competitors”</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>Steady-state algorithm mentioned in <a class="reference internal" href="minutes.html#id93"><span class="std std-ref">2022-08-06 - ECRG</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="white2023neural">
<h2>white2023neural<a class="headerlink" href="#white2023neural" title="Link to this heading"></a></h2>
<p>Neural Architecture Search: Insights from 1000 Papers</p>
<p>(White 2023) is a literature survey of NAS.</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/2301.08727">https://arxiv.org/abs/2301.08727</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="#zoph2016neural"><span class="std std-ref">(Zoph 2016)</span></a> paper that popularized NAS.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="wood2022automated">
<h2>wood2022automated<a class="headerlink" href="#wood2022automated" title="Link to this heading"></a></h2>
<p>Automated Fish Classification Using Unprocessed Fatty Acid Chromatographic Data: A Machine Learning Approach</p>
<p>Available: <a class="reference external" href="https://woodrock.github.io/#/AJCAI">https://woodrock.github.io/#/AJCAI</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><a class="reference internal" href="#black2017real"><span class="std std-ref">(Black 2017)</span></a> used REIMS for fish fraud detection.</p></li>
<li><p><span class="xref std std-ref">()</span></p></li>
</ul>
</dd>
</dl>
</section>
<section id="wolpert1997no">
<h2>wolpert1997no<a class="headerlink" href="#wolpert1997no" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>No free lunch theorum.</p></li>
<li><p>No classification algorithm that beats the rest for every problem.</p></li>
<li><p>As training instances approaches infinity, classification accuracy on all distributions of noise, approaches predicting mean class.</p></li>
<li><p>All machine learning algorithms are task specific, don’t generalize to all problems, no artifical general intelligence (AGI), yet…</p></li>
</ul>
</div></blockquote>
</section>
<section id="xie2022physics">
<h2>xie2022physics<a class="headerlink" href="#xie2022physics" title="Link to this heading"></a></h2>
<p>A Physics-Guided Reversible Residual Neural Network Model: Applied to Build Forward and Inverse Models for Turntable Servo System</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Author gave talk in <a class="reference internal" href="minutes.html#id138"><span class="std std-ref">2023-05-25 - FASLIP</span></a></p></li>
<li><p>Residual Neural Networks - Resnet, see <a class="reference internal" href="#he2016deep"><span class="std std-ref">(He 2016)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="xiong2020layer">
<h2>xiong2020layer<a class="headerlink" href="#xiong2020layer" title="Link to this heading"></a></h2>
<p>On layer normalization in the transformer architecture</p>
<p>(Xiong 2020) propose the Pre-Layer Normalization (Pre-LN) for transformers.</p>
<p>Available: <a class="reference external" href="https://proceedings.mlr.press/v119/xiong20b">https://proceedings.mlr.press/v119/xiong20b</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Transformers <a class="reference internal" href="#vaswani2017attention"><span class="std std-ref">(Vaswani 2017)</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="xie2017aggregated">
<h2>xie2017aggregated<a class="headerlink" href="#xie2017aggregated" title="Link to this heading"></a></h2>
<p>Aggregated residual transformations for deep neural networks</p>
<p>(Xie 2017) propose the ResNeXt family of models for biomdeical image segmentation.</p>
<p>Available: <a class="reference external" href="https://openaccess.thecvf.com/content_cvpr_2017/html/Xie_Aggregated_Residual_Transformations_CVPR_2017_paper.html">https://openaccess.thecvf.com/content_cvpr_2017/html/Xie_Aggregated_Residual_Transformations_CVPR_2017_paper.html</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <a class="reference internal" href="minutes.html#id187"><span class="std std-ref">2024-04-04 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="xin2022current">
<h2>xin2022current<a class="headerlink" href="#xin2022current" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Do Current Multi-Task Optimization Methods in Deep Learning Even Help?</p></li>
<li><p>A paper that is strongly against mutli-task learning.</p></li>
<li><p>TODO [ ] READ</p></li>
</ul>
</div></blockquote>
</section>
<section id="xue2014particle">
<h2>xue2014particle<a class="headerlink" href="#xue2014particle" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Brown et al. proposed a PSO with novel initialising and updating mechanisms.</p></li>
<li><p>The initialization strategy utilized both forward and backwards selection.</p></li>
<li><p>The updating mechanism overcame the limitations of the traditional method by considering the number of features.</p></li>
<li><p>The proposed algorithm had better performance in terms of computing, fewer features selected and classification accuracy.</p></li>
</ul>
</div></blockquote>
</section>
<section id="xue2015survey">
<h2>xue2015survey<a class="headerlink" href="#xue2015survey" title="Link to this heading"></a></h2>
<p>A survey on evolutionary computation approaches to feature selection</p>
<p>(Xue 2015) is a literature survey of EC methods for feature selection</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Ruwang quoted this paper in <a class="reference internal" href="minutes.html#id165"><span class="std std-ref">2023-12-08 - ECRG</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="yang2022noise">
<h2>yang2022noise<a class="headerlink" href="#yang2022noise" title="Link to this heading"></a></h2>
<p>Noise-Aware Sparse Gaussian Processes and Application to Reliable Industrial Machinery Health Monitoring</p>
<p>(Yang 2022) proposed a Noise-Aware Sparse Gaussain Process (NASGP) with Bayesian Inference Network.</p>
<p>Available: <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/9864068/">https://ieeexplore.ieee.org/abstract/document/9864068/</a></p>
<dl class="simple">
<dt>Data:</dt><dd><ul class="simple">
<li><p>Domain - maintainace of machinary equipment requires real-time health monitoring. Most state-of-the-art models require high quality monitoring data, but are not robust to noise present in real-world applications.</p></li>
<li><p>Problem - predict an estimate of the reamining useful life of machinary equipment using noisy data.</p></li>
</ul>
</dd>
<dt>Method:</dt><dd><ul class="simple">
<li><p>Noise-Awate Sparse Gaussain Processes (NASGP) + Bayesian Inference Network.</p></li>
</ul>
</dd>
<dt>Results:</dt><dd><ul class="simple">
<li><p>NASGP are capable of high-performance and credible assessment under strong noises.</p></li>
<li><p>Developed a generative additive model to bridge the gap between latent inference mechanism and domain expert knowledge.</p></li>
<li><p>Method worked well in two different domains: (1) remaining useful life prognosis, (2) fault diagnosis in rolling bearings.</p></li>
</ul>
</dd>
<dt>Why it matters?</dt><dd><ul class="simple">
<li><p>The method is robust to noise, and can be applied to real-world applications, not just academic benchmarks (toy datasets).</p></li>
<li><p>Method provides a generative additive model that works well in two different domains.</p></li>
<li><p>Important to monitor machinary equipment in real-world applications, to ensure safety, automation, and efficiency.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="minutes.html#id94"><span class="std std-ref">2022-10-12 - Deep Learning</span></a> for more</p></li>
</ul>
</dd>
</dl>
</section>
<section id="yu2019adapting">
<h2>yu2019adapting<a class="headerlink" href="#yu2019adapting" title="Link to this heading"></a></h2>
<p>Adapting BERT for target-oriented multimodal sentiment classification</p>
<p>(Yu 2019) propose TomBERT for multi-modal sentiment classification.</p>
<p>Available: <a class="reference external" href="https://ink.library.smu.edu.sg/sis_research/4441/">https://ink.library.smu.edu.sg/sis_research/4441/</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Discussed in <a class="reference internal" href="minutes.html#id179"><span class="std std-ref">2024-02-29 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="zemmal2016adaptative">
<h2>zemmal2016adaptative<a class="headerlink" href="#zemmal2016adaptative" title="Link to this heading"></a></h2>
<p>Adaptative S3VM Semi Supervised Learning with Features Cooperation for Breast Cancer Classification</p>
<p>(Zemmal 2016) propose S3VM, a semi-supverised SVM, that combines labelled and unlablled datasets, to improve SVM performance for Breast Cancer Classification.</p>
<dl class="simple">
<dt>Data:</dt><dd><ul class="simple">
<li><p>Domain - breast cancer is the most common cause of cancer and the second leading cause of all cancer deaths. Early detection in the intiial stages of cancer is crucial for survival.</p></li>
<li><p>Problem - Breast Cancer Classification with computer-aided diagnosis (CAD), to classify breast cancer tumours as malignant or benign.</p></li>
<li><p>Collecting data is expensive and time-consuming, practitioners wait 5 years after treatment to label a patient as survived or not. Label annotation of the datasets is a slow processs, but their is an abundance of unlabelled data.</p></li>
</ul>
</dd>
<dt>Method:</dt><dd><ul class="simple">
<li><p>Supervised + unsupervised learning to boost SVM performance.</p></li>
<li><p>Using unlabeleld data (unsupervised) to ensure the decision boundaries are drawn through low density areas.</p></li>
</ul>
</dd>
<dt>Results:</dt><dd><ul class="simple">
<li><p>Evaluate method by increasing the proportion of labelled-to-unlabelled data for each test (rarely, moderately low, moderate).</p></li>
<li><p>Promising results were validated on a real-world dataset of 200 images.</p></li>
</ul>
</dd>
<dt>Why it matters?</dt><dd><ul class="simple">
<li><p>SVM performance can be improved by using unlabelled data.</p></li>
<li><p>Unlabelled data is abundant, but expensive to label. Methods that utilize unlabelled data are cheap, efficient, and improve performance.</p></li>
<li><p>Early cancer detection is crucial for survival.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>TODO [ ] - read.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="zhai2021attention">
<h2>zhai2021attention<a class="headerlink" href="#zhai2021attention" title="Link to this heading"></a></h2>
<p>An attention free transformer</p>
<p><a class="reference external" href="https://arxiv.org/abs/2105.14103">(Zhai 2021)</a> is an apple paper that presents the Attenion Free Transformer (AFT).</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Recurent Neural Network for inference.</p></li>
<li><p>Cheaper inference method for GPT-like transformer models.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <span class="xref std std-ref">2023-06-10 - Deep Learning</span> where paper was dicussed.</p></li>
<li><p>See <a class="reference internal" href="#peng2023rwkv"><span class="std std-ref">(Peng 2023)</span></a> for RWKV paper that builds on this.</p></li>
<li><p>See <a class="reference internal" href="#wang2020linformer"><span class="std std-ref">(Wang 2020)</span></a> for Linformer paper.</p></li>
<li><p>See <a class="reference internal" href="#kitaev2020reformer"><span class="std std-ref">(Kitaev 2020)</span></a> for Reformer paper.</p></li>
<li><p>See <a class="reference internal" href="#katharopoulos2020transformers"><span class="std std-ref">(Katharopoulos 2020)</span></a> for linear transformers.</p></li>
<li><p>See <a class="reference internal" href="#vaswani2017attention"><span class="std std-ref">(Vaswani 2017)</span></a> for transformer paper.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="zhang2008two">
<h2>zhang2008two<a class="headerlink" href="#zhang2008two" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>Zhang et al. proposed a 2-D COW algorithm for aligning gas chromatography and mass spectrometry.</p></li>
<li><p>The algorithm warps local regions of the data to maximise the correlation with known reference samples.</p></li>
<li><p>This work uses data fusion with labelled reference samples, to improve the quality of new samples.</p></li>
</ul>
</div></blockquote>
</section>
<section id="zhang2021evolutionary">
<h2>zhang2021evolutionary<a class="headerlink" href="#zhang2021evolutionary" title="Link to this heading"></a></h2>
<blockquote>
<div><ul class="simple">
<li><p>An Evolutionary Forest for Regression</p></li>
<li><p>Hengzhe Zhang’s paper from ECRG.</p></li>
<li><p>TODO [ ] READ</p></li>
</ul>
</div></blockquote>
</section>
<section id="zhang2023adding">
<h2>zhang2023adding<a class="headerlink" href="#zhang2023adding" title="Link to this heading"></a></h2>
<p>Adding conditional control to text-to-image diffusion models</p>
<dl class="simple">
<dt>Methods:</dt><dd><ul class="simple">
<li><p>Augment existing LDM, e.g. StableDiffusion, with ControlNets,</p></li>
<li><dl class="simple">
<dt>to enable conditional inputs like:</dt><dd><ol class="arabic simple">
<li><p>edge maps,</p></li>
<li><p>segmentation maps,</p></li>
<li><p>and keypoints.</p></li>
</ol>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Results:</dt><dd><ul class="simple">
<li><p>See figure 1, <a class="reference external" href="https://twitter.com/jrhwood/status/1653612277294309378?s=20">https://twitter.com/jrhwood/status/1653612277294309378?s=20</a></p></li>
<li><p>Input: the cany edge map (bottom left)</p></li>
<li><p>Prompt: “A high-quality, detailed, professional image”</p></li>
<li><p>Output: the 4x generated images on the right</p></li>
</ul>
</dd>
<dt>Applications:</dt><dd><ul class="simple">
<li><p>Image generation</p></li>
<li><p>Fine-grained control over LDM output</p></li>
<li><p>Memes in art styles <a class="reference external" href="https://twitter.com/jrhwood/status/1653612282935656449?s=20">https://twitter.com/jrhwood/status/1653612282935656449?s=20</a></p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>See <a class="reference internal" href="minutes.html#id134"><span class="std std-ref">2023-05-03 - Deep Learning</span></a></p></li>
<li><p>See <a class="reference internal" href="#ho2020denoising"><span class="std std-ref">(Ho 2020)</span></a> for more on diffusion models.</p></li>
<li><p>See <a class="reference internal" href="#song2020denoising"><span class="std std-ref">(Song 2020)</span></a> for more on diffusion models.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="zhao2017pyramid">
<h2>zhao2017pyramid<a class="headerlink" href="#zhao2017pyramid" title="Link to this heading"></a></h2>
<p>Pyramid scene parsing network</p>
<p>(Zhao 2017) propose PSPNet for the scene parsing task.</p>
<p>Available: <a class="reference external" href="http://openaccess.thecvf.com/content_cvpr_2017/html/Zhao_Pyramid_Scene_Parsing_CVPR_2017_paper.html">http://openaccess.thecvf.com/content_cvpr_2017/html/Zhao_Pyramid_Scene_Parsing_CVPR_2017_paper.html</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Used in <a class="reference internal" href="minutes.html#id187"><span class="std std-ref">2024-04-04 - FASLIP</span></a></p></li>
</ul>
</dd>
</dl>
</section>
<section id="zhao2019maximum">
<h2>zhao2019maximum<a class="headerlink" href="#zhao2019maximum" title="Link to this heading"></a></h2>
<p>Maximum relevance and minimum redundancy feature selection methods for a marketing machine learning platform.</p>
<p>(Zhao 2019) propose a feature selection method for a marketing machine learning platform.</p>
<dl class="simple">
<dt>Intro:</dt><dd><ul class="simple">
<li><p>This (Zhao 2019) is a paper from Uber engineering.</p></li>
<li><p>Business objectives: (1) user acquisition, (2) cross/up sell, (3) user churn.</p></li>
<li><p>Curse of dimensionality: ineffeciency, overfitting, high maintance, low intrepretability.</p></li>
<li><p>FS enabled beter compliance/troubleshooting, business intiution and insights.</p></li>
<li><p>Smaller problem space for troubleshooting and diagnosis.</p></li>
<li><p>By only using important features for prediction task, it is easier to interpret what features/patterns the model is using.</p></li>
<li><p>The m best features are not the best m features - many features are correlated and redundant.</p></li>
<li><p>MRMR is a filter bases FS method that considers both: (1) relevance for predicting outcome, (2) redundancy within selected features.</p></li>
</ul>
</dd>
<dt>Background:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>Mutual Information (MI):</dt><dd><ul>
<li><p>is a measure of the mutual depedence between two random variables.</p></li>
<li><p><span class="math notranslate nohighlight">\(I(X;Y) = H(X) - H(X|Y)\)</span>, the amount of information one can geain about one random variable from another.</p></li>
<li><p><span class="math notranslate nohighlight">\(I(X;Y) = D_{KL}(P_{(X,Y)} || P_X \otimes P_X)\)</span>, let <span class="math notranslate nohighlight">\((X,Y)\)</span> be a pair of random variables, take the KL divergence between their join distribution <span class="math notranslate nohighlight">\(P_{(X,Y)}\)</span> and the product of their maginal distribution <span class="math notranslate nohighlight">\(P_X \otimes P_X\)</span>.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>MRMR</dt><dd><ul>
<li><dl class="simple">
<dt>For the MRMR framework, the feature importance can be expressed as <span class="math notranslate nohighlight">\(f^{mRMR} = I(Y,X_i) - \frac{1}{|S|} \sum_{X_s \in S} I(X_s;X_i)\)</span>. where</dt><dd><ul>
<li><p><span class="math notranslate nohighlight">\(S\)</span> is the set of selected features.</p></li>
<li><p><span class="math notranslate nohighlight">\(|S|\)</span> ois the size of the feature set.</p></li>
<li><p><span class="math notranslate nohighlight">\(X_s \in S\)</span> is one features of the set <span class="math notranslate nohighlight">\(S\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(X_i\)</span> denotes a feature is currently not selected.</p></li>
<li><p>The function <span class="math notranslate nohighlight">\(I(.;.)\)</span> os the mutual information.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>It builds a set of best features based of maximum feature importance each iteration.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Datasets:</dt><dd><ul class="simple">
<li><p>3x real-world, 1x synthetic.</p></li>
<li><p>Goal: robust FS method that generalizes to many datasets.</p></li>
</ul>
</dd>
<dt>Method:</dt><dd><ul class="simple">
<li><p>Extensions are based on relatedness to downsteam machine learning models those features are then used on.</p></li>
<li><p>RDC can identify redundancy in non-linear relationships.</p></li>
<li><p>Random-Forest correlation quotient (RFCQ) uses the feature importance metric from random forest.</p></li>
<li><p>Issues: scale differences  between relevance and redundancy metrics.</p></li>
<li><p>Metrics: computational efficiency (speed) and classification accuracy.</p></li>
<li><p>The FS methods (8) x classifiers (3) x datasets (4) are all combined to produce a multiplicity (96) sets of results.</p></li>
<li><p>Splines used to generated various kinds of features for the synthetic dataset.</p></li>
<li><p>Computation efficiency (speed) is a useful metric for motivating FS methods.</p></li>
<li><p>Correlation heatmaps are an effectieve way to visualize correlation and redundancy in a dataset. Motives FS methods.</p></li>
<li><p>Box and whisker plots provide a stunning visual for comparison of classification performance across different FS methods.</p></li>
<li><p>Metadata is provided for each dataset, i.e. Number of features, Number of users.</p></li>
<li><p>Random forest classifier is run twice using different parameters, explicit sklearn parameters for python given for reproduceability.</p></li>
</ul>
</dd>
<dt>Why it matters?</dt><dd><ul class="simple">
<li><p>Could include “Implementation in Production” section in my thesis, even if theoretical, to ground work in real-world application.</p></li>
<li><p>Future work/alterantive approaches are discussed in conclusion, they propose additional extenions of MRMR.</p></li>
<li><p>Nice to give back to the research community by thanking reviewers in the acknowledgements.</p></li>
</ul>
</dd>
<dt>Related:</dt><dd><ul class="simple">
<li><p>MRMR <a class="reference internal" href="#ding2005minimum"><span class="std std-ref">(Ding 2005)</span></a> uses mutual information to measure both relevance and redundancy.</p></li>
<li><p>Mutual information can be given for a discrete and continuos by a double sum and integral respectively. See <a class="reference internal" href="#goodfellow2016deep"><span class="std std-ref">(Goodfellow 2016)</span></a> chapter 3 pg. 72 for a derivation of Kullback-Leibler divergence.</p></li>
<li><p><a class="reference internal" href="#brown2012conditional"><span class="std std-ref">(Brown 2012)</span></a> generalizes information based FS methods, e.g. MRMR, into conditional likelihood framework.</p></li>
<li><p>Two FS papers, (<a class="reference internal" href="#liu1995chi2"><span class="std std-ref">Lui 1995</span></a>, <a class="reference internal" href="#zhang2008two"><span class="std std-ref">Zhao 2019</span></a>) use a synthetic datasets where redundant features are known.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="zhu2022few">
<h2>zhu2022few<a class="headerlink" href="#zhu2022few" title="Link to this heading"></a></h2>
<p>A few-shot meta-learning based siamese neural network using entropy features for ransomware classification},</p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p><span class="xref std std-ref">(Bromley 1993)</span> is the original siamese network paper.</p></li>
<li><p><a class="reference internal" href="#jing2022masked"><span class="std std-ref">(Jing 2022)</span></a> proposed masked siamse convnets for few-shot learning.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="zoph2016neural">
<h2>zoph2016neural<a class="headerlink" href="#zoph2016neural" title="Link to this heading"></a></h2>
<p>Neural Architecture Search: Insights from 1000 Papers</p>
<p>Available: <a class="reference external" href="https://arxiv.org/abs/2301.08727">https://arxiv.org/abs/2301.08727</a></p>
<dl class="simple">
<dt>Related:</dt><dd><ul class="simple">
<li><p>Mentioned in <a class="reference internal" href="minutes.html#id145"><span class="std std-ref">2022-09-21 - FASLIP</span></a></p></li>
<li><p>See <a class="reference internal" href="#white2023neural"><span class="std std-ref">(White 2023)</span></a> for a literature survey of NAS.</p></li>
</ul>
</dd>
</dl>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="minutes.html" class="btn btn-neutral float-left" title="Minutes" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="notes.html" class="btn btn-neutral float-right" title="Notes" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Jesse Wood, Bing Xue, Mengjie Zhang, Bach Hoai Nguyen, Daniel Killeen.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>