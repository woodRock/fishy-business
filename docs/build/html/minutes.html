

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Minutes &mdash; fish 0.0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Literature Review" href="papers.html" />
    <link rel="prev" title="About" href="about.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> fish
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="about.html">About</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Minutes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#planning">2022-02-23 - Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#fgr">2022-02-28 - FGR</a></li>
<li class="toctree-l2"><a class="reference internal" href="#faslip">2022-02-28 - FASLIP</a></li>
<li class="toctree-l2"><a class="reference internal" href="#dl">2022-03-07 - DL</a></li>
<li class="toctree-l2"><a class="reference internal" href="#induction">2022-03-08 - Induction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#weekly">2022-03-10 - Weekly</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id1">2022-03-10 - FASLIP</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ecrg">2022-03-11 - ECRG</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id2">2022-03-17 - Weekly</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id3">2022-03-17 - FASLIP</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id4">2022-03-18 - ECRG</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id5">2022-03-21 - DL</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#faculty-induction">2022-03-24 - Faculty Induction</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#id6">2022-03-17 - Weekly</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id7">2022-03-24 - FASLIP</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id8">2022-03-25 - ECRG</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id9">2022-03-28 - DL</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id10">2022-03-31 - Weekly</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id11">2022-03-31 - FASLIP</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id12">2022-04-01 - ECRG</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id13">2022-04-04 - DL</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id14">2022-04-07 - Weekly</a></li>
<li class="toctree-l2"><a class="reference internal" href="#id15">2022-04-07 - FASLIP</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="papers.html">Literature Review</a></li>
<li class="toctree-l1"><a class="reference internal" href="thoughts.html">Thoughts</a></li>
<li class="toctree-l1"><a class="reference internal" href="contact.html">Contact</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">fish</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Minutes</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/minutes.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="minutes">
<h1>Minutes<a class="headerlink" href="#minutes" title="Permalink to this headline">¶</a></h1>
<p>This page contains the minutes for our weekly meetings.</p>
<section id="planning">
<h2>2022-02-23 - Planning<a class="headerlink" href="#planning" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> C0355, <strong>Time</strong>: Monday 1pm-2pm , <strong>Attendees:</strong> Jesse Wood, Mengjie Zhang</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Faculty of Graduate Research (FGR) - office on Kelburn Parade.</p></li>
<li><p>Forms and information for enrollment is available at the FGR website.</p></li>
<li><p>Booked a room for study in MARU101 - Desk 33</p></li>
<li><p>See Duncan in ECS for an account.</p></li>
<li><p>Can work up to 12 hours per week.</p></li>
<li><p>Let supervisors and faculty know about trips out of Wellington.</p></li>
<li><p>Start as provisional registration, then candidate - write proposal, fully registered - proposal accepted.</p></li>
<li><p>Two required meetings, FASLIP (Thursday 2pm-3pm), ECRG (Friday 3pm-5pm).</p></li>
</ul>
</dd>
</dl>
</section>
<section id="fgr">
<h2>2022-02-28 - FGR<a class="headerlink" href="#fgr" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Monday 2pm-3pm , <strong>Attendees:</strong> Matthew Vink, Jesse Wood</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>This meeting covers enrollment, we will be confirming details, forms, contacts.</p></li>
<li><p>PhD Supervisors: Bing Xue, Mengjie Zhang.</p></li>
<li><dl class="simple">
<dt>Documents:</dt><dd><ol class="arabic simple">
<li><p>Confirmation of study - AIML 692 code.</p></li>
<li><p>Fees assessment - two weeks to pay levees.</p></li>
</ol>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Information sheet:</dt><dd><ol class="arabic simple">
<li><p>Community for needs bank details.</p></li>
<li><p>Tony mcGloughin - School Administrator.</p></li>
<li><p>Confirmation of Proposal Registration Form (CoPR).</p></li>
<li><p>Mathew Vink - helped me enroll today.</p></li>
<li><p>Student levees - 2 weeks due.</p></li>
</ol>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</section>
<section id="faslip">
<h2>2022-02-28 - FASLIP<a class="headerlink" href="#faslip" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Wednesay 2pm-3pm , <strong>Attendees:</strong> Matthew Vink, Jesse Wood</p>
<dl class="simple">
<dt>Neil Dodgeson - Cambridege lecture</dt><dd><ul class="simple">
<li><p>How to not give a presentation. <a class="reference external" href="https://vimeo.com/51597270">https://vimeo.com/51597270</a></p></li>
<li><p>How to present a paper. <a class="reference external" href="https://vimeo.com/7833850">https://vimeo.com/7833850</a></p></li>
</ul>
</dd>
<dt>Notes:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>Simular to ENGR401 stuff</dt><dd><ul>
<li><p>Dont need slides.</p></li>
<li><p>Trip check technologies.</p></li>
<li><p>Face audience.</p></li>
<li><p>Relevant stuff only.</p></li>
<li><p>No animations.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Research Talks</dt><dd><ul>
<li><p>Don’t type the script.</p></li>
<li><p>Planning, a lot of time before writing slides.</p></li>
<li><p>Audience, can change how you deliver a presentation.</p></li>
<li><p>Highlight key points on the last slide.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</section>
<section id="dl">
<h2>2022-03-07 - DL<a class="headerlink" href="#dl" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Monday 3pm-4pm , <strong>Attendees:</strong> Bastiaan Kleign, Jesse Wood, et al.</p>
<dl class="simple">
<dt>Papers:</dt><dd><ol class="arabic simple">
<li><p>Conditional Diffuction Probablistic Model for Speech Enhancment. <a class="reference external" href="https://arxiv.org/abs/2202.05256">https://arxiv.org/abs/2202.05256</a></p></li>
<li><p>A Study on Speech enhancment on Diffusion Probabilistic Model. <a class="reference external" href="https://arxiv.org/abs/2107.11876">https://arxiv.org/abs/2107.11876</a></p></li>
</ol>
</dd>
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Diffusion models got attention for synthesising images (i.e faces, animals).</p></li>
<li><p>Later, it bet the GAN on standard benchmarks. <a class="reference external" href="https://proceedings.neurips.cc/paper/2021/hash/49ad23d1ec9fa4bd8d77d02681df5cfa-Abstract.html">https://proceedings.neurips.cc/paper/2021/hash/49ad23d1ec9fa4bd8d77d02681df5cfa-Abstract.html</a></p></li>
<li><p>Train it to add noise, the reverse the process.</p></li>
<li><p>Diffusion: learning to denoise speech signal.</p></li>
<li><p>Isotropic gaussian distribution? <a class="reference external" href="https://math.stackexchange.com/questions/1991961/gaussian-distribution-is-isotropic">https://math.stackexchange.com/questions/1991961/gaussian-distribution-is-isotropic</a></p></li>
<li><p>Learn the signal-to-noise difference, not the mean signal.</p></li>
<li><p>Diffusion markov chain is intractable, so we use Elbo to from an approximate objective function.</p></li>
<li><p>Ratios and constants to ensure the mean and variance don’t explode or vanish.</p></li>
<li><p>New Mailing list for DL updates.</p></li>
<li><p>Next week: Bayesian Transformers.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="induction">
<h2>2022-03-08 - Induction<a class="headerlink" href="#induction" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> AM101, <strong>Time</strong>: Monday 2pm-4pm , <strong>Attendees:</strong> Neil Dodgeson, Jesse Wood, et al.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Bastiaan slide example for meetings.</p></li>
<li><p>Neil Dodgeson - Faculty of Graduate Research Dean.</p></li>
<li><p>Faculty of Graduate Research (FGR).</p></li>
<li><p>Workshops, writing events, professional development.</p></li>
<li><p>Website <a class="reference external" href="https://www.wgtn.ac.nz/fgr">https://www.wgtn.ac.nz/fgr</a></p></li>
<li><p>Workshops are practical and hands-on.</p></li>
<li><dl class="simple">
<dt>Thesis bootcamp - 20 writing hours.</dt><dd><ul>
<li><p>Aimed at final year students.</p></li>
<li><p>June november</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Research room</dt><dd><ul>
<li><p>Review, tips, stories, events, resources.</p></li>
<li><p>Updates monthly.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Candidate progress form (CPF)</dt><dd><ul>
<li><p>Report on 6 monthly progress in a report.</p></li>
<li><p>May / November.</p></li>
<li><p>Required, not academic, supporting evidence.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>4 weeks annual leave, no formal process.</p></li>
<li><p>Suspensions, for illness, bereavement, work.</p></li>
<li><p>Forms for aforementioned available online.</p></li>
<li><dl class="simple">
<dt>Proposal: first major milestone.</dt><dd><ul>
<li><p>12 month deadline.</p></li>
<li><p>no extensions available.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Automatic re-registration for first 2 years.</p></li>
<li><p>Constructive relationship with supervisor.</p></li>
<li><p>PhD certificate: competent to do invidual research.</p></li>
<li><p>Work expert in our PhD Research topic.</p></li>
<li><p>Regular meetings times.</p></li>
<li><p>Student/supervisor - same page for expectation.</p></li>
<li><p>Bring agenda to meeting.</p></li>
<li><p>Project management techniques - scrum, agile.</p></li>
<li><p>2pi rule for time estimation.</p></li>
<li><p>Secondary supervisor - (usually) hands off role.</p></li>
<li><p>“The only way through it, is to do it.”</p></li>
<li><p>Books, publications, thesis - different expectations for each course.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="weekly">
<h2>2022-03-10 - Weekly<a class="headerlink" href="#weekly" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Monday 2pm-4pm , <strong>Attendees:</strong> Bing Xue, Mengjie Zhang, Bach Hoai Nguyen, Jesse Wood</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Let Bing/Meng know about any financial difficulties.</p></li>
<li><dl class="simple">
<dt>Topic ideas:</dt><dd><ol class="arabic simple">
<li><p>Multi-objective</p></li>
<li><p>Evolutionary computation</p></li>
<li><p>Domain expertise.</p></li>
</ol>
</dd>
</dl>
</li>
<li><p>First two-weeks - extensive background reading.</p></li>
<li><p>ECRG - meeting tomorrow from 3pm - 5pm.</p></li>
<li><p>CoPR - fill out by the end of March.</p></li>
<li><p>Individual induction - copy Bach in email for meeting.</p></li>
<li><p>Add Bach to gitlab/github for the paper latex file.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="id1">
<h2>2022-03-10 - FASLIP<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Monday 2pm-4pm , <strong>Attendees:</strong> Bing Xue, Mengjie Zhang, Bach Hoai Nguyen, Jesse Wood et al.</p>
<p>Jeff Hawkins - Thousand Brains Theory: <a class="reference external" href="https://www.youtube.com/watch?v=O4geanMOsyM">https://www.youtube.com/watch?v=O4geanMOsyM</a></p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Voting, similar to droupout, bagged ensemble.</p></li>
<li><p>Many models (sub-networks) for the same thing.</p></li>
<li><p>Sparse networks, efficient -&gt; noise tolerant.</p></li>
<li><p>Only update in one area, without need for back-propagation, doesn’t require a full training for each new instance.</p></li>
<li><p>Builds a full world model, not a model for each task.</p></li>
<li><p>Thousand brain theory - solution to No Free Lunch.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="ecrg">
<h2>2022-03-11 - ECRG<a class="headerlink" href="#ecrg" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Friday 3pm-5pm , <strong>Attendees:</strong> Bing Xue, Mengjie Zhang, Hui Ma, Bach Hoai Nguyen, Jesse Wood et al.</p>
<p>Hui Ma gave presentation on Evolutionary Computation Approaches to Web Service Composition - <a class="reference external" href="https://link.springer.com/article/10.1007/s10732-017-9330-4">https://link.springer.com/article/10.1007/s10732-017-9330-4</a></p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Meng will discuss how to write a proposal.</p></li>
<li><p>EuroGP conference - ask my supervisor to register.</p></li>
<li><dl class="simple">
<dt>Introduced myself to the group</dt><dd><ul>
<li><p>paper - finish writing my Summer Research paper.</p></li>
<li><p>enrolled - lots of paper work.</p></li>
<li><p>Finish writing the paper properly.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Abdullah (lab neighbour) first week in group.</p></li>
<li><p>Evolutionary Computation Approaches to Web Service Composition.</p></li>
<li><p>Over 40 publications in the area.</p></li>
<li><p>Holidy booking service used as an example.</p></li>
<li><p>Organize services into re-usable modules.</p></li>
<li><p>Service composition is a NP-hard problem.</p></li>
<li><p>A global search is not possible, a heuristic based local search is required.</p></li>
<li><p>Evolutionary principles and techniques - crossover, mutation.</p></li>
<li><p>Automatcally create hybrid services through composition.</p></li>
<li><p>Don’t reinvent the wheel, use existing libraries instead.</p></li>
<li><p>Scheduling, routing, resource allocation, service composition - all possible for EC.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="id2">
<h2>2022-03-17 - Weekly<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Friday 12pm-1pm , <strong>Attendees:</strong> Bing Xue, Mengjie Zhang, Bach Hoai Nguyen, Jesse Wood.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Daniel can provide domain expertise for writing the chemistry sections for the paper.</p></li>
<li><p>Multi-objective - classify chemical compounds and their percentage.</p></li>
<li><p>Multi-label - one instance can belong to multiple classes.</p></li>
<li><p>copy Bing and Bach for induction email from Georgia.</p></li>
<li><p>pymoo  - multi-objective python library.</p></li>
<li><p>Read/write summaries for papers as I go - write content for second chapter iteratively.</p></li>
<li><p>Send Daniel conclusions / contributions of paper in email, then organize a follow up meeting.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="id3">
<h2>2022-03-17 - FASLIP<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Monday 2pm-3pm , <strong>Attendees:</strong> Ying, Bing Xue, Mengjie Zhang, Bach Hoai Nguyen, Jesse Wood et al.</p>
<p>Ying suggested a talk on Multi-objective Evolutionary Federated Learning <a class="reference external" href="https://vimeo.com/552900291">https://vimeo.com/552900291</a></p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Yaochi Jin - University of Surrey.</p></li>
<li><p>Multi-objective machine learning.</p></li>
<li><p>Centralized and federated learning.</p></li>
<li><p>Evolutionary multi-objecive federated learning.</p></li>
<li><p>Evolutionary federated nerual architecture search.</p></li>
<li><p>Multi-objective - gives a solution set, as their are tradeoffs between objectives.</p></li>
<li><p>Dominance, no X is worse and Y, and X is strictly better than Y for object A.</p></li>
<li><dl class="simple">
<dt>pareto front (See tegmark2020ai) set of optimal solutions.</dt><dd><ul>
<li><p>accuracy, diversity.</p></li>
<li><p>Inverse generational distance (IGD).</p></li>
<li><p>Hypervolume - nadir</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Optimize for minimal complexity implies interpretability.</p></li>
<li><p>Centralized learning - one database.</p></li>
<li><p>Localized learning - everyone trains their own model.</p></li>
<li><dl class="simple">
<dt>Privacy techniques:</dt><dd><ul>
<li><p>Secure multi-party computation.</p></li>
<li><p>Differential privacy.</p></li>
<li><p>Homomorphic encyption.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Federated learning</dt><dd><ul>
<li><p>train a high-quality centralized model with training dataq distributed over a large number of clients.</p></li>
<li><p>Each with unreliable and relatively slow network connections.</p></li>
<li><p>horizontal - all attributes, batches of data.</p></li>
<li><p>vertical - trained on subset of attributes (i.e. security reasons).</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Federated learning objectives</dt><dd><ol class="arabic simple">
<li><p>Maximise learning performance.</p></li>
<li><p>Minimize communication cost.</p></li>
</ol>
</dd>
</dl>
</li>
<li><p>Their work efficiently reduce the number of connections while maintaining similar performance.</p></li>
<li><p>Neural architecture search (TODO - watch the rest and take notes!!!)</p></li>
</ul>
</dd>
</dl>
</section>
<section id="id4">
<h2>2022-03-18 - ECRG<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Friday 3pm-5pm , <strong>Attendees:</strong> Bing Xue, Mengjie Zhang, Bach Hoai Nguyen, Jesse Wood et al.</p>
<p>A talk on Geometric Semantic Genetic Programming by Qi Chen <a class="reference external" href="https://link.springer.com/chapter/10.1007/978-3-642-32937-1_3">https://link.springer.com/chapter/10.1007/978-3-642-32937-1_3</a></p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>We have published heaps of papers that are highly cites and hot papers according to <a class="reference external" href="https://www.webofscience.com/wos/woscc/basic-search">https://www.webofscience.com/wos/woscc/basic-search</a> toool that the university has access to.</p></li>
<li><p>Top 1% of papers cited per discipline for computer science journals.</p></li>
<li><p>Evolving neural networks with evolutionary computation.</p></li>
<li><p>Me: reading psychology papers on how the brain works with memory - hunting for relative simply neuro-science ideas to apply to machine learning.</p></li>
<li><p>Geometric smenatic genetic programming (Morgalio 2012, moraglio2012geometric) <a class="reference external" href="https://link.springer.com/chapter/10.1007/978-3-642-32937-1_3">https://link.springer.com/chapter/10.1007/978-3-642-32937-1_3</a></p></li>
<li><p>Semantic genetic programming methods.</p></li>
<li><p>Traditional GP ignores program semantics.</p></li>
<li><p>Consequences - ragged gentype-phenotype mapping.</p></li>
<li><p>Is it possible to make GP aware about the effects of the program execution?</p></li>
<li><dl class="simple">
<dt>Semantics:</dt><dd><ul>
<li><p>Semantics differs from syntax.</p></li>
<li><p>Semantics related to the problem domain.</p></li>
<li><p>Semantics inform program design (Tegmark 2020, tegmark2020ai).</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Measure semantic distance between current program and target output (multi-dimensional loss function).</p></li>
<li><dl class="simple">
<dt>Genetic operators:</dt><dd><ul>
<li><p>Semantic aware cross-over (SAC)</p></li>
<li><p>Semantic similarity-based cross-over (SSC)</p></li>
<li><p>Semantic similarity-based mutation (SSM)</p></li>
<li><dl class="simple">
<dt>Senantic tournament selection.</dt><dd><ul>
<li><p>t-test for statistical signfician with assessing selection.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><p>Search directly in the semantci space of the program.</p></li>
<li><p>Semnatics of offsrping must sit in between the ntercept between its two parents in semantic space.</p></li>
<li><p>Therefore each offspring minimized distance to target semantics.</p></li>
<li><p>Each generation gets closer to the target semantics, or atleast closer than the furthest parent.</p></li>
<li><p>Independent of data, good effect on improving generalization, althougt not actual claim made in paper.</p></li>
<li><dl class="simple">
<dt>Geometric semantic programming leads to a unimodel fitness landscape - a cone where the apex is the target semantics.</dt><dd><ul>
<li><p>manhattan distance - square based pyramid.</p></li>
<li><p>euclidean distance - cone.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Efficient implementation - only store changes to program tree, similar to git version control - except for GSGP.</p></li>
<li><p>GSGR Red (reduce), simplify problems by expanding and recomputing.</p></li>
<li><dl class="simple">
<dt>Locally geometric semantic crossover (LGSX).</dt><dd><ul>
<li><p>Make offsrping similar to eachother than their parents.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Random desired operator (RDO), exploit interoperability of instructions, + can be reversed with -, * can be reversed with division, + and * are communicative.</p></li>
<li><p>Semantic backpropogation - decomposibility of the process if important for BP.</p></li>
<li><p>Angle aware metrics - larger angle metrics iis more likely to generate offspring closer to target semantics.</p></li>
<li><p>Permutations GSX and Random Segment Mutation</p></li>
<li><p>Semenatic distance (euclidean) is the same as the loss, just looking at it from a different point of view.</p></li>
<li><p>Can geometric smeantic programming work in an unsupervised or combinatorial problem? (Possibly not unimodel semantic space)</p></li>
</ul>
</dd>
</dl>
</section>
<section id="id5">
<h2>2022-03-21 - DL<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Monday 3pm-4pm , <strong>Attendees:</strong> Hayden Dyne, Bastiaan Kleign, Jesse Wood, et al.</p>
<dl class="simple">
<dt>Talk by Hayden on two papers:</dt><dd><ul class="simple">
<li><p>End-to-end driving via conditional imitation learning (Cai 2020, cai2020high) <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/8460487/">https://ieeexplore.ieee.org/abstract/document/8460487/</a></p></li>
<li><p>High-speed autonomous drifting with deep reinforcement learning (Codevilla 2018, codevilla2018end) <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/8961997/">https://ieeexplore.ieee.org/abstract/document/8961997/</a></p></li>
</ul>
</dd>
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Model-free reinforcement learning - does not rely on human understanding of world and design controllers.</p></li>
<li><p>Human driver is the trajectory with is the goal, uses a professional driver playing the game with a steering wheel.</p></li>
<li><p>Model performs on different track difficulties.</p></li>
<li><p>Reward function is scaled by velocity, so faster lap times are rewarded.</p></li>
<li><p>Works for 4 different kinds of vehicles, although the truck struggles to achieve same performance as lighter ones.</p></li>
<li><p>Second paper - e2e</p></li>
<li><p>Far easier to use real-world data on driving that has already been collected than generate simulation data.</p></li>
<li><p>Data augmentation used to help network generalize to new scenarios and edge cases not in the training data.</p></li>
</ul>
</dd>
</dl>
<section id="faculty-induction">
<h3>2022-03-24 - Faculty Induction<a class="headerlink" href="#faculty-induction" title="Permalink to this headline">¶</a></h3>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Monday 10am-11am , <strong>Attendees:</strong> Georgia Dix, Jesse Wood, Bach Hoai Nguyen.</p>
<p>Induction to my PhD studies with supervisor and faculty.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>Expectations</dt><dd><ul>
<li><dl class="simple">
<dt>Supervisor</dt><dd><ul>
<li><p>Uni life</p></li>
<li><p>Framework</p></li>
<li><p>Networking</p></li>
<li><p>Assessment</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Me</dt><dd><ul>
<li><p>action plan</p></li>
<li><p>identify problems</p></li>
<li><p>administration</p></li>
<li><p>CDP (6 monthly report)</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
<li><p>Marking can thesis can take up to 6 months - can work during this time.</p></li>
</ul>
</dd>
</dl>
</section>
</section>
<section id="id6">
<h2>2022-03-17 - Weekly<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Friday 12pm-1pm , <strong>Attendees:</strong> Bing Xue, Mengjie Zhang, Bach Hoai Nguyen, Jesse Wood.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Daniel can draft the chemistry parts for the paper.</p></li>
<li><p>Draft the full paper with Bach, then send to Daniel.</p></li>
<li><p>Read “From evolutionary computation to the evolution of things” - Nature</p></li>
<li><p>Can start coding now - explore ideas for ENGR489 and EC on existing data.</p></li>
<li><p>Transformers, LSTM, GAN - yet to be applied to GC-MS data in literature.</p></li>
<li><p>CNNs for GC, likely due to libraries, hype, understanding, Diffusion of innovation.</p></li>
<li><p>Scuba diver experiment for context-dependent memory is a good analogy for noise in ML models.</p></li>
<li><p>Came up with evolutionary ideas, like sexual selection, but (Miller 1994) did it quite some time ago.</p></li>
<li><p>Idea for EC, a dynamic environment where complexity increases, classes or features are added - similar to evolution IRL.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="id7">
<h2>2022-03-24 - FASLIP<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Monday 2pm-3pm , <strong>Attendees:</strong> Ying, Bing Xue, Mengjie Zhang, Bach Hoai Nguyen, Jesse Wood et al.</p>
<p>Ruwing Jiao suggested a video on Bayesian Optimization from Mark Deisenroth <a class="reference external" href="https://www.youtube.com/watch?v=_SC5_2vkgbA">https://www.youtube.com/watch?v=_SC5_2vkgbA</a></p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>Recommended background reading on this topic:</dt><dd><ol class="arabic simple">
<li><p>A Tutorial on Bayesian Optimization of Expensive Cost Functions (Brochu 2010, brochu2010tutorial) <a class="reference external" href="https://arxiv.org/pdf/1012.2599.pdf">https://arxiv.org/pdf/1012.2599.pdf</a></p></li>
<li><p>Taking the Human Out of theLoop: A Review of Bayesian Optimization (Shahriari 2015, shahriari2015taking) <a class="reference external" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7352306">https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7352306</a></p></li>
</ol>
</dd>
</dl>
</li>
<li><p>Latent Structural Support Vector Machine (Miller 2012) - <strong>TODO</strong> find this paper/project.</p></li>
<li><p>Deep learning often involves a lot of hyper-parameter tuning, this is usally done by the practitioner model.</p></li>
<li><dl class="simple">
<dt>Alternative approaches:</dt><dd><ul>
<li><p>Manual tuning</p></li>
<li><p>Grid search</p></li>
<li><p>Random search</p></li>
<li><p>Black magic (i.e. lr is 1e-3 is “good”)</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Computationally expensive to search for global maximum in hyper-parameter search space.</p></li>
<li><p>Globally optimize a black-box approach to evaluate (e.g. cross validatio error for a massive neural network).</p></li>
<li><dl class="simple">
<dt>Use a probabilistic model to approximate the black-box model for the hyper-parameter search.</dt><dd><ul>
<li><p>create a proxy model - this learns an approximation of the space - with less computational cost to query that space.</p></li>
<li><p>referred to ass proxy / approximate / surrogate.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>The standard model for optimizing a bayesian model is a gaussian process.</p></li>
<li><p>Evaluate the proxy function once, this saves computation.</p></li>
<li><p>A gaussian process minimized the uncertainty of the proxy function.</p></li>
<li><p>It samples the feature space at the minimum value of the shaded area (== uncertainty).</p></li>
<li><p>It repeats this often, until the proxy function is close enough to the true objective.</p></li>
<li><p>Exploration - sample areas with high uncertainty.</p></li>
<li><p>Exploitation - sample places with low mean.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="id8">
<h2>2022-03-25 - ECRG<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Friday 3pm-5pm , <strong>Attendees:</strong> Andrew Lenson, Bing Xue, Mengjie Zhang, Bach Hoai Nguyen, Jesse Wood et al.</p>
<p>Andrew gave a talk on Genetic Programming, Explainability and Interdisciplinary AI.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Heaps of students successfully submitted papers to the Gecko conference.</p></li>
<li><p>Possible to publish in conference at different levels; paper, poster, etc.</p></li>
<li><p>If a paper is declined, revise with reviewer comments, and resubmit as poster.</p></li>
<li><p>Qurrat Al Ain - Cancer research in AI.</p></li>
<li><dl class="simple">
<dt>Swiss roll manifold problem</dt><dd><ul>
<li><p>Reduce a manifold to a 2D visual representation.</p></li>
<li><p>2D path is representation of non-linear dimensionality reduction (NLDR).</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Geo-desic, shortest path from A to B, not shortest euclidean distance.</p></li>
<li><p>Lower dimensional space is referred to as an embedding.</p></li>
<li><p>We can use AI to learn or approximate this embedding (if the problem is intractable).</p></li>
<li><p>Ways to estimate the intrinsic dimensionality of the dataset - statistical techniques.</p></li>
<li><p>Kaka - count distinct nnumber of birds at Zealandia.</p></li>
<li><p>GoPro for data collection combined with crack for Kaka.</p></li>
<li><p>Law - predicting sentencing lengths with PLSR on judge summaries.</p></li>
<li><p>Names with high/low probabilities are often historic cases referred to as ‘guidance judgements’.</p></li>
<li><p>Combine data analysis and domain expertise to infer knowledge about sentencing lengths.</p></li>
<li><p>Home detention or communtiy service are associated with shorter sentences.</p></li>
<li><p>Future work, take humans out of the loop, and make sentencing deterministic.</p></li>
<li><p>^ This can be done, because their are extenuating circumstances that require a judges opinion.</p></li>
<li><p>Also, if all sentences are automated, there would no longer be guidance judgements being set historically.</p></li>
<li><p>Law is a dynamic and decentralized system, unique and specialized for each country, case, individual, etc…</p></li>
<li><p>Research more productive on letting judges analysis their blindspots, and identify bias.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="id9">
<h2>2022-03-28 - DL<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Monday 3pm-4pm , <strong>Attendees:</strong> Daniel Braithwaite, Bastiaan Kleign, Jesse Wood, et al.</p>
<dl class="simple">
<dt>Daniel Braithwaite talked about two papers related to machine learning for audio wave construction:</dt><dd><ol class="arabic simple">
<li><p>Deep Audio Priors Emerge from Harmonic Convolutional Networks <a class="reference external" href="https://openreview.net/pdf?id=rygjHxrYDB">https://openreview.net/pdf?id=rygjHxrYDB</a></p></li>
<li><p>Harmonic WaveGAN <a class="reference external" href="https://www.isca-speech.org/archive/pdfs/interspeech_2021/mizuta21_interspeech.pdf">https://www.isca-speech.org/archive/pdfs/interspeech_2021/mizuta21_interspeech.pdf</a></p></li>
</ol>
</dd>
<dt>Notes:</dt><dd><ul class="simple">
<li><p>The idea is to look at harmonic convolutions, think convolution layer but designed for audio.</p></li>
<li><p>WaveGAN and Harmonic WaveGAN use deep learning on audio signals.</p></li>
<li><p>Harmonic, is better suited towards audio signals, than wave alone.</p></li>
<li><p>Harmonic considers local connections / adjaceny better.</p></li>
<li><p><strong>TODO</strong> Read these papers and add to notes.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="id10">
<h2>2022-03-31 - Weekly<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Friday 12pm-1pm , <strong>Attendees:</strong> Bach Hoai Nguyen, Jesse Wood.</p>
<p>Bing and Meng were both unwell this week. Important to send minutes for this meeting to them.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>Augmentation - boost performance on the fish part dataset.</dt><dd><ul>
<li><p>Time-shift, shift data backwards and forward, to get time-invariant generalized model (may not work well).</p></li>
<li><p>Impute data, combine existing samples, add noise, etc…</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Worked on CNN from ENGR489 for classification task.</dt><dd><ul>
<li><p>Issues with keras and sklearn libraries, stratified cross-fold validation and one hot encoding don’t play nice together.</p></li>
<li><p>CNNs, we use 1D convolution and pooling layers on time-series data.</p></li>
<li><p>Existing ML + GC literature also use CNN for classification and regression tasks.</p></li>
<li><p>These models are powerful for extracting features in spaces with local connectivity.</p></li>
<li><p>Aim to use EC to perform neural architecture search for CNN hyperparamters - these differ for each dataset.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Both EC and Bayesian Optimization approaches work for neural architecture search.</dt><dd><ul>
<li><p>However, EC has more interpretable results, e.g. a genetic algorithm produces an explainable tree.</p></li>
<li><p>Neural networks are black-box and esoteric, we understand how (i.e. back-prop, SGD), but not why?</p></li>
<li><p>EC produces simpler representations, that can be prodded with domain expertise.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Important to read heaps for first few months of PHD.</dt><dd><ul>
<li><p>Take original notes that can contribute toward a backgroup chapter of my proposal.</p></li>
<li><p>Get an idea of what has been done, and what I want to do.</p></li>
<li><p>Still reading psychology textbook on memory and the brain to establish conceptual framework for learning.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</section>
<section id="id11">
<h2>2022-03-31 - FASLIP<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Monday 2pm-3pm , <strong>Attendees:</strong> Fangfang Zhang, Bing Xue, Mengjie Zhang, Bach Hoai Nguyen, Jesse Wood et al.</p>
<p>Fangfang suggested a video called the Big Reset 2.0 <a class="reference external" href="https://www.youtube.com/watch?v=-ePZ7OdY-Dw">https://www.youtube.com/watch?v=-ePZ7OdY-Dw</a></p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Reinforcment learning for Robotic Arms.</p></li>
<li><p>Deep blue beat Kasparov, but no AI can set up the chess board, a 6 year old can do that.</p></li>
<li><dl class="simple">
<dt>Hugh Herr designed his own AI legs <a class="reference external" href="https://www.youtube.com/watch?v=CDsNZJTWw0w">https://www.youtube.com/watch?v=CDsNZJTWw0w</a></dt><dd><ul>
<li><p>AI prosthesis is cost prohibitive for the masses, but may work with diffusion of innovation in future.</p></li>
<li><p>Prosthesis can up upgraded over time, biological body parts cannot, hardware/software updates for legs.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Fake news - Jon Stewart said MSM has more trackers than ANY other media (adult entertainment, torrent sites, social media included).</p></li>
<li><p>Chomskey, MSMs job is to sell the educated privelaged wealthy elites as an audience to the corporations advertising.</p></li>
<li><p>AI algorithms - social media, fake news, incentives.</p></li>
<li><p>AI autonomous warfare proliferation - we need to ban slaughter bots <a class="reference external" href="https://www.youtube.com/watch?v=pOv_9DNoDRY">https://www.youtube.com/watch?v=pOv_9DNoDRY</a></p></li>
<li><p>AI used for traffic management, screen-time punishment - pick up phone at cafe and pay the bill.</p></li>
<li><p>RoboMaster - robot warfare, mechatronics, AI - physical robot warfare as a game/competition.</p></li>
<li><p>Cosmo - Boris Sofman <a class="reference external" href="https://www.youtube.com/watch?v=U_AREIyd0Fc">https://www.youtube.com/watch?v=U_AREIyd0Fc</a></p></li>
<li><p>Narrow-AI and no free lunch problem - AI is good at solving very specific tasks, but not general intelligence.</p></li>
<li><p>I have an industry project, that has real-world applications in a factory settings - i.e. reduce bycatch and maximize efficiency of food processing for fish.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="id12">
<h2>2022-04-01 - ECRG<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Friday 3pm-5pm , <strong>Attendees:</strong> Andrew Lenson, Bing Xue, Mengjie Zhang, Bach Hoai Nguyen, Jesse Wood et al.</p>
<p>Meng and Bing were unwell, so Yi chaired the research group meeting.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Bach (my supervisors) first day lecturing for COMP102.</p></li>
<li><p>Me: I got 98% accuracy on the fish species dataset using a 1D CNN.</p></li>
<li><p>Shorter meeting, workshop cancelled, due to Meng being unwell.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="id13">
<h2>2022-04-04 - DL<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Monday 3pm-4pm , <strong>Attendees:</strong> Ciaran King, Bastiaan Kleign, Jesse Wood, et al.</p>
<dl class="simple">
<dt>Ciaran King was gave a talk on “Experiences using Github Copilot”.</dt><dd><ul class="simple">
<li><p>Understands the context of code, can make abstractions for helper methods.</p></li>
<li><p>Can write documentation for codebases.</p></li>
<li><p>Not software “correct” code, but (likely) the code we were going to write.</p></li>
<li><p>Can write tests for codebases with very little leading.</p></li>
</ul>
</dd>
<dt>Daniel Braithwaite on “Fixed Neural Network for Stenography”</dt><dd><ul class="simple">
<li><p>Hide messages in adversarial neural network.</p></li>
<li><p>Pre-trained stenograph, results in non-zero error, we need perfect reconstruction for encryption.</p></li>
<li><p>Face anonymization, post a persons face online, then regenerate the face, but encrypt the private face.</p></li>
<li><p>This lets friends anonmyously share images with their face online, without revealing their identity.</p></li>
</ul>
</dd>
<dt>Bastian - contractivity of neural networks.</dt><dd><ul class="simple">
<li><p>Signal processing worries about getting non-stable linear filters for signals.</p></li>
</ul>
</dd>
<dt>Jesse Wood</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>Evaluating Large Language Models Trained on Code <a class="reference external" href="https://arxiv.org/abs/2107.03374">https://arxiv.org/abs/2107.03374</a></dt><dd><ul>
<li><p>70% accuracy for basic DSA problems.</p></li>
<li><p>Can’t solve more difficult problems - doesn’t optimize solutions for performance.</p></li>
<li><p>CoPilot outperforms other state-of-the-art NLP code generation models.</p></li>
<li><p>Requires “fine-tuning”, supervised human intervention to hint towards correct answer.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Asleep at the Keyboard? Assessing the Security of GitHub Copilot’s Code Contributions <a class="reference external" href="https://arxiv.org/abs/2108.09293">https://arxiv.org/abs/2108.09293</a></dt><dd><ul>
<li><p>40% of code written with CoPilot has cybersecurity vulnerabilities.</p></li>
<li><p>CodeQL and other static analysis tools used to define the security of the code.</p></li>
<li><p>Security is a shifting landscape, WannaCry, Log4J - zero days kept secret by intelligence agencies.</p></li>
<li><p>This is true of all code, the training data was written by humans.</p></li>
<li><p>Potential vulnerability for future attacks if hackers know open-source repos are training data.</p></li>
<li><p>Don’t treat copilot as a “glass cannon”, it doesn’t deserve a false sense of security.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</section>
<section id="id14">
<h2>2022-04-07 - Weekly<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Friday 12pm-1pm , <strong>Attendees:</strong> Bing Xue, Jesse Wood.</p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Use an existing neural network architecture search algorithm - application analysis.</p></li>
<li><p>Callaghan may have extra data work with - arrange a meeting with Daniel.</p></li>
<li><p>Pre-traning, tranfer learning, NIST dataset for GC refraction index.</p></li>
<li><p>Look at existing proposals, get an idea for mine - possible to submit proposal early.</p></li>
<li><p>State-of-the-art, is 50-50 whether it works or is a bust - good to have a backup based in existing literature.</p></li>
<li><p>Pareto front with tradeoff between complexity and accuracy.</p></li>
<li><p>Proposal does not lock me into using a particular method (i.e. SVM, EC, PSO).</p></li>
<li><p>Idea: make sure students have a decent grasp of the field before conducting their own research, if not then read more.</p></li>
<li><p>Later try out ideas in the proposal, and see if they work. If they don’t change tact.</p></li>
</ul>
</dd>
</dl>
</section>
<section id="id15">
<h2>2022-04-07 - FASLIP<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h2>
<p><strong>Location:</strong> Zoom, <strong>Time</strong>: Monday 2pm-3pm , <strong>Attendees:</strong> Qi Chen, Bing Xue, Mengjie Zhang, Bach Hoai Nguyen, Jesse Wood et al.</p>
<p>Qi Chen showed a talk “Artificial Intelligence: A Guide for Thinking Humans” by Melanie Mitchell from <a class="reference external" href="https://www.youtube.com/watch?v=NMUqvhuDZtQ">https://www.youtube.com/watch?v=NMUqvhuDZtQ</a></p>
<dl class="simple">
<dt>Notes:</dt><dd><ul class="simple">
<li><p>Shannon, Simon, Minsky - all though AGI was 15 years off in their own time.</p></li>
<li><p>Andrew Ng - AI is the new electricity.</p></li>
<li><p>Elon Musk - nobody would listen - <a class="reference external" href="https://www.youtube.com/watch?v=4RMKLyaqh_8">https://www.youtube.com/watch?v=4RMKLyaqh_8</a></p></li>
<li><p>Deep learning brought back the hype for AGI.</p></li>
<li><p>“An Anarchy of Methods” - Joel Lehman 2014.</p></li>
<li><p>AI, Machine Learning, Deep Learning, onotologies of fields and their popularity change over time.</p></li>
<li><p>Deep learning looks at AI as an aritficial brain - enter the Artificial Neural Network (ANN) - the connectionists.</p></li>
<li><p>CNN based on the limited understanding of the human brain in 1950s neuroscience.</p></li>
<li><p>Facebook used CNN AI for facial recognition when a user uploads a photo.</p></li>
<li><p>ImageNet is a famous supvervised classification task that was generated through crowdfunding internet “slave” labour.</p></li>
<li><p>Famous 94% result for image classification has a sample size of PhD student (Andrew Kaparthy) - the fake news embellished the story.</p></li>
<li><p>Self-driving, stopped fire truck on the highway, the long tail of AI, edge cases.</p></li>
<li><dl class="simple">
<dt>Adversarial attacks on neural networks, crack networks to make wrong predictions based off of their flaws.</dt><dd><ul>
<li><p>“Intruiging properties of Neural Networks” <a class="reference external" href="https://arxiv.org/abs/1312.6199">https://arxiv.org/abs/1312.6199</a></p></li>
</ul>
</dd>
</dl>
</li>
<li><p>Trick self-driving cars into driving through stop signs with stickers, that make it think it is a speed limit sign.</p></li>
<li><p>“I wonder whether or not AI will every crash the barrier of meaning.” - Glen Carlo Rote 1988.</p></li>
<li><p>“common-sense” machine learning, WinnaGap NLP problem.</p></li>
<li><p>DARPA - competition to design a machine with the common-sense of an 18 month old baby.</p></li>
</ul>
</dd>
</dl>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="papers.html" class="btn btn-neutral float-right" title="Literature Review" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="about.html" class="btn btn-neutral float-left" title="About" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2022, Jesse Wood, Bing Xue, Mengjie Zhang, Bach Hoai Nguyen, Daniel Killeen

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>