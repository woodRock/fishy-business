Thoughts
========

2022-03-17
----------

raine1997brain
    * (Rain 1997) shows that different brain chemistry can result in unwanted behaviour (murder).
    * The structure of the model limits is ability to understand abstract concepts. 
    * Humans with abnormal pre-frontal cortex lack the ability to make goal-oriented decisions. 
    * Reinforcment learning, job scheduling and other AI problems also fail at capturing the complexity of delayed gratification.
    * Perhaps, the circuitry involved in a functioning pre-frontal cortex can be translated into reinforcment learning. 

craik1972levels 
    * (Craik 1972) shows that there are different levels of depth of processing.
    * Strengthening connections to existing neurons make it easier to encode information in long-term memory. 
    * We can build knowledge easier from existing context, no need to reinvent the wheel. 
    * This translates to LSTM models, pre-training (i.e. BERT), Thousand Brain Theory, etc. 
    * Models with deeper processing are more likely to be able synthesis information for challenging unseen data. 
    * Deeper processing involves elaborative rehearsal, which makes use of existing synapses, rather than training from scratch each time. 

craik1975depth
    * (Craik 1972) shows that deep processing leads to better recall. 
    * A brain is able to remember more if we associate semantic meaning and context with the task. 
    * For a task, semantic meaning and context can remain static, while new training instances are dynamic. 
    * In machine learning, we can combine natural language processing (NLP) with existing tasks for greater model representation.
    * Examples include the combination of metadata NLP and computer vision for image dataset problems like classification, segmentation, detection. 

chase1973perception
    * (Chase 1973) shows that model representations from domain experts fail on illogical scenarios. 
    * This work shows that the human brain cannot generalize on noise.
    * The analogy provides a concrete example of intelligence in humans that also translates to artificaical intelligence. 
    * This is a limitation of existing machine learning models, they struggle to perform well on unseen data. 

2022-03-18
----------
    * Sexual selection in Genetic Programming. Female preference (up, horizontal), Male (not fussy). Already done (Miller 2005)
    * Evolution in a dynamic environment + evolution can't reverse (hills and mountains analogy)
        * i.e. for multi-class, run many generations with two classes, then later add more. 
        * Slowly introduce features to the training process. 
    * Semantic distance use to eliminate redundant candidate solutions, use to assesss diversity of population and prune (see Tegmark 2020).
    * Imposing apriori belief structures on evolutionary computation - memes or culutral transmission (Dawkins 1976) to complement evolution.
        * Generalizing this, impose dogma on a model, based on domain expertise. 
        * Genetic operators become dogma, monogamy, polygamy, polyamory - only certain indiviudals carry these cultural ideas. 
        * Limit genetic operators to each individual - not all available to entire population at once. 
        * The hand the draws itself (Hofstadter 1979).