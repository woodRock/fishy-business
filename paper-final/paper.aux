\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{eder1995gas}
\citation{restek2018high}
\@writefile{toc}{\contentsline {title}{Machine Learning for Fish Oil Anaylsis}{1}{chapter.1}\protected@file@percent }
\@writefile{toc}{\authcount {1}}
\@writefile{toc}{\contentsline {author}{No Author Given}{1}{chapter.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1.1}\protected@file@percent }
\newlabel{introduction}{{1}{1}{Introduction}{section.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Goals and Objectives}{1}{subsection.1.1.1}\protected@file@percent }
\citation{eder1995gas,restek2018high,khan2013gas}
\citation{restek2018high}
\citation{restek2018high}
\citation{khan2013gas}
\citation{restek2018high}
\citation{eder1995gas,restek2018high}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{2}{section.1.2}\protected@file@percent }
\newlabel{background}{{2}{2}{Background}{section.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Gas Chromatorgraphy}{2}{subsection.1.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Gas chromatograph: the artifact of the GC method \cite  {restek2018high}. The detection is used to visualize intensity (y) and time (x) on a chromotrogaph.\relax }}{2}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:gas-chromatography}{{1}{2}{Gas chromatograph: the artifact of the GC method \cite {restek2018high}. The detection is used to visualize intensity (y) and time (x) on a chromotrogaph.\relax }{figure.caption.2}{}}
\citation{musk2020battery}
\citation{cortes1995support}
\citation{sklearn2021feature}
\citation{scholkopf2000new}
\citation{aizerman1964theoretical}
\citation{boser1992training}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Visualisation}{3}{subsection.1.2.2}\protected@file@percent }
\newlabel{sec:background-visualisation}{{2.2}{3}{Visualisation}{subsection.1.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Support Vector Machines}{3}{subsection.1.2.3}\protected@file@percent }
\newlabel{sec:background-svm}{{2.3}{3}{Support Vector Machines}{subsection.1.2.3}{}}
\citation{koppen2000curse}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  SVM kernels shapes are shown. Specifically, linear, polynomial, radial basis function (rbf) and sigmoidal kernal are shown.\relax }}{4}{figure.caption.3}\protected@file@percent }
\newlabel{fig:kernels}{{2}{4}{SVM kernels shapes are shown. Specifically, linear, polynomial, radial basis function (rbf) and sigmoidal kernal are shown.\relax }{figure.caption.3}{}}
\newlabel{eq:hyperplane}{{1}{4}{Support Vector Machines}{equation.1.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Feature Selection}{4}{subsection.1.2.4}\protected@file@percent }
\newlabel{sec:background-feature-selection}{{2.4}{4}{Feature Selection}{subsection.1.2.4}{}}
\citation{fix1989discriminatory}
\citation{ho1995random}
\citation{hand2001idiot}
\citation{loh2011classification}
\citation{cortes1995support}
\newlabel{fig:fish-hyperplane-coeffcients}{{3a}{5}{Fish Species: Hyperplane Coefficients\relax }{figure.caption.4}{}}
\newlabel{sub@fig:fish-hyperplane-coeffcients}{{a}{5}{Fish Species: Hyperplane Coefficients\relax }{figure.caption.4}{}}
\newlabel{fig:part-hyperplane-coeffcients}{{3b}{5}{Fish Part: Hyperplane Coefficients\relax }{figure.caption.4}{}}
\newlabel{sub@fig:part-hyperplane-coeffcients}{{b}{5}{Fish Part: Hyperplane Coefficients\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Two numerical solutions}}{5}{figure.caption.4}\protected@file@percent }
\newlabel{fig:hyperplane-coefficients}{{3}{5}{Two numerical solutions}{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Data processing}{5}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Classification}{5}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Classification Algorithms}{5}{subsection.1.4.1}\protected@file@percent }
\citation{sklearn2021feature}
\citation{cortes1995support}
\citation{scholkopf2000new}
\citation{sklearn2021feature}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Accuracy for different classification techniques. Accuracy is given as the stratified k-fold cross validation over 30 independent runs. \relax }}{6}{table.caption.5}\protected@file@percent }
\newlabel{t:classification}{{1}{6}{Accuracy for different classification techniques. Accuracy is given as the stratified k-fold cross validation over 30 independent runs. \relax }{table.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}SVM Model}{6}{subsection.1.4.2}\protected@file@percent }
\newlabel{sec:results-classification-svm}{{4.2}{6}{SVM Model}{subsection.1.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}SVM Kernel}{6}{subsection.1.4.3}\protected@file@percent }
\newlabel{sec:results-classification-svm-kernel}{{4.3}{6}{SVM Kernel}{subsection.1.4.3}{}}
\citation{aizerman1964theoretical}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces  Accuracy for different SVM models. Accuracy is given as the stratified k-fold cross validation over 30 independent runs. We compare Support-Vector Classification (SVC), Nu-Support Vector Classification (Nu-SVC) and Linear Support-Vector Classification (LSVC).\relax }}{7}{table.caption.6}\protected@file@percent }
\newlabel{t:svm-models}{{2}{7}{Accuracy for different SVM models. Accuracy is given as the stratified k-fold cross validation over 30 independent runs. We compare Support-Vector Classification (SVC), Nu-Support Vector Classification (Nu-SVC) and Linear Support-Vector Classification (LSVC).\relax }{table.caption.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces  Accuracy for different SVM kernals. Accuracy is given as the stratified k-fold cross validation over 30 independent runs. We compare polynomial (poly), radial basis function (rbf), sigmoidal (sigmoid) and linear.\relax }}{7}{table.caption.7}\protected@file@percent }
\newlabel{t:svm-kernels}{{3}{7}{Accuracy for different SVM kernals. Accuracy is given as the stratified k-fold cross validation over 30 independent runs. We compare polynomial (poly), radial basis function (rbf), sigmoidal (sigmoid) and linear.\relax }{table.caption.7}{}}
\citation{sklearn2021feature}
\citation{robnik2003theoretical}
\citation{chappers2015skfeature}
\citation{liu1995chi2}
\citation{ding2005minimum}
\citation{robnik2003theoretical}
\citation{kennedy1995particle,kennedy1997discrete}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Discussion}{8}{subsection.1.4.4}\protected@file@percent }
\newlabel{sec:results-classification-discussion}{{4.4}{8}{Discussion}{subsection.1.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Feature Selection}{8}{section.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Classification Accuracy $k = 500$}{8}{subsection.1.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Classification Accuracy (all $k$)}{8}{subsection.1.5.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces  Accuracy for different feature selection methods. Accuracy is given as the stratified k-fold cross validation over 30 independent runs. We compare chi$^2$ (chi), maximum relevance - minimum redundancy (MRMR), reliefF, particle swarm optimisation (PSO).\relax }}{9}{table.caption.8}\protected@file@percent }
\newlabel{t:feature-selection}{{4}{9}{Accuracy for different feature selection methods. Accuracy is given as the stratified k-fold cross validation over 30 independent runs. We compare chi$^2$ (chi), maximum relevance - minimum redundancy (MRMR), reliefF, particle swarm optimisation (PSO).\relax }{table.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Disucssion}{9}{subsection.1.5.3}\protected@file@percent }
\newlabel{sec:results-feature-selection-discussion}{{5.3}{9}{Disucssion}{subsection.1.5.3}{}}
\newlabel{fig:accuracy-features-fish-train}{{4a}{10}{Species: Training set\relax }{figure.caption.9}{}}
\newlabel{sub@fig:accuracy-features-fish-train}{{a}{10}{Species: Training set\relax }{figure.caption.9}{}}
\newlabel{fig:accuracy-features-fish-test}{{4b}{10}{Species: Test set\relax }{figure.caption.9}{}}
\newlabel{sub@fig:accuracy-features-fish-test}{{b}{10}{Species: Test set\relax }{figure.caption.9}{}}
\newlabel{fig:accuracy-features-part-train}{{4c}{10}{Part: Training set\relax }{figure.caption.9}{}}
\newlabel{sub@fig:accuracy-features-part-train}{{c}{10}{Part: Training set\relax }{figure.caption.9}{}}
\newlabel{fig:accuracy-features-part-test}{{4d}{10}{Part: Test set\relax }{figure.caption.9}{}}
\newlabel{sub@fig:accuracy-features-part-test}{{d}{10}{Part: Test set\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Two numerical solutions}}{10}{figure.caption.9}\protected@file@percent }
\newlabel{fig:animals}{{4}{10}{Two numerical solutions}{figure.caption.9}{}}
\bibstyle{splncs04}
\bibdata{refs}
\bibcite{khan2013gas}{1}
\bibcite{aizerman1964theoretical}{2}
\bibcite{boser1992training}{3}
\bibcite{chappers2015skfeature}{4}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions and Future Work}{11}{section.1.6}\protected@file@percent }
\bibcite{cortes1995support}{5}
\bibcite{ding2005minimum}{6}
\bibcite{eder1995gas}{7}
\bibcite{fix1989discriminatory}{8}
\bibcite{hand2001idiot}{9}
\bibcite{ho1995random}{10}
\bibcite{kennedy1995particle}{11}
\bibcite{kennedy1997discrete}{12}
\bibcite{koppen2000curse}{13}
\bibcite{liu1995chi2}{14}
\bibcite{loh2011classification}{15}
\bibcite{musk2020battery}{16}
\bibcite{restek2018high}{17}
\bibcite{robnik2003theoretical}{18}
\bibcite{scholkopf2000new}{19}
\bibcite{sklearn2021feature}{20}
\gdef \@abspage@last{12}
