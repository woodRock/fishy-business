\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{eder1995gas}
\citation{restek2018high}
\citation{bi2020gc,matyushin2020gas}
\@writefile{toc}{\contentsline {title}{Machine Learning for Fish Oil Analysis \unskip {}}{1}{chapter.1}\protected@file@percent }
\@writefile{toc}{\authcount {5}}
\@writefile{toc}{\contentsline {author}{Jesse Wood \and Bach Hoai Nguyen \and Bing Xue \and Mengjie Zhang \and Daniel Killeen }{1}{chapter.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1.1}\protected@file@percent }
\citation{eder1995gas,restek2018high,khan2013gas}
\citation{restek2018high}
\citation{restek2018high}
\citation{khan2013gas}
\citation{restek2018high}
\citation{eder1995gas,restek2018high}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{2}{section.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Gas Chromatorgraphy}{2}{subsection.1.2.1}\protected@file@percent }
\citation{musk2020battery}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Gas chromatograph: the artifact of the GC method \cite  {restek2018high}. The detection is used to visualize intensity (y) and time (x) on a chromotrogaph.\relax }}{3}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:gas-chromatography}{{1}{3}{Gas chromatograph: the artifact of the GC method \cite {restek2018high}. The detection is used to visualize intensity (y) and time (x) on a chromotrogaph.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Classification Algorithms}{3}{subsection.1.2.2}\protected@file@percent }
\citation{cortes1995support}
\citation{sklearn2021feature}
\citation{sklearn2021feature}
\citation{scholkopf2000new}
\citation{aizerman1964theoretical}
\citation{boser1992training}
\newlabel{sec:background-svm}{{2.2}{4}{Support Vector Machines}{section*.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Support Vector Machines}{4}{section*.3}\protected@file@percent }
\newlabel{sec:background-svm-model}{{2.2}{4}{Model}{section*.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Model}{4}{section*.4}\protected@file@percent }
\newlabel{sec:background-svm-kernel}{{2.2}{4}{Kernel}{section*.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Kernel}{4}{section*.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  SVM kernels shapes are shown. Specifically, linear, polynomial, radial basis function (rbf) and sigmoidal kernal are shown.\relax }}{4}{figure.caption.6}\protected@file@percent }
\newlabel{fig:kernels}{{2}{4}{SVM kernels shapes are shown. Specifically, linear, polynomial, radial basis function (rbf) and sigmoidal kernal are shown.\relax }{figure.caption.6}{}}
\citation{koppen2000curse}
\newlabel{sec:background-svm-hyperplane}{{2.2}{5}{Hyperplane Coefficients}{section*.7}{}}
\@writefile{toc}{\contentsline {paragraph}{Hyperplane Coefficients}{5}{section*.7}\protected@file@percent }
\newlabel{eq:hyperplane}{{1}{5}{Hyperplane Coefficients}{equation.1.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Feature Selection}{5}{subsection.1.2.3}\protected@file@percent }
\newlabel{sec:background-feature-selection}{{2.3}{5}{Feature Selection}{subsection.1.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Visualisation}{5}{subsection.1.2.4}\protected@file@percent }
\newlabel{sec:background-visualisation}{{2.4}{5}{Visualisation}{subsection.1.2.4}{}}
\citation{fix1989discriminatory}
\citation{ho1995random}
\citation{hand2001idiot}
\citation{loh2011classification}
\citation{cortes1995support}
\citation{sklearn2021feature}
\@writefile{toc}{\contentsline {section}{\numberline {3}Data processing}{6}{section.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Classification Algorithms}{6}{section.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Ensemble}{6}{subsection.1.4.1}\protected@file@percent }
\citation{cortes1995support}
\citation{scholkopf2000new}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Accuracy for different classification techniques. Accuracy is given as the stratified k-fold cross validation over 30 independent runs. We compare K-nearest neighbours (KNN), random forest (RF), decision tree (DT), naive bayes (NB) and support vector machines (SVM).\relax }}{7}{table.caption.9}\protected@file@percent }
\newlabel{t:classification}{{1}{7}{Accuracy for different classification techniques. Accuracy is given as the stratified k-fold cross validation over 30 independent runs. We compare K-nearest neighbours (KNN), random forest (RF), decision tree (DT), naive bayes (NB) and support vector machines (SVM).\relax }{table.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}SVM Model}{7}{subsection.1.4.2}\protected@file@percent }
\newlabel{sec:results-classification-svm}{{4.2}{7}{SVM Model}{subsection.1.4.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces  Accuracy for different SVM models. Accuracy is given as the stratified k-fold cross validation over 30 independent runs. We compare Support-Vector Classification (SVC), Nu-Support Vector Classification (Nu-SVC) and Linear Support-Vector Classification (LSVC).\relax }}{7}{table.caption.10}\protected@file@percent }
\newlabel{t:svm-models}{{2}{7}{Accuracy for different SVM models. Accuracy is given as the stratified k-fold cross validation over 30 independent runs. We compare Support-Vector Classification (SVC), Nu-Support Vector Classification (Nu-SVC) and Linear Support-Vector Classification (LSVC).\relax }{table.caption.10}{}}
\citation{sklearn2021feature}
\citation{aizerman1964theoretical}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}SVM Kernel}{8}{subsection.1.4.3}\protected@file@percent }
\newlabel{sec:results-classification-svm-kernel}{{4.3}{8}{SVM Kernel}{subsection.1.4.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces  Accuracy for different SVM kernals. Accuracy is given as the stratified k-fold cross validation over 30 independent runs. We compare polynomial (poly), radial basis function (rbf), sigmoidal (sigmoid) and linear.\relax }}{8}{table.caption.11}\protected@file@percent }
\newlabel{t:svm-kernels}{{3}{8}{Accuracy for different SVM kernals. Accuracy is given as the stratified k-fold cross validation over 30 independent runs. We compare polynomial (poly), radial basis function (rbf), sigmoidal (sigmoid) and linear.\relax }{table.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Discussion}{8}{subsection.1.4.4}\protected@file@percent }
\newlabel{sec:results-classification-discussion}{{4.4}{8}{Discussion}{subsection.1.4.4}{}}
\citation{sklearn2021feature}
\citation{robnik2003theoretical}
\citation{chappers2015skfeature}
\citation{liu1995chi2}
\citation{ding2005minimum}
\citation{robnik2003theoretical}
\citation{kennedy1995particle,kennedy1997discrete}
\@writefile{toc}{\contentsline {section}{\numberline {5}Feature Selection}{9}{section.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Classification Accuracy $k = 500$}{9}{subsection.1.5.1}\protected@file@percent }
\citation{aizerman1964theoretical}
\citation{ding2005minimum}
\citation{kennedy1995particle,kennedy1997discrete}
\citation{liu1995chi2}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces  Accuracy for different feature selection methods. Accuracy is given as the stratified k-fold cross validation over 30 independent runs. We compare chi$^2$ (chi), maximum relevance - minimum redundancy (MRMR), reliefF, particle swarm optimisation (PSO).\relax }}{10}{table.caption.12}\protected@file@percent }
\newlabel{t:feature-selection}{{4}{10}{Accuracy for different feature selection methods. Accuracy is given as the stratified k-fold cross validation over 30 independent runs. We compare chi$^2$ (chi), maximum relevance - minimum redundancy (MRMR), reliefF, particle swarm optimisation (PSO).\relax }{table.caption.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Classification Accuracy (all $k$)}{10}{subsection.1.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Disucssion}{11}{subsection.1.5.3}\protected@file@percent }
\newlabel{sec:results-feature-selection-discussion}{{5.3}{11}{Disucssion}{subsection.1.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Visualisation}{11}{subsection.1.5.4}\protected@file@percent }
\newlabel{sec:results-visualisation}{{5.4}{11}{Visualisation}{subsection.1.5.4}{}}
\citation{kennedy1995particle,kennedy1997discrete}
\citation{aizerman1964theoretical}
\citation{ding2005minimum}
\citation{liu1995chi2}
\citation{wood2021classification,wood2021feature}
\@writefile{toc}{\contentsline {subsubsection}{Experimental Setup}{12}{section*.15}\protected@file@percent }
\newlabel{sec:results-visualisation-feature-rankings-50}{{5.4}{12}{Feature Rankings (k=50)}{section*.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{Feature Rankings (k=50)}{12}{section*.16}\protected@file@percent }
\newlabel{sec:results-visualisation-overlap-mrmr-reliefF}{{5.4}{12}{Overlap: MRMR $\cap $ ReliefF}{section*.19}{}}
\@writefile{toc}{\contentsline {subsubsection}{Overlap: MRMR $\cap $ ReliefF}{12}{section*.19}\protected@file@percent }
\citation{wood2021feature}
\citation{wood2021classification, wood2021feature}
\citation{wood2021classification, wood2021feature}
\newlabel{sec:results-visualisation-accuracy-overlap-mrmr-reliefF}{{5.4}{13}{Accuracy: Overlap, MRMR, ReliefF}{section*.21}{}}
\@writefile{toc}{\contentsline {subsubsection}{Accuracy: Overlap, MRMR, ReliefF}{13}{section*.21}\protected@file@percent }
\newlabel{sec:results-visualisation-overlap-fs-hyperplane}{{5.4}{13}{Overlap: FS Method $\cap $ Hyperplane Coefficients}{section*.24}{}}
\@writefile{toc}{\contentsline {subsubsection}{Overlap: FS Method $\cap $ Hyperplane Coefficients}{13}{section*.24}\protected@file@percent }
\citation{clarke2013profiles}
\bibstyle{splncs04}
\bibdata{refs}
\newlabel{sec:visualisation-discussion}{{5.4}{14}{Discussion}{section*.26}{}}
\@writefile{toc}{\contentsline {subsubsection}{Discussion}{14}{section*.26}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions and Future Work}{14}{section.1.6}\protected@file@percent }
\newlabel{fig:fish-hyperplane-coeffcients}{{3a}{15}{Fish Species Hyperplane Coefficients\relax }{figure.caption.8}{}}
\newlabel{sub@fig:fish-hyperplane-coeffcients}{{a}{15}{Fish Species Hyperplane Coefficients\relax }{figure.caption.8}{}}
\newlabel{fig:part-hyperplane-coeffcients}{{3b}{15}{Fish Part Hyperplane Coefficients\relax }{figure.caption.8}{}}
\newlabel{sub@fig:part-hyperplane-coeffcients}{{b}{15}{Fish Part Hyperplane Coefficients\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Two numerical solutions}}{15}{figure.caption.8}\protected@file@percent }
\newlabel{fig:hyperplane-coefficients}{{3}{15}{Two numerical solutions}{figure.caption.8}{}}
\newlabel{fig:accuracy-features-fish-train}{{4a}{16}{Training set\relax }{figure.caption.13}{}}
\newlabel{sub@fig:accuracy-features-fish-train}{{a}{16}{Training set\relax }{figure.caption.13}{}}
\newlabel{fig:accuracy-features-fish-test}{{4b}{16}{Test set\relax }{figure.caption.13}{}}
\newlabel{sub@fig:accuracy-features-fish-test}{{b}{16}{Test set\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Two numerical solutions}}{16}{figure.caption.13}\protected@file@percent }
\newlabel{fig:accuracy-features-part-train}{{5a}{17}{Training set\relax }{figure.caption.14}{}}
\newlabel{sub@fig:accuracy-features-part-train}{{a}{17}{Training set\relax }{figure.caption.14}{}}
\newlabel{fig:accuracy-features-part-test}{{5b}{17}{Test set\relax }{figure.caption.14}{}}
\newlabel{sub@fig:accuracy-features-part-test}{{b}{17}{Test set\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Two numerical solutions}}{17}{figure.caption.14}\protected@file@percent }
\newlabel{fig:fish-rankings-reliefF}{{6a}{18}{reliefF\relax }{figure.caption.17}{}}
\newlabel{sub@fig:fish-rankings-reliefF}{{a}{18}{reliefF\relax }{figure.caption.17}{}}
\newlabel{fig:fish-rankings-mrmr}{{6b}{18}{Maximum Relevance — Minimum Redundancy (MRMR)\relax }{figure.caption.17}{}}
\newlabel{sub@fig:fish-rankings-mrmr}{{b}{18}{Maximum Relevance — Minimum Redundancy (MRMR)\relax }{figure.caption.17}{}}
\newlabel{fig:fish-rankings-chi2}{{6c}{18}{chi$^2$\relax }{figure.caption.17}{}}
\newlabel{sub@fig:fish-rankings-chi2}{{c}{18}{chi$^2$\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Two numerical solutions}}{18}{figure.caption.17}\protected@file@percent }
\newlabel{fig:part-rankings-reliefF}{{7a}{19}{reliefF\relax }{figure.caption.18}{}}
\newlabel{sub@fig:part-rankings-reliefF}{{a}{19}{reliefF\relax }{figure.caption.18}{}}
\newlabel{fig:part-rankings-mrmr}{{7b}{19}{Maximum Relevance — Minimum Redundancy (MRMR)\relax }{figure.caption.18}{}}
\newlabel{sub@fig:part-rankings-mrmr}{{b}{19}{Maximum Relevance — Minimum Redundancy (MRMR)\relax }{figure.caption.18}{}}
\newlabel{fig:part-rankings-chi2}{{7c}{19}{chi$^2$\relax }{figure.caption.18}{}}
\newlabel{sub@fig:part-rankings-chi2}{{c}{19}{chi$^2$\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Two numerical solutions}}{19}{figure.caption.18}\protected@file@percent }
\newlabel{fig:fish-k-overlap}{{8a}{20}{Fish species dataset\relax }{figure.caption.20}{}}
\newlabel{sub@fig:fish-k-overlap}{{a}{20}{Fish species dataset\relax }{figure.caption.20}{}}
\newlabel{fig:part-k-overlap}{{8b}{20}{Fish part dataset\relax }{figure.caption.20}{}}
\newlabel{sub@fig:part-k-overlap}{{b}{20}{Fish part dataset\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Two numerical solutions}}{20}{figure.caption.20}\protected@file@percent }
\newlabel{fig:fs-overlap}{{8}{20}{Two numerical solutions}{figure.caption.20}{}}
\newlabel{fig:fish-k-accuracy-train}{{9a}{21}{Training set\relax }{figure.caption.22}{}}
\newlabel{sub@fig:fish-k-accuracy-train}{{a}{21}{Training set\relax }{figure.caption.22}{}}
\newlabel{fig:fish-k-accuracy-test}{{9b}{21}{Test set\relax }{figure.caption.22}{}}
\newlabel{sub@fig:fish-k-accuracy-test}{{b}{21}{Test set\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Two numerical solutions}}{21}{figure.caption.22}\protected@file@percent }
\newlabel{fig:part-k-accuracy-train}{{10a}{22}{Train set\relax }{figure.caption.23}{}}
\newlabel{sub@fig:part-k-accuracy-train}{{a}{22}{Train set\relax }{figure.caption.23}{}}
\newlabel{fig:part-k-accuracy-test}{{10b}{22}{Test set\relax }{figure.caption.23}{}}
\newlabel{sub@fig:part-k-accuracy-test}{{b}{22}{Test set\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Two numerical solutions}}{22}{figure.caption.23}\protected@file@percent }
\newlabel{fig:fish-hyperplane-overlap}{{11a}{23}{Fish species dataset\relax }{figure.caption.25}{}}
\newlabel{sub@fig:fish-hyperplane-overlap}{{a}{23}{Fish species dataset\relax }{figure.caption.25}{}}
\newlabel{fig:part-hyperplane-overlap}{{11b}{23}{Fish part dataset\relax }{figure.caption.25}{}}
\newlabel{sub@fig:part-hyperplane-overlap}{{b}{23}{Fish part dataset\relax }{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Two numerical solutions}}{23}{figure.caption.25}\protected@file@percent }
\newlabel{hyperplane-overlap}{{11}{23}{Two numerical solutions}{figure.caption.25}{}}
\gdef \@abspage@last{23}
