% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}

% Packages 
\usepackage{graphicx} % Add assets folder to path for images. 
\graphicspath{{assets/}}
\usepackage{amsmath,amssymb,float,url} % Hide red underlines for URLs. 
\usepackage[hidelinks]{hyperref} % Stack two figures on top of each other.
\usepackage{subcaption} % Make caption text font smaller.
\usepackage{caption}
\captionsetup[figure]{font=small,labelfont=small}
% Make table-caption gap larger (source: https://bit.ly/3zm0wRn)
\captionsetup[table]{skip=10pt}

\usepackage[normalem]{ulem} % Add strikethrough text.

% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{Repsonse Letter}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
% \author{Jesse Wood\inst{1}\orcidID{0000-0003-3756-2122} \and
%   Bach Hoai Nguyen\inst{1}\orcidID{1111-2222-3333-4444} \and
%   Bing Xue\inst{1}\orcidID{2222--3333-4444-5555} \and 
%   Mengjie Zhang\inst{1}\orcidID{2222--3333-4444-5555} \and 
%   Daniel Killeen\inst{2}\orcidID{2222--3333-4444-5555}
% }
% %
% \authorrunning{J. Wood, B. Nguyen, et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
% \institute{Victoria University of Wellington, Te Herenge Waka, PO Box 600, Wellington 6140, New Zealand\\
%   \email{ \{jesse.wood, bach.nguyen, bing.xue, mengjie.zhang\}@ecs.vuw.ac.nz}\\
%   \and 
%   Plant and Food Research, Port Nelson, Nelson 7010, New Zealand\\
%   \email{daniel.killeen@plantandfood.co.nz}\\
% }

%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
  % The abstract should briefly summarize the contents of the paper in
  % 150--250 words.
    
  \keywords{

  }
\end{abstract}

\section{Review I}

\textbf{SCORE:} SCORE: 1 (weak accept)
\\\\
The first reviewer had these general comments for the paper. 

\begin{quote}
  This paper automates processing of raw Gas Chromatography data to classify biomass that include fish species and fish body parts. First, this paper proposes a preprocessing imputation method to align timestamps in the training data. Then, it uses various machine learning methods to develop models for the classification tasks. Experimental results show that the SVM approach performs the best, however, visitation shows not all the features are needed. So this paper also uses four existing feature selection methods.

  This paper is well-written and easy to read. It explains the motivations behind the work and explain why a machine learning method is needed. The reason is the manual approach needs human experts and is expensive and time-consuming. This paper is mainly about using existing machine learning algorithms in an application. The experimental setup for both classification and then feature selection is good. The experimental results are good as well.
\end{quote}

\subsection{Literature Review}

Their review raised there specific issues about the paper. The first regarding a missing literature review containing related work. 

\begin{quote}
  What I found missing is a literature review on the problem or similar problem. If this is the first of such work, the authors could explicitly claim that. Otherwise, discuss existing methods and perhaps compare with those as well.
\end{quote}

\subsection{Imputation Contribution}

The second issue was including the imputation as a contribution for the a paper. 

\begin{quote}
  Although data imputation is an important part in the pipeline, however just 0 filling, while that makes sense, is not really a contribution. The time alignment in the data appears to be trivial as well,
\end{quote}

\subsection{Figure Formatting}

The third was formating, the figures need to be larger and easier to read, the camera-ready instructions for the conference specify at least a dpi of 800.

\begin{quote}
  This figures need to be larger and visible.
\end{quote} 

\section{Reivew II}

\textbf{SCORE:} -1 (weak reject)
\\\\
The second reviewer gave the paper these general comments. 

\begin{quote}
  This paper provides an interesting application of ML for fish classification using fatty acid Chromatographic data. It proposes a pre-processing imputation method for aligning timestamps in Gas Chromatography data, it demonstrates SVM could classify compositionally diverse marine biomass based on raw chromatographic fatty acid data, which can highlight important features for classification, and it also demonstrates that feature selection reduces dimensionality and improves classification performance by accelerating the classification system by four times.
\end{quote}

\subsection{Preprocessing Experimental Results}

The reviewer had two specific issues with the paper. 
The first was the motivation and reserach problem were not clear, with a particular focus on the lack of experimental results in our preprocessing section. 

\begin{quote}
  However, the motivation and research problem is not clear; 
  for example, you need to demonstrate your pre-processing works using experimental results. 
\end{quote}

\subsection{Contributions}

The felt as if the paper contribution was not enough, our experiments should evaluate a new method and benchmark it against the existing results. 

\begin{quote}
  Also, no innovative techniques have been developed, so the contribution is not enough; you should provide a new method to compare with the methods in Tables 3 and 4.
\end{quote}

\section{Review III}

\textbf{SCORE:} SCORE: 0 (borderline paper)
\\\\
The third reviewer had two questions regarding my paper. 

The first issue mentioned the SVM uses a non-linear kernal, so the hyperplane coefficients have no relation to input features. This would make the analysis and claim on an interpretable model in section 4.3 invalid. 

\begin{quote}
  Page 6: "The hyperplane is represented by a weight vector in which each weight is associated with a feature. The larger the weight, the more important the corresponding feature. After an SVM classification algorithm is trained on the training set, an SVM classifier containing a learned weight vector is obtained. This section analyses the learned weight vector to examine the contribution of each packet/feature."

  SVMs implement kernel methods to transform original data items into a high dimensional feature space where the input samples become linearly or mostly linearly separable. SVMs can learn the hyperplane in the feature space, which separates the training data with the widest margin.

  The hyperplane is constructed in the feature space that is nonlinearly related to input space. The weight vector representing the hyperplane in the feature space wouldn't match the features of original data items in input space neither in dimensions nor in physical significance. The hyperplane, when being mapped to input space, becomes irregular contours outlined by support vectors. The important features (with larger weight) in feature space can hardly have their corresponding features in input space.

  How to use weight vector of the hyperplane in feature space to examine the contribution of each packet/feature in input space?
\end{quote}

(Usually) a conventional SVM uses a non-linear kernel, and the sklearn library defaults to the radial basis function (RBF) \cite{sklearn2021feature}. 
However, the paper states a Linear SVM model is used,

\begin{enumerate}
  \item  Experiments find that kernel-based classifiers, particularly \emph{linear SVM}, achieve high classification accuracy on the fish data [...]
  \item These experiments compare five well-known classifications: K Nearest Neighbours (KNN where K is set to 3), Naive Bayes (NB), Random Forest (RF), Decision Trees (DT), and \emph{Linear Support Vector Machines} (SVM) [...]
  \item In this work, a \emph{linear SVM} is used as the wrapped classification algorithm since it achieves good classification performance [...]
  \item For each method, the balanced classification accuracy is measured with a \emph{linear SVM} classification algorithm \cite{sklearn2021feature} [...]
  \item Among the considered classification algorithms, \emph{linear SVM} achieves the best classification performance since it is suited to high-dimensional problems [...]
\end{enumerate}

A linear kernel performs a linear transformation, which preserves the distance between points, mapping each instance to a 4800-dimensional vector in the feature space, then creates a hyperplane to linearly separate the classes in that feature space.

\subsection{Time Complexity}

Their second asks if for the time complexity of the classifer would speed up linearly with the number of features. 

\begin{quote}
  Page 9: Meanwhile, PSO can remove 75\% features, which means the classification system can be four times faster given the number of required packets/features is reduced by four times.

  Considering the dimension of features of input data, does the classification speed linearly vary with the reduction amount of features?
\end{quote}

Again, the reviewer has assumed the SVM used a non-linear kernal, in which case the complexity for non-linear SVM is expected to be $O(|\mathbb{X}|^2)$, where $|\mathbb{X}|$ is the number of training instances \cite{chang2011libsvm}. On page 9 the paper claims a linear speed up inversely proportional to the feature reduction, 

\begin{quote}
  Meanwhile, PSO can remove 75\% features, which means the classification system can be four times faster given the number of required packets/features is reduced by four times. 
\end{quote}

The paper uses SVM with linear kernal, with time complexity $O(|\mathbb{X}| \times f_n)$, where $f_n$ is the number of features. Therefore a 75\% feature reduction would speed up the classification by a factor of 4. 

\bibliographystyle{splncs04}
% \bibliography{mybibliography}
\bibliography{refs}

\end{document}
